<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="rus">
<DOC id="L0C04958T" lang="rus" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="5868" raw_text_md5="a7b9e5c6b25d0c5962f7d0ce7c1a36a8">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="55">
<ORIGINAL_TEXT>Wuhan Lab Denies Any Link to First Coronavirus Outbreak</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="5">Wuhan</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="7" end_char="9">Lab</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="11" end_char="16">Denies</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="18" end_char="20">Any</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="22" end_char="25">Link</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="27" end_char="28">to</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="30" end_char="34">First</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="36" end_char="46">Coronavirus</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="48" end_char="55">Outbreak</TOKEN>
</SEG>
<SEG id="segment-1" start_char="60" end_char="94">
<ORIGINAL_TEXT>Global Virus Cases Near 2.4 Million</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="60" end_char="65">Global</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="67" end_char="71">Virus</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="73" end_char="77">Cases</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="79" end_char="82">Near</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="84" end_char="86">2.4</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="88" end_char="94">Million</TOKEN>
</SEG>
<SEG id="segment-2" start_char="97" end_char="343">
<ORIGINAL_TEXT>A top Wuhan laboratory official has denied any role in spreading the new coronavirus, in the most high profile response from a facility at the center of months of speculation about how the previously unknown animal disease made the leap to humans.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="97" end_char="97">A</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="99" end_char="101">top</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="103" end_char="107">Wuhan</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="109" end_char="118">laboratory</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="120" end_char="127">official</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="129" end_char="131">has</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="133" end_char="138">denied</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="140" end_char="142">any</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="144" end_char="147">role</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="149" end_char="150">in</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="152" end_char="160">spreading</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="162" end_char="164">the</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="166" end_char="168">new</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="170" end_char="180">coronavirus</TOKEN>
<TOKEN id="token-2-14" pos="punct" morph="none" start_char="181" end_char="181">,</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="183" end_char="184">in</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="186" end_char="188">the</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="190" end_char="193">most</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="195" end_char="198">high</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="200" end_char="206">profile</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="208" end_char="215">response</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="217" end_char="220">from</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="222" end_char="222">a</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="224" end_char="231">facility</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="233" end_char="234">at</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="236" end_char="238">the</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="240" end_char="245">center</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="247" end_char="248">of</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="250" end_char="255">months</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="257" end_char="258">of</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="260" end_char="270">speculation</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="272" end_char="276">about</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="278" end_char="280">how</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="282" end_char="284">the</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="286" end_char="295">previously</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="297" end_char="303">unknown</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="305" end_char="310">animal</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="312" end_char="318">disease</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="320" end_char="323">made</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="325" end_char="327">the</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="329" end_char="332">leap</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="334" end_char="335">to</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="337" end_char="342">humans</TOKEN>
<TOKEN id="token-2-43" pos="punct" morph="none" start_char="343" end_char="343">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="346" end_char="546">
<ORIGINAL_TEXT>Yuan Zhiming, director of the Wuhan National Biosafety Laboratory, hit back at those promoting theories that the virus had escaped from the facility and caused the outbreak in the central Chinese city.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="346" end_char="349">Yuan</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="351" end_char="357">Zhiming</TOKEN>
<TOKEN id="token-3-2" pos="punct" morph="none" start_char="358" end_char="358">,</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="360" end_char="367">director</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="369" end_char="370">of</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="372" end_char="374">the</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="376" end_char="380">Wuhan</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="382" end_char="389">National</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="391" end_char="399">Biosafety</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="401" end_char="410">Laboratory</TOKEN>
<TOKEN id="token-3-10" pos="punct" morph="none" start_char="411" end_char="411">,</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="413" end_char="415">hit</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="417" end_char="420">back</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="422" end_char="423">at</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="425" end_char="429">those</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="431" end_char="439">promoting</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="441" end_char="448">theories</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="450" end_char="453">that</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="455" end_char="457">the</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="459" end_char="463">virus</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="465" end_char="467">had</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="469" end_char="475">escaped</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="477" end_char="480">from</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="482" end_char="484">the</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="486" end_char="493">facility</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="495" end_char="497">and</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="499" end_char="504">caused</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="506" end_char="508">the</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="510" end_char="517">outbreak</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="519" end_char="520">in</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="522" end_char="524">the</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="526" end_char="532">central</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="534" end_char="540">Chinese</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="542" end_char="545">city</TOKEN>
<TOKEN id="token-3-34" pos="punct" morph="none" start_char="546" end_char="546">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="548" end_char="708">
<ORIGINAL_TEXT>"There is absolutely no way that the virus originated from our institute," Yuan said in an interview Saturday with the state-run China Global Television Network.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="548" end_char="548">"</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="549" end_char="553">There</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="555" end_char="556">is</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="558" end_char="567">absolutely</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="569" end_char="570">no</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="572" end_char="574">way</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="576" end_char="579">that</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="581" end_char="583">the</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="585" end_char="589">virus</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="591" end_char="600">originated</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="602" end_char="605">from</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="607" end_char="609">our</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="611" end_char="619">institute</TOKEN>
<TOKEN id="token-4-13" pos="punct" morph="none" start_char="620" end_char="621">,"</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="623" end_char="626">Yuan</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="628" end_char="631">said</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="633" end_char="634">in</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="636" end_char="637">an</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="639" end_char="647">interview</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="649" end_char="656">Saturday</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="658" end_char="661">with</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="663" end_char="665">the</TOKEN>
<TOKEN id="token-4-22" pos="unknown" morph="none" start_char="667" end_char="675">state-run</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="677" end_char="681">China</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="683" end_char="688">Global</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="690" end_char="699">Television</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="701" end_char="707">Network</TOKEN>
<TOKEN id="token-4-27" pos="punct" morph="none" start_char="708" end_char="708">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="711" end_char="911">
<ORIGINAL_TEXT>Yuan rejected theories that the yet-to-be identified "Patient Zero" for Covid-19 had contact with the institute, saying none of its employees, retirees or student researchers were known to be infected.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="711" end_char="714">Yuan</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="716" end_char="723">rejected</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="725" end_char="732">theories</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="734" end_char="737">that</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="739" end_char="741">the</TOKEN>
<TOKEN id="token-5-5" pos="unknown" morph="none" start_char="743" end_char="751">yet-to-be</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="753" end_char="762">identified</TOKEN>
<TOKEN id="token-5-7" pos="punct" morph="none" start_char="764" end_char="764">"</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="765" end_char="771">Patient</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="773" end_char="776">Zero</TOKEN>
<TOKEN id="token-5-10" pos="punct" morph="none" start_char="777" end_char="777">"</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="779" end_char="781">for</TOKEN>
<TOKEN id="token-5-12" pos="unknown" morph="none" start_char="783" end_char="790">Covid-19</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="792" end_char="794">had</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="796" end_char="802">contact</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="804" end_char="807">with</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="809" end_char="811">the</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="813" end_char="821">institute</TOKEN>
<TOKEN id="token-5-18" pos="punct" morph="none" start_char="822" end_char="822">,</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="824" end_char="829">saying</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="831" end_char="834">none</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="836" end_char="837">of</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="839" end_char="841">its</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="843" end_char="851">employees</TOKEN>
<TOKEN id="token-5-24" pos="punct" morph="none" start_char="852" end_char="852">,</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="854" end_char="861">retirees</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="863" end_char="864">or</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="866" end_char="872">student</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="874" end_char="884">researchers</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="886" end_char="889">were</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="891" end_char="895">known</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="897" end_char="898">to</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="900" end_char="901">be</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="903" end_char="910">infected</TOKEN>
<TOKEN id="token-5-34" pos="punct" morph="none" start_char="911" end_char="911">.</TOKEN>
</SEG>
<SEG id="segment-6" start_char="913" end_char="924">
<ORIGINAL_TEXT>He said U.S.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="913" end_char="914">He</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="916" end_char="919">said</TOKEN>
<TOKEN id="token-6-2" pos="unknown" morph="none" start_char="921" end_char="923">U.S</TOKEN>
<TOKEN id="token-6-3" pos="punct" morph="none" start_char="924" end_char="924">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="926" end_char="1118">
<ORIGINAL_TEXT>Senator Tom Cotton, an Arkansas Republican, and Washington Post journalists were among those "deliberately leading people" to mistrust the facility and its "P4" top-level-security pathogen lab.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="926" end_char="932">Senator</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="934" end_char="936">Tom</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="938" end_char="943">Cotton</TOKEN>
<TOKEN id="token-7-3" pos="punct" morph="none" start_char="944" end_char="944">,</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="946" end_char="947">an</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="949" end_char="956">Arkansas</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="958" end_char="967">Republican</TOKEN>
<TOKEN id="token-7-7" pos="punct" morph="none" start_char="968" end_char="968">,</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="970" end_char="972">and</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="974" end_char="983">Washington</TOKEN>
<TOKEN id="token-7-10" pos="word" morph="none" start_char="985" end_char="988">Post</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="990" end_char="1000">journalists</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="1002" end_char="1005">were</TOKEN>
<TOKEN id="token-7-13" pos="word" morph="none" start_char="1007" end_char="1011">among</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="1013" end_char="1017">those</TOKEN>
<TOKEN id="token-7-15" pos="punct" morph="none" start_char="1019" end_char="1019">"</TOKEN>
<TOKEN id="token-7-16" pos="word" morph="none" start_char="1020" end_char="1031">deliberately</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="1033" end_char="1039">leading</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="1041" end_char="1046">people</TOKEN>
<TOKEN id="token-7-19" pos="punct" morph="none" start_char="1047" end_char="1047">"</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="1049" end_char="1050">to</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="1052" end_char="1059">mistrust</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="1061" end_char="1063">the</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="1065" end_char="1072">facility</TOKEN>
<TOKEN id="token-7-24" pos="word" morph="none" start_char="1074" end_char="1076">and</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="1078" end_char="1080">its</TOKEN>
<TOKEN id="token-7-26" pos="punct" morph="none" start_char="1082" end_char="1082">"</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="1083" end_char="1084">P4</TOKEN>
<TOKEN id="token-7-28" pos="punct" morph="none" start_char="1085" end_char="1085">"</TOKEN>
<TOKEN id="token-7-29" pos="unknown" morph="none" start_char="1087" end_char="1104">top-level-security</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="1106" end_char="1113">pathogen</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="1115" end_char="1117">lab</TOKEN>
<TOKEN id="token-7-32" pos="punct" morph="none" start_char="1118" end_char="1118">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="1121" end_char="1173">
<ORIGINAL_TEXT>The P4 laboratory at the Wuhan Institute of Virology.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="1121" end_char="1123">The</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="1125" end_char="1126">P4</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="1128" end_char="1137">laboratory</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="1139" end_char="1140">at</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="1142" end_char="1144">the</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="1146" end_char="1150">Wuhan</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="1152" end_char="1160">Institute</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="1162" end_char="1163">of</TOKEN>
<TOKEN id="token-8-8" pos="word" morph="none" start_char="1165" end_char="1172">Virology</TOKEN>
<TOKEN id="token-8-9" pos="punct" morph="none" start_char="1173" end_char="1173">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="1175" end_char="1223">
<ORIGINAL_TEXT>Photographer: Hector Retamal/AFP via Getty Images</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1175" end_char="1186">Photographer</TOKEN>
<TOKEN id="token-9-1" pos="punct" morph="none" start_char="1187" end_char="1187">:</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1189" end_char="1194">Hector</TOKEN>
<TOKEN id="token-9-3" pos="unknown" morph="none" start_char="1196" end_char="1206">Retamal/AFP</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1208" end_char="1210">via</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1212" end_char="1216">Getty</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1218" end_char="1223">Images</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1227" end_char="1440">
<ORIGINAL_TEXT>U.S. President Donald Trump again fanned speculation about the origins of the virus at a Saturday news conference, in which he said China should face consequences if it was "knowingly responsible" for the outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="unknown" morph="none" start_char="1227" end_char="1229">U.S</TOKEN>
<TOKEN id="token-10-1" pos="punct" morph="none" start_char="1230" end_char="1230">.</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1232" end_char="1240">President</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1242" end_char="1247">Donald</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1249" end_char="1253">Trump</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1255" end_char="1259">again</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1261" end_char="1266">fanned</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1268" end_char="1278">speculation</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1280" end_char="1284">about</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1286" end_char="1288">the</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1290" end_char="1296">origins</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1298" end_char="1299">of</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1301" end_char="1303">the</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1305" end_char="1309">virus</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1311" end_char="1312">at</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1314" end_char="1314">a</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1316" end_char="1323">Saturday</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1325" end_char="1328">news</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1330" end_char="1339">conference</TOKEN>
<TOKEN id="token-10-19" pos="punct" morph="none" start_char="1340" end_char="1340">,</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1342" end_char="1343">in</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1345" end_char="1349">which</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1351" end_char="1352">he</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1354" end_char="1357">said</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1359" end_char="1363">China</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="1365" end_char="1370">should</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="1372" end_char="1375">face</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="1377" end_char="1388">consequences</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="1390" end_char="1391">if</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="1393" end_char="1394">it</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="1396" end_char="1398">was</TOKEN>
<TOKEN id="token-10-31" pos="punct" morph="none" start_char="1400" end_char="1400">"</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="1401" end_char="1409">knowingly</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="1411" end_char="1421">responsible</TOKEN>
<TOKEN id="token-10-34" pos="punct" morph="none" start_char="1422" end_char="1422">"</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="1424" end_char="1426">for</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="1428" end_char="1430">the</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="1432" end_char="1439">outbreak</TOKEN>
<TOKEN id="token-10-38" pos="punct" morph="none" start_char="1440" end_char="1440">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1442" end_char="1682">
<ORIGINAL_TEXT>The U.S. president has at times referred to the disease as a "Chinese virus," a term he said he embraced after a Chinese foreign ministry spokesman tweeted an unsubstantiated theory about U.S. Army athletes introducing the pathogen to Wuhan.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1442" end_char="1444">The</TOKEN>
<TOKEN id="token-11-1" pos="unknown" morph="none" start_char="1446" end_char="1448">U.S</TOKEN>
<TOKEN id="token-11-2" pos="punct" morph="none" start_char="1449" end_char="1449">.</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1451" end_char="1459">president</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1461" end_char="1463">has</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1465" end_char="1466">at</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1468" end_char="1472">times</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1474" end_char="1481">referred</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1483" end_char="1484">to</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1486" end_char="1488">the</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1490" end_char="1496">disease</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1498" end_char="1499">as</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1501" end_char="1501">a</TOKEN>
<TOKEN id="token-11-13" pos="punct" morph="none" start_char="1503" end_char="1503">"</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1504" end_char="1510">Chinese</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1512" end_char="1516">virus</TOKEN>
<TOKEN id="token-11-16" pos="punct" morph="none" start_char="1517" end_char="1518">,"</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1520" end_char="1520">a</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="1522" end_char="1525">term</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1527" end_char="1528">he</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1530" end_char="1533">said</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1535" end_char="1536">he</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1538" end_char="1545">embraced</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="1547" end_char="1551">after</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1553" end_char="1553">a</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1555" end_char="1561">Chinese</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1563" end_char="1569">foreign</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1571" end_char="1578">ministry</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1580" end_char="1588">spokesman</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1590" end_char="1596">tweeted</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="1598" end_char="1599">an</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="1601" end_char="1615">unsubstantiated</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="1617" end_char="1622">theory</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="1624" end_char="1628">about</TOKEN>
<TOKEN id="token-11-34" pos="unknown" morph="none" start_char="1630" end_char="1632">U.S</TOKEN>
<TOKEN id="token-11-35" pos="punct" morph="none" start_char="1633" end_char="1633">.</TOKEN>
<TOKEN id="token-11-36" pos="word" morph="none" start_char="1635" end_char="1638">Army</TOKEN>
<TOKEN id="token-11-37" pos="word" morph="none" start_char="1640" end_char="1647">athletes</TOKEN>
<TOKEN id="token-11-38" pos="word" morph="none" start_char="1649" end_char="1659">introducing</TOKEN>
<TOKEN id="token-11-39" pos="word" morph="none" start_char="1661" end_char="1663">the</TOKEN>
<TOKEN id="token-11-40" pos="word" morph="none" start_char="1665" end_char="1672">pathogen</TOKEN>
<TOKEN id="token-11-41" pos="word" morph="none" start_char="1674" end_char="1675">to</TOKEN>
<TOKEN id="token-11-42" pos="word" morph="none" start_char="1677" end_char="1681">Wuhan</TOKEN>
<TOKEN id="token-11-43" pos="punct" morph="none" start_char="1682" end_char="1682">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1686" end_char="1837">
<ORIGINAL_TEXT>"What we know is that the ground zero for this virus was within a few miles of that lab," Peter Navarro, a Trump trade adviser, said Sunday on Fox News.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="punct" morph="none" start_char="1686" end_char="1686">"</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1687" end_char="1690">What</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1692" end_char="1693">we</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1695" end_char="1698">know</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1700" end_char="1701">is</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1703" end_char="1706">that</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1708" end_char="1710">the</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1712" end_char="1717">ground</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1719" end_char="1722">zero</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1724" end_char="1726">for</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1728" end_char="1731">this</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1733" end_char="1737">virus</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1739" end_char="1741">was</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1743" end_char="1748">within</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1750" end_char="1750">a</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1752" end_char="1754">few</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1756" end_char="1760">miles</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1762" end_char="1763">of</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1765" end_char="1768">that</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1770" end_char="1772">lab</TOKEN>
<TOKEN id="token-12-20" pos="punct" morph="none" start_char="1773" end_char="1774">,"</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1776" end_char="1780">Peter</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1782" end_char="1788">Navarro</TOKEN>
<TOKEN id="token-12-23" pos="punct" morph="none" start_char="1789" end_char="1789">,</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1791" end_char="1791">a</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1793" end_char="1797">Trump</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1799" end_char="1803">trade</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1805" end_char="1811">adviser</TOKEN>
<TOKEN id="token-12-28" pos="punct" morph="none" start_char="1812" end_char="1812">,</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1814" end_char="1817">said</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1819" end_char="1824">Sunday</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1826" end_char="1827">on</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1829" end_char="1831">Fox</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1833" end_char="1836">News</TOKEN>
<TOKEN id="token-12-34" pos="punct" morph="none" start_char="1837" end_char="1837">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1839" end_char="2007">
<ORIGINAL_TEXT>"If you simply do an Occam’s razor approach that the simplest explanation is probably the most likely, I think it’s incumbent on China to prove that it wasn’t that lab."</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="punct" morph="none" start_char="1839" end_char="1839">"</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1840" end_char="1841">If</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1843" end_char="1845">you</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1847" end_char="1852">simply</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1854" end_char="1855">do</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1857" end_char="1858">an</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1860" end_char="1866">Occam’s</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1868" end_char="1872">razor</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1874" end_char="1881">approach</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1883" end_char="1886">that</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1888" end_char="1890">the</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1892" end_char="1899">simplest</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1901" end_char="1911">explanation</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1913" end_char="1914">is</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1916" end_char="1923">probably</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1925" end_char="1927">the</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1929" end_char="1932">most</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1934" end_char="1939">likely</TOKEN>
<TOKEN id="token-13-18" pos="punct" morph="none" start_char="1940" end_char="1940">,</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1942" end_char="1942">I</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1944" end_char="1948">think</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1950" end_char="1953">it’s</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1955" end_char="1963">incumbent</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="1965" end_char="1966">on</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="1968" end_char="1972">China</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="1974" end_char="1975">to</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="1977" end_char="1981">prove</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="1983" end_char="1986">that</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="1988" end_char="1989">it</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="1991" end_char="1996">wasn’t</TOKEN>
<TOKEN id="token-13-30" pos="word" morph="none" start_char="1998" end_char="2001">that</TOKEN>
<TOKEN id="token-13-31" pos="word" morph="none" start_char="2003" end_char="2005">lab</TOKEN>
<TOKEN id="token-13-32" pos="punct" morph="none" start_char="2006" end_char="2007">."</TOKEN>
</SEG>
<SEG id="segment-14" start_char="2010" end_char="2155">
<ORIGINAL_TEXT>The U.S.-China blame game has helped fuel scrutiny of the Wuhan lab, which was studying bat-borne coronaviruses like the one that causes Covid-19.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="2010" end_char="2012">The</TOKEN>
<TOKEN id="token-14-1" pos="unknown" morph="none" start_char="2014" end_char="2023">U.S.-China</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="2025" end_char="2029">blame</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="2031" end_char="2034">game</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="2036" end_char="2038">has</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="2040" end_char="2045">helped</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="2047" end_char="2050">fuel</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="2052" end_char="2059">scrutiny</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="2061" end_char="2062">of</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="2064" end_char="2066">the</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="2068" end_char="2072">Wuhan</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="2074" end_char="2076">lab</TOKEN>
<TOKEN id="token-14-12" pos="punct" morph="none" start_char="2077" end_char="2077">,</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="2079" end_char="2083">which</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="2085" end_char="2087">was</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="2089" end_char="2096">studying</TOKEN>
<TOKEN id="token-14-16" pos="unknown" morph="none" start_char="2098" end_char="2106">bat-borne</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="2108" end_char="2120">coronaviruses</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="2122" end_char="2125">like</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="2127" end_char="2129">the</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="2131" end_char="2133">one</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="2135" end_char="2138">that</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="2140" end_char="2145">causes</TOKEN>
<TOKEN id="token-14-23" pos="unknown" morph="none" start_char="2147" end_char="2154">Covid-19</TOKEN>
<TOKEN id="token-14-24" pos="punct" morph="none" start_char="2155" end_char="2155">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="2157" end_char="2334">
<ORIGINAL_TEXT>U.S. diplomats sent back warnings about safety procedures in the lab after visits two years ago, the Washington Post reported in an April 14 commentary, citing diplomatic cables.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="unknown" morph="none" start_char="2157" end_char="2159">U.S</TOKEN>
<TOKEN id="token-15-1" pos="punct" morph="none" start_char="2160" end_char="2160">.</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="2162" end_char="2170">diplomats</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="2172" end_char="2175">sent</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="2177" end_char="2180">back</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="2182" end_char="2189">warnings</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="2191" end_char="2195">about</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="2197" end_char="2202">safety</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="2204" end_char="2213">procedures</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="2215" end_char="2216">in</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="2218" end_char="2220">the</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="2222" end_char="2224">lab</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="2226" end_char="2230">after</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="2232" end_char="2237">visits</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="2239" end_char="2241">two</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="2243" end_char="2247">years</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="2249" end_char="2251">ago</TOKEN>
<TOKEN id="token-15-17" pos="punct" morph="none" start_char="2252" end_char="2252">,</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="2254" end_char="2256">the</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="2258" end_char="2267">Washington</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="2269" end_char="2272">Post</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="2274" end_char="2281">reported</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="2283" end_char="2284">in</TOKEN>
<TOKEN id="token-15-23" pos="word" morph="none" start_char="2286" end_char="2287">an</TOKEN>
<TOKEN id="token-15-24" pos="word" morph="none" start_char="2289" end_char="2293">April</TOKEN>
<TOKEN id="token-15-25" pos="word" morph="none" start_char="2295" end_char="2296">14</TOKEN>
<TOKEN id="token-15-26" pos="word" morph="none" start_char="2298" end_char="2307">commentary</TOKEN>
<TOKEN id="token-15-27" pos="punct" morph="none" start_char="2308" end_char="2308">,</TOKEN>
<TOKEN id="token-15-28" pos="word" morph="none" start_char="2310" end_char="2315">citing</TOKEN>
<TOKEN id="token-15-29" pos="word" morph="none" start_char="2317" end_char="2326">diplomatic</TOKEN>
<TOKEN id="token-15-30" pos="word" morph="none" start_char="2328" end_char="2333">cables</TOKEN>
<TOKEN id="token-15-31" pos="punct" morph="none" start_char="2334" end_char="2334">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="2338" end_char="2443">
<ORIGINAL_TEXT>"They don’t have any evidence on this, what they rely on is only their guess," Yuan told CGTN on Saturday.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="punct" morph="none" start_char="2338" end_char="2338">"</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2339" end_char="2342">They</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2344" end_char="2348">don’t</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2350" end_char="2353">have</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2355" end_char="2357">any</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2359" end_char="2366">evidence</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2368" end_char="2369">on</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2371" end_char="2374">this</TOKEN>
<TOKEN id="token-16-8" pos="punct" morph="none" start_char="2375" end_char="2375">,</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="2377" end_char="2380">what</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2382" end_char="2385">they</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2387" end_char="2390">rely</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2392" end_char="2393">on</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2395" end_char="2396">is</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2398" end_char="2401">only</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2403" end_char="2407">their</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="2409" end_char="2413">guess</TOKEN>
<TOKEN id="token-16-17" pos="punct" morph="none" start_char="2414" end_char="2415">,"</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2417" end_char="2420">Yuan</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2422" end_char="2425">told</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2427" end_char="2430">CGTN</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="2432" end_char="2433">on</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="2435" end_char="2442">Saturday</TOKEN>
<TOKEN id="token-16-23" pos="punct" morph="none" start_char="2443" end_char="2443">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2445" end_char="2540">
<ORIGINAL_TEXT>"I hope such a conspiracy theory will not affect cooperation among scientists around the world."</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="punct" morph="none" start_char="2445" end_char="2445">"</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2446" end_char="2446">I</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2448" end_char="2451">hope</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2453" end_char="2456">such</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2458" end_char="2458">a</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2460" end_char="2469">conspiracy</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2471" end_char="2476">theory</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2478" end_char="2481">will</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2483" end_char="2485">not</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2487" end_char="2492">affect</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2494" end_char="2504">cooperation</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="2506" end_char="2510">among</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2512" end_char="2521">scientists</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2523" end_char="2528">around</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="2530" end_char="2532">the</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2534" end_char="2538">world</TOKEN>
<TOKEN id="token-17-16" pos="punct" morph="none" start_char="2539" end_char="2540">."</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2543" end_char="2675">
<ORIGINAL_TEXT>The P4 lab at the Wuhan Institute of Virology began operations in January 2018 and was the first of its kind built in mainland China.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2543" end_char="2545">The</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="2547" end_char="2548">P4</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2550" end_char="2552">lab</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2554" end_char="2555">at</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2557" end_char="2559">the</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2561" end_char="2565">Wuhan</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2567" end_char="2575">Institute</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2577" end_char="2578">of</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2580" end_char="2587">Virology</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2589" end_char="2593">began</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2595" end_char="2604">operations</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2606" end_char="2607">in</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2609" end_char="2615">January</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2617" end_char="2620">2018</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2622" end_char="2624">and</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2626" end_char="2628">was</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2630" end_char="2632">the</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2634" end_char="2638">first</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2640" end_char="2641">of</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2643" end_char="2645">its</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2647" end_char="2650">kind</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2652" end_char="2656">built</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2658" end_char="2659">in</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2661" end_char="2668">mainland</TOKEN>
<TOKEN id="token-18-24" pos="word" morph="none" start_char="2670" end_char="2674">China</TOKEN>
<TOKEN id="token-18-25" pos="punct" morph="none" start_char="2675" end_char="2675">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2678" end_char="2885">
<ORIGINAL_TEXT>It was designed with help from France as part of a joint research initiative focused on infectious diseases and equipped for the highest level of bio-containment, according to the official Xinhua News Agency.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2678" end_char="2679">It</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2681" end_char="2683">was</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2685" end_char="2692">designed</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2694" end_char="2697">with</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2699" end_char="2702">help</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2704" end_char="2707">from</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2709" end_char="2714">France</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2716" end_char="2717">as</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2719" end_char="2722">part</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2724" end_char="2725">of</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2727" end_char="2727">a</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2729" end_char="2733">joint</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2735" end_char="2742">research</TOKEN>
<TOKEN id="token-19-13" pos="word" morph="none" start_char="2744" end_char="2753">initiative</TOKEN>
<TOKEN id="token-19-14" pos="word" morph="none" start_char="2755" end_char="2761">focused</TOKEN>
<TOKEN id="token-19-15" pos="word" morph="none" start_char="2763" end_char="2764">on</TOKEN>
<TOKEN id="token-19-16" pos="word" morph="none" start_char="2766" end_char="2775">infectious</TOKEN>
<TOKEN id="token-19-17" pos="word" morph="none" start_char="2777" end_char="2784">diseases</TOKEN>
<TOKEN id="token-19-18" pos="word" morph="none" start_char="2786" end_char="2788">and</TOKEN>
<TOKEN id="token-19-19" pos="word" morph="none" start_char="2790" end_char="2797">equipped</TOKEN>
<TOKEN id="token-19-20" pos="word" morph="none" start_char="2799" end_char="2801">for</TOKEN>
<TOKEN id="token-19-21" pos="word" morph="none" start_char="2803" end_char="2805">the</TOKEN>
<TOKEN id="token-19-22" pos="word" morph="none" start_char="2807" end_char="2813">highest</TOKEN>
<TOKEN id="token-19-23" pos="word" morph="none" start_char="2815" end_char="2819">level</TOKEN>
<TOKEN id="token-19-24" pos="word" morph="none" start_char="2821" end_char="2822">of</TOKEN>
<TOKEN id="token-19-25" pos="unknown" morph="none" start_char="2824" end_char="2838">bio-containment</TOKEN>
<TOKEN id="token-19-26" pos="punct" morph="none" start_char="2839" end_char="2839">,</TOKEN>
<TOKEN id="token-19-27" pos="word" morph="none" start_char="2841" end_char="2849">according</TOKEN>
<TOKEN id="token-19-28" pos="word" morph="none" start_char="2851" end_char="2852">to</TOKEN>
<TOKEN id="token-19-29" pos="word" morph="none" start_char="2854" end_char="2856">the</TOKEN>
<TOKEN id="token-19-30" pos="word" morph="none" start_char="2858" end_char="2865">official</TOKEN>
<TOKEN id="token-19-31" pos="word" morph="none" start_char="2867" end_char="2872">Xinhua</TOKEN>
<TOKEN id="token-19-32" pos="word" morph="none" start_char="2874" end_char="2877">News</TOKEN>
<TOKEN id="token-19-33" pos="word" morph="none" start_char="2879" end_char="2884">Agency</TOKEN>
<TOKEN id="token-19-34" pos="punct" morph="none" start_char="2885" end_char="2885">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2887" end_char="3055">
<ORIGINAL_TEXT>The first project undertaken at the lab was to research Xinjiang hemorrhagic fever, a tick-borne virus with a fatality rate of as much as 50% in humans, the report said.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2887" end_char="2889">The</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2891" end_char="2895">first</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2897" end_char="2903">project</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2905" end_char="2914">undertaken</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2916" end_char="2917">at</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2919" end_char="2921">the</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2923" end_char="2925">lab</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2927" end_char="2929">was</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2931" end_char="2932">to</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2934" end_char="2941">research</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2943" end_char="2950">Xinjiang</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2952" end_char="2962">hemorrhagic</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2964" end_char="2968">fever</TOKEN>
<TOKEN id="token-20-13" pos="punct" morph="none" start_char="2969" end_char="2969">,</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2971" end_char="2971">a</TOKEN>
<TOKEN id="token-20-15" pos="unknown" morph="none" start_char="2973" end_char="2982">tick-borne</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2984" end_char="2988">virus</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2990" end_char="2993">with</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2995" end_char="2995">a</TOKEN>
<TOKEN id="token-20-19" pos="word" morph="none" start_char="2997" end_char="3004">fatality</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="3006" end_char="3009">rate</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="3011" end_char="3012">of</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="3014" end_char="3015">as</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="3017" end_char="3020">much</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="3022" end_char="3023">as</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="3025" end_char="3026">50</TOKEN>
<TOKEN id="token-20-26" pos="punct" morph="none" start_char="3027" end_char="3027">%</TOKEN>
<TOKEN id="token-20-27" pos="word" morph="none" start_char="3029" end_char="3030">in</TOKEN>
<TOKEN id="token-20-28" pos="word" morph="none" start_char="3032" end_char="3037">humans</TOKEN>
<TOKEN id="token-20-29" pos="punct" morph="none" start_char="3038" end_char="3038">,</TOKEN>
<TOKEN id="token-20-30" pos="word" morph="none" start_char="3040" end_char="3042">the</TOKEN>
<TOKEN id="token-20-31" pos="word" morph="none" start_char="3044" end_char="3049">report</TOKEN>
<TOKEN id="token-20-32" pos="word" morph="none" start_char="3051" end_char="3054">said</TOKEN>
<TOKEN id="token-20-33" pos="punct" morph="none" start_char="3055" end_char="3055">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="3058" end_char="3244">
<ORIGINAL_TEXT>The facility has been the center of multiple conspiracy theories, including one that’s circulated on Chinese social media since late January that the new coronavirus escaped from the lab.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="3058" end_char="3060">The</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="3062" end_char="3069">facility</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="3071" end_char="3073">has</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="3075" end_char="3078">been</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="3080" end_char="3082">the</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="3084" end_char="3089">center</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="3091" end_char="3092">of</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="3094" end_char="3101">multiple</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="3103" end_char="3112">conspiracy</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="3114" end_char="3121">theories</TOKEN>
<TOKEN id="token-21-10" pos="punct" morph="none" start_char="3122" end_char="3122">,</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="3124" end_char="3132">including</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="3134" end_char="3136">one</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="3138" end_char="3143">that’s</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="3145" end_char="3154">circulated</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="3156" end_char="3157">on</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="3159" end_char="3165">Chinese</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="3167" end_char="3172">social</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="3174" end_char="3178">media</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="3180" end_char="3184">since</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="3186" end_char="3189">late</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="3191" end_char="3197">January</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="3199" end_char="3202">that</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="3204" end_char="3206">the</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="3208" end_char="3210">new</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="3212" end_char="3222">coronavirus</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="3224" end_char="3230">escaped</TOKEN>
<TOKEN id="token-21-27" pos="word" morph="none" start_char="3232" end_char="3235">from</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="3237" end_char="3239">the</TOKEN>
<TOKEN id="token-21-29" pos="word" morph="none" start_char="3241" end_char="3243">lab</TOKEN>
<TOKEN id="token-21-30" pos="punct" morph="none" start_char="3244" end_char="3244">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="3246" end_char="3385">
<ORIGINAL_TEXT>Multiple posts have cited previous blunders by Chinese scientists as evidence that similar research projects haven’t been executed properly.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="3246" end_char="3253">Multiple</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="3255" end_char="3259">posts</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="3261" end_char="3264">have</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="3266" end_char="3270">cited</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="3272" end_char="3279">previous</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="3281" end_char="3288">blunders</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="3290" end_char="3291">by</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="3293" end_char="3299">Chinese</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="3301" end_char="3310">scientists</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="3312" end_char="3313">as</TOKEN>
<TOKEN id="token-22-10" pos="word" morph="none" start_char="3315" end_char="3322">evidence</TOKEN>
<TOKEN id="token-22-11" pos="word" morph="none" start_char="3324" end_char="3327">that</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="3329" end_char="3335">similar</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="3337" end_char="3344">research</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="3346" end_char="3353">projects</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="3355" end_char="3361">haven’t</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="3363" end_char="3366">been</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="3368" end_char="3375">executed</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="3377" end_char="3384">properly</TOKEN>
<TOKEN id="token-22-19" pos="punct" morph="none" start_char="3385" end_char="3385">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="3388" end_char="3661">
<ORIGINAL_TEXT>Among them was a 2017 report by the Wuhan Evening News that said Tian Junhua, a researcher at the Wuhan Centre for Disease Control and Prevention, had to quarantine himself for 14 days after accidentally coming into direct contact with bat urine during a 2012 research trip.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="3388" end_char="3392">Among</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="3394" end_char="3397">them</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="3399" end_char="3401">was</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="3403" end_char="3403">a</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="3405" end_char="3408">2017</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="3410" end_char="3415">report</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="3417" end_char="3418">by</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3420" end_char="3422">the</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3424" end_char="3428">Wuhan</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="3430" end_char="3436">Evening</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3438" end_char="3441">News</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3443" end_char="3446">that</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3448" end_char="3451">said</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3453" end_char="3456">Tian</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3458" end_char="3463">Junhua</TOKEN>
<TOKEN id="token-23-15" pos="punct" morph="none" start_char="3464" end_char="3464">,</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3466" end_char="3466">a</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3468" end_char="3477">researcher</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3479" end_char="3480">at</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3482" end_char="3484">the</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3486" end_char="3490">Wuhan</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3492" end_char="3497">Centre</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3499" end_char="3501">for</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3503" end_char="3509">Disease</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3511" end_char="3517">Control</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3519" end_char="3521">and</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3523" end_char="3532">Prevention</TOKEN>
<TOKEN id="token-23-27" pos="punct" morph="none" start_char="3533" end_char="3533">,</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3535" end_char="3537">had</TOKEN>
<TOKEN id="token-23-29" pos="word" morph="none" start_char="3539" end_char="3540">to</TOKEN>
<TOKEN id="token-23-30" pos="word" morph="none" start_char="3542" end_char="3551">quarantine</TOKEN>
<TOKEN id="token-23-31" pos="word" morph="none" start_char="3553" end_char="3559">himself</TOKEN>
<TOKEN id="token-23-32" pos="word" morph="none" start_char="3561" end_char="3563">for</TOKEN>
<TOKEN id="token-23-33" pos="word" morph="none" start_char="3565" end_char="3566">14</TOKEN>
<TOKEN id="token-23-34" pos="word" morph="none" start_char="3568" end_char="3571">days</TOKEN>
<TOKEN id="token-23-35" pos="word" morph="none" start_char="3573" end_char="3577">after</TOKEN>
<TOKEN id="token-23-36" pos="word" morph="none" start_char="3579" end_char="3590">accidentally</TOKEN>
<TOKEN id="token-23-37" pos="word" morph="none" start_char="3592" end_char="3597">coming</TOKEN>
<TOKEN id="token-23-38" pos="word" morph="none" start_char="3599" end_char="3602">into</TOKEN>
<TOKEN id="token-23-39" pos="word" morph="none" start_char="3604" end_char="3609">direct</TOKEN>
<TOKEN id="token-23-40" pos="word" morph="none" start_char="3611" end_char="3617">contact</TOKEN>
<TOKEN id="token-23-41" pos="word" morph="none" start_char="3619" end_char="3622">with</TOKEN>
<TOKEN id="token-23-42" pos="word" morph="none" start_char="3624" end_char="3626">bat</TOKEN>
<TOKEN id="token-23-43" pos="word" morph="none" start_char="3628" end_char="3632">urine</TOKEN>
<TOKEN id="token-23-44" pos="word" morph="none" start_char="3634" end_char="3639">during</TOKEN>
<TOKEN id="token-23-45" pos="word" morph="none" start_char="3641" end_char="3641">a</TOKEN>
<TOKEN id="token-23-46" pos="word" morph="none" start_char="3643" end_char="3646">2012</TOKEN>
<TOKEN id="token-23-47" pos="word" morph="none" start_char="3648" end_char="3655">research</TOKEN>
<TOKEN id="token-23-48" pos="word" morph="none" start_char="3657" end_char="3660">trip</TOKEN>
<TOKEN id="token-23-49" pos="punct" morph="none" start_char="3661" end_char="3661">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3664" end_char="3856">
<ORIGINAL_TEXT>Social-media users also cited a 2004 accident at a national lab in Beijing during experiments with Severe Acute Respiratory Syndrome-related coronavirus that led to infections -- and one death.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="unknown" morph="none" start_char="3664" end_char="3675">Social-media</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3677" end_char="3681">users</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3683" end_char="3686">also</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3688" end_char="3692">cited</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3694" end_char="3694">a</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3696" end_char="3699">2004</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3701" end_char="3708">accident</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3710" end_char="3711">at</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3713" end_char="3713">a</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="3715" end_char="3722">national</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="3724" end_char="3726">lab</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="3728" end_char="3729">in</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="3731" end_char="3737">Beijing</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="3739" end_char="3744">during</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="3746" end_char="3756">experiments</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="3758" end_char="3761">with</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="3763" end_char="3768">Severe</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="3770" end_char="3774">Acute</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="3776" end_char="3786">Respiratory</TOKEN>
<TOKEN id="token-24-19" pos="unknown" morph="none" start_char="3788" end_char="3803">Syndrome-related</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="3805" end_char="3815">coronavirus</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="3817" end_char="3820">that</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="3822" end_char="3824">led</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="3826" end_char="3827">to</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="3829" end_char="3838">infections</TOKEN>
<TOKEN id="token-24-25" pos="punct" morph="none" start_char="3840" end_char="3841">--</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="3843" end_char="3845">and</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="3847" end_char="3849">one</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="3851" end_char="3855">death</TOKEN>
<TOKEN id="token-24-29" pos="punct" morph="none" start_char="3856" end_char="3856">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="3858" end_char="3985">
<ORIGINAL_TEXT>Five top officials at the Chinese Centre for Disease Control and Prevention were punished at the time, according to China Daily.</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="3858" end_char="3861">Five</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="3863" end_char="3865">top</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="3867" end_char="3875">officials</TOKEN>
<TOKEN id="token-25-3" pos="word" morph="none" start_char="3877" end_char="3878">at</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="3880" end_char="3882">the</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="3884" end_char="3890">Chinese</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="3892" end_char="3897">Centre</TOKEN>
<TOKEN id="token-25-7" pos="word" morph="none" start_char="3899" end_char="3901">for</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="3903" end_char="3909">Disease</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="3911" end_char="3917">Control</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="3919" end_char="3921">and</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="3923" end_char="3932">Prevention</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="3934" end_char="3937">were</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="3939" end_char="3946">punished</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="3948" end_char="3949">at</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="3951" end_char="3953">the</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="3955" end_char="3958">time</TOKEN>
<TOKEN id="token-25-17" pos="punct" morph="none" start_char="3959" end_char="3959">,</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="3961" end_char="3969">according</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="3971" end_char="3972">to</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="3974" end_char="3978">China</TOKEN>
<TOKEN id="token-25-21" pos="word" morph="none" start_char="3980" end_char="3984">Daily</TOKEN>
<TOKEN id="token-25-22" pos="punct" morph="none" start_char="3985" end_char="3985">.</TOKEN>
</SEG>
<SEG id="segment-26" start_char="3988" end_char="4146">
<ORIGINAL_TEXT>Some countries including Australia have urged an independent review of how the pandemic came to infect more than 2.4 million people and kill more than 166,000.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="3988" end_char="3991">Some</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="3993" end_char="4001">countries</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="4003" end_char="4011">including</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="4013" end_char="4021">Australia</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="4023" end_char="4026">have</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="4028" end_char="4032">urged</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="4034" end_char="4035">an</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="4037" end_char="4047">independent</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="4049" end_char="4054">review</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="4056" end_char="4057">of</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="4059" end_char="4061">how</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="4063" end_char="4065">the</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="4067" end_char="4074">pandemic</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="4076" end_char="4079">came</TOKEN>
<TOKEN id="token-26-14" pos="word" morph="none" start_char="4081" end_char="4082">to</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="4084" end_char="4089">infect</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="4091" end_char="4094">more</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="4096" end_char="4099">than</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="4101" end_char="4103">2.4</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="4105" end_char="4111">million</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="4113" end_char="4118">people</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="4120" end_char="4122">and</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="4124" end_char="4127">kill</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="4129" end_char="4132">more</TOKEN>
<TOKEN id="token-26-24" pos="word" morph="none" start_char="4134" end_char="4137">than</TOKEN>
<TOKEN id="token-26-25" pos="unknown" morph="none" start_char="4139" end_char="4145">166,000</TOKEN>
<TOKEN id="token-26-26" pos="punct" morph="none" start_char="4146" end_char="4146">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="4148" end_char="4383">
<ORIGINAL_TEXT>"The issues around the coronavirus are issues for independent review and I think that is important that we do that, in fact Australia will absolutely insist," Foreign Minister Marise Payne told ABC Australia’s "Insiders" program Sunday.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="punct" morph="none" start_char="4148" end_char="4148">"</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="4149" end_char="4151">The</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="4153" end_char="4158">issues</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="4160" end_char="4165">around</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="4167" end_char="4169">the</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="4171" end_char="4181">coronavirus</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="4183" end_char="4185">are</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="4187" end_char="4192">issues</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="4194" end_char="4196">for</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="4198" end_char="4208">independent</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="4210" end_char="4215">review</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="4217" end_char="4219">and</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="4221" end_char="4221">I</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="4223" end_char="4227">think</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="4229" end_char="4232">that</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="4234" end_char="4235">is</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="4237" end_char="4245">important</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="4247" end_char="4250">that</TOKEN>
<TOKEN id="token-27-18" pos="word" morph="none" start_char="4252" end_char="4253">we</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="4255" end_char="4256">do</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="4258" end_char="4261">that</TOKEN>
<TOKEN id="token-27-21" pos="punct" morph="none" start_char="4262" end_char="4262">,</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="4264" end_char="4265">in</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="4267" end_char="4270">fact</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="4272" end_char="4280">Australia</TOKEN>
<TOKEN id="token-27-25" pos="word" morph="none" start_char="4282" end_char="4285">will</TOKEN>
<TOKEN id="token-27-26" pos="word" morph="none" start_char="4287" end_char="4296">absolutely</TOKEN>
<TOKEN id="token-27-27" pos="word" morph="none" start_char="4298" end_char="4303">insist</TOKEN>
<TOKEN id="token-27-28" pos="punct" morph="none" start_char="4304" end_char="4305">,"</TOKEN>
<TOKEN id="token-27-29" pos="word" morph="none" start_char="4307" end_char="4313">Foreign</TOKEN>
<TOKEN id="token-27-30" pos="word" morph="none" start_char="4315" end_char="4322">Minister</TOKEN>
<TOKEN id="token-27-31" pos="word" morph="none" start_char="4324" end_char="4329">Marise</TOKEN>
<TOKEN id="token-27-32" pos="word" morph="none" start_char="4331" end_char="4335">Payne</TOKEN>
<TOKEN id="token-27-33" pos="word" morph="none" start_char="4337" end_char="4340">told</TOKEN>
<TOKEN id="token-27-34" pos="word" morph="none" start_char="4342" end_char="4344">ABC</TOKEN>
<TOKEN id="token-27-35" pos="word" morph="none" start_char="4346" end_char="4356">Australia’s</TOKEN>
<TOKEN id="token-27-36" pos="punct" morph="none" start_char="4358" end_char="4358">"</TOKEN>
<TOKEN id="token-27-37" pos="word" morph="none" start_char="4359" end_char="4366">Insiders</TOKEN>
<TOKEN id="token-27-38" pos="punct" morph="none" start_char="4367" end_char="4367">"</TOKEN>
<TOKEN id="token-27-39" pos="word" morph="none" start_char="4369" end_char="4375">program</TOKEN>
<TOKEN id="token-27-40" pos="word" morph="none" start_char="4377" end_char="4382">Sunday</TOKEN>
<TOKEN id="token-27-41" pos="punct" morph="none" start_char="4383" end_char="4383">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="4386" end_char="4580">
<ORIGINAL_TEXT>While many Republicans have emphasized the Chinese origins of a virus that has killed more than 40,000 Americans, Cotton has been among the most vocal urging an investigation into the lab’s role.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="4386" end_char="4390">While</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="4392" end_char="4395">many</TOKEN>
<TOKEN id="token-28-2" pos="word" morph="none" start_char="4397" end_char="4407">Republicans</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="4409" end_char="4412">have</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="4414" end_char="4423">emphasized</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="4425" end_char="4427">the</TOKEN>
<TOKEN id="token-28-6" pos="word" morph="none" start_char="4429" end_char="4435">Chinese</TOKEN>
<TOKEN id="token-28-7" pos="word" morph="none" start_char="4437" end_char="4443">origins</TOKEN>
<TOKEN id="token-28-8" pos="word" morph="none" start_char="4445" end_char="4446">of</TOKEN>
<TOKEN id="token-28-9" pos="word" morph="none" start_char="4448" end_char="4448">a</TOKEN>
<TOKEN id="token-28-10" pos="word" morph="none" start_char="4450" end_char="4454">virus</TOKEN>
<TOKEN id="token-28-11" pos="word" morph="none" start_char="4456" end_char="4459">that</TOKEN>
<TOKEN id="token-28-12" pos="word" morph="none" start_char="4461" end_char="4463">has</TOKEN>
<TOKEN id="token-28-13" pos="word" morph="none" start_char="4465" end_char="4470">killed</TOKEN>
<TOKEN id="token-28-14" pos="word" morph="none" start_char="4472" end_char="4475">more</TOKEN>
<TOKEN id="token-28-15" pos="word" morph="none" start_char="4477" end_char="4480">than</TOKEN>
<TOKEN id="token-28-16" pos="unknown" morph="none" start_char="4482" end_char="4487">40,000</TOKEN>
<TOKEN id="token-28-17" pos="word" morph="none" start_char="4489" end_char="4497">Americans</TOKEN>
<TOKEN id="token-28-18" pos="punct" morph="none" start_char="4498" end_char="4498">,</TOKEN>
<TOKEN id="token-28-19" pos="word" morph="none" start_char="4500" end_char="4505">Cotton</TOKEN>
<TOKEN id="token-28-20" pos="word" morph="none" start_char="4507" end_char="4509">has</TOKEN>
<TOKEN id="token-28-21" pos="word" morph="none" start_char="4511" end_char="4514">been</TOKEN>
<TOKEN id="token-28-22" pos="word" morph="none" start_char="4516" end_char="4520">among</TOKEN>
<TOKEN id="token-28-23" pos="word" morph="none" start_char="4522" end_char="4524">the</TOKEN>
<TOKEN id="token-28-24" pos="word" morph="none" start_char="4526" end_char="4529">most</TOKEN>
<TOKEN id="token-28-25" pos="word" morph="none" start_char="4531" end_char="4535">vocal</TOKEN>
<TOKEN id="token-28-26" pos="word" morph="none" start_char="4537" end_char="4542">urging</TOKEN>
<TOKEN id="token-28-27" pos="word" morph="none" start_char="4544" end_char="4545">an</TOKEN>
<TOKEN id="token-28-28" pos="word" morph="none" start_char="4547" end_char="4559">investigation</TOKEN>
<TOKEN id="token-28-29" pos="word" morph="none" start_char="4561" end_char="4564">into</TOKEN>
<TOKEN id="token-28-30" pos="word" morph="none" start_char="4566" end_char="4568">the</TOKEN>
<TOKEN id="token-28-31" pos="word" morph="none" start_char="4570" end_char="4574">lab’s</TOKEN>
<TOKEN id="token-28-32" pos="word" morph="none" start_char="4576" end_char="4579">role</TOKEN>
<TOKEN id="token-28-33" pos="punct" morph="none" start_char="4580" end_char="4580">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="4582" end_char="4732">
<ORIGINAL_TEXT>On Friday, he told Fox News that "circumstantial evidence" was "stacking up pretty quickly that this virus may have originated in those labs in Wuhan."</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="4582" end_char="4583">On</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="4585" end_char="4590">Friday</TOKEN>
<TOKEN id="token-29-2" pos="punct" morph="none" start_char="4591" end_char="4591">,</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="4593" end_char="4594">he</TOKEN>
<TOKEN id="token-29-4" pos="word" morph="none" start_char="4596" end_char="4599">told</TOKEN>
<TOKEN id="token-29-5" pos="word" morph="none" start_char="4601" end_char="4603">Fox</TOKEN>
<TOKEN id="token-29-6" pos="word" morph="none" start_char="4605" end_char="4608">News</TOKEN>
<TOKEN id="token-29-7" pos="word" morph="none" start_char="4610" end_char="4613">that</TOKEN>
<TOKEN id="token-29-8" pos="punct" morph="none" start_char="4615" end_char="4615">"</TOKEN>
<TOKEN id="token-29-9" pos="word" morph="none" start_char="4616" end_char="4629">circumstantial</TOKEN>
<TOKEN id="token-29-10" pos="word" morph="none" start_char="4631" end_char="4638">evidence</TOKEN>
<TOKEN id="token-29-11" pos="punct" morph="none" start_char="4639" end_char="4639">"</TOKEN>
<TOKEN id="token-29-12" pos="word" morph="none" start_char="4641" end_char="4643">was</TOKEN>
<TOKEN id="token-29-13" pos="punct" morph="none" start_char="4645" end_char="4645">"</TOKEN>
<TOKEN id="token-29-14" pos="word" morph="none" start_char="4646" end_char="4653">stacking</TOKEN>
<TOKEN id="token-29-15" pos="word" morph="none" start_char="4655" end_char="4656">up</TOKEN>
<TOKEN id="token-29-16" pos="word" morph="none" start_char="4658" end_char="4663">pretty</TOKEN>
<TOKEN id="token-29-17" pos="word" morph="none" start_char="4665" end_char="4671">quickly</TOKEN>
<TOKEN id="token-29-18" pos="word" morph="none" start_char="4673" end_char="4676">that</TOKEN>
<TOKEN id="token-29-19" pos="word" morph="none" start_char="4678" end_char="4681">this</TOKEN>
<TOKEN id="token-29-20" pos="word" morph="none" start_char="4683" end_char="4687">virus</TOKEN>
<TOKEN id="token-29-21" pos="word" morph="none" start_char="4689" end_char="4691">may</TOKEN>
<TOKEN id="token-29-22" pos="word" morph="none" start_char="4693" end_char="4696">have</TOKEN>
<TOKEN id="token-29-23" pos="word" morph="none" start_char="4698" end_char="4707">originated</TOKEN>
<TOKEN id="token-29-24" pos="word" morph="none" start_char="4709" end_char="4710">in</TOKEN>
<TOKEN id="token-29-25" pos="word" morph="none" start_char="4712" end_char="4716">those</TOKEN>
<TOKEN id="token-29-26" pos="word" morph="none" start_char="4718" end_char="4721">labs</TOKEN>
<TOKEN id="token-29-27" pos="word" morph="none" start_char="4723" end_char="4724">in</TOKEN>
<TOKEN id="token-29-28" pos="word" morph="none" start_char="4726" end_char="4730">Wuhan</TOKEN>
<TOKEN id="token-29-29" pos="punct" morph="none" start_char="4731" end_char="4732">."</TOKEN>
</SEG>
<SEG id="segment-30" start_char="4735" end_char="4953">
<ORIGINAL_TEXT>Although the first known cluster centered on a wet market in Wuhan, the ultimate origins of the virus remain a mystery and Chinese officials have raised the possibility that the virus didn’t begin in the country at all.</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="4735" end_char="4742">Although</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="4744" end_char="4746">the</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="4748" end_char="4752">first</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="4754" end_char="4758">known</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="4760" end_char="4766">cluster</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="4768" end_char="4775">centered</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="4777" end_char="4778">on</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="4780" end_char="4780">a</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="4782" end_char="4784">wet</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="4786" end_char="4791">market</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="4793" end_char="4794">in</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="4796" end_char="4800">Wuhan</TOKEN>
<TOKEN id="token-30-12" pos="punct" morph="none" start_char="4801" end_char="4801">,</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="4803" end_char="4805">the</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="4807" end_char="4814">ultimate</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="4816" end_char="4822">origins</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="4824" end_char="4825">of</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="4827" end_char="4829">the</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="4831" end_char="4835">virus</TOKEN>
<TOKEN id="token-30-19" pos="word" morph="none" start_char="4837" end_char="4842">remain</TOKEN>
<TOKEN id="token-30-20" pos="word" morph="none" start_char="4844" end_char="4844">a</TOKEN>
<TOKEN id="token-30-21" pos="word" morph="none" start_char="4846" end_char="4852">mystery</TOKEN>
<TOKEN id="token-30-22" pos="word" morph="none" start_char="4854" end_char="4856">and</TOKEN>
<TOKEN id="token-30-23" pos="word" morph="none" start_char="4858" end_char="4864">Chinese</TOKEN>
<TOKEN id="token-30-24" pos="word" morph="none" start_char="4866" end_char="4874">officials</TOKEN>
<TOKEN id="token-30-25" pos="word" morph="none" start_char="4876" end_char="4879">have</TOKEN>
<TOKEN id="token-30-26" pos="word" morph="none" start_char="4881" end_char="4886">raised</TOKEN>
<TOKEN id="token-30-27" pos="word" morph="none" start_char="4888" end_char="4890">the</TOKEN>
<TOKEN id="token-30-28" pos="word" morph="none" start_char="4892" end_char="4902">possibility</TOKEN>
<TOKEN id="token-30-29" pos="word" morph="none" start_char="4904" end_char="4907">that</TOKEN>
<TOKEN id="token-30-30" pos="word" morph="none" start_char="4909" end_char="4911">the</TOKEN>
<TOKEN id="token-30-31" pos="word" morph="none" start_char="4913" end_char="4917">virus</TOKEN>
<TOKEN id="token-30-32" pos="word" morph="none" start_char="4919" end_char="4924">didn’t</TOKEN>
<TOKEN id="token-30-33" pos="word" morph="none" start_char="4926" end_char="4930">begin</TOKEN>
<TOKEN id="token-30-34" pos="word" morph="none" start_char="4932" end_char="4933">in</TOKEN>
<TOKEN id="token-30-35" pos="word" morph="none" start_char="4935" end_char="4937">the</TOKEN>
<TOKEN id="token-30-36" pos="word" morph="none" start_char="4939" end_char="4945">country</TOKEN>
<TOKEN id="token-30-37" pos="word" morph="none" start_char="4947" end_char="4948">at</TOKEN>
<TOKEN id="token-30-38" pos="word" morph="none" start_char="4950" end_char="4952">all</TOKEN>
<TOKEN id="token-30-39" pos="punct" morph="none" start_char="4953" end_char="4953">.</TOKEN>
</SEG>
<SEG id="segment-31" start_char="4955" end_char="5143">
<ORIGINAL_TEXT>Meanwhile, General Mark Milley, the chairman of the U.S. Joint Chiefs of Staff, has endorsed studies that have shown the virus evolved naturally, as opposed to being genetically engineered.</ORIGINAL_TEXT>
<TOKEN id="token-31-0" pos="word" morph="none" start_char="4955" end_char="4963">Meanwhile</TOKEN>
<TOKEN id="token-31-1" pos="punct" morph="none" start_char="4964" end_char="4964">,</TOKEN>
<TOKEN id="token-31-2" pos="word" morph="none" start_char="4966" end_char="4972">General</TOKEN>
<TOKEN id="token-31-3" pos="word" morph="none" start_char="4974" end_char="4977">Mark</TOKEN>
<TOKEN id="token-31-4" pos="word" morph="none" start_char="4979" end_char="4984">Milley</TOKEN>
<TOKEN id="token-31-5" pos="punct" morph="none" start_char="4985" end_char="4985">,</TOKEN>
<TOKEN id="token-31-6" pos="word" morph="none" start_char="4987" end_char="4989">the</TOKEN>
<TOKEN id="token-31-7" pos="word" morph="none" start_char="4991" end_char="4998">chairman</TOKEN>
<TOKEN id="token-31-8" pos="word" morph="none" start_char="5000" end_char="5001">of</TOKEN>
<TOKEN id="token-31-9" pos="word" morph="none" start_char="5003" end_char="5005">the</TOKEN>
<TOKEN id="token-31-10" pos="unknown" morph="none" start_char="5007" end_char="5009">U.S</TOKEN>
<TOKEN id="token-31-11" pos="punct" morph="none" start_char="5010" end_char="5010">.</TOKEN>
<TOKEN id="token-31-12" pos="word" morph="none" start_char="5012" end_char="5016">Joint</TOKEN>
<TOKEN id="token-31-13" pos="word" morph="none" start_char="5018" end_char="5023">Chiefs</TOKEN>
<TOKEN id="token-31-14" pos="word" morph="none" start_char="5025" end_char="5026">of</TOKEN>
<TOKEN id="token-31-15" pos="word" morph="none" start_char="5028" end_char="5032">Staff</TOKEN>
<TOKEN id="token-31-16" pos="punct" morph="none" start_char="5033" end_char="5033">,</TOKEN>
<TOKEN id="token-31-17" pos="word" morph="none" start_char="5035" end_char="5037">has</TOKEN>
<TOKEN id="token-31-18" pos="word" morph="none" start_char="5039" end_char="5046">endorsed</TOKEN>
<TOKEN id="token-31-19" pos="word" morph="none" start_char="5048" end_char="5054">studies</TOKEN>
<TOKEN id="token-31-20" pos="word" morph="none" start_char="5056" end_char="5059">that</TOKEN>
<TOKEN id="token-31-21" pos="word" morph="none" start_char="5061" end_char="5064">have</TOKEN>
<TOKEN id="token-31-22" pos="word" morph="none" start_char="5066" end_char="5070">shown</TOKEN>
<TOKEN id="token-31-23" pos="word" morph="none" start_char="5072" end_char="5074">the</TOKEN>
<TOKEN id="token-31-24" pos="word" morph="none" start_char="5076" end_char="5080">virus</TOKEN>
<TOKEN id="token-31-25" pos="word" morph="none" start_char="5082" end_char="5088">evolved</TOKEN>
<TOKEN id="token-31-26" pos="word" morph="none" start_char="5090" end_char="5098">naturally</TOKEN>
<TOKEN id="token-31-27" pos="punct" morph="none" start_char="5099" end_char="5099">,</TOKEN>
<TOKEN id="token-31-28" pos="word" morph="none" start_char="5101" end_char="5102">as</TOKEN>
<TOKEN id="token-31-29" pos="word" morph="none" start_char="5104" end_char="5110">opposed</TOKEN>
<TOKEN id="token-31-30" pos="word" morph="none" start_char="5112" end_char="5113">to</TOKEN>
<TOKEN id="token-31-31" pos="word" morph="none" start_char="5115" end_char="5119">being</TOKEN>
<TOKEN id="token-31-32" pos="word" morph="none" start_char="5121" end_char="5131">genetically</TOKEN>
<TOKEN id="token-31-33" pos="word" morph="none" start_char="5133" end_char="5142">engineered</TOKEN>
<TOKEN id="token-31-34" pos="punct" morph="none" start_char="5143" end_char="5143">.</TOKEN>
</SEG>
<SEG id="segment-32" start_char="5146" end_char="5364">
<ORIGINAL_TEXT>Shi Zhengli -- a researcher at the institute known as "Bat Woman" for her expeditions in bat caves -- said in a February social media post that she would "swear on my life" that the virus had nothing to do with the lab.</ORIGINAL_TEXT>
<TOKEN id="token-32-0" pos="word" morph="none" start_char="5146" end_char="5148">Shi</TOKEN>
<TOKEN id="token-32-1" pos="word" morph="none" start_char="5150" end_char="5156">Zhengli</TOKEN>
<TOKEN id="token-32-2" pos="punct" morph="none" start_char="5158" end_char="5159">--</TOKEN>
<TOKEN id="token-32-3" pos="word" morph="none" start_char="5161" end_char="5161">a</TOKEN>
<TOKEN id="token-32-4" pos="word" morph="none" start_char="5163" end_char="5172">researcher</TOKEN>
<TOKEN id="token-32-5" pos="word" morph="none" start_char="5174" end_char="5175">at</TOKEN>
<TOKEN id="token-32-6" pos="word" morph="none" start_char="5177" end_char="5179">the</TOKEN>
<TOKEN id="token-32-7" pos="word" morph="none" start_char="5181" end_char="5189">institute</TOKEN>
<TOKEN id="token-32-8" pos="word" morph="none" start_char="5191" end_char="5195">known</TOKEN>
<TOKEN id="token-32-9" pos="word" morph="none" start_char="5197" end_char="5198">as</TOKEN>
<TOKEN id="token-32-10" pos="punct" morph="none" start_char="5200" end_char="5200">"</TOKEN>
<TOKEN id="token-32-11" pos="word" morph="none" start_char="5201" end_char="5203">Bat</TOKEN>
<TOKEN id="token-32-12" pos="word" morph="none" start_char="5205" end_char="5209">Woman</TOKEN>
<TOKEN id="token-32-13" pos="punct" morph="none" start_char="5210" end_char="5210">"</TOKEN>
<TOKEN id="token-32-14" pos="word" morph="none" start_char="5212" end_char="5214">for</TOKEN>
<TOKEN id="token-32-15" pos="word" morph="none" start_char="5216" end_char="5218">her</TOKEN>
<TOKEN id="token-32-16" pos="word" morph="none" start_char="5220" end_char="5230">expeditions</TOKEN>
<TOKEN id="token-32-17" pos="word" morph="none" start_char="5232" end_char="5233">in</TOKEN>
<TOKEN id="token-32-18" pos="word" morph="none" start_char="5235" end_char="5237">bat</TOKEN>
<TOKEN id="token-32-19" pos="word" morph="none" start_char="5239" end_char="5243">caves</TOKEN>
<TOKEN id="token-32-20" pos="punct" morph="none" start_char="5245" end_char="5246">--</TOKEN>
<TOKEN id="token-32-21" pos="word" morph="none" start_char="5248" end_char="5251">said</TOKEN>
<TOKEN id="token-32-22" pos="word" morph="none" start_char="5253" end_char="5254">in</TOKEN>
<TOKEN id="token-32-23" pos="word" morph="none" start_char="5256" end_char="5256">a</TOKEN>
<TOKEN id="token-32-24" pos="word" morph="none" start_char="5258" end_char="5265">February</TOKEN>
<TOKEN id="token-32-25" pos="word" morph="none" start_char="5267" end_char="5272">social</TOKEN>
<TOKEN id="token-32-26" pos="word" morph="none" start_char="5274" end_char="5278">media</TOKEN>
<TOKEN id="token-32-27" pos="word" morph="none" start_char="5280" end_char="5283">post</TOKEN>
<TOKEN id="token-32-28" pos="word" morph="none" start_char="5285" end_char="5288">that</TOKEN>
<TOKEN id="token-32-29" pos="word" morph="none" start_char="5290" end_char="5292">she</TOKEN>
<TOKEN id="token-32-30" pos="word" morph="none" start_char="5294" end_char="5298">would</TOKEN>
<TOKEN id="token-32-31" pos="punct" morph="none" start_char="5300" end_char="5300">"</TOKEN>
<TOKEN id="token-32-32" pos="word" morph="none" start_char="5301" end_char="5305">swear</TOKEN>
<TOKEN id="token-32-33" pos="word" morph="none" start_char="5307" end_char="5308">on</TOKEN>
<TOKEN id="token-32-34" pos="word" morph="none" start_char="5310" end_char="5311">my</TOKEN>
<TOKEN id="token-32-35" pos="word" morph="none" start_char="5313" end_char="5316">life</TOKEN>
<TOKEN id="token-32-36" pos="punct" morph="none" start_char="5317" end_char="5317">"</TOKEN>
<TOKEN id="token-32-37" pos="word" morph="none" start_char="5319" end_char="5322">that</TOKEN>
<TOKEN id="token-32-38" pos="word" morph="none" start_char="5324" end_char="5326">the</TOKEN>
<TOKEN id="token-32-39" pos="word" morph="none" start_char="5328" end_char="5332">virus</TOKEN>
<TOKEN id="token-32-40" pos="word" morph="none" start_char="5334" end_char="5336">had</TOKEN>
<TOKEN id="token-32-41" pos="word" morph="none" start_char="5338" end_char="5344">nothing</TOKEN>
<TOKEN id="token-32-42" pos="word" morph="none" start_char="5346" end_char="5347">to</TOKEN>
<TOKEN id="token-32-43" pos="word" morph="none" start_char="5349" end_char="5350">do</TOKEN>
<TOKEN id="token-32-44" pos="word" morph="none" start_char="5352" end_char="5355">with</TOKEN>
<TOKEN id="token-32-45" pos="word" morph="none" start_char="5357" end_char="5359">the</TOKEN>
<TOKEN id="token-32-46" pos="word" morph="none" start_char="5361" end_char="5363">lab</TOKEN>
<TOKEN id="token-32-47" pos="punct" morph="none" start_char="5364" end_char="5364">.</TOKEN>
</SEG>
<SEG id="segment-33" start_char="5367" end_char="5373">
<ORIGINAL_TEXT>On Feb.</ORIGINAL_TEXT>
<TOKEN id="token-33-0" pos="word" morph="none" start_char="5367" end_char="5368">On</TOKEN>
<TOKEN id="token-33-1" pos="word" morph="none" start_char="5370" end_char="5372">Feb</TOKEN>
<TOKEN id="token-33-2" pos="punct" morph="none" start_char="5373" end_char="5373">.</TOKEN>
</SEG>
<SEG id="segment-34" start_char="5375" end_char="5522">
<ORIGINAL_TEXT>19, the Wuhan Institute of Virology issued a letter to staff, saying it received its first sample of the virus from Wuhan Jinyintan Hospital on Dec.</ORIGINAL_TEXT>
<TOKEN id="token-34-0" pos="word" morph="none" start_char="5375" end_char="5376">19</TOKEN>
<TOKEN id="token-34-1" pos="punct" morph="none" start_char="5377" end_char="5377">,</TOKEN>
<TOKEN id="token-34-2" pos="word" morph="none" start_char="5379" end_char="5381">the</TOKEN>
<TOKEN id="token-34-3" pos="word" morph="none" start_char="5383" end_char="5387">Wuhan</TOKEN>
<TOKEN id="token-34-4" pos="word" morph="none" start_char="5389" end_char="5397">Institute</TOKEN>
<TOKEN id="token-34-5" pos="word" morph="none" start_char="5399" end_char="5400">of</TOKEN>
<TOKEN id="token-34-6" pos="word" morph="none" start_char="5402" end_char="5409">Virology</TOKEN>
<TOKEN id="token-34-7" pos="word" morph="none" start_char="5411" end_char="5416">issued</TOKEN>
<TOKEN id="token-34-8" pos="word" morph="none" start_char="5418" end_char="5418">a</TOKEN>
<TOKEN id="token-34-9" pos="word" morph="none" start_char="5420" end_char="5425">letter</TOKEN>
<TOKEN id="token-34-10" pos="word" morph="none" start_char="5427" end_char="5428">to</TOKEN>
<TOKEN id="token-34-11" pos="word" morph="none" start_char="5430" end_char="5434">staff</TOKEN>
<TOKEN id="token-34-12" pos="punct" morph="none" start_char="5435" end_char="5435">,</TOKEN>
<TOKEN id="token-34-13" pos="word" morph="none" start_char="5437" end_char="5442">saying</TOKEN>
<TOKEN id="token-34-14" pos="word" morph="none" start_char="5444" end_char="5445">it</TOKEN>
<TOKEN id="token-34-15" pos="word" morph="none" start_char="5447" end_char="5454">received</TOKEN>
<TOKEN id="token-34-16" pos="word" morph="none" start_char="5456" end_char="5458">its</TOKEN>
<TOKEN id="token-34-17" pos="word" morph="none" start_char="5460" end_char="5464">first</TOKEN>
<TOKEN id="token-34-18" pos="word" morph="none" start_char="5466" end_char="5471">sample</TOKEN>
<TOKEN id="token-34-19" pos="word" morph="none" start_char="5473" end_char="5474">of</TOKEN>
<TOKEN id="token-34-20" pos="word" morph="none" start_char="5476" end_char="5478">the</TOKEN>
<TOKEN id="token-34-21" pos="word" morph="none" start_char="5480" end_char="5484">virus</TOKEN>
<TOKEN id="token-34-22" pos="word" morph="none" start_char="5486" end_char="5489">from</TOKEN>
<TOKEN id="token-34-23" pos="word" morph="none" start_char="5491" end_char="5495">Wuhan</TOKEN>
<TOKEN id="token-34-24" pos="word" morph="none" start_char="5497" end_char="5505">Jinyintan</TOKEN>
<TOKEN id="token-34-25" pos="word" morph="none" start_char="5507" end_char="5514">Hospital</TOKEN>
<TOKEN id="token-34-26" pos="word" morph="none" start_char="5516" end_char="5517">on</TOKEN>
<TOKEN id="token-34-27" pos="word" morph="none" start_char="5519" end_char="5521">Dec</TOKEN>
<TOKEN id="token-34-28" pos="punct" morph="none" start_char="5522" end_char="5522">.</TOKEN>
</SEG>
<SEG id="segment-35" start_char="5524" end_char="5602">
<ORIGINAL_TEXT>30, a day before Chinese authorities first disclosed the outbreak to the world.</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="5524" end_char="5525">30</TOKEN>
<TOKEN id="token-35-1" pos="punct" morph="none" start_char="5526" end_char="5526">,</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="5528" end_char="5528">a</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="5530" end_char="5532">day</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="5534" end_char="5539">before</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="5541" end_char="5547">Chinese</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="5549" end_char="5559">authorities</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="5561" end_char="5565">first</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="5567" end_char="5575">disclosed</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="5577" end_char="5579">the</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="5581" end_char="5588">outbreak</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="5590" end_char="5591">to</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="5593" end_char="5595">the</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="5597" end_char="5601">world</TOKEN>
<TOKEN id="token-35-14" pos="punct" morph="none" start_char="5602" end_char="5602">.</TOKEN>
</SEG>
<SEG id="segment-36" start_char="5604" end_char="5717">
<ORIGINAL_TEXT>Researchers finished gene-sequencing in 72 hours and submitted its findings to the national virus database by Jan.</ORIGINAL_TEXT>
<TOKEN id="token-36-0" pos="word" morph="none" start_char="5604" end_char="5614">Researchers</TOKEN>
<TOKEN id="token-36-1" pos="word" morph="none" start_char="5616" end_char="5623">finished</TOKEN>
<TOKEN id="token-36-2" pos="unknown" morph="none" start_char="5625" end_char="5639">gene-sequencing</TOKEN>
<TOKEN id="token-36-3" pos="word" morph="none" start_char="5641" end_char="5642">in</TOKEN>
<TOKEN id="token-36-4" pos="word" morph="none" start_char="5644" end_char="5645">72</TOKEN>
<TOKEN id="token-36-5" pos="word" morph="none" start_char="5647" end_char="5651">hours</TOKEN>
<TOKEN id="token-36-6" pos="word" morph="none" start_char="5653" end_char="5655">and</TOKEN>
<TOKEN id="token-36-7" pos="word" morph="none" start_char="5657" end_char="5665">submitted</TOKEN>
<TOKEN id="token-36-8" pos="word" morph="none" start_char="5667" end_char="5669">its</TOKEN>
<TOKEN id="token-36-9" pos="word" morph="none" start_char="5671" end_char="5678">findings</TOKEN>
<TOKEN id="token-36-10" pos="word" morph="none" start_char="5680" end_char="5681">to</TOKEN>
<TOKEN id="token-36-11" pos="word" morph="none" start_char="5683" end_char="5685">the</TOKEN>
<TOKEN id="token-36-12" pos="word" morph="none" start_char="5687" end_char="5694">national</TOKEN>
<TOKEN id="token-36-13" pos="word" morph="none" start_char="5696" end_char="5700">virus</TOKEN>
<TOKEN id="token-36-14" pos="word" morph="none" start_char="5702" end_char="5709">database</TOKEN>
<TOKEN id="token-36-15" pos="word" morph="none" start_char="5711" end_char="5712">by</TOKEN>
<TOKEN id="token-36-16" pos="word" morph="none" start_char="5714" end_char="5716">Jan</TOKEN>
<TOKEN id="token-36-17" pos="punct" morph="none" start_char="5717" end_char="5717">.</TOKEN>
</SEG>
<SEG id="segment-37" start_char="5719" end_char="5817">
<ORIGINAL_TEXT>9, the institute said, adding "we have a clear conscience looking back on what we’ve gone through."</ORIGINAL_TEXT>
<TOKEN id="token-37-0" pos="word" morph="none" start_char="5719" end_char="5719">9</TOKEN>
<TOKEN id="token-37-1" pos="punct" morph="none" start_char="5720" end_char="5720">,</TOKEN>
<TOKEN id="token-37-2" pos="word" morph="none" start_char="5722" end_char="5724">the</TOKEN>
<TOKEN id="token-37-3" pos="word" morph="none" start_char="5726" end_char="5734">institute</TOKEN>
<TOKEN id="token-37-4" pos="word" morph="none" start_char="5736" end_char="5739">said</TOKEN>
<TOKEN id="token-37-5" pos="punct" morph="none" start_char="5740" end_char="5740">,</TOKEN>
<TOKEN id="token-37-6" pos="word" morph="none" start_char="5742" end_char="5747">adding</TOKEN>
<TOKEN id="token-37-7" pos="punct" morph="none" start_char="5749" end_char="5749">"</TOKEN>
<TOKEN id="token-37-8" pos="word" morph="none" start_char="5750" end_char="5751">we</TOKEN>
<TOKEN id="token-37-9" pos="word" morph="none" start_char="5753" end_char="5756">have</TOKEN>
<TOKEN id="token-37-10" pos="word" morph="none" start_char="5758" end_char="5758">a</TOKEN>
<TOKEN id="token-37-11" pos="word" morph="none" start_char="5760" end_char="5764">clear</TOKEN>
<TOKEN id="token-37-12" pos="word" morph="none" start_char="5766" end_char="5775">conscience</TOKEN>
<TOKEN id="token-37-13" pos="word" morph="none" start_char="5777" end_char="5783">looking</TOKEN>
<TOKEN id="token-37-14" pos="word" morph="none" start_char="5785" end_char="5788">back</TOKEN>
<TOKEN id="token-37-15" pos="word" morph="none" start_char="5790" end_char="5791">on</TOKEN>
<TOKEN id="token-37-16" pos="word" morph="none" start_char="5793" end_char="5796">what</TOKEN>
<TOKEN id="token-37-17" pos="word" morph="none" start_char="5798" end_char="5802">we’ve</TOKEN>
<TOKEN id="token-37-18" pos="word" morph="none" start_char="5804" end_char="5807">gone</TOKEN>
<TOKEN id="token-37-19" pos="word" morph="none" start_char="5809" end_char="5815">through</TOKEN>
<TOKEN id="token-37-20" pos="punct" morph="none" start_char="5816" end_char="5817">."</TOKEN>
</SEG>
<SEG id="segment-38" start_char="5820" end_char="5864">
<ORIGINAL_TEXT>— With assistance by Sharon Chen, and Jing Li</ORIGINAL_TEXT>
<TOKEN id="token-38-0" pos="punct" morph="none" start_char="5820" end_char="5820">—</TOKEN>
<TOKEN id="token-38-1" pos="word" morph="none" start_char="5822" end_char="5825">With</TOKEN>
<TOKEN id="token-38-2" pos="word" morph="none" start_char="5827" end_char="5836">assistance</TOKEN>
<TOKEN id="token-38-3" pos="word" morph="none" start_char="5838" end_char="5839">by</TOKEN>
<TOKEN id="token-38-4" pos="word" morph="none" start_char="5841" end_char="5846">Sharon</TOKEN>
<TOKEN id="token-38-5" pos="word" morph="none" start_char="5848" end_char="5851">Chen</TOKEN>
<TOKEN id="token-38-6" pos="punct" morph="none" start_char="5852" end_char="5852">,</TOKEN>
<TOKEN id="token-38-7" pos="word" morph="none" start_char="5854" end_char="5856">and</TOKEN>
<TOKEN id="token-38-8" pos="word" morph="none" start_char="5858" end_char="5861">Jing</TOKEN>
<TOKEN id="token-38-9" pos="word" morph="none" start_char="5863" end_char="5864">Li</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
