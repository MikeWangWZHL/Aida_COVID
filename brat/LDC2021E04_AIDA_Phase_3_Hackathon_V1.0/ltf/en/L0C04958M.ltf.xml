<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="rus">
<DOC id="L0C04958M" lang="rus" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3198" raw_text_md5="a13c79dfbaf2fac2fd79a3a9d69182c4">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="105">
<ORIGINAL_TEXT>Disinfo: Coronavirus was created on purpose, probably by the same British lab which poisoned the Skripals</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="7">Disinfo</TOKEN>
<TOKEN id="token-0-1" pos="punct" morph="none" start_char="8" end_char="8">:</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="10" end_char="20">Coronavirus</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="22" end_char="24">was</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="26" end_char="32">created</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="34" end_char="35">on</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="37" end_char="43">purpose</TOKEN>
<TOKEN id="token-0-7" pos="punct" morph="none" start_char="44" end_char="44">,</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="46" end_char="53">probably</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="55" end_char="56">by</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="58" end_char="60">the</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="62" end_char="65">same</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="67" end_char="73">British</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="75" end_char="77">lab</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="79" end_char="83">which</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="85" end_char="92">poisoned</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="94" end_char="96">the</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="98" end_char="105">Skripals</TOKEN>
</SEG>
<SEG id="segment-1" start_char="109" end_char="170">
<ORIGINAL_TEXT>There is evidence that the coronavirus was created on purpose.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="109" end_char="113">There</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="115" end_char="116">is</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="118" end_char="125">evidence</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="127" end_char="130">that</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="132" end_char="134">the</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="136" end_char="146">coronavirus</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="148" end_char="150">was</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="152" end_char="158">created</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="160" end_char="161">on</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="163" end_char="169">purpose</TOKEN>
<TOKEN id="token-1-10" pos="punct" morph="none" start_char="170" end_char="170">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="172" end_char="250">
<ORIGINAL_TEXT>First of all, both the US and the UK have announced the existence of a vaccine.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="172" end_char="176">First</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="178" end_char="179">of</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="181" end_char="183">all</TOKEN>
<TOKEN id="token-2-3" pos="punct" morph="none" start_char="184" end_char="184">,</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="186" end_char="189">both</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="191" end_char="193">the</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="195" end_char="196">US</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="198" end_char="200">and</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="202" end_char="204">the</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="206" end_char="207">UK</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="209" end_char="212">have</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="214" end_char="222">announced</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="224" end_char="226">the</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="228" end_char="236">existence</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="238" end_char="239">of</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="241" end_char="241">a</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="243" end_char="249">vaccine</TOKEN>
<TOKEN id="token-2-17" pos="punct" morph="none" start_char="250" end_char="250">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="252" end_char="360">
<ORIGINAL_TEXT>But any expert knows that it’s not possible to create a vaccine against a virus, which was never seen before.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="252" end_char="254">But</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="256" end_char="258">any</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="260" end_char="265">expert</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="267" end_char="271">knows</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="273" end_char="276">that</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="278" end_char="281">it’s</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="283" end_char="285">not</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="287" end_char="294">possible</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="296" end_char="297">to</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="299" end_char="304">create</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="306" end_char="306">a</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="308" end_char="314">vaccine</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="316" end_char="322">against</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="324" end_char="324">a</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="326" end_char="330">virus</TOKEN>
<TOKEN id="token-3-15" pos="punct" morph="none" start_char="331" end_char="331">,</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="333" end_char="337">which</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="339" end_char="341">was</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="343" end_char="347">never</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="349" end_char="352">seen</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="354" end_char="359">before</TOKEN>
<TOKEN id="token-3-21" pos="punct" morph="none" start_char="360" end_char="360">.</TOKEN>
</SEG>
<SEG id="segment-4" start_char="362" end_char="542">
<ORIGINAL_TEXT>In UK the Porton Down laboratory, a quite well known organisation which has been dealing with chemical and biological weapons for a long time has said they already have the vaccine.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="362" end_char="363">In</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="365" end_char="366">UK</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="368" end_char="370">the</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="372" end_char="377">Porton</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="379" end_char="382">Down</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="384" end_char="393">laboratory</TOKEN>
<TOKEN id="token-4-6" pos="punct" morph="none" start_char="394" end_char="394">,</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="396" end_char="396">a</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="398" end_char="402">quite</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="404" end_char="407">well</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="409" end_char="413">known</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="415" end_char="426">organisation</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="428" end_char="432">which</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="434" end_char="436">has</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="438" end_char="441">been</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="443" end_char="449">dealing</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="451" end_char="454">with</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="456" end_char="463">chemical</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="465" end_char="467">and</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="469" end_char="478">biological</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="480" end_char="486">weapons</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="488" end_char="490">for</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="492" end_char="492">a</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="494" end_char="497">long</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="499" end_char="502">time</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="504" end_char="506">has</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="508" end_char="511">said</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="513" end_char="516">they</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="518" end_char="524">already</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="526" end_char="529">have</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="531" end_char="533">the</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="535" end_char="541">vaccine</TOKEN>
<TOKEN id="token-4-32" pos="punct" morph="none" start_char="542" end_char="542">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="544" end_char="606">
<ORIGINAL_TEXT>According to media, they have patented it already one year ago!</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="544" end_char="552">According</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="554" end_char="555">to</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="557" end_char="561">media</TOKEN>
<TOKEN id="token-5-3" pos="punct" morph="none" start_char="562" end_char="562">,</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="564" end_char="567">they</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="569" end_char="572">have</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="574" end_char="581">patented</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="583" end_char="584">it</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="586" end_char="592">already</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="594" end_char="596">one</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="598" end_char="601">year</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="603" end_char="605">ago</TOKEN>
<TOKEN id="token-5-12" pos="punct" morph="none" start_char="606" end_char="606">!</TOKEN>
</SEG>
<SEG id="segment-6" start_char="609" end_char="688">
<ORIGINAL_TEXT>This is the same organisation which put the poison on the Skripals’ door handle.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="609" end_char="612">This</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="614" end_char="615">is</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="617" end_char="619">the</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="621" end_char="624">same</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="626" end_char="637">organisation</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="639" end_char="643">which</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="645" end_char="647">put</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="649" end_char="651">the</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="653" end_char="658">poison</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="660" end_char="661">on</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="663" end_char="665">the</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="667" end_char="674">Skripals</TOKEN>
<TOKEN id="token-6-12" pos="punct" morph="none" start_char="675" end_char="675">’</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="677" end_char="680">door</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="682" end_char="687">handle</TOKEN>
<TOKEN id="token-6-15" pos="punct" morph="none" start_char="688" end_char="688">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="690" end_char="914">
<ORIGINAL_TEXT>Probably they put something also over the city of Wuhan, Hubei province, for example, on the door handle of the subway, or rather not the door handle but this one [thing, object] which is being touched by thousands of people.</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="word" morph="none" start_char="690" end_char="697">Probably</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="699" end_char="702">they</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="704" end_char="706">put</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="708" end_char="716">something</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="718" end_char="721">also</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="723" end_char="726">over</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="728" end_char="730">the</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="732" end_char="735">city</TOKEN>
<TOKEN id="token-7-8" pos="word" morph="none" start_char="737" end_char="738">of</TOKEN>
<TOKEN id="token-7-9" pos="word" morph="none" start_char="740" end_char="744">Wuhan</TOKEN>
<TOKEN id="token-7-10" pos="punct" morph="none" start_char="745" end_char="745">,</TOKEN>
<TOKEN id="token-7-11" pos="word" morph="none" start_char="747" end_char="751">Hubei</TOKEN>
<TOKEN id="token-7-12" pos="word" morph="none" start_char="753" end_char="760">province</TOKEN>
<TOKEN id="token-7-13" pos="punct" morph="none" start_char="761" end_char="761">,</TOKEN>
<TOKEN id="token-7-14" pos="word" morph="none" start_char="763" end_char="765">for</TOKEN>
<TOKEN id="token-7-15" pos="word" morph="none" start_char="767" end_char="773">example</TOKEN>
<TOKEN id="token-7-16" pos="punct" morph="none" start_char="774" end_char="774">,</TOKEN>
<TOKEN id="token-7-17" pos="word" morph="none" start_char="776" end_char="777">on</TOKEN>
<TOKEN id="token-7-18" pos="word" morph="none" start_char="779" end_char="781">the</TOKEN>
<TOKEN id="token-7-19" pos="word" morph="none" start_char="783" end_char="786">door</TOKEN>
<TOKEN id="token-7-20" pos="word" morph="none" start_char="788" end_char="793">handle</TOKEN>
<TOKEN id="token-7-21" pos="word" morph="none" start_char="795" end_char="796">of</TOKEN>
<TOKEN id="token-7-22" pos="word" morph="none" start_char="798" end_char="800">the</TOKEN>
<TOKEN id="token-7-23" pos="word" morph="none" start_char="802" end_char="807">subway</TOKEN>
<TOKEN id="token-7-24" pos="punct" morph="none" start_char="808" end_char="808">,</TOKEN>
<TOKEN id="token-7-25" pos="word" morph="none" start_char="810" end_char="811">or</TOKEN>
<TOKEN id="token-7-26" pos="word" morph="none" start_char="813" end_char="818">rather</TOKEN>
<TOKEN id="token-7-27" pos="word" morph="none" start_char="820" end_char="822">not</TOKEN>
<TOKEN id="token-7-28" pos="word" morph="none" start_char="824" end_char="826">the</TOKEN>
<TOKEN id="token-7-29" pos="word" morph="none" start_char="828" end_char="831">door</TOKEN>
<TOKEN id="token-7-30" pos="word" morph="none" start_char="833" end_char="838">handle</TOKEN>
<TOKEN id="token-7-31" pos="word" morph="none" start_char="840" end_char="842">but</TOKEN>
<TOKEN id="token-7-32" pos="word" morph="none" start_char="844" end_char="847">this</TOKEN>
<TOKEN id="token-7-33" pos="word" morph="none" start_char="849" end_char="851">one</TOKEN>
<TOKEN id="token-7-34" pos="punct" morph="none" start_char="853" end_char="853">[</TOKEN>
<TOKEN id="token-7-35" pos="word" morph="none" start_char="854" end_char="858">thing</TOKEN>
<TOKEN id="token-7-36" pos="punct" morph="none" start_char="859" end_char="859">,</TOKEN>
<TOKEN id="token-7-37" pos="word" morph="none" start_char="861" end_char="866">object</TOKEN>
<TOKEN id="token-7-38" pos="punct" morph="none" start_char="867" end_char="867">]</TOKEN>
<TOKEN id="token-7-39" pos="word" morph="none" start_char="869" end_char="873">which</TOKEN>
<TOKEN id="token-7-40" pos="word" morph="none" start_char="875" end_char="876">is</TOKEN>
<TOKEN id="token-7-41" pos="word" morph="none" start_char="878" end_char="882">being</TOKEN>
<TOKEN id="token-7-42" pos="word" morph="none" start_char="884" end_char="890">touched</TOKEN>
<TOKEN id="token-7-43" pos="word" morph="none" start_char="892" end_char="893">by</TOKEN>
<TOKEN id="token-7-44" pos="word" morph="none" start_char="895" end_char="903">thousands</TOKEN>
<TOKEN id="token-7-45" pos="word" morph="none" start_char="905" end_char="906">of</TOKEN>
<TOKEN id="token-7-46" pos="word" morph="none" start_char="908" end_char="913">people</TOKEN>
<TOKEN id="token-7-47" pos="punct" morph="none" start_char="914" end_char="914">.</TOKEN>
</SEG>
<SEG id="segment-8" start_char="916" end_char="964">
<ORIGINAL_TEXT>Unfortunately, we can’t exclude such a situation.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="916" end_char="928">Unfortunately</TOKEN>
<TOKEN id="token-8-1" pos="punct" morph="none" start_char="929" end_char="929">,</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="931" end_char="932">we</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="934" end_char="938">can’t</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="940" end_char="946">exclude</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="948" end_char="951">such</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="953" end_char="953">a</TOKEN>
<TOKEN id="token-8-7" pos="word" morph="none" start_char="955" end_char="963">situation</TOKEN>
<TOKEN id="token-8-8" pos="punct" morph="none" start_char="964" end_char="964">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="966" end_char="1110">
<ORIGINAL_TEXT>It can be an act of biological sabotage, it might have been carried out not by a State, for example, the US, but by certain private corporations.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="966" end_char="967">It</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="969" end_char="971">can</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="973" end_char="974">be</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="976" end_char="977">an</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="979" end_char="981">act</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="983" end_char="984">of</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="986" end_char="995">biological</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="997" end_char="1004">sabotage</TOKEN>
<TOKEN id="token-9-8" pos="punct" morph="none" start_char="1005" end_char="1005">,</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1007" end_char="1008">it</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1010" end_char="1014">might</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1016" end_char="1019">have</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1021" end_char="1024">been</TOKEN>
<TOKEN id="token-9-13" pos="word" morph="none" start_char="1026" end_char="1032">carried</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1034" end_char="1036">out</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1038" end_char="1040">not</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1042" end_char="1043">by</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1045" end_char="1045">a</TOKEN>
<TOKEN id="token-9-18" pos="word" morph="none" start_char="1047" end_char="1051">State</TOKEN>
<TOKEN id="token-9-19" pos="punct" morph="none" start_char="1052" end_char="1052">,</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1054" end_char="1056">for</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1058" end_char="1064">example</TOKEN>
<TOKEN id="token-9-22" pos="punct" morph="none" start_char="1065" end_char="1065">,</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1067" end_char="1069">the</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1071" end_char="1072">US</TOKEN>
<TOKEN id="token-9-25" pos="punct" morph="none" start_char="1073" end_char="1073">,</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1075" end_char="1077">but</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1079" end_char="1080">by</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1082" end_char="1088">certain</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1090" end_char="1096">private</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1098" end_char="1109">corporations</TOKEN>
<TOKEN id="token-9-31" pos="punct" morph="none" start_char="1110" end_char="1110">.</TOKEN>
</SEG>
<SEG id="segment-10" start_char="1112" end_char="1245">
<ORIGINAL_TEXT>The appearance of such beneficiaries able to go on market already tomorrow with an already made vaccine is a not direct proof of that.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="1112" end_char="1114">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="1116" end_char="1125">appearance</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="1127" end_char="1128">of</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="1130" end_char="1133">such</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="1135" end_char="1147">beneficiaries</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="1149" end_char="1152">able</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="1154" end_char="1155">to</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="1157" end_char="1158">go</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="1160" end_char="1161">on</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1163" end_char="1168">market</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1170" end_char="1176">already</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1178" end_char="1185">tomorrow</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1187" end_char="1190">with</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1192" end_char="1193">an</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1195" end_char="1201">already</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1203" end_char="1206">made</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1208" end_char="1214">vaccine</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1216" end_char="1217">is</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1219" end_char="1219">a</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1221" end_char="1223">not</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1225" end_char="1230">direct</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1232" end_char="1236">proof</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1238" end_char="1239">of</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1241" end_char="1244">that</TOKEN>
<TOKEN id="token-10-24" pos="punct" morph="none" start_char="1245" end_char="1245">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1248" end_char="1420">
<ORIGINAL_TEXT>The statement has no supporting evidence and is another example of conspiracy narratives on a plot against China, profitable to the US; on the UK which invented coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1248" end_char="1250">The</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1252" end_char="1260">statement</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1262" end_char="1264">has</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1266" end_char="1267">no</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1269" end_char="1278">supporting</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="1280" end_char="1287">evidence</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="1289" end_char="1291">and</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="1293" end_char="1294">is</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="1296" end_char="1302">another</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="1304" end_char="1310">example</TOKEN>
<TOKEN id="token-11-10" pos="word" morph="none" start_char="1312" end_char="1313">of</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="1315" end_char="1324">conspiracy</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="1326" end_char="1335">narratives</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="1337" end_char="1338">on</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="1340" end_char="1340">a</TOKEN>
<TOKEN id="token-11-15" pos="word" morph="none" start_char="1342" end_char="1345">plot</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="1347" end_char="1353">against</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="1355" end_char="1359">China</TOKEN>
<TOKEN id="token-11-18" pos="punct" morph="none" start_char="1360" end_char="1360">,</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="1362" end_char="1371">profitable</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="1373" end_char="1374">to</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="1376" end_char="1378">the</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="1380" end_char="1381">US</TOKEN>
<TOKEN id="token-11-23" pos="punct" morph="none" start_char="1382" end_char="1382">;</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="1384" end_char="1385">on</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="1387" end_char="1389">the</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="1391" end_char="1392">UK</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="1394" end_char="1398">which</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="1400" end_char="1407">invented</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="1409" end_char="1419">coronavirus</TOKEN>
<TOKEN id="token-11-30" pos="punct" morph="none" start_char="1420" end_char="1420">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1422" end_char="1491">
<ORIGINAL_TEXT>See more examples of groundless statements about the coronavirus here.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1422" end_char="1424">See</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1426" end_char="1429">more</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1431" end_char="1438">examples</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1440" end_char="1441">of</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1443" end_char="1452">groundless</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1454" end_char="1463">statements</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1465" end_char="1469">about</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1471" end_char="1473">the</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1475" end_char="1485">coronavirus</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1487" end_char="1490">here</TOKEN>
<TOKEN id="token-12-10" pos="punct" morph="none" start_char="1491" end_char="1491">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1494" end_char="1609">
<ORIGINAL_TEXT>The current coronavirus (2019-nCoV) comes from a family of viruses that include other viruses such as SARS and MERS.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1494" end_char="1496">The</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1498" end_char="1504">current</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1506" end_char="1516">coronavirus</TOKEN>
<TOKEN id="token-13-3" pos="punct" morph="none" start_char="1518" end_char="1518">(</TOKEN>
<TOKEN id="token-13-4" pos="unknown" morph="none" start_char="1519" end_char="1527">2019-nCoV</TOKEN>
<TOKEN id="token-13-5" pos="punct" morph="none" start_char="1528" end_char="1528">)</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1530" end_char="1534">comes</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1536" end_char="1539">from</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1541" end_char="1541">a</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1543" end_char="1548">family</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1550" end_char="1551">of</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1553" end_char="1559">viruses</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="1561" end_char="1564">that</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1566" end_char="1572">include</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1574" end_char="1578">other</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1580" end_char="1586">viruses</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1588" end_char="1591">such</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1593" end_char="1594">as</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1596" end_char="1599">SARS</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1601" end_char="1603">and</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1605" end_char="1608">MERS</TOKEN>
<TOKEN id="token-13-21" pos="punct" morph="none" start_char="1609" end_char="1609">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1611" end_char="1869">
<ORIGINAL_TEXT>It was first reported in the Chinese city of Wuhan in central China and has been rapidly spreading with new cases being reported in the Asia-Pacific region as well as Europe, North America and the Middle East, causing more than 700 deaths by 10 February 2020.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1611" end_char="1612">It</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1614" end_char="1616">was</TOKEN>
<TOKEN id="token-14-2" pos="word" morph="none" start_char="1618" end_char="1622">first</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1624" end_char="1631">reported</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1633" end_char="1634">in</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1636" end_char="1638">the</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1640" end_char="1646">Chinese</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1648" end_char="1651">city</TOKEN>
<TOKEN id="token-14-8" pos="word" morph="none" start_char="1653" end_char="1654">of</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1656" end_char="1660">Wuhan</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1662" end_char="1663">in</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1665" end_char="1671">central</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1673" end_char="1677">China</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1679" end_char="1681">and</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1683" end_char="1685">has</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1687" end_char="1690">been</TOKEN>
<TOKEN id="token-14-16" pos="word" morph="none" start_char="1692" end_char="1698">rapidly</TOKEN>
<TOKEN id="token-14-17" pos="word" morph="none" start_char="1700" end_char="1708">spreading</TOKEN>
<TOKEN id="token-14-18" pos="word" morph="none" start_char="1710" end_char="1713">with</TOKEN>
<TOKEN id="token-14-19" pos="word" morph="none" start_char="1715" end_char="1717">new</TOKEN>
<TOKEN id="token-14-20" pos="word" morph="none" start_char="1719" end_char="1723">cases</TOKEN>
<TOKEN id="token-14-21" pos="word" morph="none" start_char="1725" end_char="1729">being</TOKEN>
<TOKEN id="token-14-22" pos="word" morph="none" start_char="1731" end_char="1738">reported</TOKEN>
<TOKEN id="token-14-23" pos="word" morph="none" start_char="1740" end_char="1741">in</TOKEN>
<TOKEN id="token-14-24" pos="word" morph="none" start_char="1743" end_char="1745">the</TOKEN>
<TOKEN id="token-14-25" pos="unknown" morph="none" start_char="1747" end_char="1758">Asia-Pacific</TOKEN>
<TOKEN id="token-14-26" pos="word" morph="none" start_char="1760" end_char="1765">region</TOKEN>
<TOKEN id="token-14-27" pos="word" morph="none" start_char="1767" end_char="1768">as</TOKEN>
<TOKEN id="token-14-28" pos="word" morph="none" start_char="1770" end_char="1773">well</TOKEN>
<TOKEN id="token-14-29" pos="word" morph="none" start_char="1775" end_char="1776">as</TOKEN>
<TOKEN id="token-14-30" pos="word" morph="none" start_char="1778" end_char="1783">Europe</TOKEN>
<TOKEN id="token-14-31" pos="punct" morph="none" start_char="1784" end_char="1784">,</TOKEN>
<TOKEN id="token-14-32" pos="word" morph="none" start_char="1786" end_char="1790">North</TOKEN>
<TOKEN id="token-14-33" pos="word" morph="none" start_char="1792" end_char="1798">America</TOKEN>
<TOKEN id="token-14-34" pos="word" morph="none" start_char="1800" end_char="1802">and</TOKEN>
<TOKEN id="token-14-35" pos="word" morph="none" start_char="1804" end_char="1806">the</TOKEN>
<TOKEN id="token-14-36" pos="word" morph="none" start_char="1808" end_char="1813">Middle</TOKEN>
<TOKEN id="token-14-37" pos="word" morph="none" start_char="1815" end_char="1818">East</TOKEN>
<TOKEN id="token-14-38" pos="punct" morph="none" start_char="1819" end_char="1819">,</TOKEN>
<TOKEN id="token-14-39" pos="word" morph="none" start_char="1821" end_char="1827">causing</TOKEN>
<TOKEN id="token-14-40" pos="word" morph="none" start_char="1829" end_char="1832">more</TOKEN>
<TOKEN id="token-14-41" pos="word" morph="none" start_char="1834" end_char="1837">than</TOKEN>
<TOKEN id="token-14-42" pos="word" morph="none" start_char="1839" end_char="1841">700</TOKEN>
<TOKEN id="token-14-43" pos="word" morph="none" start_char="1843" end_char="1848">deaths</TOKEN>
<TOKEN id="token-14-44" pos="word" morph="none" start_char="1850" end_char="1851">by</TOKEN>
<TOKEN id="token-14-45" pos="word" morph="none" start_char="1853" end_char="1854">10</TOKEN>
<TOKEN id="token-14-46" pos="word" morph="none" start_char="1856" end_char="1863">February</TOKEN>
<TOKEN id="token-14-47" pos="word" morph="none" start_char="1865" end_char="1868">2020</TOKEN>
<TOKEN id="token-14-48" pos="punct" morph="none" start_char="1869" end_char="1869">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1872" end_char="1996">
<ORIGINAL_TEXT>The identity of the animal source of the coronavirus, named nCoV-2019, has been one of the key questions for the researchers.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1872" end_char="1874">The</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1876" end_char="1883">identity</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1885" end_char="1886">of</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1888" end_char="1890">the</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1892" end_char="1897">animal</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1899" end_char="1904">source</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1906" end_char="1907">of</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1909" end_char="1911">the</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1913" end_char="1923">coronavirus</TOKEN>
<TOKEN id="token-15-9" pos="punct" morph="none" start_char="1924" end_char="1924">,</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1926" end_char="1930">named</TOKEN>
<TOKEN id="token-15-11" pos="unknown" morph="none" start_char="1932" end_char="1940">nCoV-2019</TOKEN>
<TOKEN id="token-15-12" pos="punct" morph="none" start_char="1941" end_char="1941">,</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1943" end_char="1945">has</TOKEN>
<TOKEN id="token-15-14" pos="word" morph="none" start_char="1947" end_char="1950">been</TOKEN>
<TOKEN id="token-15-15" pos="word" morph="none" start_char="1952" end_char="1954">one</TOKEN>
<TOKEN id="token-15-16" pos="word" morph="none" start_char="1956" end_char="1957">of</TOKEN>
<TOKEN id="token-15-17" pos="word" morph="none" start_char="1959" end_char="1961">the</TOKEN>
<TOKEN id="token-15-18" pos="word" morph="none" start_char="1963" end_char="1965">key</TOKEN>
<TOKEN id="token-15-19" pos="word" morph="none" start_char="1967" end_char="1975">questions</TOKEN>
<TOKEN id="token-15-20" pos="word" morph="none" start_char="1977" end_char="1979">for</TOKEN>
<TOKEN id="token-15-21" pos="word" morph="none" start_char="1981" end_char="1983">the</TOKEN>
<TOKEN id="token-15-22" pos="word" morph="none" start_char="1985" end_char="1995">researchers</TOKEN>
<TOKEN id="token-15-23" pos="punct" morph="none" start_char="1996" end_char="1996">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1998" end_char="2135">
<ORIGINAL_TEXT>Coronaviruses are known to circulate in mammals and birds, and scientists have already suggested that nCoV-2019 originally came from bats.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1998" end_char="2010">Coronaviruses</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="2012" end_char="2014">are</TOKEN>
<TOKEN id="token-16-2" pos="word" morph="none" start_char="2016" end_char="2020">known</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="2022" end_char="2023">to</TOKEN>
<TOKEN id="token-16-4" pos="word" morph="none" start_char="2025" end_char="2033">circulate</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="2035" end_char="2036">in</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="2038" end_char="2044">mammals</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="2046" end_char="2048">and</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="2050" end_char="2054">birds</TOKEN>
<TOKEN id="token-16-9" pos="punct" morph="none" start_char="2055" end_char="2055">,</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="2057" end_char="2059">and</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="2061" end_char="2070">scientists</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="2072" end_char="2075">have</TOKEN>
<TOKEN id="token-16-13" pos="word" morph="none" start_char="2077" end_char="2083">already</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="2085" end_char="2093">suggested</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="2095" end_char="2098">that</TOKEN>
<TOKEN id="token-16-16" pos="unknown" morph="none" start_char="2100" end_char="2108">nCoV-2019</TOKEN>
<TOKEN id="token-16-17" pos="word" morph="none" start_char="2110" end_char="2119">originally</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="2121" end_char="2124">came</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="2126" end_char="2129">from</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="2131" end_char="2134">bats</TOKEN>
<TOKEN id="token-16-21" pos="punct" morph="none" start_char="2135" end_char="2135">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="2137" end_char="2267">
<ORIGINAL_TEXT>One of the previous coronaviruses that caused severe acute respiratory syndrome, or SARS, spread from bats to civet cats to humans.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="2137" end_char="2139">One</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="2141" end_char="2142">of</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="2144" end_char="2146">the</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="2148" end_char="2155">previous</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="2157" end_char="2169">coronaviruses</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="2171" end_char="2174">that</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="2176" end_char="2181">caused</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="2183" end_char="2188">severe</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="2190" end_char="2194">acute</TOKEN>
<TOKEN id="token-17-9" pos="word" morph="none" start_char="2196" end_char="2206">respiratory</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="2208" end_char="2215">syndrome</TOKEN>
<TOKEN id="token-17-11" pos="punct" morph="none" start_char="2216" end_char="2216">,</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="2218" end_char="2219">or</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="2221" end_char="2224">SARS</TOKEN>
<TOKEN id="token-17-14" pos="punct" morph="none" start_char="2225" end_char="2225">,</TOKEN>
<TOKEN id="token-17-15" pos="word" morph="none" start_char="2227" end_char="2232">spread</TOKEN>
<TOKEN id="token-17-16" pos="word" morph="none" start_char="2234" end_char="2237">from</TOKEN>
<TOKEN id="token-17-17" pos="word" morph="none" start_char="2239" end_char="2242">bats</TOKEN>
<TOKEN id="token-17-18" pos="word" morph="none" start_char="2244" end_char="2245">to</TOKEN>
<TOKEN id="token-17-19" pos="word" morph="none" start_char="2247" end_char="2251">civet</TOKEN>
<TOKEN id="token-17-20" pos="word" morph="none" start_char="2253" end_char="2256">cats</TOKEN>
<TOKEN id="token-17-21" pos="word" morph="none" start_char="2258" end_char="2259">to</TOKEN>
<TOKEN id="token-17-22" pos="word" morph="none" start_char="2261" end_char="2266">humans</TOKEN>
<TOKEN id="token-17-23" pos="punct" morph="none" start_char="2267" end_char="2267">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="2270" end_char="2426">
<ORIGINAL_TEXT>Now, the South China Agricultural University in Guangzhou says that two of its researchers have identified the pangolin as the potential source of nCoV-2019.</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="2270" end_char="2272">Now</TOKEN>
<TOKEN id="token-18-1" pos="punct" morph="none" start_char="2273" end_char="2273">,</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="2275" end_char="2277">the</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="2279" end_char="2283">South</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="2285" end_char="2289">China</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="2291" end_char="2302">Agricultural</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="2304" end_char="2313">University</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="2315" end_char="2316">in</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="2318" end_char="2326">Guangzhou</TOKEN>
<TOKEN id="token-18-9" pos="word" morph="none" start_char="2328" end_char="2331">says</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="2333" end_char="2336">that</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="2338" end_char="2340">two</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="2342" end_char="2343">of</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="2345" end_char="2347">its</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="2349" end_char="2359">researchers</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="2361" end_char="2364">have</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="2366" end_char="2375">identified</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="2377" end_char="2379">the</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="2381" end_char="2388">pangolin</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="2390" end_char="2391">as</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="2393" end_char="2395">the</TOKEN>
<TOKEN id="token-18-21" pos="word" morph="none" start_char="2397" end_char="2405">potential</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="2407" end_char="2412">source</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="2414" end_char="2415">of</TOKEN>
<TOKEN id="token-18-24" pos="unknown" morph="none" start_char="2417" end_char="2425">nCoV-2019</TOKEN>
<TOKEN id="token-18-25" pos="punct" morph="none" start_char="2426" end_char="2426">.</TOKEN>
</SEG>
<SEG id="segment-19" start_char="2428" end_char="2500">
<ORIGINAL_TEXT>This was announced to reporters at a press conference on 7 February 2020.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="2428" end_char="2431">This</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="2433" end_char="2435">was</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="2437" end_char="2445">announced</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="2447" end_char="2448">to</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="2450" end_char="2458">reporters</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="2460" end_char="2461">at</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="2463" end_char="2463">a</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="2465" end_char="2469">press</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="2471" end_char="2480">conference</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="2482" end_char="2483">on</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="2485" end_char="2485">7</TOKEN>
<TOKEN id="token-19-11" pos="word" morph="none" start_char="2487" end_char="2494">February</TOKEN>
<TOKEN id="token-19-12" pos="word" morph="none" start_char="2496" end_char="2499">2020</TOKEN>
<TOKEN id="token-19-13" pos="punct" morph="none" start_char="2500" end_char="2500">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="2503" end_char="2652">
<ORIGINAL_TEXT>As for the statement that British scientists from Porton Down laboratory put poison on the Skripals' door handle, it is not supported by any evidence.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="2503" end_char="2504">As</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="2506" end_char="2508">for</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="2510" end_char="2512">the</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="2514" end_char="2522">statement</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="2524" end_char="2527">that</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2529" end_char="2535">British</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2537" end_char="2546">scientists</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2548" end_char="2551">from</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2553" end_char="2558">Porton</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2560" end_char="2563">Down</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2565" end_char="2574">laboratory</TOKEN>
<TOKEN id="token-20-11" pos="word" morph="none" start_char="2576" end_char="2578">put</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2580" end_char="2585">poison</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2587" end_char="2588">on</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2590" end_char="2592">the</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2594" end_char="2601">Skripals</TOKEN>
<TOKEN id="token-20-16" pos="punct" morph="none" start_char="2602" end_char="2602">'</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2604" end_char="2607">door</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2609" end_char="2614">handle</TOKEN>
<TOKEN id="token-20-19" pos="punct" morph="none" start_char="2615" end_char="2615">,</TOKEN>
<TOKEN id="token-20-20" pos="word" morph="none" start_char="2617" end_char="2618">it</TOKEN>
<TOKEN id="token-20-21" pos="word" morph="none" start_char="2620" end_char="2621">is</TOKEN>
<TOKEN id="token-20-22" pos="word" morph="none" start_char="2623" end_char="2625">not</TOKEN>
<TOKEN id="token-20-23" pos="word" morph="none" start_char="2627" end_char="2635">supported</TOKEN>
<TOKEN id="token-20-24" pos="word" morph="none" start_char="2637" end_char="2638">by</TOKEN>
<TOKEN id="token-20-25" pos="word" morph="none" start_char="2640" end_char="2642">any</TOKEN>
<TOKEN id="token-20-26" pos="word" morph="none" start_char="2644" end_char="2651">evidence</TOKEN>
<TOKEN id="token-20-27" pos="punct" morph="none" start_char="2652" end_char="2652">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2654" end_char="2888">
<ORIGINAL_TEXT>British police and intelligence investigations have produced hard forensic evidence which was sufficient to charge two Russian nationals, identified as officers of the Russian Military Intelligence, GRU, for the attack on the Skripals.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2654" end_char="2660">British</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2662" end_char="2667">police</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2669" end_char="2671">and</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2673" end_char="2684">intelligence</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2686" end_char="2699">investigations</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2701" end_char="2704">have</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2706" end_char="2713">produced</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2715" end_char="2718">hard</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2720" end_char="2727">forensic</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2729" end_char="2736">evidence</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2738" end_char="2742">which</TOKEN>
<TOKEN id="token-21-11" pos="word" morph="none" start_char="2744" end_char="2746">was</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2748" end_char="2757">sufficient</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2759" end_char="2760">to</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2762" end_char="2767">charge</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2769" end_char="2771">two</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2773" end_char="2779">Russian</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2781" end_char="2789">nationals</TOKEN>
<TOKEN id="token-21-18" pos="punct" morph="none" start_char="2790" end_char="2790">,</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2792" end_char="2801">identified</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2803" end_char="2804">as</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2806" end_char="2813">officers</TOKEN>
<TOKEN id="token-21-22" pos="word" morph="none" start_char="2815" end_char="2816">of</TOKEN>
<TOKEN id="token-21-23" pos="word" morph="none" start_char="2818" end_char="2820">the</TOKEN>
<TOKEN id="token-21-24" pos="word" morph="none" start_char="2822" end_char="2828">Russian</TOKEN>
<TOKEN id="token-21-25" pos="word" morph="none" start_char="2830" end_char="2837">Military</TOKEN>
<TOKEN id="token-21-26" pos="word" morph="none" start_char="2839" end_char="2850">Intelligence</TOKEN>
<TOKEN id="token-21-27" pos="punct" morph="none" start_char="2851" end_char="2851">,</TOKEN>
<TOKEN id="token-21-28" pos="word" morph="none" start_char="2853" end_char="2855">GRU</TOKEN>
<TOKEN id="token-21-29" pos="punct" morph="none" start_char="2856" end_char="2856">,</TOKEN>
<TOKEN id="token-21-30" pos="word" morph="none" start_char="2858" end_char="2860">for</TOKEN>
<TOKEN id="token-21-31" pos="word" morph="none" start_char="2862" end_char="2864">the</TOKEN>
<TOKEN id="token-21-32" pos="word" morph="none" start_char="2866" end_char="2871">attack</TOKEN>
<TOKEN id="token-21-33" pos="word" morph="none" start_char="2873" end_char="2874">on</TOKEN>
<TOKEN id="token-21-34" pos="word" morph="none" start_char="2876" end_char="2878">the</TOKEN>
<TOKEN id="token-21-35" pos="word" morph="none" start_char="2880" end_char="2887">Skripals</TOKEN>
<TOKEN id="token-21-36" pos="punct" morph="none" start_char="2888" end_char="2888">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2890" end_char="2942">
<ORIGINAL_TEXT>Part of the material has been released to the public.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2890" end_char="2893">Part</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2895" end_char="2896">of</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2898" end_char="2900">the</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2902" end_char="2909">material</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2911" end_char="2913">has</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2915" end_char="2918">been</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2920" end_char="2927">released</TOKEN>
<TOKEN id="token-22-7" pos="word" morph="none" start_char="2929" end_char="2930">to</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2932" end_char="2934">the</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2936" end_char="2941">public</TOKEN>
<TOKEN id="token-22-10" pos="punct" morph="none" start_char="2942" end_char="2942">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2945" end_char="3131">
<ORIGINAL_TEXT>See previous pro-Kremlin disinformation cases, alleging that cancer, syphilis and Spanish flu are US biological weapons and that the Rockefeller foundation owns the patent for Zika virus.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2945" end_char="2947">See</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2949" end_char="2956">previous</TOKEN>
<TOKEN id="token-23-2" pos="unknown" morph="none" start_char="2958" end_char="2968">pro-Kremlin</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2970" end_char="2983">disinformation</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2985" end_char="2989">cases</TOKEN>
<TOKEN id="token-23-5" pos="punct" morph="none" start_char="2990" end_char="2990">,</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2992" end_char="2999">alleging</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="3001" end_char="3004">that</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="3006" end_char="3011">cancer</TOKEN>
<TOKEN id="token-23-9" pos="punct" morph="none" start_char="3012" end_char="3012">,</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="3014" end_char="3021">syphilis</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="3023" end_char="3025">and</TOKEN>
<TOKEN id="token-23-12" pos="word" morph="none" start_char="3027" end_char="3033">Spanish</TOKEN>
<TOKEN id="token-23-13" pos="word" morph="none" start_char="3035" end_char="3037">flu</TOKEN>
<TOKEN id="token-23-14" pos="word" morph="none" start_char="3039" end_char="3041">are</TOKEN>
<TOKEN id="token-23-15" pos="word" morph="none" start_char="3043" end_char="3044">US</TOKEN>
<TOKEN id="token-23-16" pos="word" morph="none" start_char="3046" end_char="3055">biological</TOKEN>
<TOKEN id="token-23-17" pos="word" morph="none" start_char="3057" end_char="3063">weapons</TOKEN>
<TOKEN id="token-23-18" pos="word" morph="none" start_char="3065" end_char="3067">and</TOKEN>
<TOKEN id="token-23-19" pos="word" morph="none" start_char="3069" end_char="3072">that</TOKEN>
<TOKEN id="token-23-20" pos="word" morph="none" start_char="3074" end_char="3076">the</TOKEN>
<TOKEN id="token-23-21" pos="word" morph="none" start_char="3078" end_char="3088">Rockefeller</TOKEN>
<TOKEN id="token-23-22" pos="word" morph="none" start_char="3090" end_char="3099">foundation</TOKEN>
<TOKEN id="token-23-23" pos="word" morph="none" start_char="3101" end_char="3104">owns</TOKEN>
<TOKEN id="token-23-24" pos="word" morph="none" start_char="3106" end_char="3108">the</TOKEN>
<TOKEN id="token-23-25" pos="word" morph="none" start_char="3110" end_char="3115">patent</TOKEN>
<TOKEN id="token-23-26" pos="word" morph="none" start_char="3117" end_char="3119">for</TOKEN>
<TOKEN id="token-23-27" pos="word" morph="none" start_char="3121" end_char="3124">Zika</TOKEN>
<TOKEN id="token-23-28" pos="word" morph="none" start_char="3126" end_char="3130">virus</TOKEN>
<TOKEN id="token-23-29" pos="punct" morph="none" start_char="3131" end_char="3131">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="3133" end_char="3194">
<ORIGINAL_TEXT>See also more disinformation cases on the Skripal's poisoning.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="3133" end_char="3135">See</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="3137" end_char="3140">also</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="3142" end_char="3145">more</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="3147" end_char="3160">disinformation</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="3162" end_char="3166">cases</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="3168" end_char="3169">on</TOKEN>
<TOKEN id="token-24-6" pos="word" morph="none" start_char="3171" end_char="3173">the</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="3175" end_char="3183">Skripal's</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="3185" end_char="3193">poisoning</TOKEN>
<TOKEN id="token-24-9" pos="punct" morph="none" start_char="3194" end_char="3194">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
