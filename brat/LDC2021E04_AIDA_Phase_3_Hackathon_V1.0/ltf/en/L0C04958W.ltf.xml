<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT lang="rus">
<DOC id="L0C04958W" lang="rus" tokenization="tokenization_parameters.v5.0" grammar="none" raw_text_char_length="3196" raw_text_md5="8af97b20dc6e28d2af6cfe841a571b55">
<TEXT>
<SEG id="segment-0" start_char="1" end_char="77">
<ORIGINAL_TEXT>No evidence that Chinese officials will say coronavirus was leaked from a lab</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="1" end_char="2">No</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="4" end_char="11">evidence</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="13" end_char="16">that</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="18" end_char="24">Chinese</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="26" end_char="34">officials</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="36" end_char="39">will</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="41" end_char="43">say</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="45" end_char="55">coronavirus</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="57" end_char="59">was</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="61" end_char="66">leaked</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="68" end_char="71">from</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="73" end_char="73">a</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="75" end_char="77">lab</TOKEN>
</SEG>
<SEG id="segment-1" start_char="81" end_char="203">
<ORIGINAL_TEXT>A website with ties to Steve Bannon and a Chinese billionaire is claiming to have a scoop on the source of the coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="81" end_char="81">A</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="83" end_char="89">website</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="91" end_char="94">with</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="96" end_char="99">ties</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="101" end_char="102">to</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="104" end_char="108">Steve</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="110" end_char="115">Bannon</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="117" end_char="119">and</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="121" end_char="121">a</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="123" end_char="129">Chinese</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="131" end_char="141">billionaire</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="143" end_char="144">is</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="146" end_char="153">claiming</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="155" end_char="156">to</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="158" end_char="161">have</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="163" end_char="163">a</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="165" end_char="169">scoop</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="171" end_char="172">on</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="174" end_char="176">the</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="178" end_char="183">source</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="185" end_char="186">of</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="188" end_char="190">the</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="192" end_char="202">coronavirus</TOKEN>
<TOKEN id="token-1-23" pos="punct" morph="none" start_char="203" end_char="203">.</TOKEN>
</SEG>
<SEG id="segment-2" start_char="206" end_char="233">
<ORIGINAL_TEXT>In an article published Jan.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="206" end_char="207">In</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="209" end_char="210">an</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="212" end_char="218">article</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="220" end_char="228">published</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="230" end_char="232">Jan</TOKEN>
<TOKEN id="token-2-5" pos="punct" morph="none" start_char="233" end_char="233">.</TOKEN>
</SEG>
<SEG id="segment-3" start_char="235" end_char="430">
<ORIGINAL_TEXT>25, G News wrote that Chinese Communist Party officials would soon "admit that the real source of the coronavirus is from ‘a lab in Wuhan (China)’ linked to its covert biological weapon programs."</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="235" end_char="236">25</TOKEN>
<TOKEN id="token-3-1" pos="punct" morph="none" start_char="237" end_char="237">,</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="239" end_char="239">G</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="241" end_char="244">News</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="246" end_char="250">wrote</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="252" end_char="255">that</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="257" end_char="263">Chinese</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="265" end_char="273">Communist</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="275" end_char="279">Party</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="281" end_char="289">officials</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="291" end_char="295">would</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="297" end_char="300">soon</TOKEN>
<TOKEN id="token-3-12" pos="punct" morph="none" start_char="302" end_char="302">"</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="303" end_char="307">admit</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="309" end_char="312">that</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="314" end_char="316">the</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="318" end_char="321">real</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="323" end_char="328">source</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="330" end_char="331">of</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="333" end_char="335">the</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="337" end_char="347">coronavirus</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="349" end_char="350">is</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="352" end_char="355">from</TOKEN>
<TOKEN id="token-3-23" pos="punct" morph="none" start_char="357" end_char="357">‘</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="358" end_char="358">a</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="360" end_char="362">lab</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="364" end_char="365">in</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="367" end_char="371">Wuhan</TOKEN>
<TOKEN id="token-3-28" pos="punct" morph="none" start_char="373" end_char="373">(</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="374" end_char="378">China</TOKEN>
<TOKEN id="token-3-30" pos="punct" morph="none" start_char="379" end_char="380">)’</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="382" end_char="387">linked</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="389" end_char="390">to</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="392" end_char="394">its</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="396" end_char="401">covert</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="403" end_char="412">biological</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="414" end_char="419">weapon</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="421" end_char="428">programs</TOKEN>
<TOKEN id="token-3-38" pos="punct" morph="none" start_char="429" end_char="430">."</TOKEN>
</SEG>
<SEG id="segment-4" start_char="433" end_char="656">
<ORIGINAL_TEXT>"A reliable source told Miles Guo today that the Chinese Communist Party (CCP) will admit to the public of an ‘accidental’ leak of lab-created virus from a P4 lab in Wuhan to put blames on ‘human errors,’" the article reads.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="punct" morph="none" start_char="433" end_char="433">"</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="434" end_char="434">A</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="436" end_char="443">reliable</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="445" end_char="450">source</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="452" end_char="455">told</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="457" end_char="461">Miles</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="463" end_char="465">Guo</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="467" end_char="471">today</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="473" end_char="476">that</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="478" end_char="480">the</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="482" end_char="488">Chinese</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="490" end_char="498">Communist</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="500" end_char="504">Party</TOKEN>
<TOKEN id="token-4-13" pos="punct" morph="none" start_char="506" end_char="506">(</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="507" end_char="509">CCP</TOKEN>
<TOKEN id="token-4-15" pos="punct" morph="none" start_char="510" end_char="510">)</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="512" end_char="515">will</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="517" end_char="521">admit</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="523" end_char="524">to</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="526" end_char="528">the</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="530" end_char="535">public</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="537" end_char="538">of</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="540" end_char="541">an</TOKEN>
<TOKEN id="token-4-23" pos="punct" morph="none" start_char="543" end_char="543">‘</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="544" end_char="553">accidental</TOKEN>
<TOKEN id="token-4-25" pos="punct" morph="none" start_char="554" end_char="554">’</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="556" end_char="559">leak</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="561" end_char="562">of</TOKEN>
<TOKEN id="token-4-28" pos="unknown" morph="none" start_char="564" end_char="574">lab-created</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="576" end_char="580">virus</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="582" end_char="585">from</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="587" end_char="587">a</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="589" end_char="590">P4</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="592" end_char="594">lab</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="596" end_char="597">in</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="599" end_char="603">Wuhan</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="605" end_char="606">to</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="608" end_char="610">put</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="612" end_char="617">blames</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="619" end_char="620">on</TOKEN>
<TOKEN id="token-4-40" pos="punct" morph="none" start_char="622" end_char="622">‘</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="623" end_char="627">human</TOKEN>
<TOKEN id="token-4-42" pos="word" morph="none" start_char="629" end_char="634">errors</TOKEN>
<TOKEN id="token-4-43" pos="punct" morph="none" start_char="635" end_char="637">,’"</TOKEN>
<TOKEN id="token-4-44" pos="word" morph="none" start_char="639" end_char="641">the</TOKEN>
<TOKEN id="token-4-45" pos="word" morph="none" start_char="643" end_char="649">article</TOKEN>
<TOKEN id="token-4-46" pos="word" morph="none" start_char="651" end_char="655">reads</TOKEN>
<TOKEN id="token-4-47" pos="punct" morph="none" start_char="656" end_char="656">.</TOKEN>
</SEG>
<SEG id="segment-5" start_char="658" end_char="714">
<ORIGINAL_TEXT>"But the official announcement is still being finalized."</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="punct" morph="none" start_char="658" end_char="658">"</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="659" end_char="661">But</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="663" end_char="665">the</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="667" end_char="674">official</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="676" end_char="687">announcement</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="689" end_char="690">is</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="692" end_char="696">still</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="698" end_char="702">being</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="704" end_char="712">finalized</TOKEN>
<TOKEN id="token-5-9" pos="punct" morph="none" start_char="713" end_char="714">."</TOKEN>
</SEG>
<SEG id="segment-6" start_char="717" end_char="827">
<ORIGINAL_TEXT>The article was flagged as part of Facebook’s efforts to combat false news and misinformation on its News Feed.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="717" end_char="719">The</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="721" end_char="727">article</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="729" end_char="731">was</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="733" end_char="739">flagged</TOKEN>
<TOKEN id="token-6-4" pos="word" morph="none" start_char="741" end_char="742">as</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="744" end_char="747">part</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="749" end_char="750">of</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="752" end_char="761">Facebook’s</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="763" end_char="769">efforts</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="771" end_char="772">to</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="774" end_char="779">combat</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="781" end_char="785">false</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="787" end_char="790">news</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="792" end_char="794">and</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="796" end_char="809">misinformation</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="811" end_char="812">on</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="814" end_char="816">its</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="818" end_char="821">News</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="823" end_char="826">Feed</TOKEN>
<TOKEN id="token-6-19" pos="punct" morph="none" start_char="827" end_char="827">.</TOKEN>
</SEG>
<SEG id="segment-7" start_char="829" end_char="876">
<ORIGINAL_TEXT>(Read more about our partnership with Facebook.)</ORIGINAL_TEXT>
<TOKEN id="token-7-0" pos="punct" morph="none" start_char="829" end_char="829">(</TOKEN>
<TOKEN id="token-7-1" pos="word" morph="none" start_char="830" end_char="833">Read</TOKEN>
<TOKEN id="token-7-2" pos="word" morph="none" start_char="835" end_char="838">more</TOKEN>
<TOKEN id="token-7-3" pos="word" morph="none" start_char="840" end_char="844">about</TOKEN>
<TOKEN id="token-7-4" pos="word" morph="none" start_char="846" end_char="848">our</TOKEN>
<TOKEN id="token-7-5" pos="word" morph="none" start_char="850" end_char="860">partnership</TOKEN>
<TOKEN id="token-7-6" pos="word" morph="none" start_char="862" end_char="865">with</TOKEN>
<TOKEN id="token-7-7" pos="word" morph="none" start_char="867" end_char="874">Facebook</TOKEN>
<TOKEN id="token-7-8" pos="punct" morph="none" start_char="875" end_char="876">.)</TOKEN>
</SEG>
<SEG id="segment-8" start_char="878" end_char="915">
<ORIGINAL_TEXT>It has been shared thousands of times.</ORIGINAL_TEXT>
<TOKEN id="token-8-0" pos="word" morph="none" start_char="878" end_char="879">It</TOKEN>
<TOKEN id="token-8-1" pos="word" morph="none" start_char="881" end_char="883">has</TOKEN>
<TOKEN id="token-8-2" pos="word" morph="none" start_char="885" end_char="888">been</TOKEN>
<TOKEN id="token-8-3" pos="word" morph="none" start_char="890" end_char="895">shared</TOKEN>
<TOKEN id="token-8-4" pos="word" morph="none" start_char="897" end_char="905">thousands</TOKEN>
<TOKEN id="token-8-5" pos="word" morph="none" start_char="907" end_char="908">of</TOKEN>
<TOKEN id="token-8-6" pos="word" morph="none" start_char="910" end_char="914">times</TOKEN>
<TOKEN id="token-8-7" pos="punct" morph="none" start_char="915" end_char="915">.</TOKEN>
</SEG>
<SEG id="segment-9" start_char="918" end_char="941">
<ORIGINAL_TEXT>(Screenshot from G News)</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="punct" morph="none" start_char="918" end_char="918">(</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="919" end_char="928">Screenshot</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="930" end_char="933">from</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="935" end_char="935">G</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="937" end_char="940">News</TOKEN>
<TOKEN id="token-9-5" pos="punct" morph="none" start_char="941" end_char="941">)</TOKEN>
</SEG>
<SEG id="segment-10" start_char="945" end_char="1080">
<ORIGINAL_TEXT>The coronavirus, which originated in the central China city of Wuhan, has infected more than 2,700 people worldwide, according to a Jan.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="945" end_char="947">The</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="949" end_char="959">coronavirus</TOKEN>
<TOKEN id="token-10-2" pos="punct" morph="none" start_char="960" end_char="960">,</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="962" end_char="966">which</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="968" end_char="977">originated</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="979" end_char="980">in</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="982" end_char="984">the</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="986" end_char="992">central</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="994" end_char="998">China</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="1000" end_char="1003">city</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1005" end_char="1006">of</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1008" end_char="1012">Wuhan</TOKEN>
<TOKEN id="token-10-12" pos="punct" morph="none" start_char="1013" end_char="1013">,</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1015" end_char="1017">has</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1019" end_char="1026">infected</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1028" end_char="1031">more</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1033" end_char="1036">than</TOKEN>
<TOKEN id="token-10-17" pos="unknown" morph="none" start_char="1038" end_char="1042">2,700</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1044" end_char="1049">people</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1051" end_char="1059">worldwide</TOKEN>
<TOKEN id="token-10-20" pos="punct" morph="none" start_char="1060" end_char="1060">,</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1062" end_char="1070">according</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="1072" end_char="1073">to</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="1075" end_char="1075">a</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="1077" end_char="1079">Jan</TOKEN>
<TOKEN id="token-10-25" pos="punct" morph="none" start_char="1080" end_char="1080">.</TOKEN>
</SEG>
<SEG id="segment-11" start_char="1082" end_char="1117">
<ORIGINAL_TEXT>27 World Health Organization report.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="1082" end_char="1083">27</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="1085" end_char="1089">World</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="1091" end_char="1096">Health</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="1098" end_char="1109">Organization</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="1111" end_char="1116">report</TOKEN>
<TOKEN id="token-11-5" pos="punct" morph="none" start_char="1117" end_char="1117">.</TOKEN>
</SEG>
<SEG id="segment-12" start_char="1119" end_char="1190">
<ORIGINAL_TEXT>China has restricted travel within the country amid a rising death toll.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1119" end_char="1123">China</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1125" end_char="1127">has</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1129" end_char="1138">restricted</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1140" end_char="1145">travel</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1147" end_char="1152">within</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1154" end_char="1156">the</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1158" end_char="1164">country</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1166" end_char="1169">amid</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1171" end_char="1171">a</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1173" end_char="1178">rising</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1180" end_char="1184">death</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1186" end_char="1189">toll</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1190" end_char="1190">.</TOKEN>
</SEG>
<SEG id="segment-13" start_char="1193" end_char="1305">
<ORIGINAL_TEXT>While we can’t know who G News has or hasn’t spoken to, we could find no evidence to support the website’s story.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="1193" end_char="1197">While</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="1199" end_char="1200">we</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="1202" end_char="1206">can’t</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="1208" end_char="1211">know</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="1213" end_char="1215">who</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="1217" end_char="1217">G</TOKEN>
<TOKEN id="token-13-6" pos="word" morph="none" start_char="1219" end_char="1222">News</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="1224" end_char="1226">has</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="1228" end_char="1229">or</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="1231" end_char="1236">hasn’t</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="1238" end_char="1243">spoken</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="1245" end_char="1246">to</TOKEN>
<TOKEN id="token-13-12" pos="punct" morph="none" start_char="1247" end_char="1247">,</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="1249" end_char="1250">we</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="1252" end_char="1256">could</TOKEN>
<TOKEN id="token-13-15" pos="word" morph="none" start_char="1258" end_char="1261">find</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="1263" end_char="1264">no</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="1266" end_char="1273">evidence</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="1275" end_char="1276">to</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="1278" end_char="1284">support</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="1286" end_char="1288">the</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="1290" end_char="1298">website’s</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="1300" end_char="1304">story</TOKEN>
<TOKEN id="token-13-23" pos="punct" morph="none" start_char="1305" end_char="1305">.</TOKEN>
</SEG>
<SEG id="segment-14" start_char="1308" end_char="1392">
<ORIGINAL_TEXT>Miles Guo, also known as Guo Wengui, is a Chinese billionaire and political activist.</ORIGINAL_TEXT>
<TOKEN id="token-14-0" pos="word" morph="none" start_char="1308" end_char="1312">Miles</TOKEN>
<TOKEN id="token-14-1" pos="word" morph="none" start_char="1314" end_char="1316">Guo</TOKEN>
<TOKEN id="token-14-2" pos="punct" morph="none" start_char="1317" end_char="1317">,</TOKEN>
<TOKEN id="token-14-3" pos="word" morph="none" start_char="1319" end_char="1322">also</TOKEN>
<TOKEN id="token-14-4" pos="word" morph="none" start_char="1324" end_char="1328">known</TOKEN>
<TOKEN id="token-14-5" pos="word" morph="none" start_char="1330" end_char="1331">as</TOKEN>
<TOKEN id="token-14-6" pos="word" morph="none" start_char="1333" end_char="1335">Guo</TOKEN>
<TOKEN id="token-14-7" pos="word" morph="none" start_char="1337" end_char="1342">Wengui</TOKEN>
<TOKEN id="token-14-8" pos="punct" morph="none" start_char="1343" end_char="1343">,</TOKEN>
<TOKEN id="token-14-9" pos="word" morph="none" start_char="1345" end_char="1346">is</TOKEN>
<TOKEN id="token-14-10" pos="word" morph="none" start_char="1348" end_char="1348">a</TOKEN>
<TOKEN id="token-14-11" pos="word" morph="none" start_char="1350" end_char="1356">Chinese</TOKEN>
<TOKEN id="token-14-12" pos="word" morph="none" start_char="1358" end_char="1368">billionaire</TOKEN>
<TOKEN id="token-14-13" pos="word" morph="none" start_char="1370" end_char="1372">and</TOKEN>
<TOKEN id="token-14-14" pos="word" morph="none" start_char="1374" end_char="1382">political</TOKEN>
<TOKEN id="token-14-15" pos="word" morph="none" start_char="1384" end_char="1391">activist</TOKEN>
<TOKEN id="token-14-16" pos="punct" morph="none" start_char="1392" end_char="1392">.</TOKEN>
</SEG>
<SEG id="segment-15" start_char="1394" end_char="1478">
<ORIGINAL_TEXT>He fled China in 2014 in anticipation of corruption charges from the Communist Party.</ORIGINAL_TEXT>
<TOKEN id="token-15-0" pos="word" morph="none" start_char="1394" end_char="1395">He</TOKEN>
<TOKEN id="token-15-1" pos="word" morph="none" start_char="1397" end_char="1400">fled</TOKEN>
<TOKEN id="token-15-2" pos="word" morph="none" start_char="1402" end_char="1406">China</TOKEN>
<TOKEN id="token-15-3" pos="word" morph="none" start_char="1408" end_char="1409">in</TOKEN>
<TOKEN id="token-15-4" pos="word" morph="none" start_char="1411" end_char="1414">2014</TOKEN>
<TOKEN id="token-15-5" pos="word" morph="none" start_char="1416" end_char="1417">in</TOKEN>
<TOKEN id="token-15-6" pos="word" morph="none" start_char="1419" end_char="1430">anticipation</TOKEN>
<TOKEN id="token-15-7" pos="word" morph="none" start_char="1432" end_char="1433">of</TOKEN>
<TOKEN id="token-15-8" pos="word" morph="none" start_char="1435" end_char="1444">corruption</TOKEN>
<TOKEN id="token-15-9" pos="word" morph="none" start_char="1446" end_char="1452">charges</TOKEN>
<TOKEN id="token-15-10" pos="word" morph="none" start_char="1454" end_char="1457">from</TOKEN>
<TOKEN id="token-15-11" pos="word" morph="none" start_char="1459" end_char="1461">the</TOKEN>
<TOKEN id="token-15-12" pos="word" morph="none" start_char="1463" end_char="1471">Communist</TOKEN>
<TOKEN id="token-15-13" pos="word" morph="none" start_char="1473" end_char="1477">Party</TOKEN>
<TOKEN id="token-15-14" pos="punct" morph="none" start_char="1478" end_char="1478">.</TOKEN>
</SEG>
<SEG id="segment-16" start_char="1480" end_char="1660">
<ORIGINAL_TEXT>Since then, Wengui, who is a member of President Donald Trump’s Mar-a-Lago resort in Florida, has become known for his outspoken criticism of Chinese efforts to weed out corruption.</ORIGINAL_TEXT>
<TOKEN id="token-16-0" pos="word" morph="none" start_char="1480" end_char="1484">Since</TOKEN>
<TOKEN id="token-16-1" pos="word" morph="none" start_char="1486" end_char="1489">then</TOKEN>
<TOKEN id="token-16-2" pos="punct" morph="none" start_char="1490" end_char="1490">,</TOKEN>
<TOKEN id="token-16-3" pos="word" morph="none" start_char="1492" end_char="1497">Wengui</TOKEN>
<TOKEN id="token-16-4" pos="punct" morph="none" start_char="1498" end_char="1498">,</TOKEN>
<TOKEN id="token-16-5" pos="word" morph="none" start_char="1500" end_char="1502">who</TOKEN>
<TOKEN id="token-16-6" pos="word" morph="none" start_char="1504" end_char="1505">is</TOKEN>
<TOKEN id="token-16-7" pos="word" morph="none" start_char="1507" end_char="1507">a</TOKEN>
<TOKEN id="token-16-8" pos="word" morph="none" start_char="1509" end_char="1514">member</TOKEN>
<TOKEN id="token-16-9" pos="word" morph="none" start_char="1516" end_char="1517">of</TOKEN>
<TOKEN id="token-16-10" pos="word" morph="none" start_char="1519" end_char="1527">President</TOKEN>
<TOKEN id="token-16-11" pos="word" morph="none" start_char="1529" end_char="1534">Donald</TOKEN>
<TOKEN id="token-16-12" pos="word" morph="none" start_char="1536" end_char="1542">Trump’s</TOKEN>
<TOKEN id="token-16-13" pos="unknown" morph="none" start_char="1544" end_char="1553">Mar-a-Lago</TOKEN>
<TOKEN id="token-16-14" pos="word" morph="none" start_char="1555" end_char="1560">resort</TOKEN>
<TOKEN id="token-16-15" pos="word" morph="none" start_char="1562" end_char="1563">in</TOKEN>
<TOKEN id="token-16-16" pos="word" morph="none" start_char="1565" end_char="1571">Florida</TOKEN>
<TOKEN id="token-16-17" pos="punct" morph="none" start_char="1572" end_char="1572">,</TOKEN>
<TOKEN id="token-16-18" pos="word" morph="none" start_char="1574" end_char="1576">has</TOKEN>
<TOKEN id="token-16-19" pos="word" morph="none" start_char="1578" end_char="1583">become</TOKEN>
<TOKEN id="token-16-20" pos="word" morph="none" start_char="1585" end_char="1589">known</TOKEN>
<TOKEN id="token-16-21" pos="word" morph="none" start_char="1591" end_char="1593">for</TOKEN>
<TOKEN id="token-16-22" pos="word" morph="none" start_char="1595" end_char="1597">his</TOKEN>
<TOKEN id="token-16-23" pos="word" morph="none" start_char="1599" end_char="1607">outspoken</TOKEN>
<TOKEN id="token-16-24" pos="word" morph="none" start_char="1609" end_char="1617">criticism</TOKEN>
<TOKEN id="token-16-25" pos="word" morph="none" start_char="1619" end_char="1620">of</TOKEN>
<TOKEN id="token-16-26" pos="word" morph="none" start_char="1622" end_char="1628">Chinese</TOKEN>
<TOKEN id="token-16-27" pos="word" morph="none" start_char="1630" end_char="1636">efforts</TOKEN>
<TOKEN id="token-16-28" pos="word" morph="none" start_char="1638" end_char="1639">to</TOKEN>
<TOKEN id="token-16-29" pos="word" morph="none" start_char="1641" end_char="1644">weed</TOKEN>
<TOKEN id="token-16-30" pos="word" morph="none" start_char="1646" end_char="1648">out</TOKEN>
<TOKEN id="token-16-31" pos="word" morph="none" start_char="1650" end_char="1659">corruption</TOKEN>
<TOKEN id="token-16-32" pos="punct" morph="none" start_char="1660" end_char="1660">.</TOKEN>
</SEG>
<SEG id="segment-17" start_char="1663" end_char="1727">
<ORIGINAL_TEXT>G News is the media arm of Guo Media, a company linked to Wengui.</ORIGINAL_TEXT>
<TOKEN id="token-17-0" pos="word" morph="none" start_char="1663" end_char="1663">G</TOKEN>
<TOKEN id="token-17-1" pos="word" morph="none" start_char="1665" end_char="1668">News</TOKEN>
<TOKEN id="token-17-2" pos="word" morph="none" start_char="1670" end_char="1671">is</TOKEN>
<TOKEN id="token-17-3" pos="word" morph="none" start_char="1673" end_char="1675">the</TOKEN>
<TOKEN id="token-17-4" pos="word" morph="none" start_char="1677" end_char="1681">media</TOKEN>
<TOKEN id="token-17-5" pos="word" morph="none" start_char="1683" end_char="1685">arm</TOKEN>
<TOKEN id="token-17-6" pos="word" morph="none" start_char="1687" end_char="1688">of</TOKEN>
<TOKEN id="token-17-7" pos="word" morph="none" start_char="1690" end_char="1692">Guo</TOKEN>
<TOKEN id="token-17-8" pos="word" morph="none" start_char="1694" end_char="1698">Media</TOKEN>
<TOKEN id="token-17-9" pos="punct" morph="none" start_char="1699" end_char="1699">,</TOKEN>
<TOKEN id="token-17-10" pos="word" morph="none" start_char="1701" end_char="1701">a</TOKEN>
<TOKEN id="token-17-11" pos="word" morph="none" start_char="1703" end_char="1709">company</TOKEN>
<TOKEN id="token-17-12" pos="word" morph="none" start_char="1711" end_char="1716">linked</TOKEN>
<TOKEN id="token-17-13" pos="word" morph="none" start_char="1718" end_char="1719">to</TOKEN>
<TOKEN id="token-17-14" pos="word" morph="none" start_char="1721" end_char="1726">Wengui</TOKEN>
<TOKEN id="token-17-15" pos="punct" morph="none" start_char="1727" end_char="1727">.</TOKEN>
</SEG>
<SEG id="segment-18" start_char="1729" end_char="1921">
<ORIGINAL_TEXT>Axios reported in October that the company paid Bannon, Trump’s former chief strategist and former executive chairman of Breitbart News, at least $1 million for "strategic consulting services."</ORIGINAL_TEXT>
<TOKEN id="token-18-0" pos="word" morph="none" start_char="1729" end_char="1733">Axios</TOKEN>
<TOKEN id="token-18-1" pos="word" morph="none" start_char="1735" end_char="1742">reported</TOKEN>
<TOKEN id="token-18-2" pos="word" morph="none" start_char="1744" end_char="1745">in</TOKEN>
<TOKEN id="token-18-3" pos="word" morph="none" start_char="1747" end_char="1753">October</TOKEN>
<TOKEN id="token-18-4" pos="word" morph="none" start_char="1755" end_char="1758">that</TOKEN>
<TOKEN id="token-18-5" pos="word" morph="none" start_char="1760" end_char="1762">the</TOKEN>
<TOKEN id="token-18-6" pos="word" morph="none" start_char="1764" end_char="1770">company</TOKEN>
<TOKEN id="token-18-7" pos="word" morph="none" start_char="1772" end_char="1775">paid</TOKEN>
<TOKEN id="token-18-8" pos="word" morph="none" start_char="1777" end_char="1782">Bannon</TOKEN>
<TOKEN id="token-18-9" pos="punct" morph="none" start_char="1783" end_char="1783">,</TOKEN>
<TOKEN id="token-18-10" pos="word" morph="none" start_char="1785" end_char="1791">Trump’s</TOKEN>
<TOKEN id="token-18-11" pos="word" morph="none" start_char="1793" end_char="1798">former</TOKEN>
<TOKEN id="token-18-12" pos="word" morph="none" start_char="1800" end_char="1804">chief</TOKEN>
<TOKEN id="token-18-13" pos="word" morph="none" start_char="1806" end_char="1815">strategist</TOKEN>
<TOKEN id="token-18-14" pos="word" morph="none" start_char="1817" end_char="1819">and</TOKEN>
<TOKEN id="token-18-15" pos="word" morph="none" start_char="1821" end_char="1826">former</TOKEN>
<TOKEN id="token-18-16" pos="word" morph="none" start_char="1828" end_char="1836">executive</TOKEN>
<TOKEN id="token-18-17" pos="word" morph="none" start_char="1838" end_char="1845">chairman</TOKEN>
<TOKEN id="token-18-18" pos="word" morph="none" start_char="1847" end_char="1848">of</TOKEN>
<TOKEN id="token-18-19" pos="word" morph="none" start_char="1850" end_char="1858">Breitbart</TOKEN>
<TOKEN id="token-18-20" pos="word" morph="none" start_char="1860" end_char="1863">News</TOKEN>
<TOKEN id="token-18-21" pos="punct" morph="none" start_char="1864" end_char="1864">,</TOKEN>
<TOKEN id="token-18-22" pos="word" morph="none" start_char="1866" end_char="1867">at</TOKEN>
<TOKEN id="token-18-23" pos="word" morph="none" start_char="1869" end_char="1873">least</TOKEN>
<TOKEN id="token-18-24" pos="unknown" morph="none" start_char="1875" end_char="1876">$1</TOKEN>
<TOKEN id="token-18-25" pos="word" morph="none" start_char="1878" end_char="1884">million</TOKEN>
<TOKEN id="token-18-26" pos="word" morph="none" start_char="1886" end_char="1888">for</TOKEN>
<TOKEN id="token-18-27" pos="punct" morph="none" start_char="1890" end_char="1890">"</TOKEN>
<TOKEN id="token-18-28" pos="word" morph="none" start_char="1891" end_char="1899">strategic</TOKEN>
<TOKEN id="token-18-29" pos="word" morph="none" start_char="1901" end_char="1910">consulting</TOKEN>
<TOKEN id="token-18-30" pos="word" morph="none" start_char="1912" end_char="1919">services</TOKEN>
<TOKEN id="token-18-31" pos="punct" morph="none" start_char="1920" end_char="1921">."</TOKEN>
</SEG>
<SEG id="segment-19" start_char="1923" end_char="1979">
<ORIGINAL_TEXT>Both Bannon and Wengui have their own sections on G News.</ORIGINAL_TEXT>
<TOKEN id="token-19-0" pos="word" morph="none" start_char="1923" end_char="1926">Both</TOKEN>
<TOKEN id="token-19-1" pos="word" morph="none" start_char="1928" end_char="1933">Bannon</TOKEN>
<TOKEN id="token-19-2" pos="word" morph="none" start_char="1935" end_char="1937">and</TOKEN>
<TOKEN id="token-19-3" pos="word" morph="none" start_char="1939" end_char="1944">Wengui</TOKEN>
<TOKEN id="token-19-4" pos="word" morph="none" start_char="1946" end_char="1949">have</TOKEN>
<TOKEN id="token-19-5" pos="word" morph="none" start_char="1951" end_char="1955">their</TOKEN>
<TOKEN id="token-19-6" pos="word" morph="none" start_char="1957" end_char="1959">own</TOKEN>
<TOKEN id="token-19-7" pos="word" morph="none" start_char="1961" end_char="1968">sections</TOKEN>
<TOKEN id="token-19-8" pos="word" morph="none" start_char="1970" end_char="1971">on</TOKEN>
<TOKEN id="token-19-9" pos="word" morph="none" start_char="1973" end_char="1973">G</TOKEN>
<TOKEN id="token-19-10" pos="word" morph="none" start_char="1975" end_char="1978">News</TOKEN>
<TOKEN id="token-19-11" pos="punct" morph="none" start_char="1979" end_char="1979">.</TOKEN>
</SEG>
<SEG id="segment-20" start_char="1982" end_char="2085">
<ORIGINAL_TEXT>We could find no other media reports that corroborate G News’ story about the source of the coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-20-0" pos="word" morph="none" start_char="1982" end_char="1983">We</TOKEN>
<TOKEN id="token-20-1" pos="word" morph="none" start_char="1985" end_char="1989">could</TOKEN>
<TOKEN id="token-20-2" pos="word" morph="none" start_char="1991" end_char="1994">find</TOKEN>
<TOKEN id="token-20-3" pos="word" morph="none" start_char="1996" end_char="1997">no</TOKEN>
<TOKEN id="token-20-4" pos="word" morph="none" start_char="1999" end_char="2003">other</TOKEN>
<TOKEN id="token-20-5" pos="word" morph="none" start_char="2005" end_char="2009">media</TOKEN>
<TOKEN id="token-20-6" pos="word" morph="none" start_char="2011" end_char="2017">reports</TOKEN>
<TOKEN id="token-20-7" pos="word" morph="none" start_char="2019" end_char="2022">that</TOKEN>
<TOKEN id="token-20-8" pos="word" morph="none" start_char="2024" end_char="2034">corroborate</TOKEN>
<TOKEN id="token-20-9" pos="word" morph="none" start_char="2036" end_char="2036">G</TOKEN>
<TOKEN id="token-20-10" pos="word" morph="none" start_char="2038" end_char="2041">News</TOKEN>
<TOKEN id="token-20-11" pos="punct" morph="none" start_char="2042" end_char="2042">’</TOKEN>
<TOKEN id="token-20-12" pos="word" morph="none" start_char="2044" end_char="2048">story</TOKEN>
<TOKEN id="token-20-13" pos="word" morph="none" start_char="2050" end_char="2054">about</TOKEN>
<TOKEN id="token-20-14" pos="word" morph="none" start_char="2056" end_char="2058">the</TOKEN>
<TOKEN id="token-20-15" pos="word" morph="none" start_char="2060" end_char="2065">source</TOKEN>
<TOKEN id="token-20-16" pos="word" morph="none" start_char="2067" end_char="2068">of</TOKEN>
<TOKEN id="token-20-17" pos="word" morph="none" start_char="2070" end_char="2072">the</TOKEN>
<TOKEN id="token-20-18" pos="word" morph="none" start_char="2074" end_char="2084">coronavirus</TOKEN>
<TOKEN id="token-20-19" pos="punct" morph="none" start_char="2085" end_char="2085">.</TOKEN>
</SEG>
<SEG id="segment-21" start_char="2088" end_char="2213">
<ORIGINAL_TEXT>There is a lab near Wuhan that deals with dangerous pathogens — and some have linked it to China’s biological warfare program.</ORIGINAL_TEXT>
<TOKEN id="token-21-0" pos="word" morph="none" start_char="2088" end_char="2092">There</TOKEN>
<TOKEN id="token-21-1" pos="word" morph="none" start_char="2094" end_char="2095">is</TOKEN>
<TOKEN id="token-21-2" pos="word" morph="none" start_char="2097" end_char="2097">a</TOKEN>
<TOKEN id="token-21-3" pos="word" morph="none" start_char="2099" end_char="2101">lab</TOKEN>
<TOKEN id="token-21-4" pos="word" morph="none" start_char="2103" end_char="2106">near</TOKEN>
<TOKEN id="token-21-5" pos="word" morph="none" start_char="2108" end_char="2112">Wuhan</TOKEN>
<TOKEN id="token-21-6" pos="word" morph="none" start_char="2114" end_char="2117">that</TOKEN>
<TOKEN id="token-21-7" pos="word" morph="none" start_char="2119" end_char="2123">deals</TOKEN>
<TOKEN id="token-21-8" pos="word" morph="none" start_char="2125" end_char="2128">with</TOKEN>
<TOKEN id="token-21-9" pos="word" morph="none" start_char="2130" end_char="2138">dangerous</TOKEN>
<TOKEN id="token-21-10" pos="word" morph="none" start_char="2140" end_char="2148">pathogens</TOKEN>
<TOKEN id="token-21-11" pos="punct" morph="none" start_char="2150" end_char="2150">—</TOKEN>
<TOKEN id="token-21-12" pos="word" morph="none" start_char="2152" end_char="2154">and</TOKEN>
<TOKEN id="token-21-13" pos="word" morph="none" start_char="2156" end_char="2159">some</TOKEN>
<TOKEN id="token-21-14" pos="word" morph="none" start_char="2161" end_char="2164">have</TOKEN>
<TOKEN id="token-21-15" pos="word" morph="none" start_char="2166" end_char="2171">linked</TOKEN>
<TOKEN id="token-21-16" pos="word" morph="none" start_char="2173" end_char="2174">it</TOKEN>
<TOKEN id="token-21-17" pos="word" morph="none" start_char="2176" end_char="2177">to</TOKEN>
<TOKEN id="token-21-18" pos="word" morph="none" start_char="2179" end_char="2185">China’s</TOKEN>
<TOKEN id="token-21-19" pos="word" morph="none" start_char="2187" end_char="2196">biological</TOKEN>
<TOKEN id="token-21-20" pos="word" morph="none" start_char="2198" end_char="2204">warfare</TOKEN>
<TOKEN id="token-21-21" pos="word" morph="none" start_char="2206" end_char="2212">program</TOKEN>
<TOKEN id="token-21-22" pos="punct" morph="none" start_char="2213" end_char="2213">.</TOKEN>
</SEG>
<SEG id="segment-22" start_char="2215" end_char="2426">
<ORIGINAL_TEXT>The country denies having such a program, but the U.S. State Department has raised concerns about China’s potential noncompliance with the Biological Weapons Convention, which bans the production of such weapons.</ORIGINAL_TEXT>
<TOKEN id="token-22-0" pos="word" morph="none" start_char="2215" end_char="2217">The</TOKEN>
<TOKEN id="token-22-1" pos="word" morph="none" start_char="2219" end_char="2225">country</TOKEN>
<TOKEN id="token-22-2" pos="word" morph="none" start_char="2227" end_char="2232">denies</TOKEN>
<TOKEN id="token-22-3" pos="word" morph="none" start_char="2234" end_char="2239">having</TOKEN>
<TOKEN id="token-22-4" pos="word" morph="none" start_char="2241" end_char="2244">such</TOKEN>
<TOKEN id="token-22-5" pos="word" morph="none" start_char="2246" end_char="2246">a</TOKEN>
<TOKEN id="token-22-6" pos="word" morph="none" start_char="2248" end_char="2254">program</TOKEN>
<TOKEN id="token-22-7" pos="punct" morph="none" start_char="2255" end_char="2255">,</TOKEN>
<TOKEN id="token-22-8" pos="word" morph="none" start_char="2257" end_char="2259">but</TOKEN>
<TOKEN id="token-22-9" pos="word" morph="none" start_char="2261" end_char="2263">the</TOKEN>
<TOKEN id="token-22-10" pos="unknown" morph="none" start_char="2265" end_char="2267">U.S</TOKEN>
<TOKEN id="token-22-11" pos="punct" morph="none" start_char="2268" end_char="2268">.</TOKEN>
<TOKEN id="token-22-12" pos="word" morph="none" start_char="2270" end_char="2274">State</TOKEN>
<TOKEN id="token-22-13" pos="word" morph="none" start_char="2276" end_char="2285">Department</TOKEN>
<TOKEN id="token-22-14" pos="word" morph="none" start_char="2287" end_char="2289">has</TOKEN>
<TOKEN id="token-22-15" pos="word" morph="none" start_char="2291" end_char="2296">raised</TOKEN>
<TOKEN id="token-22-16" pos="word" morph="none" start_char="2298" end_char="2305">concerns</TOKEN>
<TOKEN id="token-22-17" pos="word" morph="none" start_char="2307" end_char="2311">about</TOKEN>
<TOKEN id="token-22-18" pos="word" morph="none" start_char="2313" end_char="2319">China’s</TOKEN>
<TOKEN id="token-22-19" pos="word" morph="none" start_char="2321" end_char="2329">potential</TOKEN>
<TOKEN id="token-22-20" pos="word" morph="none" start_char="2331" end_char="2343">noncompliance</TOKEN>
<TOKEN id="token-22-21" pos="word" morph="none" start_char="2345" end_char="2348">with</TOKEN>
<TOKEN id="token-22-22" pos="word" morph="none" start_char="2350" end_char="2352">the</TOKEN>
<TOKEN id="token-22-23" pos="word" morph="none" start_char="2354" end_char="2363">Biological</TOKEN>
<TOKEN id="token-22-24" pos="word" morph="none" start_char="2365" end_char="2371">Weapons</TOKEN>
<TOKEN id="token-22-25" pos="word" morph="none" start_char="2373" end_char="2382">Convention</TOKEN>
<TOKEN id="token-22-26" pos="punct" morph="none" start_char="2383" end_char="2383">,</TOKEN>
<TOKEN id="token-22-27" pos="word" morph="none" start_char="2385" end_char="2389">which</TOKEN>
<TOKEN id="token-22-28" pos="word" morph="none" start_char="2391" end_char="2394">bans</TOKEN>
<TOKEN id="token-22-29" pos="word" morph="none" start_char="2396" end_char="2398">the</TOKEN>
<TOKEN id="token-22-30" pos="word" morph="none" start_char="2400" end_char="2409">production</TOKEN>
<TOKEN id="token-22-31" pos="word" morph="none" start_char="2411" end_char="2412">of</TOKEN>
<TOKEN id="token-22-32" pos="word" morph="none" start_char="2414" end_char="2417">such</TOKEN>
<TOKEN id="token-22-33" pos="word" morph="none" start_char="2419" end_char="2425">weapons</TOKEN>
<TOKEN id="token-22-34" pos="punct" morph="none" start_char="2426" end_char="2426">.</TOKEN>
</SEG>
<SEG id="segment-23" start_char="2429" end_char="2508">
<ORIGINAL_TEXT>Officials are still working to determine the source of the coronavirus outbreak.</ORIGINAL_TEXT>
<TOKEN id="token-23-0" pos="word" morph="none" start_char="2429" end_char="2437">Officials</TOKEN>
<TOKEN id="token-23-1" pos="word" morph="none" start_char="2439" end_char="2441">are</TOKEN>
<TOKEN id="token-23-2" pos="word" morph="none" start_char="2443" end_char="2447">still</TOKEN>
<TOKEN id="token-23-3" pos="word" morph="none" start_char="2449" end_char="2455">working</TOKEN>
<TOKEN id="token-23-4" pos="word" morph="none" start_char="2457" end_char="2458">to</TOKEN>
<TOKEN id="token-23-5" pos="word" morph="none" start_char="2460" end_char="2468">determine</TOKEN>
<TOKEN id="token-23-6" pos="word" morph="none" start_char="2470" end_char="2472">the</TOKEN>
<TOKEN id="token-23-7" pos="word" morph="none" start_char="2474" end_char="2479">source</TOKEN>
<TOKEN id="token-23-8" pos="word" morph="none" start_char="2481" end_char="2482">of</TOKEN>
<TOKEN id="token-23-9" pos="word" morph="none" start_char="2484" end_char="2486">the</TOKEN>
<TOKEN id="token-23-10" pos="word" morph="none" start_char="2488" end_char="2498">coronavirus</TOKEN>
<TOKEN id="token-23-11" pos="word" morph="none" start_char="2500" end_char="2507">outbreak</TOKEN>
<TOKEN id="token-23-12" pos="punct" morph="none" start_char="2508" end_char="2508">.</TOKEN>
</SEG>
<SEG id="segment-24" start_char="2510" end_char="2684">
<ORIGINAL_TEXT>In its most recent situation summary, the Centers for Disease Control and Prevention said that both it and Chinese authorities had isolated the genome of the 2019 coronavirus.</ORIGINAL_TEXT>
<TOKEN id="token-24-0" pos="word" morph="none" start_char="2510" end_char="2511">In</TOKEN>
<TOKEN id="token-24-1" pos="word" morph="none" start_char="2513" end_char="2515">its</TOKEN>
<TOKEN id="token-24-2" pos="word" morph="none" start_char="2517" end_char="2520">most</TOKEN>
<TOKEN id="token-24-3" pos="word" morph="none" start_char="2522" end_char="2527">recent</TOKEN>
<TOKEN id="token-24-4" pos="word" morph="none" start_char="2529" end_char="2537">situation</TOKEN>
<TOKEN id="token-24-5" pos="word" morph="none" start_char="2539" end_char="2545">summary</TOKEN>
<TOKEN id="token-24-6" pos="punct" morph="none" start_char="2546" end_char="2546">,</TOKEN>
<TOKEN id="token-24-7" pos="word" morph="none" start_char="2548" end_char="2550">the</TOKEN>
<TOKEN id="token-24-8" pos="word" morph="none" start_char="2552" end_char="2558">Centers</TOKEN>
<TOKEN id="token-24-9" pos="word" morph="none" start_char="2560" end_char="2562">for</TOKEN>
<TOKEN id="token-24-10" pos="word" morph="none" start_char="2564" end_char="2570">Disease</TOKEN>
<TOKEN id="token-24-11" pos="word" morph="none" start_char="2572" end_char="2578">Control</TOKEN>
<TOKEN id="token-24-12" pos="word" morph="none" start_char="2580" end_char="2582">and</TOKEN>
<TOKEN id="token-24-13" pos="word" morph="none" start_char="2584" end_char="2593">Prevention</TOKEN>
<TOKEN id="token-24-14" pos="word" morph="none" start_char="2595" end_char="2598">said</TOKEN>
<TOKEN id="token-24-15" pos="word" morph="none" start_char="2600" end_char="2603">that</TOKEN>
<TOKEN id="token-24-16" pos="word" morph="none" start_char="2605" end_char="2608">both</TOKEN>
<TOKEN id="token-24-17" pos="word" morph="none" start_char="2610" end_char="2611">it</TOKEN>
<TOKEN id="token-24-18" pos="word" morph="none" start_char="2613" end_char="2615">and</TOKEN>
<TOKEN id="token-24-19" pos="word" morph="none" start_char="2617" end_char="2623">Chinese</TOKEN>
<TOKEN id="token-24-20" pos="word" morph="none" start_char="2625" end_char="2635">authorities</TOKEN>
<TOKEN id="token-24-21" pos="word" morph="none" start_char="2637" end_char="2639">had</TOKEN>
<TOKEN id="token-24-22" pos="word" morph="none" start_char="2641" end_char="2648">isolated</TOKEN>
<TOKEN id="token-24-23" pos="word" morph="none" start_char="2650" end_char="2652">the</TOKEN>
<TOKEN id="token-24-24" pos="word" morph="none" start_char="2654" end_char="2659">genome</TOKEN>
<TOKEN id="token-24-25" pos="word" morph="none" start_char="2661" end_char="2662">of</TOKEN>
<TOKEN id="token-24-26" pos="word" morph="none" start_char="2664" end_char="2666">the</TOKEN>
<TOKEN id="token-24-27" pos="word" morph="none" start_char="2668" end_char="2671">2019</TOKEN>
<TOKEN id="token-24-28" pos="word" morph="none" start_char="2673" end_char="2683">coronavirus</TOKEN>
<TOKEN id="token-24-29" pos="punct" morph="none" start_char="2684" end_char="2684">.</TOKEN>
</SEG>
<SEG id="segment-25" start_char="2687" end_char="2812">
<ORIGINAL_TEXT>Their findings suggest "a likely single, recent emergence from a virus related to bat coronaviruses and the SARS coronavirus."</ORIGINAL_TEXT>
<TOKEN id="token-25-0" pos="word" morph="none" start_char="2687" end_char="2691">Their</TOKEN>
<TOKEN id="token-25-1" pos="word" morph="none" start_char="2693" end_char="2700">findings</TOKEN>
<TOKEN id="token-25-2" pos="word" morph="none" start_char="2702" end_char="2708">suggest</TOKEN>
<TOKEN id="token-25-3" pos="punct" morph="none" start_char="2710" end_char="2710">"</TOKEN>
<TOKEN id="token-25-4" pos="word" morph="none" start_char="2711" end_char="2711">a</TOKEN>
<TOKEN id="token-25-5" pos="word" morph="none" start_char="2713" end_char="2718">likely</TOKEN>
<TOKEN id="token-25-6" pos="word" morph="none" start_char="2720" end_char="2725">single</TOKEN>
<TOKEN id="token-25-7" pos="punct" morph="none" start_char="2726" end_char="2726">,</TOKEN>
<TOKEN id="token-25-8" pos="word" morph="none" start_char="2728" end_char="2733">recent</TOKEN>
<TOKEN id="token-25-9" pos="word" morph="none" start_char="2735" end_char="2743">emergence</TOKEN>
<TOKEN id="token-25-10" pos="word" morph="none" start_char="2745" end_char="2748">from</TOKEN>
<TOKEN id="token-25-11" pos="word" morph="none" start_char="2750" end_char="2750">a</TOKEN>
<TOKEN id="token-25-12" pos="word" morph="none" start_char="2752" end_char="2756">virus</TOKEN>
<TOKEN id="token-25-13" pos="word" morph="none" start_char="2758" end_char="2764">related</TOKEN>
<TOKEN id="token-25-14" pos="word" morph="none" start_char="2766" end_char="2767">to</TOKEN>
<TOKEN id="token-25-15" pos="word" morph="none" start_char="2769" end_char="2771">bat</TOKEN>
<TOKEN id="token-25-16" pos="word" morph="none" start_char="2773" end_char="2785">coronaviruses</TOKEN>
<TOKEN id="token-25-17" pos="word" morph="none" start_char="2787" end_char="2789">and</TOKEN>
<TOKEN id="token-25-18" pos="word" morph="none" start_char="2791" end_char="2793">the</TOKEN>
<TOKEN id="token-25-19" pos="word" morph="none" start_char="2795" end_char="2798">SARS</TOKEN>
<TOKEN id="token-25-20" pos="word" morph="none" start_char="2800" end_char="2810">coronavirus</TOKEN>
<TOKEN id="token-25-21" pos="punct" morph="none" start_char="2811" end_char="2812">."</TOKEN>
</SEG>
<SEG id="segment-26" start_char="2814" end_char="2994">
<ORIGINAL_TEXT>The disease appears to have originated at a seafood and animal market in Wuhan, and it spread from there to several Asian countries, Australia, France, Canada and the United States.</ORIGINAL_TEXT>
<TOKEN id="token-26-0" pos="word" morph="none" start_char="2814" end_char="2816">The</TOKEN>
<TOKEN id="token-26-1" pos="word" morph="none" start_char="2818" end_char="2824">disease</TOKEN>
<TOKEN id="token-26-2" pos="word" morph="none" start_char="2826" end_char="2832">appears</TOKEN>
<TOKEN id="token-26-3" pos="word" morph="none" start_char="2834" end_char="2835">to</TOKEN>
<TOKEN id="token-26-4" pos="word" morph="none" start_char="2837" end_char="2840">have</TOKEN>
<TOKEN id="token-26-5" pos="word" morph="none" start_char="2842" end_char="2851">originated</TOKEN>
<TOKEN id="token-26-6" pos="word" morph="none" start_char="2853" end_char="2854">at</TOKEN>
<TOKEN id="token-26-7" pos="word" morph="none" start_char="2856" end_char="2856">a</TOKEN>
<TOKEN id="token-26-8" pos="word" morph="none" start_char="2858" end_char="2864">seafood</TOKEN>
<TOKEN id="token-26-9" pos="word" morph="none" start_char="2866" end_char="2868">and</TOKEN>
<TOKEN id="token-26-10" pos="word" morph="none" start_char="2870" end_char="2875">animal</TOKEN>
<TOKEN id="token-26-11" pos="word" morph="none" start_char="2877" end_char="2882">market</TOKEN>
<TOKEN id="token-26-12" pos="word" morph="none" start_char="2884" end_char="2885">in</TOKEN>
<TOKEN id="token-26-13" pos="word" morph="none" start_char="2887" end_char="2891">Wuhan</TOKEN>
<TOKEN id="token-26-14" pos="punct" morph="none" start_char="2892" end_char="2892">,</TOKEN>
<TOKEN id="token-26-15" pos="word" morph="none" start_char="2894" end_char="2896">and</TOKEN>
<TOKEN id="token-26-16" pos="word" morph="none" start_char="2898" end_char="2899">it</TOKEN>
<TOKEN id="token-26-17" pos="word" morph="none" start_char="2901" end_char="2906">spread</TOKEN>
<TOKEN id="token-26-18" pos="word" morph="none" start_char="2908" end_char="2911">from</TOKEN>
<TOKEN id="token-26-19" pos="word" morph="none" start_char="2913" end_char="2917">there</TOKEN>
<TOKEN id="token-26-20" pos="word" morph="none" start_char="2919" end_char="2920">to</TOKEN>
<TOKEN id="token-26-21" pos="word" morph="none" start_char="2922" end_char="2928">several</TOKEN>
<TOKEN id="token-26-22" pos="word" morph="none" start_char="2930" end_char="2934">Asian</TOKEN>
<TOKEN id="token-26-23" pos="word" morph="none" start_char="2936" end_char="2944">countries</TOKEN>
<TOKEN id="token-26-24" pos="punct" morph="none" start_char="2945" end_char="2945">,</TOKEN>
<TOKEN id="token-26-25" pos="word" morph="none" start_char="2947" end_char="2955">Australia</TOKEN>
<TOKEN id="token-26-26" pos="punct" morph="none" start_char="2956" end_char="2956">,</TOKEN>
<TOKEN id="token-26-27" pos="word" morph="none" start_char="2958" end_char="2963">France</TOKEN>
<TOKEN id="token-26-28" pos="punct" morph="none" start_char="2964" end_char="2964">,</TOKEN>
<TOKEN id="token-26-29" pos="word" morph="none" start_char="2966" end_char="2971">Canada</TOKEN>
<TOKEN id="token-26-30" pos="word" morph="none" start_char="2973" end_char="2975">and</TOKEN>
<TOKEN id="token-26-31" pos="word" morph="none" start_char="2977" end_char="2979">the</TOKEN>
<TOKEN id="token-26-32" pos="word" morph="none" start_char="2981" end_char="2986">United</TOKEN>
<TOKEN id="token-26-33" pos="word" morph="none" start_char="2988" end_char="2993">States</TOKEN>
<TOKEN id="token-26-34" pos="punct" morph="none" start_char="2994" end_char="2994">.</TOKEN>
</SEG>
<SEG id="segment-27" start_char="2996" end_char="3144">
<ORIGINAL_TEXT>Researchers believe the current outbreak pattern suggests the coronavirus may have spread from animal to human at first, and now from human to human.</ORIGINAL_TEXT>
<TOKEN id="token-27-0" pos="word" morph="none" start_char="2996" end_char="3006">Researchers</TOKEN>
<TOKEN id="token-27-1" pos="word" morph="none" start_char="3008" end_char="3014">believe</TOKEN>
<TOKEN id="token-27-2" pos="word" morph="none" start_char="3016" end_char="3018">the</TOKEN>
<TOKEN id="token-27-3" pos="word" morph="none" start_char="3020" end_char="3026">current</TOKEN>
<TOKEN id="token-27-4" pos="word" morph="none" start_char="3028" end_char="3035">outbreak</TOKEN>
<TOKEN id="token-27-5" pos="word" morph="none" start_char="3037" end_char="3043">pattern</TOKEN>
<TOKEN id="token-27-6" pos="word" morph="none" start_char="3045" end_char="3052">suggests</TOKEN>
<TOKEN id="token-27-7" pos="word" morph="none" start_char="3054" end_char="3056">the</TOKEN>
<TOKEN id="token-27-8" pos="word" morph="none" start_char="3058" end_char="3068">coronavirus</TOKEN>
<TOKEN id="token-27-9" pos="word" morph="none" start_char="3070" end_char="3072">may</TOKEN>
<TOKEN id="token-27-10" pos="word" morph="none" start_char="3074" end_char="3077">have</TOKEN>
<TOKEN id="token-27-11" pos="word" morph="none" start_char="3079" end_char="3084">spread</TOKEN>
<TOKEN id="token-27-12" pos="word" morph="none" start_char="3086" end_char="3089">from</TOKEN>
<TOKEN id="token-27-13" pos="word" morph="none" start_char="3091" end_char="3096">animal</TOKEN>
<TOKEN id="token-27-14" pos="word" morph="none" start_char="3098" end_char="3099">to</TOKEN>
<TOKEN id="token-27-15" pos="word" morph="none" start_char="3101" end_char="3105">human</TOKEN>
<TOKEN id="token-27-16" pos="word" morph="none" start_char="3107" end_char="3108">at</TOKEN>
<TOKEN id="token-27-17" pos="word" morph="none" start_char="3110" end_char="3114">first</TOKEN>
<TOKEN id="token-27-18" pos="punct" morph="none" start_char="3115" end_char="3115">,</TOKEN>
<TOKEN id="token-27-19" pos="word" morph="none" start_char="3117" end_char="3119">and</TOKEN>
<TOKEN id="token-27-20" pos="word" morph="none" start_char="3121" end_char="3123">now</TOKEN>
<TOKEN id="token-27-21" pos="word" morph="none" start_char="3125" end_char="3128">from</TOKEN>
<TOKEN id="token-27-22" pos="word" morph="none" start_char="3130" end_char="3134">human</TOKEN>
<TOKEN id="token-27-23" pos="word" morph="none" start_char="3136" end_char="3137">to</TOKEN>
<TOKEN id="token-27-24" pos="word" morph="none" start_char="3139" end_char="3143">human</TOKEN>
<TOKEN id="token-27-25" pos="punct" morph="none" start_char="3144" end_char="3144">.</TOKEN>
</SEG>
<SEG id="segment-28" start_char="3147" end_char="3174">
<ORIGINAL_TEXT>G News’ story is inaccurate.</ORIGINAL_TEXT>
<TOKEN id="token-28-0" pos="word" morph="none" start_char="3147" end_char="3147">G</TOKEN>
<TOKEN id="token-28-1" pos="word" morph="none" start_char="3149" end_char="3152">News</TOKEN>
<TOKEN id="token-28-2" pos="punct" morph="none" start_char="3153" end_char="3153">’</TOKEN>
<TOKEN id="token-28-3" pos="word" morph="none" start_char="3155" end_char="3159">story</TOKEN>
<TOKEN id="token-28-4" pos="word" morph="none" start_char="3161" end_char="3162">is</TOKEN>
<TOKEN id="token-28-5" pos="word" morph="none" start_char="3164" end_char="3173">inaccurate</TOKEN>
<TOKEN id="token-28-6" pos="punct" morph="none" start_char="3174" end_char="3174">.</TOKEN>
</SEG>
<SEG id="segment-29" start_char="3176" end_char="3192">
<ORIGINAL_TEXT>We rate it False.</ORIGINAL_TEXT>
<TOKEN id="token-29-0" pos="word" morph="none" start_char="3176" end_char="3177">We</TOKEN>
<TOKEN id="token-29-1" pos="word" morph="none" start_char="3179" end_char="3182">rate</TOKEN>
<TOKEN id="token-29-2" pos="word" morph="none" start_char="3184" end_char="3185">it</TOKEN>
<TOKEN id="token-29-3" pos="word" morph="none" start_char="3187" end_char="3191">False</TOKEN>
<TOKEN id="token-29-4" pos="punct" morph="none" start_char="3192" end_char="3192">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>
