<?xml version="1.0" encoding="utf-8"?>
<LCTL_TEXT>
	<DOC id="covid19scenario-3">
		<TEXT>
			<SEG id="covid19scenario-3-0" start_char="0" end_char="132">
				<ORIGINAL_TEXT>Corrections &amp; Clarifications: This fact-check has been revised based on updated reporting since it was first published in March 2020.</ORIGINAL_TEXT>
				<TOKEN id="token-0-0" start_char="0" end_char="10">Corrections</TOKEN>
				<TOKEN id="token-0-1" start_char="12" end_char="12">&amp;</TOKEN>
				<TOKEN id="token-0-2" start_char="14" end_char="27">Clarifications</TOKEN>
				<TOKEN id="token-0-3" start_char="28" end_char="28">:</TOKEN>
				<TOKEN id="token-0-4" start_char="30" end_char="33">This</TOKEN>
				<TOKEN id="token-0-5" start_char="35" end_char="38">fact</TOKEN>
				<TOKEN id="token-0-6" start_char="39" end_char="39">-</TOKEN>
				<TOKEN id="token-0-7" start_char="40" end_char="44">check</TOKEN>
				<TOKEN id="token-0-8" start_char="46" end_char="48">has</TOKEN>
				<TOKEN id="token-0-9" start_char="50" end_char="53">been</TOKEN>
				<TOKEN id="token-0-10" start_char="55" end_char="61">revised</TOKEN>
				<TOKEN id="token-0-11" start_char="63" end_char="67">based</TOKEN>
				<TOKEN id="token-0-12" start_char="69" end_char="70">on</TOKEN>
				<TOKEN id="token-0-13" start_char="72" end_char="78">updated</TOKEN>
				<TOKEN id="token-0-14" start_char="80" end_char="88">reporting</TOKEN>
				<TOKEN id="token-0-15" start_char="90" end_char="94">since</TOKEN>
				<TOKEN id="token-0-16" start_char="96" end_char="97">it</TOKEN>
				<TOKEN id="token-0-17" start_char="99" end_char="101">was</TOKEN>
				<TOKEN id="token-0-18" start_char="103" end_char="107">first</TOKEN>
				<TOKEN id="token-0-19" start_char="109" end_char="117">published</TOKEN>
				<TOKEN id="token-0-20" start_char="119" end_char="120">in</TOKEN>
				<TOKEN id="token-0-21" start_char="122" end_char="126">March</TOKEN>
				<TOKEN id="token-0-22" start_char="128" end_char="131">2020</TOKEN>
				<TOKEN id="token-0-23" start_char="132" end_char="132">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-1" start_char="134" end_char="216">
				<ORIGINAL_TEXT>The rating on the claim has been changed to Partly False to reflect that reporting.</ORIGINAL_TEXT>
				<TOKEN id="token-1-0" start_char="134" end_char="136">The</TOKEN>
				<TOKEN id="token-1-1" start_char="138" end_char="143">rating</TOKEN>
				<TOKEN id="token-1-2" start_char="145" end_char="146">on</TOKEN>
				<TOKEN id="token-1-3" start_char="148" end_char="150">the</TOKEN>
				<TOKEN id="token-1-4" start_char="152" end_char="156">claim</TOKEN>
				<TOKEN id="token-1-5" start_char="158" end_char="160">has</TOKEN>
				<TOKEN id="token-1-6" start_char="162" end_char="165">been</TOKEN>
				<TOKEN id="token-1-7" start_char="167" end_char="173">changed</TOKEN>
				<TOKEN id="token-1-8" start_char="175" end_char="176">to</TOKEN>
				<TOKEN id="token-1-9" start_char="178" end_char="183">Partly</TOKEN>
				<TOKEN id="token-1-10" start_char="185" end_char="189">False</TOKEN>
				<TOKEN id="token-1-11" start_char="191" end_char="192">to</TOKEN>
				<TOKEN id="token-1-12" start_char="194" end_char="200">reflect</TOKEN>
				<TOKEN id="token-1-13" start_char="202" end_char="205">that</TOKEN>
				<TOKEN id="token-1-14" start_char="207" end_char="215">reporting</TOKEN>
				<TOKEN id="token-1-15" start_char="216" end_char="216">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-2" start_char="218" end_char="333">
				<ORIGINAL_TEXT>In February 2021, this story has been updated to reflect current information on the origin of the novel coronavirus.</ORIGINAL_TEXT>
				<TOKEN id="token-2-0" start_char="218" end_char="219">In</TOKEN>
				<TOKEN id="token-2-1" start_char="221" end_char="228">February</TOKEN>
				<TOKEN id="token-2-2" start_char="230" end_char="233">2021</TOKEN>
				<TOKEN id="token-2-3" start_char="234" end_char="234">,</TOKEN>
				<TOKEN id="token-2-4" start_char="236" end_char="239">this</TOKEN>
				<TOKEN id="token-2-5" start_char="241" end_char="245">story</TOKEN>
				<TOKEN id="token-2-6" start_char="247" end_char="249">has</TOKEN>
				<TOKEN id="token-2-7" start_char="251" end_char="254">been</TOKEN>
				<TOKEN id="token-2-8" start_char="256" end_char="262">updated</TOKEN>
				<TOKEN id="token-2-9" start_char="264" end_char="265">to</TOKEN>
				<TOKEN id="token-2-10" start_char="267" end_char="273">reflect</TOKEN>
				<TOKEN id="token-2-11" start_char="275" end_char="281">current</TOKEN>
				<TOKEN id="token-2-12" start_char="283" end_char="293">information</TOKEN>
				<TOKEN id="token-2-13" start_char="295" end_char="296">on</TOKEN>
				<TOKEN id="token-2-14" start_char="298" end_char="300">the</TOKEN>
				<TOKEN id="token-2-15" start_char="302" end_char="307">origin</TOKEN>
				<TOKEN id="token-2-16" start_char="309" end_char="310">of</TOKEN>
				<TOKEN id="token-2-17" start_char="312" end_char="314">the</TOKEN>
				<TOKEN id="token-2-18" start_char="316" end_char="320">novel</TOKEN>
				<TOKEN id="token-2-19" start_char="322" end_char="332">coronavirus</TOKEN>
				<TOKEN id="token-2-20" start_char="333" end_char="333">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-3" start_char="335" end_char="405">
				<ORIGINAL_TEXT>The claim: The coronavirus may have originated in a Chinese laboratory.</ORIGINAL_TEXT>
				<TOKEN id="token-3-0" start_char="335" end_char="337">The</TOKEN>
				<TOKEN id="token-3-1" start_char="339" end_char="343">claim</TOKEN>
				<TOKEN id="token-3-2" start_char="344" end_char="344">:</TOKEN>
				<TOKEN id="token-3-3" start_char="346" end_char="348">The</TOKEN>
				<TOKEN id="token-3-4" start_char="350" end_char="360">coronavirus</TOKEN>
				<TOKEN id="token-3-5" start_char="362" end_char="364">may</TOKEN>
				<TOKEN id="token-3-6" start_char="366" end_char="369">have</TOKEN>
				<TOKEN id="token-3-7" start_char="371" end_char="380">originated</TOKEN>
				<TOKEN id="token-3-8" start_char="382" end_char="383">in</TOKEN>
				<TOKEN id="token-3-9" start_char="385" end_char="385">a</TOKEN>
				<TOKEN id="token-3-10" start_char="387" end_char="393">Chinese</TOKEN>
				<TOKEN id="token-3-11" start_char="395" end_char="404">laboratory</TOKEN>
				<TOKEN id="token-3-12" start_char="405" end_char="405">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-4" start_char="407" end_char="481">
				<ORIGINAL_TEXT>As the new coronavirus spreads, theories about its origins have circulated.</ORIGINAL_TEXT>
				<TOKEN id="token-4-0" start_char="407" end_char="408">As</TOKEN>
				<TOKEN id="token-4-1" start_char="410" end_char="412">the</TOKEN>
				<TOKEN id="token-4-2" start_char="414" end_char="416">new</TOKEN>
				<TOKEN id="token-4-3" start_char="418" end_char="428">coronavirus</TOKEN>
				<TOKEN id="token-4-4" start_char="430" end_char="436">spreads</TOKEN>
				<TOKEN id="token-4-5" start_char="437" end_char="437">,</TOKEN>
				<TOKEN id="token-4-6" start_char="439" end_char="446">theories</TOKEN>
				<TOKEN id="token-4-7" start_char="448" end_char="452">about</TOKEN>
				<TOKEN id="token-4-8" start_char="454" end_char="456">its</TOKEN>
				<TOKEN id="token-4-9" start_char="458" end_char="464">origins</TOKEN>
				<TOKEN id="token-4-10" start_char="466" end_char="469">have</TOKEN>
				<TOKEN id="token-4-11" start_char="471" end_char="480">circulated</TOKEN>
				<TOKEN id="token-4-12" start_char="481" end_char="481">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-5" start_char="483" end_char="566">
				<ORIGINAL_TEXT>And as scientists have studied the virus, some theories have been debunked as false.</ORIGINAL_TEXT>
				<TOKEN id="token-5-0" start_char="483" end_char="485">And</TOKEN>
				<TOKEN id="token-5-1" start_char="487" end_char="488">as</TOKEN>
				<TOKEN id="token-5-2" start_char="490" end_char="499">scientists</TOKEN>
				<TOKEN id="token-5-3" start_char="501" end_char="504">have</TOKEN>
				<TOKEN id="token-5-4" start_char="506" end_char="512">studied</TOKEN>
				<TOKEN id="token-5-5" start_char="514" end_char="516">the</TOKEN>
				<TOKEN id="token-5-6" start_char="518" end_char="522">virus</TOKEN>
				<TOKEN id="token-5-7" start_char="523" end_char="523">,</TOKEN>
				<TOKEN id="token-5-8" start_char="525" end_char="528">some</TOKEN>
				<TOKEN id="token-5-9" start_char="530" end_char="537">theories</TOKEN>
				<TOKEN id="token-5-10" start_char="539" end_char="542">have</TOKEN>
				<TOKEN id="token-5-11" start_char="544" end_char="547">been</TOKEN>
				<TOKEN id="token-5-12" start_char="549" end_char="556">debunked</TOKEN>
				<TOKEN id="token-5-13" start_char="558" end_char="559">as</TOKEN>
				<TOKEN id="token-5-14" start_char="561" end_char="565">false</TOKEN>
				<TOKEN id="token-5-15" start_char="566" end_char="566">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-6" start_char="568" end_char="791">
				<ORIGINAL_TEXT>One of the most prominent initial reports on the virus is an article published in January 2020 by the right-leaning Washington Times that suggests the coronavirus may have originated in a research laboratory in Wuhan, China.</ORIGINAL_TEXT>
				<TOKEN id="token-6-0" start_char="568" end_char="570">One</TOKEN>
				<TOKEN id="token-6-1" start_char="572" end_char="573">of</TOKEN>
				<TOKEN id="token-6-2" start_char="575" end_char="577">the</TOKEN>
				<TOKEN id="token-6-3" start_char="579" end_char="582">most</TOKEN>
				<TOKEN id="token-6-4" start_char="584" end_char="592">prominent</TOKEN>
				<TOKEN id="token-6-5" start_char="594" end_char="600">initial</TOKEN>
				<TOKEN id="token-6-6" start_char="602" end_char="608">reports</TOKEN>
				<TOKEN id="token-6-7" start_char="610" end_char="611">on</TOKEN>
				<TOKEN id="token-6-8" start_char="613" end_char="615">the</TOKEN>
				<TOKEN id="token-6-9" start_char="617" end_char="621">virus</TOKEN>
				<TOKEN id="token-6-10" start_char="623" end_char="624">is</TOKEN>
				<TOKEN id="token-6-11" start_char="626" end_char="627">an</TOKEN>
				<TOKEN id="token-6-12" start_char="629" end_char="635">article</TOKEN>
				<TOKEN id="token-6-13" start_char="637" end_char="645">published</TOKEN>
				<TOKEN id="token-6-14" start_char="647" end_char="648">in</TOKEN>
				<TOKEN id="token-6-15" start_char="650" end_char="656">January</TOKEN>
				<TOKEN id="token-6-16" start_char="658" end_char="661">2020</TOKEN>
				<TOKEN id="token-6-17" start_char="663" end_char="664">by</TOKEN>
				<TOKEN id="token-6-18" start_char="666" end_char="668">the</TOKEN>
				<TOKEN id="token-6-19" start_char="670" end_char="674">right</TOKEN>
				<TOKEN id="token-6-20" start_char="675" end_char="675">-</TOKEN>
				<TOKEN id="token-6-21" start_char="676" end_char="682">leaning</TOKEN>
				<TOKEN id="token-6-22" start_char="684" end_char="693">Washington</TOKEN>
				<TOKEN id="token-6-23" start_char="695" end_char="699">Times</TOKEN>
				<TOKEN id="token-6-24" start_char="701" end_char="704">that</TOKEN>
				<TOKEN id="token-6-25" start_char="706" end_char="713">suggests</TOKEN>
				<TOKEN id="token-6-26" start_char="715" end_char="717">the</TOKEN>
				<TOKEN id="token-6-27" start_char="719" end_char="729">coronavirus</TOKEN>
				<TOKEN id="token-6-28" start_char="731" end_char="733">may</TOKEN>
				<TOKEN id="token-6-29" start_char="735" end_char="738">have</TOKEN>
				<TOKEN id="token-6-30" start_char="740" end_char="749">originated</TOKEN>
				<TOKEN id="token-6-31" start_char="751" end_char="752">in</TOKEN>
				<TOKEN id="token-6-32" start_char="754" end_char="754">a</TOKEN>
				<TOKEN id="token-6-33" start_char="756" end_char="763">research</TOKEN>
				<TOKEN id="token-6-34" start_char="765" end_char="774">laboratory</TOKEN>
				<TOKEN id="token-6-35" start_char="776" end_char="777">in</TOKEN>
				<TOKEN id="token-6-36" start_char="779" end_char="783">Wuhan</TOKEN>
				<TOKEN id="token-6-37" start_char="784" end_char="784">,</TOKEN>
				<TOKEN id="token-6-38" start_char="786" end_char="790">China</TOKEN>
				<TOKEN id="token-6-39" start_char="791" end_char="791">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-7" start_char="793" end_char="866">
				<ORIGINAL_TEXT>Related:WHO says coronavirus came from an animal and was not made in a lab</ORIGINAL_TEXT>
				<TOKEN id="token-7-0" start_char="793" end_char="799">Related</TOKEN>
				<TOKEN id="token-7-1" start_char="800" end_char="800">:</TOKEN>
				<TOKEN id="token-7-2" start_char="801" end_char="803">WHO</TOKEN>
				<TOKEN id="token-7-3" start_char="805" end_char="808">says</TOKEN>
				<TOKEN id="token-7-4" start_char="810" end_char="820">coronavirus</TOKEN>
				<TOKEN id="token-7-5" start_char="822" end_char="825">came</TOKEN>
				<TOKEN id="token-7-6" start_char="827" end_char="830">from</TOKEN>
				<TOKEN id="token-7-7" start_char="832" end_char="833">an</TOKEN>
				<TOKEN id="token-7-8" start_char="835" end_char="840">animal</TOKEN>
				<TOKEN id="token-7-9" start_char="842" end_char="844">and</TOKEN>
				<TOKEN id="token-7-10" start_char="846" end_char="848">was</TOKEN>
				<TOKEN id="token-7-11" start_char="850" end_char="852">not</TOKEN>
				<TOKEN id="token-7-12" start_char="854" end_char="857">made</TOKEN>
				<TOKEN id="token-7-13" start_char="859" end_char="860">in</TOKEN>
				<TOKEN id="token-7-14" start_char="862" end_char="862">a</TOKEN>
				<TOKEN id="token-7-15" start_char="864" end_char="866">lab</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-8" start_char="868" end_char="959">
				<ORIGINAL_TEXT>More:Fact check: Coronavirus originated in China, not elsewhere, researchers and studies say</ORIGINAL_TEXT>
				<TOKEN id="token-8-0" start_char="868" end_char="871">More</TOKEN>
				<TOKEN id="token-8-1" start_char="872" end_char="872">:</TOKEN>
				<TOKEN id="token-8-2" start_char="873" end_char="876">Fact</TOKEN>
				<TOKEN id="token-8-3" start_char="878" end_char="882">check</TOKEN>
				<TOKEN id="token-8-4" start_char="883" end_char="883">:</TOKEN>
				<TOKEN id="token-8-5" start_char="885" end_char="895">Coronavirus</TOKEN>
				<TOKEN id="token-8-6" start_char="897" end_char="906">originated</TOKEN>
				<TOKEN id="token-8-7" start_char="908" end_char="909">in</TOKEN>
				<TOKEN id="token-8-8" start_char="911" end_char="915">China</TOKEN>
				<TOKEN id="token-8-9" start_char="916" end_char="916">,</TOKEN>
				<TOKEN id="token-8-10" start_char="918" end_char="920">not</TOKEN>
				<TOKEN id="token-8-11" start_char="922" end_char="930">elsewhere</TOKEN>
				<TOKEN id="token-8-12" start_char="931" end_char="931">,</TOKEN>
				<TOKEN id="token-8-13" start_char="933" end_char="943">researchers</TOKEN>
				<TOKEN id="token-8-14" start_char="945" end_char="947">and</TOKEN>
				<TOKEN id="token-8-15" start_char="949" end_char="955">studies</TOKEN>
				<TOKEN id="token-8-16" start_char="957" end_char="959">say</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-9" start_char="961" end_char="1204">
				<ORIGINAL_TEXT>The article quoted a former military intelligence officer who claimed the Wuhan Institute of Virology, a maximum-security Chinese laboratory granted authority to research dangerous pathogens, “is linked to Beijing’s covert bio-weapons program.”</ORIGINAL_TEXT>
				<TOKEN id="token-9-0" start_char="961" end_char="963">The</TOKEN>
				<TOKEN id="token-9-1" start_char="965" end_char="971">article</TOKEN>
				<TOKEN id="token-9-2" start_char="973" end_char="978">quoted</TOKEN>
				<TOKEN id="token-9-3" start_char="980" end_char="980">a</TOKEN>
				<TOKEN id="token-9-4" start_char="982" end_char="987">former</TOKEN>
				<TOKEN id="token-9-5" start_char="989" end_char="996">military</TOKEN>
				<TOKEN id="token-9-6" start_char="998" end_char="1009">intelligence</TOKEN>
				<TOKEN id="token-9-7" start_char="1011" end_char="1017">officer</TOKEN>
				<TOKEN id="token-9-8" start_char="1019" end_char="1021">who</TOKEN>
				<TOKEN id="token-9-9" start_char="1023" end_char="1029">claimed</TOKEN>
				<TOKEN id="token-9-10" start_char="1031" end_char="1033">the</TOKEN>
				<TOKEN id="token-9-11" start_char="1035" end_char="1039">Wuhan</TOKEN>
				<TOKEN id="token-9-12" start_char="1041" end_char="1049">Institute</TOKEN>
				<TOKEN id="token-9-13" start_char="1051" end_char="1052">of</TOKEN>
				<TOKEN id="token-9-14" start_char="1054" end_char="1061">Virology</TOKEN>
				<TOKEN id="token-9-15" start_char="1062" end_char="1062">,</TOKEN>
				<TOKEN id="token-9-16" start_char="1064" end_char="1064">a</TOKEN>
				<TOKEN id="token-9-17" start_char="1066" end_char="1072">maximum</TOKEN>
				<TOKEN id="token-9-18" start_char="1073" end_char="1073">-</TOKEN>
				<TOKEN id="token-9-19" start_char="1074" end_char="1081">security</TOKEN>
				<TOKEN id="token-9-20" start_char="1083" end_char="1089">Chinese</TOKEN>
				<TOKEN id="token-9-21" start_char="1091" end_char="1100">laboratory</TOKEN>
				<TOKEN id="token-9-22" start_char="1102" end_char="1108">granted</TOKEN>
				<TOKEN id="token-9-23" start_char="1110" end_char="1118">authority</TOKEN>
				<TOKEN id="token-9-24" start_char="1120" end_char="1121">to</TOKEN>
				<TOKEN id="token-9-25" start_char="1123" end_char="1130">research</TOKEN>
				<TOKEN id="token-9-26" start_char="1132" end_char="1140">dangerous</TOKEN>
				<TOKEN id="token-9-27" start_char="1142" end_char="1150">pathogens</TOKEN>
				<TOKEN id="token-9-28" start_char="1151" end_char="1151">,</TOKEN>
				<TOKEN id="token-9-29" start_char="1153" end_char="1153">“</TOKEN>
				<TOKEN id="token-9-30" start_char="1154" end_char="1155">is</TOKEN>
				<TOKEN id="token-9-31" start_char="1157" end_char="1162">linked</TOKEN>
				<TOKEN id="token-9-32" start_char="1164" end_char="1165">to</TOKEN>
				<TOKEN id="token-9-33" start_char="1167" end_char="1173">Beijing</TOKEN>
				<TOKEN id="token-9-34" start_char="1174" end_char="1174">’</TOKEN>
				<TOKEN id="token-9-35" start_char="1175" end_char="1175">s</TOKEN>
				<TOKEN id="token-9-36" start_char="1177" end_char="1182">covert</TOKEN>
				<TOKEN id="token-9-37" start_char="1184" end_char="1186">bio</TOKEN>
				<TOKEN id="token-9-38" start_char="1187" end_char="1187">-</TOKEN>
				<TOKEN id="token-9-39" start_char="1188" end_char="1194">weapons</TOKEN>
				<TOKEN id="token-9-40" start_char="1196" end_char="1202">program</TOKEN>
				<TOKEN id="token-9-41" start_char="1203" end_char="1204">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-10" start_char="1206" end_char="1331">
				<ORIGINAL_TEXT>In mid-March, USA TODAY contacted the author of the article, Bill Gertz, with a request to comment but did not get a response.</ORIGINAL_TEXT>
				<TOKEN id="token-10-0" start_char="1206" end_char="1207">In</TOKEN>
				<TOKEN id="token-10-1" start_char="1209" end_char="1211">mid</TOKEN>
				<TOKEN id="token-10-2" start_char="1212" end_char="1212">-</TOKEN>
				<TOKEN id="token-10-3" start_char="1213" end_char="1217">March</TOKEN>
				<TOKEN id="token-10-4" start_char="1218" end_char="1218">,</TOKEN>
				<TOKEN id="token-10-5" start_char="1220" end_char="1222">USA</TOKEN>
				<TOKEN id="token-10-6" start_char="1224" end_char="1228">TODAY</TOKEN>
				<TOKEN id="token-10-7" start_char="1230" end_char="1238">contacted</TOKEN>
				<TOKEN id="token-10-8" start_char="1240" end_char="1242">the</TOKEN>
				<TOKEN id="token-10-9" start_char="1244" end_char="1249">author</TOKEN>
				<TOKEN id="token-10-10" start_char="1251" end_char="1252">of</TOKEN>
				<TOKEN id="token-10-11" start_char="1254" end_char="1256">the</TOKEN>
				<TOKEN id="token-10-12" start_char="1258" end_char="1264">article</TOKEN>
				<TOKEN id="token-10-13" start_char="1265" end_char="1265">,</TOKEN>
				<TOKEN id="token-10-14" start_char="1267" end_char="1270">Bill</TOKEN>
				<TOKEN id="token-10-15" start_char="1272" end_char="1276">Gertz</TOKEN>
				<TOKEN id="token-10-16" start_char="1277" end_char="1277">,</TOKEN>
				<TOKEN id="token-10-17" start_char="1279" end_char="1282">with</TOKEN>
				<TOKEN id="token-10-18" start_char="1284" end_char="1284">a</TOKEN>
				<TOKEN id="token-10-19" start_char="1286" end_char="1292">request</TOKEN>
				<TOKEN id="token-10-20" start_char="1294" end_char="1295">to</TOKEN>
				<TOKEN id="token-10-21" start_char="1297" end_char="1303">comment</TOKEN>
				<TOKEN id="token-10-22" start_char="1305" end_char="1307">but</TOKEN>
				<TOKEN id="token-10-23" start_char="1309" end_char="1311">did</TOKEN>
				<TOKEN id="token-10-24" start_char="1313" end_char="1315">not</TOKEN>
				<TOKEN id="token-10-25" start_char="1317" end_char="1319">get</TOKEN>
				<TOKEN id="token-10-26" start_char="1321" end_char="1321">a</TOKEN>
				<TOKEN id="token-10-27" start_char="1323" end_char="1330">response</TOKEN>
				<TOKEN id="token-10-28" start_char="1331" end_char="1331">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-11" start_char="1333" end_char="1557">
				<ORIGINAL_TEXT>On March 25, the Washington Times published an updated article that reflects what an editor's note said is updated reporting: &quot;Since this story ran, scientists outside of China have had a chance to study the SARS-CoV-2 virus.</ORIGINAL_TEXT>
				<TOKEN id="token-11-0" start_char="1333" end_char="1334">On</TOKEN>
				<TOKEN id="token-11-1" start_char="1336" end_char="1340">March</TOKEN>
				<TOKEN id="token-11-2" start_char="1342" end_char="1343">25</TOKEN>
				<TOKEN id="token-11-3" start_char="1344" end_char="1344">,</TOKEN>
				<TOKEN id="token-11-4" start_char="1346" end_char="1348">the</TOKEN>
				<TOKEN id="token-11-5" start_char="1350" end_char="1359">Washington</TOKEN>
				<TOKEN id="token-11-6" start_char="1361" end_char="1365">Times</TOKEN>
				<TOKEN id="token-11-7" start_char="1367" end_char="1375">published</TOKEN>
				<TOKEN id="token-11-8" start_char="1377" end_char="1378">an</TOKEN>
				<TOKEN id="token-11-9" start_char="1380" end_char="1386">updated</TOKEN>
				<TOKEN id="token-11-10" start_char="1388" end_char="1394">article</TOKEN>
				<TOKEN id="token-11-11" start_char="1396" end_char="1399">that</TOKEN>
				<TOKEN id="token-11-12" start_char="1401" end_char="1408">reflects</TOKEN>
				<TOKEN id="token-11-13" start_char="1410" end_char="1413">what</TOKEN>
				<TOKEN id="token-11-14" start_char="1415" end_char="1416">an</TOKEN>
				<TOKEN id="token-11-15" start_char="1418" end_char="1423">editor</TOKEN>
				<TOKEN id="token-11-16" start_char="1424" end_char="1424">'</TOKEN>
				<TOKEN id="token-11-17" start_char="1425" end_char="1425">s</TOKEN>
				<TOKEN id="token-11-18" start_char="1427" end_char="1430">note</TOKEN>
				<TOKEN id="token-11-19" start_char="1432" end_char="1435">said</TOKEN>
				<TOKEN id="token-11-20" start_char="1437" end_char="1438">is</TOKEN>
				<TOKEN id="token-11-21" start_char="1440" end_char="1446">updated</TOKEN>
				<TOKEN id="token-11-22" start_char="1448" end_char="1456">reporting</TOKEN>
				<TOKEN id="token-11-23" start_char="1457" end_char="1457">:</TOKEN>
				<TOKEN id="token-11-24" start_char="1459" end_char="1459">&quot;</TOKEN>
				<TOKEN id="token-11-25" start_char="1460" end_char="1464">Since</TOKEN>
				<TOKEN id="token-11-26" start_char="1466" end_char="1469">this</TOKEN>
				<TOKEN id="token-11-27" start_char="1471" end_char="1475">story</TOKEN>
				<TOKEN id="token-11-28" start_char="1477" end_char="1479">ran</TOKEN>
				<TOKEN id="token-11-29" start_char="1480" end_char="1480">,</TOKEN>
				<TOKEN id="token-11-30" start_char="1482" end_char="1491">scientists</TOKEN>
				<TOKEN id="token-11-31" start_char="1493" end_char="1499">outside</TOKEN>
				<TOKEN id="token-11-32" start_char="1501" end_char="1502">of</TOKEN>
				<TOKEN id="token-11-33" start_char="1504" end_char="1508">China</TOKEN>
				<TOKEN id="token-11-34" start_char="1510" end_char="1513">have</TOKEN>
				<TOKEN id="token-11-35" start_char="1515" end_char="1517">had</TOKEN>
				<TOKEN id="token-11-36" start_char="1519" end_char="1519">a</TOKEN>
				<TOKEN id="token-11-37" start_char="1521" end_char="1526">chance</TOKEN>
				<TOKEN id="token-11-38" start_char="1528" end_char="1529">to</TOKEN>
				<TOKEN id="token-11-39" start_char="1531" end_char="1535">study</TOKEN>
				<TOKEN id="token-11-40" start_char="1537" end_char="1539">the</TOKEN>
				<TOKEN id="token-11-41" start_char="1541" end_char="1544">SARS</TOKEN>
				<TOKEN id="token-11-42" start_char="1545" end_char="1545">-</TOKEN>
				<TOKEN id="token-11-43" start_char="1546" end_char="1548">CoV</TOKEN>
				<TOKEN id="token-11-44" start_char="1549" end_char="1549">-</TOKEN>
				<TOKEN id="token-11-45" start_char="1550" end_char="1550">2</TOKEN>
				<TOKEN id="token-11-46" start_char="1552" end_char="1556">virus</TOKEN>
				<TOKEN id="token-11-47" start_char="1557" end_char="1557">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-12" start_char="1559" end_char="1787">
				<ORIGINAL_TEXT>They concluded it does not show signs of having been manufactured or purposefully manipulated in a lab, though the exact origin remains murky and experts debate whether it may have leaked from a Chinese lab that was studying it.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-12-0" start_char="1559" end_char="1562">They</TOKEN>
				<TOKEN id="token-12-1" start_char="1564" end_char="1572">concluded</TOKEN>
				<TOKEN id="token-12-2" start_char="1574" end_char="1575">it</TOKEN>
				<TOKEN id="token-12-3" start_char="1577" end_char="1580">does</TOKEN>
				<TOKEN id="token-12-4" start_char="1582" end_char="1584">not</TOKEN>
				<TOKEN id="token-12-5" start_char="1586" end_char="1589">show</TOKEN>
				<TOKEN id="token-12-6" start_char="1591" end_char="1595">signs</TOKEN>
				<TOKEN id="token-12-7" start_char="1597" end_char="1598">of</TOKEN>
				<TOKEN id="token-12-8" start_char="1600" end_char="1605">having</TOKEN>
				<TOKEN id="token-12-9" start_char="1607" end_char="1610">been</TOKEN>
				<TOKEN id="token-12-10" start_char="1612" end_char="1623">manufactured</TOKEN>
				<TOKEN id="token-12-11" start_char="1625" end_char="1626">or</TOKEN>
				<TOKEN id="token-12-12" start_char="1628" end_char="1639">purposefully</TOKEN>
				<TOKEN id="token-12-13" start_char="1641" end_char="1651">manipulated</TOKEN>
				<TOKEN id="token-12-14" start_char="1653" end_char="1654">in</TOKEN>
				<TOKEN id="token-12-15" start_char="1656" end_char="1656">a</TOKEN>
				<TOKEN id="token-12-16" start_char="1658" end_char="1660">lab</TOKEN>
				<TOKEN id="token-12-17" start_char="1661" end_char="1661">,</TOKEN>
				<TOKEN id="token-12-18" start_char="1663" end_char="1668">though</TOKEN>
				<TOKEN id="token-12-19" start_char="1670" end_char="1672">the</TOKEN>
				<TOKEN id="token-12-20" start_char="1674" end_char="1678">exact</TOKEN>
				<TOKEN id="token-12-21" start_char="1680" end_char="1685">origin</TOKEN>
				<TOKEN id="token-12-22" start_char="1687" end_char="1693">remains</TOKEN>
				<TOKEN id="token-12-23" start_char="1695" end_char="1699">murky</TOKEN>
				<TOKEN id="token-12-24" start_char="1701" end_char="1703">and</TOKEN>
				<TOKEN id="token-12-25" start_char="1705" end_char="1711">experts</TOKEN>
				<TOKEN id="token-12-26" start_char="1713" end_char="1718">debate</TOKEN>
				<TOKEN id="token-12-27" start_char="1720" end_char="1726">whether</TOKEN>
				<TOKEN id="token-12-28" start_char="1728" end_char="1729">it</TOKEN>
				<TOKEN id="token-12-29" start_char="1731" end_char="1733">may</TOKEN>
				<TOKEN id="token-12-30" start_char="1735" end_char="1738">have</TOKEN>
				<TOKEN id="token-12-31" start_char="1740" end_char="1745">leaked</TOKEN>
				<TOKEN id="token-12-32" start_char="1747" end_char="1750">from</TOKEN>
				<TOKEN id="token-12-33" start_char="1752" end_char="1752">a</TOKEN>
				<TOKEN id="token-12-34" start_char="1754" end_char="1760">Chinese</TOKEN>
				<TOKEN id="token-12-35" start_char="1762" end_char="1764">lab</TOKEN>
				<TOKEN id="token-12-36" start_char="1766" end_char="1769">that</TOKEN>
				<TOKEN id="token-12-37" start_char="1771" end_char="1773">was</TOKEN>
				<TOKEN id="token-12-38" start_char="1775" end_char="1782">studying</TOKEN>
				<TOKEN id="token-12-39" start_char="1784" end_char="1785">it</TOKEN>
				<TOKEN id="token-12-40" start_char="1786" end_char="1787">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-13" start_char="1789" end_char="1897">
				<ORIGINAL_TEXT>People on multiple platforms and networks have shared the same or a similar version of the conspiracy theory.</ORIGINAL_TEXT>
				<TOKEN id="token-13-0" start_char="1789" end_char="1794">People</TOKEN>
				<TOKEN id="token-13-1" start_char="1796" end_char="1797">on</TOKEN>
				<TOKEN id="token-13-2" start_char="1799" end_char="1806">multiple</TOKEN>
				<TOKEN id="token-13-3" start_char="1808" end_char="1816">platforms</TOKEN>
				<TOKEN id="token-13-4" start_char="1818" end_char="1820">and</TOKEN>
				<TOKEN id="token-13-5" start_char="1822" end_char="1829">networks</TOKEN>
				<TOKEN id="token-13-6" start_char="1831" end_char="1834">have</TOKEN>
				<TOKEN id="token-13-7" start_char="1836" end_char="1841">shared</TOKEN>
				<TOKEN id="token-13-8" start_char="1843" end_char="1845">the</TOKEN>
				<TOKEN id="token-13-9" start_char="1847" end_char="1850">same</TOKEN>
				<TOKEN id="token-13-10" start_char="1852" end_char="1853">or</TOKEN>
				<TOKEN id="token-13-11" start_char="1855" end_char="1855">a</TOKEN>
				<TOKEN id="token-13-12" start_char="1857" end_char="1863">similar</TOKEN>
				<TOKEN id="token-13-13" start_char="1865" end_char="1871">version</TOKEN>
				<TOKEN id="token-13-14" start_char="1873" end_char="1874">of</TOKEN>
				<TOKEN id="token-13-15" start_char="1876" end_char="1878">the</TOKEN>
				<TOKEN id="token-13-16" start_char="1880" end_char="1889">conspiracy</TOKEN>
				<TOKEN id="token-13-17" start_char="1891" end_char="1896">theory</TOKEN>
				<TOKEN id="token-13-18" start_char="1897" end_char="1897">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-14" start_char="1899" end_char="2043">
				<ORIGINAL_TEXT>Sen. Tom Cotton, R-Ark., has suggested to Congress and Fox News that there may be a connection between the Wuhan lab and the origin of the virus.</ORIGINAL_TEXT>
				<TOKEN id="token-14-0" start_char="1899" end_char="1901">Sen</TOKEN>
				<TOKEN id="token-14-1" start_char="1902" end_char="1902">.</TOKEN>
				<TOKEN id="token-14-2" start_char="1904" end_char="1906">Tom</TOKEN>
				<TOKEN id="token-14-3" start_char="1908" end_char="1913">Cotton</TOKEN>
				<TOKEN id="token-14-4" start_char="1914" end_char="1914">,</TOKEN>
				<TOKEN id="token-14-5" start_char="1916" end_char="1916">R</TOKEN>
				<TOKEN id="token-14-6" start_char="1917" end_char="1917">-</TOKEN>
				<TOKEN id="token-14-7" start_char="1918" end_char="1920">Ark</TOKEN>
				<TOKEN id="token-14-8" start_char="1921" end_char="1922">.,</TOKEN>
				<TOKEN id="token-14-9" start_char="1924" end_char="1926">has</TOKEN>
				<TOKEN id="token-14-10" start_char="1928" end_char="1936">suggested</TOKEN>
				<TOKEN id="token-14-11" start_char="1938" end_char="1939">to</TOKEN>
				<TOKEN id="token-14-12" start_char="1941" end_char="1948">Congress</TOKEN>
				<TOKEN id="token-14-13" start_char="1950" end_char="1952">and</TOKEN>
				<TOKEN id="token-14-14" start_char="1954" end_char="1956">Fox</TOKEN>
				<TOKEN id="token-14-15" start_char="1958" end_char="1961">News</TOKEN>
				<TOKEN id="token-14-16" start_char="1963" end_char="1966">that</TOKEN>
				<TOKEN id="token-14-17" start_char="1968" end_char="1972">there</TOKEN>
				<TOKEN id="token-14-18" start_char="1974" end_char="1976">may</TOKEN>
				<TOKEN id="token-14-19" start_char="1978" end_char="1979">be</TOKEN>
				<TOKEN id="token-14-20" start_char="1981" end_char="1981">a</TOKEN>
				<TOKEN id="token-14-21" start_char="1983" end_char="1992">connection</TOKEN>
				<TOKEN id="token-14-22" start_char="1994" end_char="2000">between</TOKEN>
				<TOKEN id="token-14-23" start_char="2002" end_char="2004">the</TOKEN>
				<TOKEN id="token-14-24" start_char="2006" end_char="2010">Wuhan</TOKEN>
				<TOKEN id="token-14-25" start_char="2012" end_char="2014">lab</TOKEN>
				<TOKEN id="token-14-26" start_char="2016" end_char="2018">and</TOKEN>
				<TOKEN id="token-14-27" start_char="2020" end_char="2022">the</TOKEN>
				<TOKEN id="token-14-28" start_char="2024" end_char="2029">origin</TOKEN>
				<TOKEN id="token-14-29" start_char="2031" end_char="2032">of</TOKEN>
				<TOKEN id="token-14-30" start_char="2034" end_char="2036">the</TOKEN>
				<TOKEN id="token-14-31" start_char="2038" end_char="2042">virus</TOKEN>
				<TOKEN id="token-14-32" start_char="2043" end_char="2043">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-15" start_char="2045" end_char="2234">
				<ORIGINAL_TEXT>And conservative radio host Rush Limbaugh wrote in an article in February that “it probably is a ChiCom (Chinese Communist) laboratory experiment that is in the process of being weaponized.”</ORIGINAL_TEXT>
				<TOKEN id="token-15-0" start_char="2045" end_char="2047">And</TOKEN>
				<TOKEN id="token-15-1" start_char="2049" end_char="2060">conservative</TOKEN>
				<TOKEN id="token-15-2" start_char="2062" end_char="2066">radio</TOKEN>
				<TOKEN id="token-15-3" start_char="2068" end_char="2071">host</TOKEN>
				<TOKEN id="token-15-4" start_char="2073" end_char="2076">Rush</TOKEN>
				<TOKEN id="token-15-5" start_char="2078" end_char="2085">Limbaugh</TOKEN>
				<TOKEN id="token-15-6" start_char="2087" end_char="2091">wrote</TOKEN>
				<TOKEN id="token-15-7" start_char="2093" end_char="2094">in</TOKEN>
				<TOKEN id="token-15-8" start_char="2096" end_char="2097">an</TOKEN>
				<TOKEN id="token-15-9" start_char="2099" end_char="2105">article</TOKEN>
				<TOKEN id="token-15-10" start_char="2107" end_char="2108">in</TOKEN>
				<TOKEN id="token-15-11" start_char="2110" end_char="2117">February</TOKEN>
				<TOKEN id="token-15-12" start_char="2119" end_char="2122">that</TOKEN>
				<TOKEN id="token-15-13" start_char="2124" end_char="2124">“</TOKEN>
				<TOKEN id="token-15-14" start_char="2125" end_char="2126">it</TOKEN>
				<TOKEN id="token-15-15" start_char="2128" end_char="2135">probably</TOKEN>
				<TOKEN id="token-15-16" start_char="2137" end_char="2138">is</TOKEN>
				<TOKEN id="token-15-17" start_char="2140" end_char="2140">a</TOKEN>
				<TOKEN id="token-15-18" start_char="2142" end_char="2147">ChiCom</TOKEN>
				<TOKEN id="token-15-19" start_char="2149" end_char="2149">(</TOKEN>
				<TOKEN id="token-15-20" start_char="2150" end_char="2156">Chinese</TOKEN>
				<TOKEN id="token-15-21" start_char="2158" end_char="2166">Communist</TOKEN>
				<TOKEN id="token-15-22" start_char="2167" end_char="2167">)</TOKEN>
				<TOKEN id="token-15-23" start_char="2169" end_char="2178">laboratory</TOKEN>
				<TOKEN id="token-15-24" start_char="2180" end_char="2189">experiment</TOKEN>
				<TOKEN id="token-15-25" start_char="2191" end_char="2194">that</TOKEN>
				<TOKEN id="token-15-26" start_char="2196" end_char="2197">is</TOKEN>
				<TOKEN id="token-15-27" start_char="2199" end_char="2200">in</TOKEN>
				<TOKEN id="token-15-28" start_char="2202" end_char="2204">the</TOKEN>
				<TOKEN id="token-15-29" start_char="2206" end_char="2212">process</TOKEN>
				<TOKEN id="token-15-30" start_char="2214" end_char="2215">of</TOKEN>
				<TOKEN id="token-15-31" start_char="2217" end_char="2221">being</TOKEN>
				<TOKEN id="token-15-32" start_char="2223" end_char="2232">weaponized</TOKEN>
				<TOKEN id="token-15-33" start_char="2233" end_char="2234">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-16" start_char="2236" end_char="2324">
				<ORIGINAL_TEXT>Former White House strategist Steve Bannon repeated a similar claim on Fox News in March.</ORIGINAL_TEXT>
				<TOKEN id="token-16-0" start_char="2236" end_char="2241">Former</TOKEN>
				<TOKEN id="token-16-1" start_char="2243" end_char="2247">White</TOKEN>
				<TOKEN id="token-16-2" start_char="2249" end_char="2253">House</TOKEN>
				<TOKEN id="token-16-3" start_char="2255" end_char="2264">strategist</TOKEN>
				<TOKEN id="token-16-4" start_char="2266" end_char="2270">Steve</TOKEN>
				<TOKEN id="token-16-5" start_char="2272" end_char="2277">Bannon</TOKEN>
				<TOKEN id="token-16-6" start_char="2279" end_char="2286">repeated</TOKEN>
				<TOKEN id="token-16-7" start_char="2288" end_char="2288">a</TOKEN>
				<TOKEN id="token-16-8" start_char="2290" end_char="2296">similar</TOKEN>
				<TOKEN id="token-16-9" start_char="2298" end_char="2302">claim</TOKEN>
				<TOKEN id="token-16-10" start_char="2304" end_char="2305">on</TOKEN>
				<TOKEN id="token-16-11" start_char="2307" end_char="2309">Fox</TOKEN>
				<TOKEN id="token-16-12" start_char="2311" end_char="2314">News</TOKEN>
				<TOKEN id="token-16-13" start_char="2316" end_char="2317">in</TOKEN>
				<TOKEN id="token-16-14" start_char="2319" end_char="2323">March</TOKEN>
				<TOKEN id="token-16-15" start_char="2324" end_char="2324">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-17" start_char="2326" end_char="2410">
				<ORIGINAL_TEXT>And opinion columnist Steven Mosher touted the idea in the New York Post in February.</ORIGINAL_TEXT>
				<TOKEN id="token-17-0" start_char="2326" end_char="2328">And</TOKEN>
				<TOKEN id="token-17-1" start_char="2330" end_char="2336">opinion</TOKEN>
				<TOKEN id="token-17-2" start_char="2338" end_char="2346">columnist</TOKEN>
				<TOKEN id="token-17-3" start_char="2348" end_char="2353">Steven</TOKEN>
				<TOKEN id="token-17-4" start_char="2355" end_char="2360">Mosher</TOKEN>
				<TOKEN id="token-17-5" start_char="2362" end_char="2367">touted</TOKEN>
				<TOKEN id="token-17-6" start_char="2369" end_char="2371">the</TOKEN>
				<TOKEN id="token-17-7" start_char="2373" end_char="2376">idea</TOKEN>
				<TOKEN id="token-17-8" start_char="2378" end_char="2379">in</TOKEN>
				<TOKEN id="token-17-9" start_char="2381" end_char="2383">the</TOKEN>
				<TOKEN id="token-17-10" start_char="2385" end_char="2387">New</TOKEN>
				<TOKEN id="token-17-11" start_char="2389" end_char="2392">York</TOKEN>
				<TOKEN id="token-17-12" start_char="2394" end_char="2397">Post</TOKEN>
				<TOKEN id="token-17-13" start_char="2399" end_char="2400">in</TOKEN>
				<TOKEN id="token-17-14" start_char="2402" end_char="2409">February</TOKEN>
				<TOKEN id="token-17-15" start_char="2410" end_char="2410">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-18" start_char="2412" end_char="2569">
				<ORIGINAL_TEXT>Vox reported the claim also has been shared widely via message boards in China, prompting Chinese officials to release a statement denouncing the information.</ORIGINAL_TEXT>
				<TOKEN id="token-18-0" start_char="2412" end_char="2414">Vox</TOKEN>
				<TOKEN id="token-18-1" start_char="2416" end_char="2423">reported</TOKEN>
				<TOKEN id="token-18-2" start_char="2425" end_char="2427">the</TOKEN>
				<TOKEN id="token-18-3" start_char="2429" end_char="2433">claim</TOKEN>
				<TOKEN id="token-18-4" start_char="2435" end_char="2438">also</TOKEN>
				<TOKEN id="token-18-5" start_char="2440" end_char="2442">has</TOKEN>
				<TOKEN id="token-18-6" start_char="2444" end_char="2447">been</TOKEN>
				<TOKEN id="token-18-7" start_char="2449" end_char="2454">shared</TOKEN>
				<TOKEN id="token-18-8" start_char="2456" end_char="2461">widely</TOKEN>
				<TOKEN id="token-18-9" start_char="2463" end_char="2465">via</TOKEN>
				<TOKEN id="token-18-10" start_char="2467" end_char="2473">message</TOKEN>
				<TOKEN id="token-18-11" start_char="2475" end_char="2480">boards</TOKEN>
				<TOKEN id="token-18-12" start_char="2482" end_char="2483">in</TOKEN>
				<TOKEN id="token-18-13" start_char="2485" end_char="2489">China</TOKEN>
				<TOKEN id="token-18-14" start_char="2490" end_char="2490">,</TOKEN>
				<TOKEN id="token-18-15" start_char="2492" end_char="2500">prompting</TOKEN>
				<TOKEN id="token-18-16" start_char="2502" end_char="2508">Chinese</TOKEN>
				<TOKEN id="token-18-17" start_char="2510" end_char="2518">officials</TOKEN>
				<TOKEN id="token-18-18" start_char="2520" end_char="2521">to</TOKEN>
				<TOKEN id="token-18-19" start_char="2523" end_char="2529">release</TOKEN>
				<TOKEN id="token-18-20" start_char="2531" end_char="2531">a</TOKEN>
				<TOKEN id="token-18-21" start_char="2533" end_char="2541">statement</TOKEN>
				<TOKEN id="token-18-22" start_char="2543" end_char="2552">denouncing</TOKEN>
				<TOKEN id="token-18-23" start_char="2554" end_char="2556">the</TOKEN>
				<TOKEN id="token-18-24" start_char="2558" end_char="2568">information</TOKEN>
				<TOKEN id="token-18-25" start_char="2569" end_char="2569">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-19" start_char="2571" end_char="2628">
				<ORIGINAL_TEXT>What researchers say: COVID-19 likely originated in nature</ORIGINAL_TEXT>
				<TOKEN id="token-19-0" start_char="2571" end_char="2574">What</TOKEN>
				<TOKEN id="token-19-1" start_char="2576" end_char="2586">researchers</TOKEN>
				<TOKEN id="token-19-2" start_char="2588" end_char="2590">say</TOKEN>
				<TOKEN id="token-19-3" start_char="2591" end_char="2591">:</TOKEN>
				<TOKEN id="token-19-4" start_char="2593" end_char="2597">COVID</TOKEN>
				<TOKEN id="token-19-5" start_char="2598" end_char="2598">-</TOKEN>
				<TOKEN id="token-19-6" start_char="2599" end_char="2600">19</TOKEN>
				<TOKEN id="token-19-7" start_char="2602" end_char="2607">likely</TOKEN>
				<TOKEN id="token-19-8" start_char="2609" end_char="2618">originated</TOKEN>
				<TOKEN id="token-19-9" start_char="2620" end_char="2621">in</TOKEN>
				<TOKEN id="token-19-10" start_char="2623" end_char="2628">nature</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-20" start_char="2630" end_char="2740">
				<ORIGINAL_TEXT>Researchers have been racing to learn about the virus since it was recognized in December 2019 as a new strain.</ORIGINAL_TEXT>
				<TOKEN id="token-20-0" start_char="2630" end_char="2640">Researchers</TOKEN>
				<TOKEN id="token-20-1" start_char="2642" end_char="2645">have</TOKEN>
				<TOKEN id="token-20-2" start_char="2647" end_char="2650">been</TOKEN>
				<TOKEN id="token-20-3" start_char="2652" end_char="2657">racing</TOKEN>
				<TOKEN id="token-20-4" start_char="2659" end_char="2660">to</TOKEN>
				<TOKEN id="token-20-5" start_char="2662" end_char="2666">learn</TOKEN>
				<TOKEN id="token-20-6" start_char="2668" end_char="2672">about</TOKEN>
				<TOKEN id="token-20-7" start_char="2674" end_char="2676">the</TOKEN>
				<TOKEN id="token-20-8" start_char="2678" end_char="2682">virus</TOKEN>
				<TOKEN id="token-20-9" start_char="2684" end_char="2688">since</TOKEN>
				<TOKEN id="token-20-10" start_char="2690" end_char="2691">it</TOKEN>
				<TOKEN id="token-20-11" start_char="2693" end_char="2695">was</TOKEN>
				<TOKEN id="token-20-12" start_char="2697" end_char="2706">recognized</TOKEN>
				<TOKEN id="token-20-13" start_char="2708" end_char="2709">in</TOKEN>
				<TOKEN id="token-20-14" start_char="2711" end_char="2718">December</TOKEN>
				<TOKEN id="token-20-15" start_char="2720" end_char="2723">2019</TOKEN>
				<TOKEN id="token-20-16" start_char="2725" end_char="2726">as</TOKEN>
				<TOKEN id="token-20-17" start_char="2728" end_char="2728">a</TOKEN>
				<TOKEN id="token-20-18" start_char="2730" end_char="2732">new</TOKEN>
				<TOKEN id="token-20-19" start_char="2734" end_char="2739">strain</TOKEN>
				<TOKEN id="token-20-20" start_char="2740" end_char="2740">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-21" start_char="2742" end_char="2823">
				<ORIGINAL_TEXT>Medical journals have pointed toward animals in nature as the origin of the virus.</ORIGINAL_TEXT>
				<TOKEN id="token-21-0" start_char="2742" end_char="2748">Medical</TOKEN>
				<TOKEN id="token-21-1" start_char="2750" end_char="2757">journals</TOKEN>
				<TOKEN id="token-21-2" start_char="2759" end_char="2762">have</TOKEN>
				<TOKEN id="token-21-3" start_char="2764" end_char="2770">pointed</TOKEN>
				<TOKEN id="token-21-4" start_char="2772" end_char="2777">toward</TOKEN>
				<TOKEN id="token-21-5" start_char="2779" end_char="2785">animals</TOKEN>
				<TOKEN id="token-21-6" start_char="2787" end_char="2788">in</TOKEN>
				<TOKEN id="token-21-7" start_char="2790" end_char="2795">nature</TOKEN>
				<TOKEN id="token-21-8" start_char="2797" end_char="2798">as</TOKEN>
				<TOKEN id="token-21-9" start_char="2800" end_char="2802">the</TOKEN>
				<TOKEN id="token-21-10" start_char="2804" end_char="2809">origin</TOKEN>
				<TOKEN id="token-21-11" start_char="2811" end_char="2812">of</TOKEN>
				<TOKEN id="token-21-12" start_char="2814" end_char="2816">the</TOKEN>
				<TOKEN id="token-21-13" start_char="2818" end_char="2822">virus</TOKEN>
				<TOKEN id="token-21-14" start_char="2823" end_char="2823">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-22" start_char="2825" end_char="3051">
				<ORIGINAL_TEXT>On April 21, the World Health Organization noted at a briefing that available evidence indicates coronavirus originated in animals in China late last year and was not manipulated or produced in a laboratory as has been alleged.</ORIGINAL_TEXT>
				<TOKEN id="token-22-0" start_char="2825" end_char="2826">On</TOKEN>
				<TOKEN id="token-22-1" start_char="2828" end_char="2832">April</TOKEN>
				<TOKEN id="token-22-2" start_char="2834" end_char="2835">21</TOKEN>
				<TOKEN id="token-22-3" start_char="2836" end_char="2836">,</TOKEN>
				<TOKEN id="token-22-4" start_char="2838" end_char="2840">the</TOKEN>
				<TOKEN id="token-22-5" start_char="2842" end_char="2846">World</TOKEN>
				<TOKEN id="token-22-6" start_char="2848" end_char="2853">Health</TOKEN>
				<TOKEN id="token-22-7" start_char="2855" end_char="2866">Organization</TOKEN>
				<TOKEN id="token-22-8" start_char="2868" end_char="2872">noted</TOKEN>
				<TOKEN id="token-22-9" start_char="2874" end_char="2875">at</TOKEN>
				<TOKEN id="token-22-10" start_char="2877" end_char="2877">a</TOKEN>
				<TOKEN id="token-22-11" start_char="2879" end_char="2886">briefing</TOKEN>
				<TOKEN id="token-22-12" start_char="2888" end_char="2891">that</TOKEN>
				<TOKEN id="token-22-13" start_char="2893" end_char="2901">available</TOKEN>
				<TOKEN id="token-22-14" start_char="2903" end_char="2910">evidence</TOKEN>
				<TOKEN id="token-22-15" start_char="2912" end_char="2920">indicates</TOKEN>
				<TOKEN id="token-22-16" start_char="2922" end_char="2932">coronavirus</TOKEN>
				<TOKEN id="token-22-17" start_char="2934" end_char="2943">originated</TOKEN>
				<TOKEN id="token-22-18" start_char="2945" end_char="2946">in</TOKEN>
				<TOKEN id="token-22-19" start_char="2948" end_char="2954">animals</TOKEN>
				<TOKEN id="token-22-20" start_char="2956" end_char="2957">in</TOKEN>
				<TOKEN id="token-22-21" start_char="2959" end_char="2963">China</TOKEN>
				<TOKEN id="token-22-22" start_char="2965" end_char="2968">late</TOKEN>
				<TOKEN id="token-22-23" start_char="2970" end_char="2973">last</TOKEN>
				<TOKEN id="token-22-24" start_char="2975" end_char="2978">year</TOKEN>
				<TOKEN id="token-22-25" start_char="2980" end_char="2982">and</TOKEN>
				<TOKEN id="token-22-26" start_char="2984" end_char="2986">was</TOKEN>
				<TOKEN id="token-22-27" start_char="2988" end_char="2990">not</TOKEN>
				<TOKEN id="token-22-28" start_char="2992" end_char="3002">manipulated</TOKEN>
				<TOKEN id="token-22-29" start_char="3004" end_char="3005">or</TOKEN>
				<TOKEN id="token-22-30" start_char="3007" end_char="3014">produced</TOKEN>
				<TOKEN id="token-22-31" start_char="3016" end_char="3017">in</TOKEN>
				<TOKEN id="token-22-32" start_char="3019" end_char="3019">a</TOKEN>
				<TOKEN id="token-22-33" start_char="3021" end_char="3030">laboratory</TOKEN>
				<TOKEN id="token-22-34" start_char="3032" end_char="3033">as</TOKEN>
				<TOKEN id="token-22-35" start_char="3035" end_char="3037">has</TOKEN>
				<TOKEN id="token-22-36" start_char="3039" end_char="3042">been</TOKEN>
				<TOKEN id="token-22-37" start_char="3044" end_char="3050">alleged</TOKEN>
				<TOKEN id="token-22-38" start_char="3051" end_char="3051">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-23" start_char="3053" end_char="3148">
				<ORIGINAL_TEXT>&quot;It is probable, likely, that the virus is of animal origin,&quot; WHO spokeswoman Fadela Chaib said.</ORIGINAL_TEXT>
				<TOKEN id="token-23-0" start_char="3053" end_char="3053">&quot;</TOKEN>
				<TOKEN id="token-23-1" start_char="3054" end_char="3055">It</TOKEN>
				<TOKEN id="token-23-2" start_char="3057" end_char="3058">is</TOKEN>
				<TOKEN id="token-23-3" start_char="3060" end_char="3067">probable</TOKEN>
				<TOKEN id="token-23-4" start_char="3068" end_char="3068">,</TOKEN>
				<TOKEN id="token-23-5" start_char="3070" end_char="3075">likely</TOKEN>
				<TOKEN id="token-23-6" start_char="3076" end_char="3076">,</TOKEN>
				<TOKEN id="token-23-7" start_char="3078" end_char="3081">that</TOKEN>
				<TOKEN id="token-23-8" start_char="3083" end_char="3085">the</TOKEN>
				<TOKEN id="token-23-9" start_char="3087" end_char="3091">virus</TOKEN>
				<TOKEN id="token-23-10" start_char="3093" end_char="3094">is</TOKEN>
				<TOKEN id="token-23-11" start_char="3096" end_char="3097">of</TOKEN>
				<TOKEN id="token-23-12" start_char="3099" end_char="3104">animal</TOKEN>
				<TOKEN id="token-23-13" start_char="3106" end_char="3111">origin</TOKEN>
				<TOKEN id="token-23-14" start_char="3112" end_char="3113">,&quot;</TOKEN>
				<TOKEN id="token-23-15" start_char="3115" end_char="3117">WHO</TOKEN>
				<TOKEN id="token-23-16" start_char="3119" end_char="3129">spokeswoman</TOKEN>
				<TOKEN id="token-23-17" start_char="3131" end_char="3136">Fadela</TOKEN>
				<TOKEN id="token-23-18" start_char="3138" end_char="3142">Chaib</TOKEN>
				<TOKEN id="token-23-19" start_char="3144" end_char="3147">said</TOKEN>
				<TOKEN id="token-23-20" start_char="3148" end_char="3148">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-24" start_char="3150" end_char="3396">
				<ORIGINAL_TEXT>Richard Ebright, a professor of chemical biology at Rutgers University, said earlier this year in an interview with The Washington Post: “Based on the virus genome and properties, there is no indication whatsoever that it was an engineered virus.”</ORIGINAL_TEXT>
				<TOKEN id="token-24-0" start_char="3150" end_char="3156">Richard</TOKEN>
				<TOKEN id="token-24-1" start_char="3158" end_char="3164">Ebright</TOKEN>
				<TOKEN id="token-24-2" start_char="3165" end_char="3165">,</TOKEN>
				<TOKEN id="token-24-3" start_char="3167" end_char="3167">a</TOKEN>
				<TOKEN id="token-24-4" start_char="3169" end_char="3177">professor</TOKEN>
				<TOKEN id="token-24-5" start_char="3179" end_char="3180">of</TOKEN>
				<TOKEN id="token-24-6" start_char="3182" end_char="3189">chemical</TOKEN>
				<TOKEN id="token-24-7" start_char="3191" end_char="3197">biology</TOKEN>
				<TOKEN id="token-24-8" start_char="3199" end_char="3200">at</TOKEN>
				<TOKEN id="token-24-9" start_char="3202" end_char="3208">Rutgers</TOKEN>
				<TOKEN id="token-24-10" start_char="3210" end_char="3219">University</TOKEN>
				<TOKEN id="token-24-11" start_char="3220" end_char="3220">,</TOKEN>
				<TOKEN id="token-24-12" start_char="3222" end_char="3225">said</TOKEN>
				<TOKEN id="token-24-13" start_char="3227" end_char="3233">earlier</TOKEN>
				<TOKEN id="token-24-14" start_char="3235" end_char="3238">this</TOKEN>
				<TOKEN id="token-24-15" start_char="3240" end_char="3243">year</TOKEN>
				<TOKEN id="token-24-16" start_char="3245" end_char="3246">in</TOKEN>
				<TOKEN id="token-24-17" start_char="3248" end_char="3249">an</TOKEN>
				<TOKEN id="token-24-18" start_char="3251" end_char="3259">interview</TOKEN>
				<TOKEN id="token-24-19" start_char="3261" end_char="3264">with</TOKEN>
				<TOKEN id="token-24-20" start_char="3266" end_char="3268">The</TOKEN>
				<TOKEN id="token-24-21" start_char="3270" end_char="3279">Washington</TOKEN>
				<TOKEN id="token-24-22" start_char="3281" end_char="3284">Post</TOKEN>
				<TOKEN id="token-24-23" start_char="3285" end_char="3285">:</TOKEN>
				<TOKEN id="token-24-24" start_char="3287" end_char="3287">“</TOKEN>
				<TOKEN id="token-24-25" start_char="3288" end_char="3292">Based</TOKEN>
				<TOKEN id="token-24-26" start_char="3294" end_char="3295">on</TOKEN>
				<TOKEN id="token-24-27" start_char="3297" end_char="3299">the</TOKEN>
				<TOKEN id="token-24-28" start_char="3301" end_char="3305">virus</TOKEN>
				<TOKEN id="token-24-29" start_char="3307" end_char="3312">genome</TOKEN>
				<TOKEN id="token-24-30" start_char="3314" end_char="3316">and</TOKEN>
				<TOKEN id="token-24-31" start_char="3318" end_char="3327">properties</TOKEN>
				<TOKEN id="token-24-32" start_char="3328" end_char="3328">,</TOKEN>
				<TOKEN id="token-24-33" start_char="3330" end_char="3334">there</TOKEN>
				<TOKEN id="token-24-34" start_char="3336" end_char="3337">is</TOKEN>
				<TOKEN id="token-24-35" start_char="3339" end_char="3340">no</TOKEN>
				<TOKEN id="token-24-36" start_char="3342" end_char="3351">indication</TOKEN>
				<TOKEN id="token-24-37" start_char="3353" end_char="3362">whatsoever</TOKEN>
				<TOKEN id="token-24-38" start_char="3364" end_char="3367">that</TOKEN>
				<TOKEN id="token-24-39" start_char="3369" end_char="3370">it</TOKEN>
				<TOKEN id="token-24-40" start_char="3372" end_char="3374">was</TOKEN>
				<TOKEN id="token-24-41" start_char="3376" end_char="3377">an</TOKEN>
				<TOKEN id="token-24-42" start_char="3379" end_char="3388">engineered</TOKEN>
				<TOKEN id="token-24-43" start_char="3390" end_char="3394">virus</TOKEN>
				<TOKEN id="token-24-44" start_char="3395" end_char="3396">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-25" start_char="3398" end_char="3537">
				<ORIGINAL_TEXT>The Washington Post reported most countries have abandoned their bioweapons programs after years of work did not yield satisfactory results.</ORIGINAL_TEXT>
				<TOKEN id="token-25-0" start_char="3398" end_char="3400">The</TOKEN>
				<TOKEN id="token-25-1" start_char="3402" end_char="3411">Washington</TOKEN>
				<TOKEN id="token-25-2" start_char="3413" end_char="3416">Post</TOKEN>
				<TOKEN id="token-25-3" start_char="3418" end_char="3425">reported</TOKEN>
				<TOKEN id="token-25-4" start_char="3427" end_char="3430">most</TOKEN>
				<TOKEN id="token-25-5" start_char="3432" end_char="3440">countries</TOKEN>
				<TOKEN id="token-25-6" start_char="3442" end_char="3445">have</TOKEN>
				<TOKEN id="token-25-7" start_char="3447" end_char="3455">abandoned</TOKEN>
				<TOKEN id="token-25-8" start_char="3457" end_char="3461">their</TOKEN>
				<TOKEN id="token-25-9" start_char="3463" end_char="3472">bioweapons</TOKEN>
				<TOKEN id="token-25-10" start_char="3474" end_char="3481">programs</TOKEN>
				<TOKEN id="token-25-11" start_char="3483" end_char="3487">after</TOKEN>
				<TOKEN id="token-25-12" start_char="3489" end_char="3493">years</TOKEN>
				<TOKEN id="token-25-13" start_char="3495" end_char="3496">of</TOKEN>
				<TOKEN id="token-25-14" start_char="3498" end_char="3501">work</TOKEN>
				<TOKEN id="token-25-15" start_char="3503" end_char="3505">did</TOKEN>
				<TOKEN id="token-25-16" start_char="3507" end_char="3509">not</TOKEN>
				<TOKEN id="token-25-17" start_char="3511" end_char="3515">yield</TOKEN>
				<TOKEN id="token-25-18" start_char="3517" end_char="3528">satisfactory</TOKEN>
				<TOKEN id="token-25-19" start_char="3530" end_char="3536">results</TOKEN>
				<TOKEN id="token-25-20" start_char="3537" end_char="3537">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-26" start_char="3539" end_char="3638">
				<ORIGINAL_TEXT>The Scripps Research Institute released a study that rejects the notion that the virus was man-made.</ORIGINAL_TEXT>
				<TOKEN id="token-26-0" start_char="3539" end_char="3541">The</TOKEN>
				<TOKEN id="token-26-1" start_char="3543" end_char="3549">Scripps</TOKEN>
				<TOKEN id="token-26-2" start_char="3551" end_char="3558">Research</TOKEN>
				<TOKEN id="token-26-3" start_char="3560" end_char="3568">Institute</TOKEN>
				<TOKEN id="token-26-4" start_char="3570" end_char="3577">released</TOKEN>
				<TOKEN id="token-26-5" start_char="3579" end_char="3579">a</TOKEN>
				<TOKEN id="token-26-6" start_char="3581" end_char="3585">study</TOKEN>
				<TOKEN id="token-26-7" start_char="3587" end_char="3590">that</TOKEN>
				<TOKEN id="token-26-8" start_char="3592" end_char="3598">rejects</TOKEN>
				<TOKEN id="token-26-9" start_char="3600" end_char="3602">the</TOKEN>
				<TOKEN id="token-26-10" start_char="3604" end_char="3609">notion</TOKEN>
				<TOKEN id="token-26-11" start_char="3611" end_char="3614">that</TOKEN>
				<TOKEN id="token-26-12" start_char="3616" end_char="3618">the</TOKEN>
				<TOKEN id="token-26-13" start_char="3620" end_char="3624">virus</TOKEN>
				<TOKEN id="token-26-14" start_char="3626" end_char="3628">was</TOKEN>
				<TOKEN id="token-26-15" start_char="3630" end_char="3632">man</TOKEN>
				<TOKEN id="token-26-16" start_char="3633" end_char="3633">-</TOKEN>
				<TOKEN id="token-26-17" start_char="3634" end_char="3637">made</TOKEN>
				<TOKEN id="token-26-18" start_char="3638" end_char="3638">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-27" start_char="3640" end_char="3797">
				<ORIGINAL_TEXT>Researchers concluded that if the virus were engineered, its genome sequence would more closely resemble earlier and more serious versions of the coronavirus.</ORIGINAL_TEXT>
				<TOKEN id="token-27-0" start_char="3640" end_char="3650">Researchers</TOKEN>
				<TOKEN id="token-27-1" start_char="3652" end_char="3660">concluded</TOKEN>
				<TOKEN id="token-27-2" start_char="3662" end_char="3665">that</TOKEN>
				<TOKEN id="token-27-3" start_char="3667" end_char="3668">if</TOKEN>
				<TOKEN id="token-27-4" start_char="3670" end_char="3672">the</TOKEN>
				<TOKEN id="token-27-5" start_char="3674" end_char="3678">virus</TOKEN>
				<TOKEN id="token-27-6" start_char="3680" end_char="3683">were</TOKEN>
				<TOKEN id="token-27-7" start_char="3685" end_char="3694">engineered</TOKEN>
				<TOKEN id="token-27-8" start_char="3695" end_char="3695">,</TOKEN>
				<TOKEN id="token-27-9" start_char="3697" end_char="3699">its</TOKEN>
				<TOKEN id="token-27-10" start_char="3701" end_char="3706">genome</TOKEN>
				<TOKEN id="token-27-11" start_char="3708" end_char="3715">sequence</TOKEN>
				<TOKEN id="token-27-12" start_char="3717" end_char="3721">would</TOKEN>
				<TOKEN id="token-27-13" start_char="3723" end_char="3726">more</TOKEN>
				<TOKEN id="token-27-14" start_char="3728" end_char="3734">closely</TOKEN>
				<TOKEN id="token-27-15" start_char="3736" end_char="3743">resemble</TOKEN>
				<TOKEN id="token-27-16" start_char="3745" end_char="3751">earlier</TOKEN>
				<TOKEN id="token-27-17" start_char="3753" end_char="3755">and</TOKEN>
				<TOKEN id="token-27-18" start_char="3757" end_char="3760">more</TOKEN>
				<TOKEN id="token-27-19" start_char="3762" end_char="3768">serious</TOKEN>
				<TOKEN id="token-27-20" start_char="3770" end_char="3777">versions</TOKEN>
				<TOKEN id="token-27-21" start_char="3779" end_char="3780">of</TOKEN>
				<TOKEN id="token-27-22" start_char="3782" end_char="3784">the</TOKEN>
				<TOKEN id="token-27-23" start_char="3786" end_char="3796">coronavirus</TOKEN>
				<TOKEN id="token-27-24" start_char="3797" end_char="3797">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-28" start_char="3799" end_char="3969">
				<ORIGINAL_TEXT>“If someone were seeking to engineer a new coronavirus as a pathogen, they would have constructed it from the backbone of a virus known to cause illness,” the report said.</ORIGINAL_TEXT>
				<TOKEN id="token-28-0" start_char="3799" end_char="3799">“</TOKEN>
				<TOKEN id="token-28-1" start_char="3800" end_char="3801">If</TOKEN>
				<TOKEN id="token-28-2" start_char="3803" end_char="3809">someone</TOKEN>
				<TOKEN id="token-28-3" start_char="3811" end_char="3814">were</TOKEN>
				<TOKEN id="token-28-4" start_char="3816" end_char="3822">seeking</TOKEN>
				<TOKEN id="token-28-5" start_char="3824" end_char="3825">to</TOKEN>
				<TOKEN id="token-28-6" start_char="3827" end_char="3834">engineer</TOKEN>
				<TOKEN id="token-28-7" start_char="3836" end_char="3836">a</TOKEN>
				<TOKEN id="token-28-8" start_char="3838" end_char="3840">new</TOKEN>
				<TOKEN id="token-28-9" start_char="3842" end_char="3852">coronavirus</TOKEN>
				<TOKEN id="token-28-10" start_char="3854" end_char="3855">as</TOKEN>
				<TOKEN id="token-28-11" start_char="3857" end_char="3857">a</TOKEN>
				<TOKEN id="token-28-12" start_char="3859" end_char="3866">pathogen</TOKEN>
				<TOKEN id="token-28-13" start_char="3867" end_char="3867">,</TOKEN>
				<TOKEN id="token-28-14" start_char="3869" end_char="3872">they</TOKEN>
				<TOKEN id="token-28-15" start_char="3874" end_char="3878">would</TOKEN>
				<TOKEN id="token-28-16" start_char="3880" end_char="3883">have</TOKEN>
				<TOKEN id="token-28-17" start_char="3885" end_char="3895">constructed</TOKEN>
				<TOKEN id="token-28-18" start_char="3897" end_char="3898">it</TOKEN>
				<TOKEN id="token-28-19" start_char="3900" end_char="3903">from</TOKEN>
				<TOKEN id="token-28-20" start_char="3905" end_char="3907">the</TOKEN>
				<TOKEN id="token-28-21" start_char="3909" end_char="3916">backbone</TOKEN>
				<TOKEN id="token-28-22" start_char="3918" end_char="3919">of</TOKEN>
				<TOKEN id="token-28-23" start_char="3921" end_char="3921">a</TOKEN>
				<TOKEN id="token-28-24" start_char="3923" end_char="3927">virus</TOKEN>
				<TOKEN id="token-28-25" start_char="3929" end_char="3933">known</TOKEN>
				<TOKEN id="token-28-26" start_char="3935" end_char="3936">to</TOKEN>
				<TOKEN id="token-28-27" start_char="3938" end_char="3942">cause</TOKEN>
				<TOKEN id="token-28-28" start_char="3944" end_char="3950">illness</TOKEN>
				<TOKEN id="token-28-29" start_char="3951" end_char="3952">,”</TOKEN>
				<TOKEN id="token-28-30" start_char="3954" end_char="3956">the</TOKEN>
				<TOKEN id="token-28-31" start_char="3958" end_char="3963">report</TOKEN>
				<TOKEN id="token-28-32" start_char="3965" end_char="3968">said</TOKEN>
				<TOKEN id="token-28-33" start_char="3969" end_char="3969">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-29" start_char="3971" end_char="4156">
				<ORIGINAL_TEXT>“But the scientists found that the SARS-CoV-2 backbone differed substantially from those of already known coronaviruses and mostly resembled related viruses found in bats and pangolins.”</ORIGINAL_TEXT>
				<TOKEN id="token-29-0" start_char="3971" end_char="3971">“</TOKEN>
				<TOKEN id="token-29-1" start_char="3972" end_char="3974">But</TOKEN>
				<TOKEN id="token-29-2" start_char="3976" end_char="3978">the</TOKEN>
				<TOKEN id="token-29-3" start_char="3980" end_char="3989">scientists</TOKEN>
				<TOKEN id="token-29-4" start_char="3991" end_char="3995">found</TOKEN>
				<TOKEN id="token-29-5" start_char="3997" end_char="4000">that</TOKEN>
				<TOKEN id="token-29-6" start_char="4002" end_char="4004">the</TOKEN>
				<TOKEN id="token-29-7" start_char="4006" end_char="4009">SARS</TOKEN>
				<TOKEN id="token-29-8" start_char="4010" end_char="4010">-</TOKEN>
				<TOKEN id="token-29-9" start_char="4011" end_char="4013">CoV</TOKEN>
				<TOKEN id="token-29-10" start_char="4014" end_char="4014">-</TOKEN>
				<TOKEN id="token-29-11" start_char="4015" end_char="4015">2</TOKEN>
				<TOKEN id="token-29-12" start_char="4017" end_char="4024">backbone</TOKEN>
				<TOKEN id="token-29-13" start_char="4026" end_char="4033">differed</TOKEN>
				<TOKEN id="token-29-14" start_char="4035" end_char="4047">substantially</TOKEN>
				<TOKEN id="token-29-15" start_char="4049" end_char="4052">from</TOKEN>
				<TOKEN id="token-29-16" start_char="4054" end_char="4058">those</TOKEN>
				<TOKEN id="token-29-17" start_char="4060" end_char="4061">of</TOKEN>
				<TOKEN id="token-29-18" start_char="4063" end_char="4069">already</TOKEN>
				<TOKEN id="token-29-19" start_char="4071" end_char="4075">known</TOKEN>
				<TOKEN id="token-29-20" start_char="4077" end_char="4089">coronaviruses</TOKEN>
				<TOKEN id="token-29-21" start_char="4091" end_char="4093">and</TOKEN>
				<TOKEN id="token-29-22" start_char="4095" end_char="4100">mostly</TOKEN>
				<TOKEN id="token-29-23" start_char="4102" end_char="4110">resembled</TOKEN>
				<TOKEN id="token-29-24" start_char="4112" end_char="4118">related</TOKEN>
				<TOKEN id="token-29-25" start_char="4120" end_char="4126">viruses</TOKEN>
				<TOKEN id="token-29-26" start_char="4128" end_char="4132">found</TOKEN>
				<TOKEN id="token-29-27" start_char="4134" end_char="4135">in</TOKEN>
				<TOKEN id="token-29-28" start_char="4137" end_char="4140">bats</TOKEN>
				<TOKEN id="token-29-29" start_char="4142" end_char="4144">and</TOKEN>
				<TOKEN id="token-29-30" start_char="4146" end_char="4154">pangolins</TOKEN>
				<TOKEN id="token-29-31" start_char="4155" end_char="4156">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-30" start_char="4158" end_char="4578">
				<ORIGINAL_TEXT>A statement in the Lancet, a medical journal, written by public health officials who have been following the progression of the virus also asserted that animals are the likely source: “Scientists from multiple countries have published and analysed genomes of the causative agent, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), and they overwhelmingly conclude that this coronavirus originated in wildlife.”</ORIGINAL_TEXT>
				<TOKEN id="token-30-0" start_char="4158" end_char="4158">A</TOKEN>
				<TOKEN id="token-30-1" start_char="4160" end_char="4168">statement</TOKEN>
				<TOKEN id="token-30-2" start_char="4170" end_char="4171">in</TOKEN>
				<TOKEN id="token-30-3" start_char="4173" end_char="4175">the</TOKEN>
				<TOKEN id="token-30-4" start_char="4177" end_char="4182">Lancet</TOKEN>
				<TOKEN id="token-30-5" start_char="4183" end_char="4183">,</TOKEN>
				<TOKEN id="token-30-6" start_char="4185" end_char="4185">a</TOKEN>
				<TOKEN id="token-30-7" start_char="4187" end_char="4193">medical</TOKEN>
				<TOKEN id="token-30-8" start_char="4195" end_char="4201">journal</TOKEN>
				<TOKEN id="token-30-9" start_char="4202" end_char="4202">,</TOKEN>
				<TOKEN id="token-30-10" start_char="4204" end_char="4210">written</TOKEN>
				<TOKEN id="token-30-11" start_char="4212" end_char="4213">by</TOKEN>
				<TOKEN id="token-30-12" start_char="4215" end_char="4220">public</TOKEN>
				<TOKEN id="token-30-13" start_char="4222" end_char="4227">health</TOKEN>
				<TOKEN id="token-30-14" start_char="4229" end_char="4237">officials</TOKEN>
				<TOKEN id="token-30-15" start_char="4239" end_char="4241">who</TOKEN>
				<TOKEN id="token-30-16" start_char="4243" end_char="4246">have</TOKEN>
				<TOKEN id="token-30-17" start_char="4248" end_char="4251">been</TOKEN>
				<TOKEN id="token-30-18" start_char="4253" end_char="4261">following</TOKEN>
				<TOKEN id="token-30-19" start_char="4263" end_char="4265">the</TOKEN>
				<TOKEN id="token-30-20" start_char="4267" end_char="4277">progression</TOKEN>
				<TOKEN id="token-30-21" start_char="4279" end_char="4280">of</TOKEN>
				<TOKEN id="token-30-22" start_char="4282" end_char="4284">the</TOKEN>
				<TOKEN id="token-30-23" start_char="4286" end_char="4290">virus</TOKEN>
				<TOKEN id="token-30-24" start_char="4292" end_char="4295">also</TOKEN>
				<TOKEN id="token-30-25" start_char="4297" end_char="4304">asserted</TOKEN>
				<TOKEN id="token-30-26" start_char="4306" end_char="4309">that</TOKEN>
				<TOKEN id="token-30-27" start_char="4311" end_char="4317">animals</TOKEN>
				<TOKEN id="token-30-28" start_char="4319" end_char="4321">are</TOKEN>
				<TOKEN id="token-30-29" start_char="4323" end_char="4325">the</TOKEN>
				<TOKEN id="token-30-30" start_char="4327" end_char="4332">likely</TOKEN>
				<TOKEN id="token-30-31" start_char="4334" end_char="4339">source</TOKEN>
				<TOKEN id="token-30-32" start_char="4340" end_char="4340">:</TOKEN>
				<TOKEN id="token-30-33" start_char="4342" end_char="4342">“</TOKEN>
				<TOKEN id="token-30-34" start_char="4343" end_char="4352">Scientists</TOKEN>
				<TOKEN id="token-30-35" start_char="4354" end_char="4357">from</TOKEN>
				<TOKEN id="token-30-36" start_char="4359" end_char="4366">multiple</TOKEN>
				<TOKEN id="token-30-37" start_char="4368" end_char="4376">countries</TOKEN>
				<TOKEN id="token-30-38" start_char="4378" end_char="4381">have</TOKEN>
				<TOKEN id="token-30-39" start_char="4383" end_char="4391">published</TOKEN>
				<TOKEN id="token-30-40" start_char="4393" end_char="4395">and</TOKEN>
				<TOKEN id="token-30-41" start_char="4397" end_char="4404">analysed</TOKEN>
				<TOKEN id="token-30-42" start_char="4406" end_char="4412">genomes</TOKEN>
				<TOKEN id="token-30-43" start_char="4414" end_char="4415">of</TOKEN>
				<TOKEN id="token-30-44" start_char="4417" end_char="4419">the</TOKEN>
				<TOKEN id="token-30-45" start_char="4421" end_char="4429">causative</TOKEN>
				<TOKEN id="token-30-46" start_char="4431" end_char="4435">agent</TOKEN>
				<TOKEN id="token-30-47" start_char="4436" end_char="4436">,</TOKEN>
				<TOKEN id="token-30-48" start_char="4438" end_char="4443">severe</TOKEN>
				<TOKEN id="token-30-49" start_char="4445" end_char="4449">acute</TOKEN>
				<TOKEN id="token-30-50" start_char="4451" end_char="4461">respiratory</TOKEN>
				<TOKEN id="token-30-51" start_char="4463" end_char="4470">syndrome</TOKEN>
				<TOKEN id="token-30-52" start_char="4472" end_char="4482">coronavirus</TOKEN>
				<TOKEN id="token-30-53" start_char="4484" end_char="4484">2</TOKEN>
				<TOKEN id="token-30-54" start_char="4486" end_char="4486">(</TOKEN>
				<TOKEN id="token-30-55" start_char="4487" end_char="4490">SARS</TOKEN>
				<TOKEN id="token-30-56" start_char="4491" end_char="4491">-</TOKEN>
				<TOKEN id="token-30-57" start_char="4492" end_char="4494">CoV</TOKEN>
				<TOKEN id="token-30-58" start_char="4495" end_char="4495">-</TOKEN>
				<TOKEN id="token-30-59" start_char="4496" end_char="4496">2</TOKEN>
				<TOKEN id="token-30-60" start_char="4497" end_char="4498">),</TOKEN>
				<TOKEN id="token-30-61" start_char="4500" end_char="4502">and</TOKEN>
				<TOKEN id="token-30-62" start_char="4504" end_char="4507">they</TOKEN>
				<TOKEN id="token-30-63" start_char="4509" end_char="4522">overwhelmingly</TOKEN>
				<TOKEN id="token-30-64" start_char="4524" end_char="4531">conclude</TOKEN>
				<TOKEN id="token-30-65" start_char="4533" end_char="4536">that</TOKEN>
				<TOKEN id="token-30-66" start_char="4538" end_char="4541">this</TOKEN>
				<TOKEN id="token-30-67" start_char="4543" end_char="4553">coronavirus</TOKEN>
				<TOKEN id="token-30-68" start_char="4555" end_char="4564">originated</TOKEN>
				<TOKEN id="token-30-69" start_char="4566" end_char="4567">in</TOKEN>
				<TOKEN id="token-30-70" start_char="4569" end_char="4576">wildlife</TOKEN>
				<TOKEN id="token-30-71" start_char="4577" end_char="4578">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-31" start_char="4580" end_char="4692">
				<ORIGINAL_TEXT>The statement referenced multiple academic and government sources that supported the Lancet article’s conclusion.</ORIGINAL_TEXT>
				<TOKEN id="token-31-0" start_char="4580" end_char="4582">The</TOKEN>
				<TOKEN id="token-31-1" start_char="4584" end_char="4592">statement</TOKEN>
				<TOKEN id="token-31-2" start_char="4594" end_char="4603">referenced</TOKEN>
				<TOKEN id="token-31-3" start_char="4605" end_char="4612">multiple</TOKEN>
				<TOKEN id="token-31-4" start_char="4614" end_char="4621">academic</TOKEN>
				<TOKEN id="token-31-5" start_char="4623" end_char="4625">and</TOKEN>
				<TOKEN id="token-31-6" start_char="4627" end_char="4636">government</TOKEN>
				<TOKEN id="token-31-7" start_char="4638" end_char="4644">sources</TOKEN>
				<TOKEN id="token-31-8" start_char="4646" end_char="4649">that</TOKEN>
				<TOKEN id="token-31-9" start_char="4651" end_char="4659">supported</TOKEN>
				<TOKEN id="token-31-10" start_char="4661" end_char="4663">the</TOKEN>
				<TOKEN id="token-31-11" start_char="4665" end_char="4670">Lancet</TOKEN>
				<TOKEN id="token-31-12" start_char="4672" end_char="4678">article</TOKEN>
				<TOKEN id="token-31-13" start_char="4679" end_char="4679">’</TOKEN>
				<TOKEN id="token-31-14" start_char="4680" end_char="4680">s</TOKEN>
				<TOKEN id="token-31-15" start_char="4682" end_char="4691">conclusion</TOKEN>
				<TOKEN id="token-31-16" start_char="4692" end_char="4692">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-32" start_char="4694" end_char="4944">
				<ORIGINAL_TEXT>These sources include the Cold Spring Harbor Laboratory; Nature; U.S. National Academies of Science, Engineering and Medicine; the New England Journal of Medicine; the Chinese Medical Journal; and the medical journal Infection, Genetics and Evolution.</ORIGINAL_TEXT>
				<TOKEN id="token-32-0" start_char="4694" end_char="4698">These</TOKEN>
				<TOKEN id="token-32-1" start_char="4700" end_char="4706">sources</TOKEN>
				<TOKEN id="token-32-2" start_char="4708" end_char="4714">include</TOKEN>
				<TOKEN id="token-32-3" start_char="4716" end_char="4718">the</TOKEN>
				<TOKEN id="token-32-4" start_char="4720" end_char="4723">Cold</TOKEN>
				<TOKEN id="token-32-5" start_char="4725" end_char="4730">Spring</TOKEN>
				<TOKEN id="token-32-6" start_char="4732" end_char="4737">Harbor</TOKEN>
				<TOKEN id="token-32-7" start_char="4739" end_char="4748">Laboratory</TOKEN>
				<TOKEN id="token-32-8" start_char="4749" end_char="4749">;</TOKEN>
				<TOKEN id="token-32-9" start_char="4751" end_char="4756">Nature</TOKEN>
				<TOKEN id="token-32-10" start_char="4757" end_char="4757">;</TOKEN>
				<TOKEN id="token-32-11" start_char="4759" end_char="4759">U</TOKEN>
				<TOKEN id="token-32-12" start_char="4760" end_char="4760">.</TOKEN>
				<TOKEN id="token-32-13" start_char="4761" end_char="4761">S</TOKEN>
				<TOKEN id="token-32-14" start_char="4762" end_char="4762">.</TOKEN>
				<TOKEN id="token-32-15" start_char="4764" end_char="4771">National</TOKEN>
				<TOKEN id="token-32-16" start_char="4773" end_char="4781">Academies</TOKEN>
				<TOKEN id="token-32-17" start_char="4783" end_char="4784">of</TOKEN>
				<TOKEN id="token-32-18" start_char="4786" end_char="4792">Science</TOKEN>
				<TOKEN id="token-32-19" start_char="4793" end_char="4793">,</TOKEN>
				<TOKEN id="token-32-20" start_char="4795" end_char="4805">Engineering</TOKEN>
				<TOKEN id="token-32-21" start_char="4807" end_char="4809">and</TOKEN>
				<TOKEN id="token-32-22" start_char="4811" end_char="4818">Medicine</TOKEN>
				<TOKEN id="token-32-23" start_char="4819" end_char="4819">;</TOKEN>
				<TOKEN id="token-32-24" start_char="4821" end_char="4823">the</TOKEN>
				<TOKEN id="token-32-25" start_char="4825" end_char="4827">New</TOKEN>
				<TOKEN id="token-32-26" start_char="4829" end_char="4835">England</TOKEN>
				<TOKEN id="token-32-27" start_char="4837" end_char="4843">Journal</TOKEN>
				<TOKEN id="token-32-28" start_char="4845" end_char="4846">of</TOKEN>
				<TOKEN id="token-32-29" start_char="4848" end_char="4855">Medicine</TOKEN>
				<TOKEN id="token-32-30" start_char="4856" end_char="4856">;</TOKEN>
				<TOKEN id="token-32-31" start_char="4858" end_char="4860">the</TOKEN>
				<TOKEN id="token-32-32" start_char="4862" end_char="4868">Chinese</TOKEN>
				<TOKEN id="token-32-33" start_char="4870" end_char="4876">Medical</TOKEN>
				<TOKEN id="token-32-34" start_char="4878" end_char="4884">Journal</TOKEN>
				<TOKEN id="token-32-35" start_char="4885" end_char="4885">;</TOKEN>
				<TOKEN id="token-32-36" start_char="4887" end_char="4889">and</TOKEN>
				<TOKEN id="token-32-37" start_char="4891" end_char="4893">the</TOKEN>
				<TOKEN id="token-32-38" start_char="4895" end_char="4901">medical</TOKEN>
				<TOKEN id="token-32-39" start_char="4903" end_char="4909">journal</TOKEN>
				<TOKEN id="token-32-40" start_char="4911" end_char="4919">Infection</TOKEN>
				<TOKEN id="token-32-41" start_char="4920" end_char="4920">,</TOKEN>
				<TOKEN id="token-32-42" start_char="4922" end_char="4929">Genetics</TOKEN>
				<TOKEN id="token-32-43" start_char="4931" end_char="4933">and</TOKEN>
				<TOKEN id="token-32-44" start_char="4935" end_char="4943">Evolution</TOKEN>
				<TOKEN id="token-32-45" start_char="4944" end_char="4944">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-33" start_char="4946" end_char="5159">
				<ORIGINAL_TEXT>Researchers who analyzed the genome of the coronavirus found its sequence shared a very high resemblance to a coronavirus in bats, but it's possible other animals may have been involved in the transmission process.</ORIGINAL_TEXT>
				<TOKEN id="token-33-0" start_char="4946" end_char="4956">Researchers</TOKEN>
				<TOKEN id="token-33-1" start_char="4958" end_char="4960">who</TOKEN>
				<TOKEN id="token-33-2" start_char="4962" end_char="4969">analyzed</TOKEN>
				<TOKEN id="token-33-3" start_char="4971" end_char="4973">the</TOKEN>
				<TOKEN id="token-33-4" start_char="4975" end_char="4980">genome</TOKEN>
				<TOKEN id="token-33-5" start_char="4982" end_char="4983">of</TOKEN>
				<TOKEN id="token-33-6" start_char="4985" end_char="4987">the</TOKEN>
				<TOKEN id="token-33-7" start_char="4989" end_char="4999">coronavirus</TOKEN>
				<TOKEN id="token-33-8" start_char="5001" end_char="5005">found</TOKEN>
				<TOKEN id="token-33-9" start_char="5007" end_char="5009">its</TOKEN>
				<TOKEN id="token-33-10" start_char="5011" end_char="5018">sequence</TOKEN>
				<TOKEN id="token-33-11" start_char="5020" end_char="5025">shared</TOKEN>
				<TOKEN id="token-33-12" start_char="5027" end_char="5027">a</TOKEN>
				<TOKEN id="token-33-13" start_char="5029" end_char="5032">very</TOKEN>
				<TOKEN id="token-33-14" start_char="5034" end_char="5037">high</TOKEN>
				<TOKEN id="token-33-15" start_char="5039" end_char="5049">resemblance</TOKEN>
				<TOKEN id="token-33-16" start_char="5051" end_char="5052">to</TOKEN>
				<TOKEN id="token-33-17" start_char="5054" end_char="5054">a</TOKEN>
				<TOKEN id="token-33-18" start_char="5056" end_char="5066">coronavirus</TOKEN>
				<TOKEN id="token-33-19" start_char="5068" end_char="5069">in</TOKEN>
				<TOKEN id="token-33-20" start_char="5071" end_char="5074">bats</TOKEN>
				<TOKEN id="token-33-21" start_char="5075" end_char="5075">,</TOKEN>
				<TOKEN id="token-33-22" start_char="5077" end_char="5079">but</TOKEN>
				<TOKEN id="token-33-23" start_char="5081" end_char="5082">it</TOKEN>
				<TOKEN id="token-33-24" start_char="5083" end_char="5083">'</TOKEN>
				<TOKEN id="token-33-25" start_char="5084" end_char="5084">s</TOKEN>
				<TOKEN id="token-33-26" start_char="5086" end_char="5093">possible</TOKEN>
				<TOKEN id="token-33-27" start_char="5095" end_char="5099">other</TOKEN>
				<TOKEN id="token-33-28" start_char="5101" end_char="5107">animals</TOKEN>
				<TOKEN id="token-33-29" start_char="5109" end_char="5111">may</TOKEN>
				<TOKEN id="token-33-30" start_char="5113" end_char="5116">have</TOKEN>
				<TOKEN id="token-33-31" start_char="5118" end_char="5121">been</TOKEN>
				<TOKEN id="token-33-32" start_char="5123" end_char="5130">involved</TOKEN>
				<TOKEN id="token-33-33" start_char="5132" end_char="5133">in</TOKEN>
				<TOKEN id="token-33-34" start_char="5135" end_char="5137">the</TOKEN>
				<TOKEN id="token-33-35" start_char="5139" end_char="5150">transmission</TOKEN>
				<TOKEN id="token-33-36" start_char="5152" end_char="5158">process</TOKEN>
				<TOKEN id="token-33-37" start_char="5159" end_char="5159">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-34" start_char="5161" end_char="5290">
				<ORIGINAL_TEXT>“2019-nCoV is 96% identical at the whole-genome level to a bat coronavirus,” a study published in the science journal Nature said.</ORIGINAL_TEXT>
				<TOKEN id="token-34-0" start_char="5161" end_char="5161">“</TOKEN>
				<TOKEN id="token-34-1" start_char="5162" end_char="5165">2019</TOKEN>
				<TOKEN id="token-34-2" start_char="5166" end_char="5166">-</TOKEN>
				<TOKEN id="token-34-3" start_char="5167" end_char="5170">nCoV</TOKEN>
				<TOKEN id="token-34-4" start_char="5172" end_char="5173">is</TOKEN>
				<TOKEN id="token-34-5" start_char="5175" end_char="5176">96</TOKEN>
				<TOKEN id="token-34-6" start_char="5177" end_char="5177">%</TOKEN>
				<TOKEN id="token-34-7" start_char="5179" end_char="5187">identical</TOKEN>
				<TOKEN id="token-34-8" start_char="5189" end_char="5190">at</TOKEN>
				<TOKEN id="token-34-9" start_char="5192" end_char="5194">the</TOKEN>
				<TOKEN id="token-34-10" start_char="5196" end_char="5200">whole</TOKEN>
				<TOKEN id="token-34-11" start_char="5201" end_char="5201">-</TOKEN>
				<TOKEN id="token-34-12" start_char="5202" end_char="5207">genome</TOKEN>
				<TOKEN id="token-34-13" start_char="5209" end_char="5213">level</TOKEN>
				<TOKEN id="token-34-14" start_char="5215" end_char="5216">to</TOKEN>
				<TOKEN id="token-34-15" start_char="5218" end_char="5218">a</TOKEN>
				<TOKEN id="token-34-16" start_char="5220" end_char="5222">bat</TOKEN>
				<TOKEN id="token-34-17" start_char="5224" end_char="5234">coronavirus</TOKEN>
				<TOKEN id="token-34-18" start_char="5235" end_char="5236">,”</TOKEN>
				<TOKEN id="token-34-19" start_char="5238" end_char="5238">a</TOKEN>
				<TOKEN id="token-34-20" start_char="5240" end_char="5244">study</TOKEN>
				<TOKEN id="token-34-21" start_char="5246" end_char="5254">published</TOKEN>
				<TOKEN id="token-34-22" start_char="5256" end_char="5257">in</TOKEN>
				<TOKEN id="token-34-23" start_char="5259" end_char="5261">the</TOKEN>
				<TOKEN id="token-34-24" start_char="5263" end_char="5269">science</TOKEN>
				<TOKEN id="token-34-25" start_char="5271" end_char="5277">journal</TOKEN>
				<TOKEN id="token-34-26" start_char="5279" end_char="5284">Nature</TOKEN>
				<TOKEN id="token-34-27" start_char="5286" end_char="5289">said</TOKEN>
				<TOKEN id="token-34-28" start_char="5290" end_char="5290">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-35" start_char="5292" end_char="5476">
				<ORIGINAL_TEXT>Another study published in the Lancet found results based on samples collected from nine patients who had contracted the virus corroborated the theory that the virus had come from bats.</ORIGINAL_TEXT>
				<TOKEN id="token-35-0" start_char="5292" end_char="5298">Another</TOKEN>
				<TOKEN id="token-35-1" start_char="5300" end_char="5304">study</TOKEN>
				<TOKEN id="token-35-2" start_char="5306" end_char="5314">published</TOKEN>
				<TOKEN id="token-35-3" start_char="5316" end_char="5317">in</TOKEN>
				<TOKEN id="token-35-4" start_char="5319" end_char="5321">the</TOKEN>
				<TOKEN id="token-35-5" start_char="5323" end_char="5328">Lancet</TOKEN>
				<TOKEN id="token-35-6" start_char="5330" end_char="5334">found</TOKEN>
				<TOKEN id="token-35-7" start_char="5336" end_char="5342">results</TOKEN>
				<TOKEN id="token-35-8" start_char="5344" end_char="5348">based</TOKEN>
				<TOKEN id="token-35-9" start_char="5350" end_char="5351">on</TOKEN>
				<TOKEN id="token-35-10" start_char="5353" end_char="5359">samples</TOKEN>
				<TOKEN id="token-35-11" start_char="5361" end_char="5369">collected</TOKEN>
				<TOKEN id="token-35-12" start_char="5371" end_char="5374">from</TOKEN>
				<TOKEN id="token-35-13" start_char="5376" end_char="5379">nine</TOKEN>
				<TOKEN id="token-35-14" start_char="5381" end_char="5388">patients</TOKEN>
				<TOKEN id="token-35-15" start_char="5390" end_char="5392">who</TOKEN>
				<TOKEN id="token-35-16" start_char="5394" end_char="5396">had</TOKEN>
				<TOKEN id="token-35-17" start_char="5398" end_char="5407">contracted</TOKEN>
				<TOKEN id="token-35-18" start_char="5409" end_char="5411">the</TOKEN>
				<TOKEN id="token-35-19" start_char="5413" end_char="5417">virus</TOKEN>
				<TOKEN id="token-35-20" start_char="5419" end_char="5430">corroborated</TOKEN>
				<TOKEN id="token-35-21" start_char="5432" end_char="5434">the</TOKEN>
				<TOKEN id="token-35-22" start_char="5436" end_char="5441">theory</TOKEN>
				<TOKEN id="token-35-23" start_char="5443" end_char="5446">that</TOKEN>
				<TOKEN id="token-35-24" start_char="5448" end_char="5450">the</TOKEN>
				<TOKEN id="token-35-25" start_char="5452" end_char="5456">virus</TOKEN>
				<TOKEN id="token-35-26" start_char="5458" end_char="5460">had</TOKEN>
				<TOKEN id="token-35-27" start_char="5462" end_char="5465">come</TOKEN>
				<TOKEN id="token-35-28" start_char="5467" end_char="5470">from</TOKEN>
				<TOKEN id="token-35-29" start_char="5472" end_char="5475">bats</TOKEN>
				<TOKEN id="token-35-30" start_char="5476" end_char="5476">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-36" start_char="5478" end_char="5642">
				<ORIGINAL_TEXT>Researchers concluded the genome sequences of the coronavirus “was closely related … to two bat-derived severe acute respiratory syndrome (SARS)-like coronaviruses.”</ORIGINAL_TEXT>
				<TOKEN id="token-36-0" start_char="5478" end_char="5488">Researchers</TOKEN>
				<TOKEN id="token-36-1" start_char="5490" end_char="5498">concluded</TOKEN>
				<TOKEN id="token-36-2" start_char="5500" end_char="5502">the</TOKEN>
				<TOKEN id="token-36-3" start_char="5504" end_char="5509">genome</TOKEN>
				<TOKEN id="token-36-4" start_char="5511" end_char="5519">sequences</TOKEN>
				<TOKEN id="token-36-5" start_char="5521" end_char="5522">of</TOKEN>
				<TOKEN id="token-36-6" start_char="5524" end_char="5526">the</TOKEN>
				<TOKEN id="token-36-7" start_char="5528" end_char="5538">coronavirus</TOKEN>
				<TOKEN id="token-36-8" start_char="5540" end_char="5540">“</TOKEN>
				<TOKEN id="token-36-9" start_char="5541" end_char="5543">was</TOKEN>
				<TOKEN id="token-36-10" start_char="5545" end_char="5551">closely</TOKEN>
				<TOKEN id="token-36-11" start_char="5553" end_char="5559">related</TOKEN>
				<TOKEN id="token-36-12" start_char="5561" end_char="5561">…</TOKEN>
				<TOKEN id="token-36-13" start_char="5563" end_char="5564">to</TOKEN>
				<TOKEN id="token-36-14" start_char="5566" end_char="5568">two</TOKEN>
				<TOKEN id="token-36-15" start_char="5570" end_char="5572">bat</TOKEN>
				<TOKEN id="token-36-16" start_char="5573" end_char="5573">-</TOKEN>
				<TOKEN id="token-36-17" start_char="5574" end_char="5580">derived</TOKEN>
				<TOKEN id="token-36-18" start_char="5582" end_char="5587">severe</TOKEN>
				<TOKEN id="token-36-19" start_char="5589" end_char="5593">acute</TOKEN>
				<TOKEN id="token-36-20" start_char="5595" end_char="5605">respiratory</TOKEN>
				<TOKEN id="token-36-21" start_char="5607" end_char="5614">syndrome</TOKEN>
				<TOKEN id="token-36-22" start_char="5616" end_char="5616">(</TOKEN>
				<TOKEN id="token-36-23" start_char="5617" end_char="5620">SARS</TOKEN>
				<TOKEN id="token-36-24" start_char="5621" end_char="5622">)-</TOKEN>
				<TOKEN id="token-36-25" start_char="5623" end_char="5626">like</TOKEN>
				<TOKEN id="token-36-26" start_char="5628" end_char="5640">coronaviruses</TOKEN>
				<TOKEN id="token-36-27" start_char="5641" end_char="5642">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-37" start_char="5644" end_char="5868">
				<ORIGINAL_TEXT>Although scientists say they believe bats were likely the original host, it’s also very possible, the study notes, that the virus was transferred from a bat to another animal that may have been at the seafood market in Wuhan.</ORIGINAL_TEXT>
				<TOKEN id="token-37-0" start_char="5644" end_char="5651">Although</TOKEN>
				<TOKEN id="token-37-1" start_char="5653" end_char="5662">scientists</TOKEN>
				<TOKEN id="token-37-2" start_char="5664" end_char="5666">say</TOKEN>
				<TOKEN id="token-37-3" start_char="5668" end_char="5671">they</TOKEN>
				<TOKEN id="token-37-4" start_char="5673" end_char="5679">believe</TOKEN>
				<TOKEN id="token-37-5" start_char="5681" end_char="5684">bats</TOKEN>
				<TOKEN id="token-37-6" start_char="5686" end_char="5689">were</TOKEN>
				<TOKEN id="token-37-7" start_char="5691" end_char="5696">likely</TOKEN>
				<TOKEN id="token-37-8" start_char="5698" end_char="5700">the</TOKEN>
				<TOKEN id="token-37-9" start_char="5702" end_char="5709">original</TOKEN>
				<TOKEN id="token-37-10" start_char="5711" end_char="5714">host</TOKEN>
				<TOKEN id="token-37-11" start_char="5715" end_char="5715">,</TOKEN>
				<TOKEN id="token-37-12" start_char="5717" end_char="5718">it</TOKEN>
				<TOKEN id="token-37-13" start_char="5719" end_char="5719">’</TOKEN>
				<TOKEN id="token-37-14" start_char="5720" end_char="5720">s</TOKEN>
				<TOKEN id="token-37-15" start_char="5722" end_char="5725">also</TOKEN>
				<TOKEN id="token-37-16" start_char="5727" end_char="5730">very</TOKEN>
				<TOKEN id="token-37-17" start_char="5732" end_char="5739">possible</TOKEN>
				<TOKEN id="token-37-18" start_char="5740" end_char="5740">,</TOKEN>
				<TOKEN id="token-37-19" start_char="5742" end_char="5744">the</TOKEN>
				<TOKEN id="token-37-20" start_char="5746" end_char="5750">study</TOKEN>
				<TOKEN id="token-37-21" start_char="5752" end_char="5756">notes</TOKEN>
				<TOKEN id="token-37-22" start_char="5757" end_char="5757">,</TOKEN>
				<TOKEN id="token-37-23" start_char="5759" end_char="5762">that</TOKEN>
				<TOKEN id="token-37-24" start_char="5764" end_char="5766">the</TOKEN>
				<TOKEN id="token-37-25" start_char="5768" end_char="5772">virus</TOKEN>
				<TOKEN id="token-37-26" start_char="5774" end_char="5776">was</TOKEN>
				<TOKEN id="token-37-27" start_char="5778" end_char="5788">transferred</TOKEN>
				<TOKEN id="token-37-28" start_char="5790" end_char="5793">from</TOKEN>
				<TOKEN id="token-37-29" start_char="5795" end_char="5795">a</TOKEN>
				<TOKEN id="token-37-30" start_char="5797" end_char="5799">bat</TOKEN>
				<TOKEN id="token-37-31" start_char="5801" end_char="5802">to</TOKEN>
				<TOKEN id="token-37-32" start_char="5804" end_char="5810">another</TOKEN>
				<TOKEN id="token-37-33" start_char="5812" end_char="5817">animal</TOKEN>
				<TOKEN id="token-37-34" start_char="5819" end_char="5822">that</TOKEN>
				<TOKEN id="token-37-35" start_char="5824" end_char="5826">may</TOKEN>
				<TOKEN id="token-37-36" start_char="5828" end_char="5831">have</TOKEN>
				<TOKEN id="token-37-37" start_char="5833" end_char="5836">been</TOKEN>
				<TOKEN id="token-37-38" start_char="5838" end_char="5839">at</TOKEN>
				<TOKEN id="token-37-39" start_char="5841" end_char="5843">the</TOKEN>
				<TOKEN id="token-37-40" start_char="5845" end_char="5851">seafood</TOKEN>
				<TOKEN id="token-37-41" start_char="5853" end_char="5858">market</TOKEN>
				<TOKEN id="token-37-42" start_char="5860" end_char="5861">in</TOKEN>
				<TOKEN id="token-37-43" start_char="5863" end_char="5867">Wuhan</TOKEN>
				<TOKEN id="token-37-44" start_char="5868" end_char="5868">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-38" start_char="5870" end_char="5956">
				<ORIGINAL_TEXT>While experts agree the virus came from nature, its origins beyond that remain unclear.</ORIGINAL_TEXT>
				<TOKEN id="token-38-0" start_char="5870" end_char="5874">While</TOKEN>
				<TOKEN id="token-38-1" start_char="5876" end_char="5882">experts</TOKEN>
				<TOKEN id="token-38-2" start_char="5884" end_char="5888">agree</TOKEN>
				<TOKEN id="token-38-3" start_char="5890" end_char="5892">the</TOKEN>
				<TOKEN id="token-38-4" start_char="5894" end_char="5898">virus</TOKEN>
				<TOKEN id="token-38-5" start_char="5900" end_char="5903">came</TOKEN>
				<TOKEN id="token-38-6" start_char="5905" end_char="5908">from</TOKEN>
				<TOKEN id="token-38-7" start_char="5910" end_char="5915">nature</TOKEN>
				<TOKEN id="token-38-8" start_char="5916" end_char="5916">,</TOKEN>
				<TOKEN id="token-38-9" start_char="5918" end_char="5920">its</TOKEN>
				<TOKEN id="token-38-10" start_char="5922" end_char="5928">origins</TOKEN>
				<TOKEN id="token-38-11" start_char="5930" end_char="5935">beyond</TOKEN>
				<TOKEN id="token-38-12" start_char="5937" end_char="5940">that</TOKEN>
				<TOKEN id="token-38-13" start_char="5942" end_char="5947">remain</TOKEN>
				<TOKEN id="token-38-14" start_char="5949" end_char="5955">unclear</TOKEN>
				<TOKEN id="token-38-15" start_char="5956" end_char="5956">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-39" start_char="5958" end_char="6105">
				<ORIGINAL_TEXT>One scenario has the virus occurring naturally – from a bat, say – but accidentally escaping the research facility because of poor safety protocols.</ORIGINAL_TEXT>
				<TOKEN id="token-39-0" start_char="5958" end_char="5960">One</TOKEN>
				<TOKEN id="token-39-1" start_char="5962" end_char="5969">scenario</TOKEN>
				<TOKEN id="token-39-2" start_char="5971" end_char="5973">has</TOKEN>
				<TOKEN id="token-39-3" start_char="5975" end_char="5977">the</TOKEN>
				<TOKEN id="token-39-4" start_char="5979" end_char="5983">virus</TOKEN>
				<TOKEN id="token-39-5" start_char="5985" end_char="5993">occurring</TOKEN>
				<TOKEN id="token-39-6" start_char="5995" end_char="6003">naturally</TOKEN>
				<TOKEN id="token-39-7" start_char="6005" end_char="6005">–</TOKEN>
				<TOKEN id="token-39-8" start_char="6007" end_char="6010">from</TOKEN>
				<TOKEN id="token-39-9" start_char="6012" end_char="6012">a</TOKEN>
				<TOKEN id="token-39-10" start_char="6014" end_char="6016">bat</TOKEN>
				<TOKEN id="token-39-11" start_char="6017" end_char="6017">,</TOKEN>
				<TOKEN id="token-39-12" start_char="6019" end_char="6021">say</TOKEN>
				<TOKEN id="token-39-13" start_char="6023" end_char="6023">–</TOKEN>
				<TOKEN id="token-39-14" start_char="6025" end_char="6027">but</TOKEN>
				<TOKEN id="token-39-15" start_char="6029" end_char="6040">accidentally</TOKEN>
				<TOKEN id="token-39-16" start_char="6042" end_char="6049">escaping</TOKEN>
				<TOKEN id="token-39-17" start_char="6051" end_char="6053">the</TOKEN>
				<TOKEN id="token-39-18" start_char="6055" end_char="6062">research</TOKEN>
				<TOKEN id="token-39-19" start_char="6064" end_char="6071">facility</TOKEN>
				<TOKEN id="token-39-20" start_char="6073" end_char="6079">because</TOKEN>
				<TOKEN id="token-39-21" start_char="6081" end_char="6082">of</TOKEN>
				<TOKEN id="token-39-22" start_char="6084" end_char="6087">poor</TOKEN>
				<TOKEN id="token-39-23" start_char="6089" end_char="6094">safety</TOKEN>
				<TOKEN id="token-39-24" start_char="6096" end_char="6104">protocols</TOKEN>
				<TOKEN id="token-39-25" start_char="6105" end_char="6105">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-40" start_char="6107" end_char="6347">
				<ORIGINAL_TEXT>This is based on circumstantial evidence such as the Wuhan Institute of Virology's history of studying coronaviruses in bats, the lab's proximity to where some of the infections were first diagnosed and China's lax safety record in its labs.</ORIGINAL_TEXT>
				<TOKEN id="token-40-0" start_char="6107" end_char="6110">This</TOKEN>
				<TOKEN id="token-40-1" start_char="6112" end_char="6113">is</TOKEN>
				<TOKEN id="token-40-2" start_char="6115" end_char="6119">based</TOKEN>
				<TOKEN id="token-40-3" start_char="6121" end_char="6122">on</TOKEN>
				<TOKEN id="token-40-4" start_char="6124" end_char="6137">circumstantial</TOKEN>
				<TOKEN id="token-40-5" start_char="6139" end_char="6146">evidence</TOKEN>
				<TOKEN id="token-40-6" start_char="6148" end_char="6151">such</TOKEN>
				<TOKEN id="token-40-7" start_char="6153" end_char="6154">as</TOKEN>
				<TOKEN id="token-40-8" start_char="6156" end_char="6158">the</TOKEN>
				<TOKEN id="token-40-9" start_char="6160" end_char="6164">Wuhan</TOKEN>
				<TOKEN id="token-40-10" start_char="6166" end_char="6174">Institute</TOKEN>
				<TOKEN id="token-40-11" start_char="6176" end_char="6177">of</TOKEN>
				<TOKEN id="token-40-12" start_char="6179" end_char="6186">Virology</TOKEN>
				<TOKEN id="token-40-13" start_char="6187" end_char="6187">'</TOKEN>
				<TOKEN id="token-40-14" start_char="6188" end_char="6188">s</TOKEN>
				<TOKEN id="token-40-15" start_char="6190" end_char="6196">history</TOKEN>
				<TOKEN id="token-40-16" start_char="6198" end_char="6199">of</TOKEN>
				<TOKEN id="token-40-17" start_char="6201" end_char="6208">studying</TOKEN>
				<TOKEN id="token-40-18" start_char="6210" end_char="6222">coronaviruses</TOKEN>
				<TOKEN id="token-40-19" start_char="6224" end_char="6225">in</TOKEN>
				<TOKEN id="token-40-20" start_char="6227" end_char="6230">bats</TOKEN>
				<TOKEN id="token-40-21" start_char="6231" end_char="6231">,</TOKEN>
				<TOKEN id="token-40-22" start_char="6233" end_char="6235">the</TOKEN>
				<TOKEN id="token-40-23" start_char="6237" end_char="6239">lab</TOKEN>
				<TOKEN id="token-40-24" start_char="6240" end_char="6240">'</TOKEN>
				<TOKEN id="token-40-25" start_char="6241" end_char="6241">s</TOKEN>
				<TOKEN id="token-40-26" start_char="6243" end_char="6251">proximity</TOKEN>
				<TOKEN id="token-40-27" start_char="6253" end_char="6254">to</TOKEN>
				<TOKEN id="token-40-28" start_char="6256" end_char="6260">where</TOKEN>
				<TOKEN id="token-40-29" start_char="6262" end_char="6265">some</TOKEN>
				<TOKEN id="token-40-30" start_char="6267" end_char="6268">of</TOKEN>
				<TOKEN id="token-40-31" start_char="6270" end_char="6272">the</TOKEN>
				<TOKEN id="token-40-32" start_char="6274" end_char="6283">infections</TOKEN>
				<TOKEN id="token-40-33" start_char="6285" end_char="6288">were</TOKEN>
				<TOKEN id="token-40-34" start_char="6290" end_char="6294">first</TOKEN>
				<TOKEN id="token-40-35" start_char="6296" end_char="6304">diagnosed</TOKEN>
				<TOKEN id="token-40-36" start_char="6306" end_char="6308">and</TOKEN>
				<TOKEN id="token-40-37" start_char="6310" end_char="6314">China</TOKEN>
				<TOKEN id="token-40-38" start_char="6315" end_char="6315">'</TOKEN>
				<TOKEN id="token-40-39" start_char="6316" end_char="6316">s</TOKEN>
				<TOKEN id="token-40-40" start_char="6318" end_char="6320">lax</TOKEN>
				<TOKEN id="token-40-41" start_char="6322" end_char="6327">safety</TOKEN>
				<TOKEN id="token-40-42" start_char="6329" end_char="6334">record</TOKEN>
				<TOKEN id="token-40-43" start_char="6336" end_char="6337">in</TOKEN>
				<TOKEN id="token-40-44" start_char="6339" end_char="6341">its</TOKEN>
				<TOKEN id="token-40-45" start_char="6343" end_char="6346">labs</TOKEN>
				<TOKEN id="token-40-46" start_char="6347" end_char="6347">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-41" start_char="6349" end_char="6516">
				<ORIGINAL_TEXT>Anthony Fauci, the U.S.'s top infectious disease expert, was dismissive of the theory of an accidental escape from a Chinese laboratory, USA TODAY reported on April 18.</ORIGINAL_TEXT>
				<TOKEN id="token-41-0" start_char="6349" end_char="6355">Anthony</TOKEN>
				<TOKEN id="token-41-1" start_char="6357" end_char="6361">Fauci</TOKEN>
				<TOKEN id="token-41-2" start_char="6362" end_char="6362">,</TOKEN>
				<TOKEN id="token-41-3" start_char="6364" end_char="6366">the</TOKEN>
				<TOKEN id="token-41-4" start_char="6368" end_char="6368">U</TOKEN>
				<TOKEN id="token-41-5" start_char="6369" end_char="6369">.</TOKEN>
				<TOKEN id="token-41-6" start_char="6370" end_char="6370">S</TOKEN>
				<TOKEN id="token-41-7" start_char="6371" end_char="6372">.'</TOKEN>
				<TOKEN id="token-41-8" start_char="6373" end_char="6373">s</TOKEN>
				<TOKEN id="token-41-9" start_char="6375" end_char="6377">top</TOKEN>
				<TOKEN id="token-41-10" start_char="6379" end_char="6388">infectious</TOKEN>
				<TOKEN id="token-41-11" start_char="6390" end_char="6396">disease</TOKEN>
				<TOKEN id="token-41-12" start_char="6398" end_char="6403">expert</TOKEN>
				<TOKEN id="token-41-13" start_char="6404" end_char="6404">,</TOKEN>
				<TOKEN id="token-41-14" start_char="6406" end_char="6408">was</TOKEN>
				<TOKEN id="token-41-15" start_char="6410" end_char="6419">dismissive</TOKEN>
				<TOKEN id="token-41-16" start_char="6421" end_char="6422">of</TOKEN>
				<TOKEN id="token-41-17" start_char="6424" end_char="6426">the</TOKEN>
				<TOKEN id="token-41-18" start_char="6428" end_char="6433">theory</TOKEN>
				<TOKEN id="token-41-19" start_char="6435" end_char="6436">of</TOKEN>
				<TOKEN id="token-41-20" start_char="6438" end_char="6439">an</TOKEN>
				<TOKEN id="token-41-21" start_char="6441" end_char="6450">accidental</TOKEN>
				<TOKEN id="token-41-22" start_char="6452" end_char="6457">escape</TOKEN>
				<TOKEN id="token-41-23" start_char="6459" end_char="6462">from</TOKEN>
				<TOKEN id="token-41-24" start_char="6464" end_char="6464">a</TOKEN>
				<TOKEN id="token-41-25" start_char="6466" end_char="6472">Chinese</TOKEN>
				<TOKEN id="token-41-26" start_char="6474" end_char="6483">laboratory</TOKEN>
				<TOKEN id="token-41-27" start_char="6484" end_char="6484">,</TOKEN>
				<TOKEN id="token-41-28" start_char="6486" end_char="6488">USA</TOKEN>
				<TOKEN id="token-41-29" start_char="6490" end_char="6494">TODAY</TOKEN>
				<TOKEN id="token-41-30" start_char="6496" end_char="6503">reported</TOKEN>
				<TOKEN id="token-41-31" start_char="6505" end_char="6506">on</TOKEN>
				<TOKEN id="token-41-32" start_char="6508" end_char="6512">April</TOKEN>
				<TOKEN id="token-41-33" start_char="6514" end_char="6515">18</TOKEN>
				<TOKEN id="token-41-34" start_char="6516" end_char="6516">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-42" start_char="6518" end_char="6618">
				<ORIGINAL_TEXT>&quot;A group of highly qualified evolutionary virologists looked at the sequences in bats as they evolve.</ORIGINAL_TEXT>
				<TOKEN id="token-42-0" start_char="6518" end_char="6518">&quot;</TOKEN>
				<TOKEN id="token-42-1" start_char="6519" end_char="6519">A</TOKEN>
				<TOKEN id="token-42-2" start_char="6521" end_char="6525">group</TOKEN>
				<TOKEN id="token-42-3" start_char="6527" end_char="6528">of</TOKEN>
				<TOKEN id="token-42-4" start_char="6530" end_char="6535">highly</TOKEN>
				<TOKEN id="token-42-5" start_char="6537" end_char="6545">qualified</TOKEN>
				<TOKEN id="token-42-6" start_char="6547" end_char="6558">evolutionary</TOKEN>
				<TOKEN id="token-42-7" start_char="6560" end_char="6570">virologists</TOKEN>
				<TOKEN id="token-42-8" start_char="6572" end_char="6577">looked</TOKEN>
				<TOKEN id="token-42-9" start_char="6579" end_char="6580">at</TOKEN>
				<TOKEN id="token-42-10" start_char="6582" end_char="6584">the</TOKEN>
				<TOKEN id="token-42-11" start_char="6586" end_char="6594">sequences</TOKEN>
				<TOKEN id="token-42-12" start_char="6596" end_char="6597">in</TOKEN>
				<TOKEN id="token-42-13" start_char="6599" end_char="6602">bats</TOKEN>
				<TOKEN id="token-42-14" start_char="6604" end_char="6605">as</TOKEN>
				<TOKEN id="token-42-15" start_char="6607" end_char="6610">they</TOKEN>
				<TOKEN id="token-42-16" start_char="6612" end_char="6617">evolve</TOKEN>
				<TOKEN id="token-42-17" start_char="6618" end_char="6618">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-43" start_char="6620" end_char="6807">
				<ORIGINAL_TEXT>The mutations that it took to get to the point where it is now are totally consistent with a jump of a species from an animal to a human,&quot; he said Friday in the White House press briefing.</ORIGINAL_TEXT>
				<TOKEN id="token-43-0" start_char="6620" end_char="6622">The</TOKEN>
				<TOKEN id="token-43-1" start_char="6624" end_char="6632">mutations</TOKEN>
				<TOKEN id="token-43-2" start_char="6634" end_char="6637">that</TOKEN>
				<TOKEN id="token-43-3" start_char="6639" end_char="6640">it</TOKEN>
				<TOKEN id="token-43-4" start_char="6642" end_char="6645">took</TOKEN>
				<TOKEN id="token-43-5" start_char="6647" end_char="6648">to</TOKEN>
				<TOKEN id="token-43-6" start_char="6650" end_char="6652">get</TOKEN>
				<TOKEN id="token-43-7" start_char="6654" end_char="6655">to</TOKEN>
				<TOKEN id="token-43-8" start_char="6657" end_char="6659">the</TOKEN>
				<TOKEN id="token-43-9" start_char="6661" end_char="6665">point</TOKEN>
				<TOKEN id="token-43-10" start_char="6667" end_char="6671">where</TOKEN>
				<TOKEN id="token-43-11" start_char="6673" end_char="6674">it</TOKEN>
				<TOKEN id="token-43-12" start_char="6676" end_char="6677">is</TOKEN>
				<TOKEN id="token-43-13" start_char="6679" end_char="6681">now</TOKEN>
				<TOKEN id="token-43-14" start_char="6683" end_char="6685">are</TOKEN>
				<TOKEN id="token-43-15" start_char="6687" end_char="6693">totally</TOKEN>
				<TOKEN id="token-43-16" start_char="6695" end_char="6704">consistent</TOKEN>
				<TOKEN id="token-43-17" start_char="6706" end_char="6709">with</TOKEN>
				<TOKEN id="token-43-18" start_char="6711" end_char="6711">a</TOKEN>
				<TOKEN id="token-43-19" start_char="6713" end_char="6716">jump</TOKEN>
				<TOKEN id="token-43-20" start_char="6718" end_char="6719">of</TOKEN>
				<TOKEN id="token-43-21" start_char="6721" end_char="6721">a</TOKEN>
				<TOKEN id="token-43-22" start_char="6723" end_char="6729">species</TOKEN>
				<TOKEN id="token-43-23" start_char="6731" end_char="6734">from</TOKEN>
				<TOKEN id="token-43-24" start_char="6736" end_char="6737">an</TOKEN>
				<TOKEN id="token-43-25" start_char="6739" end_char="6744">animal</TOKEN>
				<TOKEN id="token-43-26" start_char="6746" end_char="6747">to</TOKEN>
				<TOKEN id="token-43-27" start_char="6749" end_char="6749">a</TOKEN>
				<TOKEN id="token-43-28" start_char="6751" end_char="6755">human</TOKEN>
				<TOKEN id="token-43-29" start_char="6756" end_char="6757">,&quot;</TOKEN>
				<TOKEN id="token-43-30" start_char="6759" end_char="6760">he</TOKEN>
				<TOKEN id="token-43-31" start_char="6762" end_char="6765">said</TOKEN>
				<TOKEN id="token-43-32" start_char="6767" end_char="6772">Friday</TOKEN>
				<TOKEN id="token-43-33" start_char="6774" end_char="6775">in</TOKEN>
				<TOKEN id="token-43-34" start_char="6777" end_char="6779">the</TOKEN>
				<TOKEN id="token-43-35" start_char="6781" end_char="6785">White</TOKEN>
				<TOKEN id="token-43-36" start_char="6787" end_char="6791">House</TOKEN>
				<TOKEN id="token-43-37" start_char="6793" end_char="6797">press</TOKEN>
				<TOKEN id="token-43-38" start_char="6799" end_char="6806">briefing</TOKEN>
				<TOKEN id="token-43-39" start_char="6807" end_char="6807">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-44" start_char="6809" end_char="7159">
				<ORIGINAL_TEXT>But two administration officials with knowledge of the investigation, speaking to USA TODAY on condition of anonymity because it is classified and sensitive, said they have always questioned China's account of how the virus originated and have taken seriously suggestions that it may have resulted from a lab accident that the Chinese are covering up.</ORIGINAL_TEXT>
				<TOKEN id="token-44-0" start_char="6809" end_char="6811">But</TOKEN>
				<TOKEN id="token-44-1" start_char="6813" end_char="6815">two</TOKEN>
				<TOKEN id="token-44-2" start_char="6817" end_char="6830">administration</TOKEN>
				<TOKEN id="token-44-3" start_char="6832" end_char="6840">officials</TOKEN>
				<TOKEN id="token-44-4" start_char="6842" end_char="6845">with</TOKEN>
				<TOKEN id="token-44-5" start_char="6847" end_char="6855">knowledge</TOKEN>
				<TOKEN id="token-44-6" start_char="6857" end_char="6858">of</TOKEN>
				<TOKEN id="token-44-7" start_char="6860" end_char="6862">the</TOKEN>
				<TOKEN id="token-44-8" start_char="6864" end_char="6876">investigation</TOKEN>
				<TOKEN id="token-44-9" start_char="6877" end_char="6877">,</TOKEN>
				<TOKEN id="token-44-10" start_char="6879" end_char="6886">speaking</TOKEN>
				<TOKEN id="token-44-11" start_char="6888" end_char="6889">to</TOKEN>
				<TOKEN id="token-44-12" start_char="6891" end_char="6893">USA</TOKEN>
				<TOKEN id="token-44-13" start_char="6895" end_char="6899">TODAY</TOKEN>
				<TOKEN id="token-44-14" start_char="6901" end_char="6902">on</TOKEN>
				<TOKEN id="token-44-15" start_char="6904" end_char="6912">condition</TOKEN>
				<TOKEN id="token-44-16" start_char="6914" end_char="6915">of</TOKEN>
				<TOKEN id="token-44-17" start_char="6917" end_char="6925">anonymity</TOKEN>
				<TOKEN id="token-44-18" start_char="6927" end_char="6933">because</TOKEN>
				<TOKEN id="token-44-19" start_char="6935" end_char="6936">it</TOKEN>
				<TOKEN id="token-44-20" start_char="6938" end_char="6939">is</TOKEN>
				<TOKEN id="token-44-21" start_char="6941" end_char="6950">classified</TOKEN>
				<TOKEN id="token-44-22" start_char="6952" end_char="6954">and</TOKEN>
				<TOKEN id="token-44-23" start_char="6956" end_char="6964">sensitive</TOKEN>
				<TOKEN id="token-44-24" start_char="6965" end_char="6965">,</TOKEN>
				<TOKEN id="token-44-25" start_char="6967" end_char="6970">said</TOKEN>
				<TOKEN id="token-44-26" start_char="6972" end_char="6975">they</TOKEN>
				<TOKEN id="token-44-27" start_char="6977" end_char="6980">have</TOKEN>
				<TOKEN id="token-44-28" start_char="6982" end_char="6987">always</TOKEN>
				<TOKEN id="token-44-29" start_char="6989" end_char="6998">questioned</TOKEN>
				<TOKEN id="token-44-30" start_char="7000" end_char="7004">China</TOKEN>
				<TOKEN id="token-44-31" start_char="7005" end_char="7005">'</TOKEN>
				<TOKEN id="token-44-32" start_char="7006" end_char="7006">s</TOKEN>
				<TOKEN id="token-44-33" start_char="7008" end_char="7014">account</TOKEN>
				<TOKEN id="token-44-34" start_char="7016" end_char="7017">of</TOKEN>
				<TOKEN id="token-44-35" start_char="7019" end_char="7021">how</TOKEN>
				<TOKEN id="token-44-36" start_char="7023" end_char="7025">the</TOKEN>
				<TOKEN id="token-44-37" start_char="7027" end_char="7031">virus</TOKEN>
				<TOKEN id="token-44-38" start_char="7033" end_char="7042">originated</TOKEN>
				<TOKEN id="token-44-39" start_char="7044" end_char="7046">and</TOKEN>
				<TOKEN id="token-44-40" start_char="7048" end_char="7051">have</TOKEN>
				<TOKEN id="token-44-41" start_char="7053" end_char="7057">taken</TOKEN>
				<TOKEN id="token-44-42" start_char="7059" end_char="7067">seriously</TOKEN>
				<TOKEN id="token-44-43" start_char="7069" end_char="7079">suggestions</TOKEN>
				<TOKEN id="token-44-44" start_char="7081" end_char="7084">that</TOKEN>
				<TOKEN id="token-44-45" start_char="7086" end_char="7087">it</TOKEN>
				<TOKEN id="token-44-46" start_char="7089" end_char="7091">may</TOKEN>
				<TOKEN id="token-44-47" start_char="7093" end_char="7096">have</TOKEN>
				<TOKEN id="token-44-48" start_char="7098" end_char="7105">resulted</TOKEN>
				<TOKEN id="token-44-49" start_char="7107" end_char="7110">from</TOKEN>
				<TOKEN id="token-44-50" start_char="7112" end_char="7112">a</TOKEN>
				<TOKEN id="token-44-51" start_char="7114" end_char="7116">lab</TOKEN>
				<TOKEN id="token-44-52" start_char="7118" end_char="7125">accident</TOKEN>
				<TOKEN id="token-44-53" start_char="7127" end_char="7130">that</TOKEN>
				<TOKEN id="token-44-54" start_char="7132" end_char="7134">the</TOKEN>
				<TOKEN id="token-44-55" start_char="7136" end_char="7142">Chinese</TOKEN>
				<TOKEN id="token-44-56" start_char="7144" end_char="7146">are</TOKEN>
				<TOKEN id="token-44-57" start_char="7148" end_char="7155">covering</TOKEN>
				<TOKEN id="token-44-58" start_char="7157" end_char="7158">up</TOKEN>
				<TOKEN id="token-44-59" start_char="7159" end_char="7159">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-45" start_char="7161" end_char="7215">
				<ORIGINAL_TEXT>&quot;There's a high level of suspicion,&quot; one official said.</ORIGINAL_TEXT>
				<TOKEN id="token-45-0" start_char="7161" end_char="7161">&quot;</TOKEN>
				<TOKEN id="token-45-1" start_char="7162" end_char="7166">There</TOKEN>
				<TOKEN id="token-45-2" start_char="7167" end_char="7167">'</TOKEN>
				<TOKEN id="token-45-3" start_char="7168" end_char="7168">s</TOKEN>
				<TOKEN id="token-45-4" start_char="7170" end_char="7170">a</TOKEN>
				<TOKEN id="token-45-5" start_char="7172" end_char="7175">high</TOKEN>
				<TOKEN id="token-45-6" start_char="7177" end_char="7181">level</TOKEN>
				<TOKEN id="token-45-7" start_char="7183" end_char="7184">of</TOKEN>
				<TOKEN id="token-45-8" start_char="7186" end_char="7194">suspicion</TOKEN>
				<TOKEN id="token-45-9" start_char="7195" end_char="7196">,&quot;</TOKEN>
				<TOKEN id="token-45-10" start_char="7198" end_char="7200">one</TOKEN>
				<TOKEN id="token-45-11" start_char="7202" end_char="7209">official</TOKEN>
				<TOKEN id="token-45-12" start_char="7211" end_char="7214">said</TOKEN>
				<TOKEN id="token-45-13" start_char="7215" end_char="7215">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-46" start_char="7217" end_char="7348">
				<ORIGINAL_TEXT>The officials emphasized that no conclusions have been drawn from an investigation that is ongoing among U.S. intelligence agencies.</ORIGINAL_TEXT>
				<TOKEN id="token-46-0" start_char="7217" end_char="7219">The</TOKEN>
				<TOKEN id="token-46-1" start_char="7221" end_char="7229">officials</TOKEN>
				<TOKEN id="token-46-2" start_char="7231" end_char="7240">emphasized</TOKEN>
				<TOKEN id="token-46-3" start_char="7242" end_char="7245">that</TOKEN>
				<TOKEN id="token-46-4" start_char="7247" end_char="7248">no</TOKEN>
				<TOKEN id="token-46-5" start_char="7250" end_char="7260">conclusions</TOKEN>
				<TOKEN id="token-46-6" start_char="7262" end_char="7265">have</TOKEN>
				<TOKEN id="token-46-7" start_char="7267" end_char="7270">been</TOKEN>
				<TOKEN id="token-46-8" start_char="7272" end_char="7276">drawn</TOKEN>
				<TOKEN id="token-46-9" start_char="7278" end_char="7281">from</TOKEN>
				<TOKEN id="token-46-10" start_char="7283" end_char="7284">an</TOKEN>
				<TOKEN id="token-46-11" start_char="7286" end_char="7298">investigation</TOKEN>
				<TOKEN id="token-46-12" start_char="7300" end_char="7303">that</TOKEN>
				<TOKEN id="token-46-13" start_char="7305" end_char="7306">is</TOKEN>
				<TOKEN id="token-46-14" start_char="7308" end_char="7314">ongoing</TOKEN>
				<TOKEN id="token-46-15" start_char="7316" end_char="7320">among</TOKEN>
				<TOKEN id="token-46-16" start_char="7322" end_char="7322">U</TOKEN>
				<TOKEN id="token-46-17" start_char="7323" end_char="7323">.</TOKEN>
				<TOKEN id="token-46-18" start_char="7324" end_char="7324">S</TOKEN>
				<TOKEN id="token-46-19" start_char="7325" end_char="7325">.</TOKEN>
				<TOKEN id="token-46-20" start_char="7327" end_char="7338">intelligence</TOKEN>
				<TOKEN id="token-46-21" start_char="7340" end_char="7347">agencies</TOKEN>
				<TOKEN id="token-46-22" start_char="7348" end_char="7348">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-47" start_char="7350" end_char="7595">
				<ORIGINAL_TEXT>But even as of Jan. 15, 2021, its origins are unclear, as described in this State Department statement: &quot;The U.S. government does not know exactly where, when, or how the COVID-19 virus — known as SARS-CoV-2 — was transmitted initially to humans.</ORIGINAL_TEXT>
				<TOKEN id="token-47-0" start_char="7350" end_char="7352">But</TOKEN>
				<TOKEN id="token-47-1" start_char="7354" end_char="7357">even</TOKEN>
				<TOKEN id="token-47-2" start_char="7359" end_char="7360">as</TOKEN>
				<TOKEN id="token-47-3" start_char="7362" end_char="7363">of</TOKEN>
				<TOKEN id="token-47-4" start_char="7365" end_char="7367">Jan</TOKEN>
				<TOKEN id="token-47-5" start_char="7368" end_char="7368">.</TOKEN>
				<TOKEN id="token-47-6" start_char="7370" end_char="7371">15</TOKEN>
				<TOKEN id="token-47-7" start_char="7372" end_char="7372">,</TOKEN>
				<TOKEN id="token-47-8" start_char="7374" end_char="7377">2021</TOKEN>
				<TOKEN id="token-47-9" start_char="7378" end_char="7378">,</TOKEN>
				<TOKEN id="token-47-10" start_char="7380" end_char="7382">its</TOKEN>
				<TOKEN id="token-47-11" start_char="7384" end_char="7390">origins</TOKEN>
				<TOKEN id="token-47-12" start_char="7392" end_char="7394">are</TOKEN>
				<TOKEN id="token-47-13" start_char="7396" end_char="7402">unclear</TOKEN>
				<TOKEN id="token-47-14" start_char="7403" end_char="7403">,</TOKEN>
				<TOKEN id="token-47-15" start_char="7405" end_char="7406">as</TOKEN>
				<TOKEN id="token-47-16" start_char="7408" end_char="7416">described</TOKEN>
				<TOKEN id="token-47-17" start_char="7418" end_char="7419">in</TOKEN>
				<TOKEN id="token-47-18" start_char="7421" end_char="7424">this</TOKEN>
				<TOKEN id="token-47-19" start_char="7426" end_char="7430">State</TOKEN>
				<TOKEN id="token-47-20" start_char="7432" end_char="7441">Department</TOKEN>
				<TOKEN id="token-47-21" start_char="7443" end_char="7451">statement</TOKEN>
				<TOKEN id="token-47-22" start_char="7452" end_char="7452">:</TOKEN>
				<TOKEN id="token-47-23" start_char="7454" end_char="7454">&quot;</TOKEN>
				<TOKEN id="token-47-24" start_char="7455" end_char="7457">The</TOKEN>
				<TOKEN id="token-47-25" start_char="7459" end_char="7459">U</TOKEN>
				<TOKEN id="token-47-26" start_char="7460" end_char="7460">.</TOKEN>
				<TOKEN id="token-47-27" start_char="7461" end_char="7461">S</TOKEN>
				<TOKEN id="token-47-28" start_char="7462" end_char="7462">.</TOKEN>
				<TOKEN id="token-47-29" start_char="7464" end_char="7473">government</TOKEN>
				<TOKEN id="token-47-30" start_char="7475" end_char="7478">does</TOKEN>
				<TOKEN id="token-47-31" start_char="7480" end_char="7482">not</TOKEN>
				<TOKEN id="token-47-32" start_char="7484" end_char="7487">know</TOKEN>
				<TOKEN id="token-47-33" start_char="7489" end_char="7495">exactly</TOKEN>
				<TOKEN id="token-47-34" start_char="7497" end_char="7501">where</TOKEN>
				<TOKEN id="token-47-35" start_char="7502" end_char="7502">,</TOKEN>
				<TOKEN id="token-47-36" start_char="7504" end_char="7507">when</TOKEN>
				<TOKEN id="token-47-37" start_char="7508" end_char="7508">,</TOKEN>
				<TOKEN id="token-47-38" start_char="7510" end_char="7511">or</TOKEN>
				<TOKEN id="token-47-39" start_char="7513" end_char="7515">how</TOKEN>
				<TOKEN id="token-47-40" start_char="7517" end_char="7519">the</TOKEN>
				<TOKEN id="token-47-41" start_char="7521" end_char="7525">COVID</TOKEN>
				<TOKEN id="token-47-42" start_char="7526" end_char="7526">-</TOKEN>
				<TOKEN id="token-47-43" start_char="7527" end_char="7528">19</TOKEN>
				<TOKEN id="token-47-44" start_char="7530" end_char="7534">virus</TOKEN>
				<TOKEN id="token-47-45" start_char="7536" end_char="7536">—</TOKEN>
				<TOKEN id="token-47-46" start_char="7538" end_char="7542">known</TOKEN>
				<TOKEN id="token-47-47" start_char="7544" end_char="7545">as</TOKEN>
				<TOKEN id="token-47-48" start_char="7547" end_char="7550">SARS</TOKEN>
				<TOKEN id="token-47-49" start_char="7551" end_char="7551">-</TOKEN>
				<TOKEN id="token-47-50" start_char="7552" end_char="7554">CoV</TOKEN>
				<TOKEN id="token-47-51" start_char="7555" end_char="7555">-</TOKEN>
				<TOKEN id="token-47-52" start_char="7556" end_char="7556">2</TOKEN>
				<TOKEN id="token-47-53" start_char="7558" end_char="7558">—</TOKEN>
				<TOKEN id="token-47-54" start_char="7560" end_char="7562">was</TOKEN>
				<TOKEN id="token-47-55" start_char="7564" end_char="7574">transmitted</TOKEN>
				<TOKEN id="token-47-56" start_char="7576" end_char="7584">initially</TOKEN>
				<TOKEN id="token-47-57" start_char="7586" end_char="7587">to</TOKEN>
				<TOKEN id="token-47-58" start_char="7589" end_char="7594">humans</TOKEN>
				<TOKEN id="token-47-59" start_char="7595" end_char="7595">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-48" start_char="7597" end_char="7750">
				<ORIGINAL_TEXT>We have not determined whether the outbreak began through contact with infected animals or was the result of an accident at a laboratory in Wuhan, China.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-48-0" start_char="7597" end_char="7598">We</TOKEN>
				<TOKEN id="token-48-1" start_char="7600" end_char="7603">have</TOKEN>
				<TOKEN id="token-48-2" start_char="7605" end_char="7607">not</TOKEN>
				<TOKEN id="token-48-3" start_char="7609" end_char="7618">determined</TOKEN>
				<TOKEN id="token-48-4" start_char="7620" end_char="7626">whether</TOKEN>
				<TOKEN id="token-48-5" start_char="7628" end_char="7630">the</TOKEN>
				<TOKEN id="token-48-6" start_char="7632" end_char="7639">outbreak</TOKEN>
				<TOKEN id="token-48-7" start_char="7641" end_char="7645">began</TOKEN>
				<TOKEN id="token-48-8" start_char="7647" end_char="7653">through</TOKEN>
				<TOKEN id="token-48-9" start_char="7655" end_char="7661">contact</TOKEN>
				<TOKEN id="token-48-10" start_char="7663" end_char="7666">with</TOKEN>
				<TOKEN id="token-48-11" start_char="7668" end_char="7675">infected</TOKEN>
				<TOKEN id="token-48-12" start_char="7677" end_char="7683">animals</TOKEN>
				<TOKEN id="token-48-13" start_char="7685" end_char="7686">or</TOKEN>
				<TOKEN id="token-48-14" start_char="7688" end_char="7690">was</TOKEN>
				<TOKEN id="token-48-15" start_char="7692" end_char="7694">the</TOKEN>
				<TOKEN id="token-48-16" start_char="7696" end_char="7701">result</TOKEN>
				<TOKEN id="token-48-17" start_char="7703" end_char="7704">of</TOKEN>
				<TOKEN id="token-48-18" start_char="7706" end_char="7707">an</TOKEN>
				<TOKEN id="token-48-19" start_char="7709" end_char="7716">accident</TOKEN>
				<TOKEN id="token-48-20" start_char="7718" end_char="7719">at</TOKEN>
				<TOKEN id="token-48-21" start_char="7721" end_char="7721">a</TOKEN>
				<TOKEN id="token-48-22" start_char="7723" end_char="7732">laboratory</TOKEN>
				<TOKEN id="token-48-23" start_char="7734" end_char="7735">in</TOKEN>
				<TOKEN id="token-48-24" start_char="7737" end_char="7741">Wuhan</TOKEN>
				<TOKEN id="token-48-25" start_char="7742" end_char="7742">,</TOKEN>
				<TOKEN id="token-48-26" start_char="7744" end_char="7748">China</TOKEN>
				<TOKEN id="token-48-27" start_char="7749" end_char="7750">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-49" start_char="7752" end_char="7775">
				<ORIGINAL_TEXT>Our ruling: Partly False</ORIGINAL_TEXT>
				<TOKEN id="token-49-0" start_char="7752" end_char="7754">Our</TOKEN>
				<TOKEN id="token-49-1" start_char="7756" end_char="7761">ruling</TOKEN>
				<TOKEN id="token-49-2" start_char="7762" end_char="7762">:</TOKEN>
				<TOKEN id="token-49-3" start_char="7764" end_char="7769">Partly</TOKEN>
				<TOKEN id="token-49-4" start_char="7771" end_char="7775">False</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-50" start_char="7777" end_char="7861">
				<ORIGINAL_TEXT>We rate the claim that COVID-19 may have originated in a Chinese lab as PARTLY FALSE.</ORIGINAL_TEXT>
				<TOKEN id="token-50-0" start_char="7777" end_char="7778">We</TOKEN>
				<TOKEN id="token-50-1" start_char="7780" end_char="7783">rate</TOKEN>
				<TOKEN id="token-50-2" start_char="7785" end_char="7787">the</TOKEN>
				<TOKEN id="token-50-3" start_char="7789" end_char="7793">claim</TOKEN>
				<TOKEN id="token-50-4" start_char="7795" end_char="7798">that</TOKEN>
				<TOKEN id="token-50-5" start_char="7800" end_char="7804">COVID</TOKEN>
				<TOKEN id="token-50-6" start_char="7805" end_char="7805">-</TOKEN>
				<TOKEN id="token-50-7" start_char="7806" end_char="7807">19</TOKEN>
				<TOKEN id="token-50-8" start_char="7809" end_char="7811">may</TOKEN>
				<TOKEN id="token-50-9" start_char="7813" end_char="7816">have</TOKEN>
				<TOKEN id="token-50-10" start_char="7818" end_char="7827">originated</TOKEN>
				<TOKEN id="token-50-11" start_char="7829" end_char="7830">in</TOKEN>
				<TOKEN id="token-50-12" start_char="7832" end_char="7832">a</TOKEN>
				<TOKEN id="token-50-13" start_char="7834" end_char="7840">Chinese</TOKEN>
				<TOKEN id="token-50-14" start_char="7842" end_char="7844">lab</TOKEN>
				<TOKEN id="token-50-15" start_char="7846" end_char="7847">as</TOKEN>
				<TOKEN id="token-50-16" start_char="7849" end_char="7854">PARTLY</TOKEN>
				<TOKEN id="token-50-17" start_char="7856" end_char="7860">FALSE</TOKEN>
				<TOKEN id="token-50-18" start_char="7861" end_char="7861">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-51" start_char="7863" end_char="8080">
				<ORIGINAL_TEXT>Suggestions that the novel coronavirus was engineered for use in bioweapons in a high-security biomedical laboratory in Wuhan, China, were debunked, based on scientific research since the virus began its global spread.</ORIGINAL_TEXT>
				<TOKEN id="token-51-0" start_char="7863" end_char="7873">Suggestions</TOKEN>
				<TOKEN id="token-51-1" start_char="7875" end_char="7878">that</TOKEN>
				<TOKEN id="token-51-2" start_char="7880" end_char="7882">the</TOKEN>
				<TOKEN id="token-51-3" start_char="7884" end_char="7888">novel</TOKEN>
				<TOKEN id="token-51-4" start_char="7890" end_char="7900">coronavirus</TOKEN>
				<TOKEN id="token-51-5" start_char="7902" end_char="7904">was</TOKEN>
				<TOKEN id="token-51-6" start_char="7906" end_char="7915">engineered</TOKEN>
				<TOKEN id="token-51-7" start_char="7917" end_char="7919">for</TOKEN>
				<TOKEN id="token-51-8" start_char="7921" end_char="7923">use</TOKEN>
				<TOKEN id="token-51-9" start_char="7925" end_char="7926">in</TOKEN>
				<TOKEN id="token-51-10" start_char="7928" end_char="7937">bioweapons</TOKEN>
				<TOKEN id="token-51-11" start_char="7939" end_char="7940">in</TOKEN>
				<TOKEN id="token-51-12" start_char="7942" end_char="7942">a</TOKEN>
				<TOKEN id="token-51-13" start_char="7944" end_char="7947">high</TOKEN>
				<TOKEN id="token-51-14" start_char="7948" end_char="7948">-</TOKEN>
				<TOKEN id="token-51-15" start_char="7949" end_char="7956">security</TOKEN>
				<TOKEN id="token-51-16" start_char="7958" end_char="7967">biomedical</TOKEN>
				<TOKEN id="token-51-17" start_char="7969" end_char="7978">laboratory</TOKEN>
				<TOKEN id="token-51-18" start_char="7980" end_char="7981">in</TOKEN>
				<TOKEN id="token-51-19" start_char="7983" end_char="7987">Wuhan</TOKEN>
				<TOKEN id="token-51-20" start_char="7988" end_char="7988">,</TOKEN>
				<TOKEN id="token-51-21" start_char="7990" end_char="7994">China</TOKEN>
				<TOKEN id="token-51-22" start_char="7995" end_char="7995">,</TOKEN>
				<TOKEN id="token-51-23" start_char="7997" end_char="8000">were</TOKEN>
				<TOKEN id="token-51-24" start_char="8002" end_char="8009">debunked</TOKEN>
				<TOKEN id="token-51-25" start_char="8010" end_char="8010">,</TOKEN>
				<TOKEN id="token-51-26" start_char="8012" end_char="8016">based</TOKEN>
				<TOKEN id="token-51-27" start_char="8018" end_char="8019">on</TOKEN>
				<TOKEN id="token-51-28" start_char="8021" end_char="8030">scientific</TOKEN>
				<TOKEN id="token-51-29" start_char="8032" end_char="8039">research</TOKEN>
				<TOKEN id="token-51-30" start_char="8041" end_char="8045">since</TOKEN>
				<TOKEN id="token-51-31" start_char="8047" end_char="8049">the</TOKEN>
				<TOKEN id="token-51-32" start_char="8051" end_char="8055">virus</TOKEN>
				<TOKEN id="token-51-33" start_char="8057" end_char="8061">began</TOKEN>
				<TOKEN id="token-51-34" start_char="8063" end_char="8065">its</TOKEN>
				<TOKEN id="token-51-35" start_char="8067" end_char="8072">global</TOKEN>
				<TOKEN id="token-51-36" start_char="8074" end_char="8079">spread</TOKEN>
				<TOKEN id="token-51-37" start_char="8080" end_char="8080">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-52" start_char="8082" end_char="8247">
				<ORIGINAL_TEXT>Investigations continue into where COVID-19 began, and no conclusions can be drawn, nor has evidence been presented, that definitively explains the pathogen’s origin.</ORIGINAL_TEXT>
				<TOKEN id="token-52-0" start_char="8082" end_char="8095">Investigations</TOKEN>
				<TOKEN id="token-52-1" start_char="8097" end_char="8104">continue</TOKEN>
				<TOKEN id="token-52-2" start_char="8106" end_char="8109">into</TOKEN>
				<TOKEN id="token-52-3" start_char="8111" end_char="8115">where</TOKEN>
				<TOKEN id="token-52-4" start_char="8117" end_char="8121">COVID</TOKEN>
				<TOKEN id="token-52-5" start_char="8122" end_char="8122">-</TOKEN>
				<TOKEN id="token-52-6" start_char="8123" end_char="8124">19</TOKEN>
				<TOKEN id="token-52-7" start_char="8126" end_char="8130">began</TOKEN>
				<TOKEN id="token-52-8" start_char="8131" end_char="8131">,</TOKEN>
				<TOKEN id="token-52-9" start_char="8133" end_char="8135">and</TOKEN>
				<TOKEN id="token-52-10" start_char="8137" end_char="8138">no</TOKEN>
				<TOKEN id="token-52-11" start_char="8140" end_char="8150">conclusions</TOKEN>
				<TOKEN id="token-52-12" start_char="8152" end_char="8154">can</TOKEN>
				<TOKEN id="token-52-13" start_char="8156" end_char="8157">be</TOKEN>
				<TOKEN id="token-52-14" start_char="8159" end_char="8163">drawn</TOKEN>
				<TOKEN id="token-52-15" start_char="8164" end_char="8164">,</TOKEN>
				<TOKEN id="token-52-16" start_char="8166" end_char="8168">nor</TOKEN>
				<TOKEN id="token-52-17" start_char="8170" end_char="8172">has</TOKEN>
				<TOKEN id="token-52-18" start_char="8174" end_char="8181">evidence</TOKEN>
				<TOKEN id="token-52-19" start_char="8183" end_char="8186">been</TOKEN>
				<TOKEN id="token-52-20" start_char="8188" end_char="8196">presented</TOKEN>
				<TOKEN id="token-52-21" start_char="8197" end_char="8197">,</TOKEN>
				<TOKEN id="token-52-22" start_char="8199" end_char="8202">that</TOKEN>
				<TOKEN id="token-52-23" start_char="8204" end_char="8215">definitively</TOKEN>
				<TOKEN id="token-52-24" start_char="8217" end_char="8224">explains</TOKEN>
				<TOKEN id="token-52-25" start_char="8226" end_char="8228">the</TOKEN>
				<TOKEN id="token-52-26" start_char="8230" end_char="8237">pathogen</TOKEN>
				<TOKEN id="token-52-27" start_char="8238" end_char="8238">’</TOKEN>
				<TOKEN id="token-52-28" start_char="8239" end_char="8239">s</TOKEN>
				<TOKEN id="token-52-29" start_char="8241" end_char="8246">origin</TOKEN>
				<TOKEN id="token-52-30" start_char="8247" end_char="8247">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-53" start_char="8249" end_char="8363">
				<ORIGINAL_TEXT>Circumstantial evidence suggests the virus could have escaped from the Wuhan lab due to a lapse in safety measures.</ORIGINAL_TEXT>
				<TOKEN id="token-53-0" start_char="8249" end_char="8262">Circumstantial</TOKEN>
				<TOKEN id="token-53-1" start_char="8264" end_char="8271">evidence</TOKEN>
				<TOKEN id="token-53-2" start_char="8273" end_char="8280">suggests</TOKEN>
				<TOKEN id="token-53-3" start_char="8282" end_char="8284">the</TOKEN>
				<TOKEN id="token-53-4" start_char="8286" end_char="8290">virus</TOKEN>
				<TOKEN id="token-53-5" start_char="8292" end_char="8296">could</TOKEN>
				<TOKEN id="token-53-6" start_char="8298" end_char="8301">have</TOKEN>
				<TOKEN id="token-53-7" start_char="8303" end_char="8309">escaped</TOKEN>
				<TOKEN id="token-53-8" start_char="8311" end_char="8314">from</TOKEN>
				<TOKEN id="token-53-9" start_char="8316" end_char="8318">the</TOKEN>
				<TOKEN id="token-53-10" start_char="8320" end_char="8324">Wuhan</TOKEN>
				<TOKEN id="token-53-11" start_char="8326" end_char="8328">lab</TOKEN>
				<TOKEN id="token-53-12" start_char="8330" end_char="8332">due</TOKEN>
				<TOKEN id="token-53-13" start_char="8334" end_char="8335">to</TOKEN>
				<TOKEN id="token-53-14" start_char="8337" end_char="8337">a</TOKEN>
				<TOKEN id="token-53-15" start_char="8339" end_char="8343">lapse</TOKEN>
				<TOKEN id="token-53-16" start_char="8345" end_char="8346">in</TOKEN>
				<TOKEN id="token-53-17" start_char="8348" end_char="8353">safety</TOKEN>
				<TOKEN id="token-53-18" start_char="8355" end_char="8362">measures</TOKEN>
				<TOKEN id="token-53-19" start_char="8363" end_char="8363">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-3-54" start_char="8365" end_char="8387">
				<ORIGINAL_TEXT>Our fact-check sources:</ORIGINAL_TEXT>
				<TOKEN id="token-54-0" start_char="8365" end_char="8367">Our</TOKEN>
				<TOKEN id="token-54-1" start_char="8369" end_char="8372">fact</TOKEN>
				<TOKEN id="token-54-2" start_char="8373" end_char="8373">-</TOKEN>
				<TOKEN id="token-54-3" start_char="8374" end_char="8378">check</TOKEN>
				<TOKEN id="token-54-4" start_char="8380" end_char="8386">sources</TOKEN>
				<TOKEN id="token-54-5" start_char="8387" end_char="8387">:</TOKEN>
			</SEG>
		</TEXT>
	</DOC>
</LCTL_TEXT>
