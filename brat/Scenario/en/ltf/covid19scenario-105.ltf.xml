<?xml version="1.0" encoding="utf-8"?>
<LCTL_TEXT>
	<DOC id="covid19scenario-105">
		<TEXT>
			<SEG id="covid19scenario-105-0" start_char="0" end_char="178">
				<ORIGINAL_TEXT>Despite evidence to the contrary, nearly 3 in 10 Americans believe the coronavirus was created in a lab, according to survey results released Wednesday by the Pew Research Center.</ORIGINAL_TEXT>
				<TOKEN id="token-0-0" start_char="0" end_char="6">Despite</TOKEN>
				<TOKEN id="token-0-1" start_char="8" end_char="15">evidence</TOKEN>
				<TOKEN id="token-0-2" start_char="17" end_char="18">to</TOKEN>
				<TOKEN id="token-0-3" start_char="20" end_char="22">the</TOKEN>
				<TOKEN id="token-0-4" start_char="24" end_char="31">contrary</TOKEN>
				<TOKEN id="token-0-5" start_char="32" end_char="32">,</TOKEN>
				<TOKEN id="token-0-6" start_char="34" end_char="39">nearly</TOKEN>
				<TOKEN id="token-0-7" start_char="41" end_char="41">3</TOKEN>
				<TOKEN id="token-0-8" start_char="43" end_char="44">in</TOKEN>
				<TOKEN id="token-0-9" start_char="46" end_char="47">10</TOKEN>
				<TOKEN id="token-0-10" start_char="49" end_char="57">Americans</TOKEN>
				<TOKEN id="token-0-11" start_char="59" end_char="65">believe</TOKEN>
				<TOKEN id="token-0-12" start_char="67" end_char="69">the</TOKEN>
				<TOKEN id="token-0-13" start_char="71" end_char="81">coronavirus</TOKEN>
				<TOKEN id="token-0-14" start_char="83" end_char="85">was</TOKEN>
				<TOKEN id="token-0-15" start_char="87" end_char="93">created</TOKEN>
				<TOKEN id="token-0-16" start_char="95" end_char="96">in</TOKEN>
				<TOKEN id="token-0-17" start_char="98" end_char="98">a</TOKEN>
				<TOKEN id="token-0-18" start_char="100" end_char="102">lab</TOKEN>
				<TOKEN id="token-0-19" start_char="103" end_char="103">,</TOKEN>
				<TOKEN id="token-0-20" start_char="105" end_char="113">according</TOKEN>
				<TOKEN id="token-0-21" start_char="115" end_char="116">to</TOKEN>
				<TOKEN id="token-0-22" start_char="118" end_char="123">survey</TOKEN>
				<TOKEN id="token-0-23" start_char="125" end_char="131">results</TOKEN>
				<TOKEN id="token-0-24" start_char="133" end_char="140">released</TOKEN>
				<TOKEN id="token-0-25" start_char="142" end_char="150">Wednesday</TOKEN>
				<TOKEN id="token-0-26" start_char="152" end_char="153">by</TOKEN>
				<TOKEN id="token-0-27" start_char="155" end_char="157">the</TOKEN>
				<TOKEN id="token-0-28" start_char="159" end_char="161">Pew</TOKEN>
				<TOKEN id="token-0-29" start_char="163" end_char="170">Research</TOKEN>
				<TOKEN id="token-0-30" start_char="172" end_char="177">Center</TOKEN>
				<TOKEN id="token-0-31" start_char="178" end_char="178">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-1" start_char="180" end_char="338">
				<ORIGINAL_TEXT>Approximately 29% of those surveyed said the virus was &quot;most likely&quot; made in a lab, with a large share of that group (23%) saying it was done so intentionally.</ORIGINAL_TEXT>
				<TOKEN id="token-1-0" start_char="180" end_char="192">Approximately</TOKEN>
				<TOKEN id="token-1-1" start_char="194" end_char="195">29</TOKEN>
				<TOKEN id="token-1-2" start_char="196" end_char="196">%</TOKEN>
				<TOKEN id="token-1-3" start_char="198" end_char="199">of</TOKEN>
				<TOKEN id="token-1-4" start_char="201" end_char="205">those</TOKEN>
				<TOKEN id="token-1-5" start_char="207" end_char="214">surveyed</TOKEN>
				<TOKEN id="token-1-6" start_char="216" end_char="219">said</TOKEN>
				<TOKEN id="token-1-7" start_char="221" end_char="223">the</TOKEN>
				<TOKEN id="token-1-8" start_char="225" end_char="229">virus</TOKEN>
				<TOKEN id="token-1-9" start_char="231" end_char="233">was</TOKEN>
				<TOKEN id="token-1-10" start_char="235" end_char="235">&quot;</TOKEN>
				<TOKEN id="token-1-11" start_char="236" end_char="239">most</TOKEN>
				<TOKEN id="token-1-12" start_char="241" end_char="246">likely</TOKEN>
				<TOKEN id="token-1-13" start_char="247" end_char="247">&quot;</TOKEN>
				<TOKEN id="token-1-14" start_char="249" end_char="252">made</TOKEN>
				<TOKEN id="token-1-15" start_char="254" end_char="255">in</TOKEN>
				<TOKEN id="token-1-16" start_char="257" end_char="257">a</TOKEN>
				<TOKEN id="token-1-17" start_char="259" end_char="261">lab</TOKEN>
				<TOKEN id="token-1-18" start_char="262" end_char="262">,</TOKEN>
				<TOKEN id="token-1-19" start_char="264" end_char="267">with</TOKEN>
				<TOKEN id="token-1-20" start_char="269" end_char="269">a</TOKEN>
				<TOKEN id="token-1-21" start_char="271" end_char="275">large</TOKEN>
				<TOKEN id="token-1-22" start_char="277" end_char="281">share</TOKEN>
				<TOKEN id="token-1-23" start_char="283" end_char="284">of</TOKEN>
				<TOKEN id="token-1-24" start_char="286" end_char="289">that</TOKEN>
				<TOKEN id="token-1-25" start_char="291" end_char="295">group</TOKEN>
				<TOKEN id="token-1-26" start_char="297" end_char="297">(</TOKEN>
				<TOKEN id="token-1-27" start_char="298" end_char="299">23</TOKEN>
				<TOKEN id="token-1-28" start_char="300" end_char="301">%)</TOKEN>
				<TOKEN id="token-1-29" start_char="303" end_char="308">saying</TOKEN>
				<TOKEN id="token-1-30" start_char="310" end_char="311">it</TOKEN>
				<TOKEN id="token-1-31" start_char="313" end_char="315">was</TOKEN>
				<TOKEN id="token-1-32" start_char="317" end_char="320">done</TOKEN>
				<TOKEN id="token-1-33" start_char="322" end_char="323">so</TOKEN>
				<TOKEN id="token-1-34" start_char="325" end_char="337">intentionally</TOKEN>
				<TOKEN id="token-1-35" start_char="338" end_char="338">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-2" start_char="340" end_char="460">
				<ORIGINAL_TEXT>Only 6% of respondents said the coronavirus was created accidentally, while 43% said it most likely came about naturally.</ORIGINAL_TEXT>
				<TOKEN id="token-2-0" start_char="340" end_char="343">Only</TOKEN>
				<TOKEN id="token-2-1" start_char="345" end_char="345">6</TOKEN>
				<TOKEN id="token-2-2" start_char="346" end_char="346">%</TOKEN>
				<TOKEN id="token-2-3" start_char="348" end_char="349">of</TOKEN>
				<TOKEN id="token-2-4" start_char="351" end_char="361">respondents</TOKEN>
				<TOKEN id="token-2-5" start_char="363" end_char="366">said</TOKEN>
				<TOKEN id="token-2-6" start_char="368" end_char="370">the</TOKEN>
				<TOKEN id="token-2-7" start_char="372" end_char="382">coronavirus</TOKEN>
				<TOKEN id="token-2-8" start_char="384" end_char="386">was</TOKEN>
				<TOKEN id="token-2-9" start_char="388" end_char="394">created</TOKEN>
				<TOKEN id="token-2-10" start_char="396" end_char="407">accidentally</TOKEN>
				<TOKEN id="token-2-11" start_char="408" end_char="408">,</TOKEN>
				<TOKEN id="token-2-12" start_char="410" end_char="414">while</TOKEN>
				<TOKEN id="token-2-13" start_char="416" end_char="417">43</TOKEN>
				<TOKEN id="token-2-14" start_char="418" end_char="418">%</TOKEN>
				<TOKEN id="token-2-15" start_char="420" end_char="423">said</TOKEN>
				<TOKEN id="token-2-16" start_char="425" end_char="426">it</TOKEN>
				<TOKEN id="token-2-17" start_char="428" end_char="431">most</TOKEN>
				<TOKEN id="token-2-18" start_char="433" end_char="438">likely</TOKEN>
				<TOKEN id="token-2-19" start_char="440" end_char="443">came</TOKEN>
				<TOKEN id="token-2-20" start_char="445" end_char="449">about</TOKEN>
				<TOKEN id="token-2-21" start_char="451" end_char="459">naturally</TOKEN>
				<TOKEN id="token-2-22" start_char="460" end_char="460">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-3" start_char="462" end_char="515">
				<ORIGINAL_TEXT>Another quarter of respondents noted they were unsure.</ORIGINAL_TEXT>
				<TOKEN id="token-3-0" start_char="462" end_char="468">Another</TOKEN>
				<TOKEN id="token-3-1" start_char="470" end_char="476">quarter</TOKEN>
				<TOKEN id="token-3-2" start_char="478" end_char="479">of</TOKEN>
				<TOKEN id="token-3-3" start_char="481" end_char="491">respondents</TOKEN>
				<TOKEN id="token-3-4" start_char="493" end_char="497">noted</TOKEN>
				<TOKEN id="token-3-5" start_char="499" end_char="502">they</TOKEN>
				<TOKEN id="token-3-6" start_char="504" end_char="507">were</TOKEN>
				<TOKEN id="token-3-7" start_char="509" end_char="514">unsure</TOKEN>
				<TOKEN id="token-3-8" start_char="515" end_char="515">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-4" start_char="517" end_char="732">
				<ORIGINAL_TEXT>At least one study from March from the Scripps Research Institute found that the novel coronavirus is a product of natural evolution, with there being no evidence that it was created in a lab or otherwise engineered.</ORIGINAL_TEXT>
				<TOKEN id="token-4-0" start_char="517" end_char="518">At</TOKEN>
				<TOKEN id="token-4-1" start_char="520" end_char="524">least</TOKEN>
				<TOKEN id="token-4-2" start_char="526" end_char="528">one</TOKEN>
				<TOKEN id="token-4-3" start_char="530" end_char="534">study</TOKEN>
				<TOKEN id="token-4-4" start_char="536" end_char="539">from</TOKEN>
				<TOKEN id="token-4-5" start_char="541" end_char="545">March</TOKEN>
				<TOKEN id="token-4-6" start_char="547" end_char="550">from</TOKEN>
				<TOKEN id="token-4-7" start_char="552" end_char="554">the</TOKEN>
				<TOKEN id="token-4-8" start_char="556" end_char="562">Scripps</TOKEN>
				<TOKEN id="token-4-9" start_char="564" end_char="571">Research</TOKEN>
				<TOKEN id="token-4-10" start_char="573" end_char="581">Institute</TOKEN>
				<TOKEN id="token-4-11" start_char="583" end_char="587">found</TOKEN>
				<TOKEN id="token-4-12" start_char="589" end_char="592">that</TOKEN>
				<TOKEN id="token-4-13" start_char="594" end_char="596">the</TOKEN>
				<TOKEN id="token-4-14" start_char="598" end_char="602">novel</TOKEN>
				<TOKEN id="token-4-15" start_char="604" end_char="614">coronavirus</TOKEN>
				<TOKEN id="token-4-16" start_char="616" end_char="617">is</TOKEN>
				<TOKEN id="token-4-17" start_char="619" end_char="619">a</TOKEN>
				<TOKEN id="token-4-18" start_char="621" end_char="627">product</TOKEN>
				<TOKEN id="token-4-19" start_char="629" end_char="630">of</TOKEN>
				<TOKEN id="token-4-20" start_char="632" end_char="638">natural</TOKEN>
				<TOKEN id="token-4-21" start_char="640" end_char="648">evolution</TOKEN>
				<TOKEN id="token-4-22" start_char="649" end_char="649">,</TOKEN>
				<TOKEN id="token-4-23" start_char="651" end_char="654">with</TOKEN>
				<TOKEN id="token-4-24" start_char="656" end_char="660">there</TOKEN>
				<TOKEN id="token-4-25" start_char="662" end_char="666">being</TOKEN>
				<TOKEN id="token-4-26" start_char="668" end_char="669">no</TOKEN>
				<TOKEN id="token-4-27" start_char="671" end_char="678">evidence</TOKEN>
				<TOKEN id="token-4-28" start_char="680" end_char="683">that</TOKEN>
				<TOKEN id="token-4-29" start_char="685" end_char="686">it</TOKEN>
				<TOKEN id="token-4-30" start_char="688" end_char="690">was</TOKEN>
				<TOKEN id="token-4-31" start_char="692" end_char="698">created</TOKEN>
				<TOKEN id="token-4-32" start_char="700" end_char="701">in</TOKEN>
				<TOKEN id="token-4-33" start_char="703" end_char="703">a</TOKEN>
				<TOKEN id="token-4-34" start_char="705" end_char="707">lab</TOKEN>
				<TOKEN id="token-4-35" start_char="709" end_char="710">or</TOKEN>
				<TOKEN id="token-4-36" start_char="712" end_char="720">otherwise</TOKEN>
				<TOKEN id="token-4-37" start_char="722" end_char="731">engineered</TOKEN>
				<TOKEN id="token-4-38" start_char="732" end_char="732">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-5" start_char="734" end_char="888">
				<ORIGINAL_TEXT>Globally, there are more than 1.4 million cases of and 83,000 deaths caused by COVID-19, according to the latest data compiled by Johns Hopkins University.</ORIGINAL_TEXT>
				<TOKEN id="token-5-0" start_char="734" end_char="741">Globally</TOKEN>
				<TOKEN id="token-5-1" start_char="742" end_char="742">,</TOKEN>
				<TOKEN id="token-5-2" start_char="744" end_char="748">there</TOKEN>
				<TOKEN id="token-5-3" start_char="750" end_char="752">are</TOKEN>
				<TOKEN id="token-5-4" start_char="754" end_char="757">more</TOKEN>
				<TOKEN id="token-5-5" start_char="759" end_char="762">than</TOKEN>
				<TOKEN id="token-5-6" start_char="764" end_char="764">1</TOKEN>
				<TOKEN id="token-5-7" start_char="765" end_char="765">.</TOKEN>
				<TOKEN id="token-5-8" start_char="766" end_char="766">4</TOKEN>
				<TOKEN id="token-5-9" start_char="768" end_char="774">million</TOKEN>
				<TOKEN id="token-5-10" start_char="776" end_char="780">cases</TOKEN>
				<TOKEN id="token-5-11" start_char="782" end_char="783">of</TOKEN>
				<TOKEN id="token-5-12" start_char="785" end_char="787">and</TOKEN>
				<TOKEN id="token-5-13" start_char="789" end_char="790">83</TOKEN>
				<TOKEN id="token-5-14" start_char="791" end_char="791">,</TOKEN>
				<TOKEN id="token-5-15" start_char="792" end_char="794">000</TOKEN>
				<TOKEN id="token-5-16" start_char="796" end_char="801">deaths</TOKEN>
				<TOKEN id="token-5-17" start_char="803" end_char="808">caused</TOKEN>
				<TOKEN id="token-5-18" start_char="810" end_char="811">by</TOKEN>
				<TOKEN id="token-5-19" start_char="813" end_char="817">COVID</TOKEN>
				<TOKEN id="token-5-20" start_char="818" end_char="818">-</TOKEN>
				<TOKEN id="token-5-21" start_char="819" end_char="820">19</TOKEN>
				<TOKEN id="token-5-22" start_char="821" end_char="821">,</TOKEN>
				<TOKEN id="token-5-23" start_char="823" end_char="831">according</TOKEN>
				<TOKEN id="token-5-24" start_char="833" end_char="834">to</TOKEN>
				<TOKEN id="token-5-25" start_char="836" end_char="838">the</TOKEN>
				<TOKEN id="token-5-26" start_char="840" end_char="845">latest</TOKEN>
				<TOKEN id="token-5-27" start_char="847" end_char="850">data</TOKEN>
				<TOKEN id="token-5-28" start_char="852" end_char="859">compiled</TOKEN>
				<TOKEN id="token-5-29" start_char="861" end_char="862">by</TOKEN>
				<TOKEN id="token-5-30" start_char="864" end_char="868">Johns</TOKEN>
				<TOKEN id="token-5-31" start_char="870" end_char="876">Hopkins</TOKEN>
				<TOKEN id="token-5-32" start_char="878" end_char="887">University</TOKEN>
				<TOKEN id="token-5-33" start_char="888" end_char="888">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-6" start_char="890" end_char="959">
				<ORIGINAL_TEXT>Pew's survey results contain differences between certain demographics.</ORIGINAL_TEXT>
				<TOKEN id="token-6-0" start_char="890" end_char="892">Pew</TOKEN>
				<TOKEN id="token-6-1" start_char="893" end_char="893">'</TOKEN>
				<TOKEN id="token-6-2" start_char="894" end_char="894">s</TOKEN>
				<TOKEN id="token-6-3" start_char="896" end_char="901">survey</TOKEN>
				<TOKEN id="token-6-4" start_char="903" end_char="909">results</TOKEN>
				<TOKEN id="token-6-5" start_char="911" end_char="917">contain</TOKEN>
				<TOKEN id="token-6-6" start_char="919" end_char="929">differences</TOKEN>
				<TOKEN id="token-6-7" start_char="931" end_char="937">between</TOKEN>
				<TOKEN id="token-6-8" start_char="939" end_char="945">certain</TOKEN>
				<TOKEN id="token-6-9" start_char="947" end_char="958">demographics</TOKEN>
				<TOKEN id="token-6-10" start_char="959" end_char="959">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-7" start_char="961" end_char="1106">
				<ORIGINAL_TEXT>Younger adults and those with a high school diploma or a lower education level were more likely to believe that the coronavirus was made in a lab.</ORIGINAL_TEXT>
				<TOKEN id="token-7-0" start_char="961" end_char="967">Younger</TOKEN>
				<TOKEN id="token-7-1" start_char="969" end_char="974">adults</TOKEN>
				<TOKEN id="token-7-2" start_char="976" end_char="978">and</TOKEN>
				<TOKEN id="token-7-3" start_char="980" end_char="984">those</TOKEN>
				<TOKEN id="token-7-4" start_char="986" end_char="989">with</TOKEN>
				<TOKEN id="token-7-5" start_char="991" end_char="991">a</TOKEN>
				<TOKEN id="token-7-6" start_char="993" end_char="996">high</TOKEN>
				<TOKEN id="token-7-7" start_char="998" end_char="1003">school</TOKEN>
				<TOKEN id="token-7-8" start_char="1005" end_char="1011">diploma</TOKEN>
				<TOKEN id="token-7-9" start_char="1013" end_char="1014">or</TOKEN>
				<TOKEN id="token-7-10" start_char="1016" end_char="1016">a</TOKEN>
				<TOKEN id="token-7-11" start_char="1018" end_char="1022">lower</TOKEN>
				<TOKEN id="token-7-12" start_char="1024" end_char="1032">education</TOKEN>
				<TOKEN id="token-7-13" start_char="1034" end_char="1038">level</TOKEN>
				<TOKEN id="token-7-14" start_char="1040" end_char="1043">were</TOKEN>
				<TOKEN id="token-7-15" start_char="1045" end_char="1048">more</TOKEN>
				<TOKEN id="token-7-16" start_char="1050" end_char="1055">likely</TOKEN>
				<TOKEN id="token-7-17" start_char="1057" end_char="1058">to</TOKEN>
				<TOKEN id="token-7-18" start_char="1060" end_char="1066">believe</TOKEN>
				<TOKEN id="token-7-19" start_char="1068" end_char="1071">that</TOKEN>
				<TOKEN id="token-7-20" start_char="1073" end_char="1075">the</TOKEN>
				<TOKEN id="token-7-21" start_char="1077" end_char="1087">coronavirus</TOKEN>
				<TOKEN id="token-7-22" start_char="1089" end_char="1091">was</TOKEN>
				<TOKEN id="token-7-23" start_char="1093" end_char="1096">made</TOKEN>
				<TOKEN id="token-7-24" start_char="1098" end_char="1099">in</TOKEN>
				<TOKEN id="token-7-25" start_char="1101" end_char="1101">a</TOKEN>
				<TOKEN id="token-7-26" start_char="1103" end_char="1105">lab</TOKEN>
				<TOKEN id="token-7-27" start_char="1106" end_char="1106">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-8" start_char="1108" end_char="1205">
				<ORIGINAL_TEXT>Republicans were also more likely than Democrats to say the coronavirus was created by scientists.</ORIGINAL_TEXT>
				<TOKEN id="token-8-0" start_char="1108" end_char="1118">Republicans</TOKEN>
				<TOKEN id="token-8-1" start_char="1120" end_char="1123">were</TOKEN>
				<TOKEN id="token-8-2" start_char="1125" end_char="1128">also</TOKEN>
				<TOKEN id="token-8-3" start_char="1130" end_char="1133">more</TOKEN>
				<TOKEN id="token-8-4" start_char="1135" end_char="1140">likely</TOKEN>
				<TOKEN id="token-8-5" start_char="1142" end_char="1145">than</TOKEN>
				<TOKEN id="token-8-6" start_char="1147" end_char="1155">Democrats</TOKEN>
				<TOKEN id="token-8-7" start_char="1157" end_char="1158">to</TOKEN>
				<TOKEN id="token-8-8" start_char="1160" end_char="1162">say</TOKEN>
				<TOKEN id="token-8-9" start_char="1164" end_char="1166">the</TOKEN>
				<TOKEN id="token-8-10" start_char="1168" end_char="1178">coronavirus</TOKEN>
				<TOKEN id="token-8-11" start_char="1180" end_char="1182">was</TOKEN>
				<TOKEN id="token-8-12" start_char="1184" end_char="1190">created</TOKEN>
				<TOKEN id="token-8-13" start_char="1192" end_char="1193">by</TOKEN>
				<TOKEN id="token-8-14" start_char="1195" end_char="1204">scientists</TOKEN>
				<TOKEN id="token-8-15" start_char="1205" end_char="1205">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-9" start_char="1207" end_char="1270">
				<ORIGINAL_TEXT>The survey also touched on news consumption during the pandemic.</ORIGINAL_TEXT>
				<TOKEN id="token-9-0" start_char="1207" end_char="1209">The</TOKEN>
				<TOKEN id="token-9-1" start_char="1211" end_char="1216">survey</TOKEN>
				<TOKEN id="token-9-2" start_char="1218" end_char="1221">also</TOKEN>
				<TOKEN id="token-9-3" start_char="1223" end_char="1229">touched</TOKEN>
				<TOKEN id="token-9-4" start_char="1231" end_char="1232">on</TOKEN>
				<TOKEN id="token-9-5" start_char="1234" end_char="1237">news</TOKEN>
				<TOKEN id="token-9-6" start_char="1239" end_char="1249">consumption</TOKEN>
				<TOKEN id="token-9-7" start_char="1251" end_char="1256">during</TOKEN>
				<TOKEN id="token-9-8" start_char="1258" end_char="1260">the</TOKEN>
				<TOKEN id="token-9-9" start_char="1262" end_char="1269">pandemic</TOKEN>
				<TOKEN id="token-9-10" start_char="1270" end_char="1270">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-10" start_char="1272" end_char="1419">
				<ORIGINAL_TEXT>Nearly half of respondents (approximately 47%) said they had come across at least some news stories or information that &quot;seemed completely made up.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-10-0" start_char="1272" end_char="1277">Nearly</TOKEN>
				<TOKEN id="token-10-1" start_char="1279" end_char="1282">half</TOKEN>
				<TOKEN id="token-10-2" start_char="1284" end_char="1285">of</TOKEN>
				<TOKEN id="token-10-3" start_char="1287" end_char="1297">respondents</TOKEN>
				<TOKEN id="token-10-4" start_char="1299" end_char="1299">(</TOKEN>
				<TOKEN id="token-10-5" start_char="1300" end_char="1312">approximately</TOKEN>
				<TOKEN id="token-10-6" start_char="1314" end_char="1315">47</TOKEN>
				<TOKEN id="token-10-7" start_char="1316" end_char="1317">%)</TOKEN>
				<TOKEN id="token-10-8" start_char="1319" end_char="1322">said</TOKEN>
				<TOKEN id="token-10-9" start_char="1324" end_char="1327">they</TOKEN>
				<TOKEN id="token-10-10" start_char="1329" end_char="1331">had</TOKEN>
				<TOKEN id="token-10-11" start_char="1333" end_char="1336">come</TOKEN>
				<TOKEN id="token-10-12" start_char="1338" end_char="1343">across</TOKEN>
				<TOKEN id="token-10-13" start_char="1345" end_char="1346">at</TOKEN>
				<TOKEN id="token-10-14" start_char="1348" end_char="1352">least</TOKEN>
				<TOKEN id="token-10-15" start_char="1354" end_char="1357">some</TOKEN>
				<TOKEN id="token-10-16" start_char="1359" end_char="1362">news</TOKEN>
				<TOKEN id="token-10-17" start_char="1364" end_char="1370">stories</TOKEN>
				<TOKEN id="token-10-18" start_char="1372" end_char="1373">or</TOKEN>
				<TOKEN id="token-10-19" start_char="1375" end_char="1385">information</TOKEN>
				<TOKEN id="token-10-20" start_char="1387" end_char="1390">that</TOKEN>
				<TOKEN id="token-10-21" start_char="1392" end_char="1392">&quot;</TOKEN>
				<TOKEN id="token-10-22" start_char="1393" end_char="1398">seemed</TOKEN>
				<TOKEN id="token-10-23" start_char="1400" end_char="1409">completely</TOKEN>
				<TOKEN id="token-10-24" start_char="1411" end_char="1414">made</TOKEN>
				<TOKEN id="token-10-25" start_char="1416" end_char="1417">up</TOKEN>
				<TOKEN id="token-10-26" start_char="1418" end_char="1419">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-11" start_char="1421" end_char="1496">
				<ORIGINAL_TEXT>Of that group, 12% said they had seen &quot;a lot&quot; of examples of misinformation.</ORIGINAL_TEXT>
				<TOKEN id="token-11-0" start_char="1421" end_char="1422">Of</TOKEN>
				<TOKEN id="token-11-1" start_char="1424" end_char="1427">that</TOKEN>
				<TOKEN id="token-11-2" start_char="1429" end_char="1433">group</TOKEN>
				<TOKEN id="token-11-3" start_char="1434" end_char="1434">,</TOKEN>
				<TOKEN id="token-11-4" start_char="1436" end_char="1437">12</TOKEN>
				<TOKEN id="token-11-5" start_char="1438" end_char="1438">%</TOKEN>
				<TOKEN id="token-11-6" start_char="1440" end_char="1443">said</TOKEN>
				<TOKEN id="token-11-7" start_char="1445" end_char="1448">they</TOKEN>
				<TOKEN id="token-11-8" start_char="1450" end_char="1452">had</TOKEN>
				<TOKEN id="token-11-9" start_char="1454" end_char="1457">seen</TOKEN>
				<TOKEN id="token-11-10" start_char="1459" end_char="1459">&quot;</TOKEN>
				<TOKEN id="token-11-11" start_char="1460" end_char="1460">a</TOKEN>
				<TOKEN id="token-11-12" start_char="1462" end_char="1464">lot</TOKEN>
				<TOKEN id="token-11-13" start_char="1465" end_char="1465">&quot;</TOKEN>
				<TOKEN id="token-11-14" start_char="1467" end_char="1468">of</TOKEN>
				<TOKEN id="token-11-15" start_char="1470" end_char="1477">examples</TOKEN>
				<TOKEN id="token-11-16" start_char="1479" end_char="1480">of</TOKEN>
				<TOKEN id="token-11-17" start_char="1482" end_char="1495">misinformation</TOKEN>
				<TOKEN id="token-11-18" start_char="1496" end_char="1496">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-105-12" start_char="1498" end_char="1618">
				<ORIGINAL_TEXT>The Pew survey was conducted March 10-16 and gathered information from 8,914 U.S. adults, with a margin of error of 1.6%.</ORIGINAL_TEXT>
				<TOKEN id="token-12-0" start_char="1498" end_char="1500">The</TOKEN>
				<TOKEN id="token-12-1" start_char="1502" end_char="1504">Pew</TOKEN>
				<TOKEN id="token-12-2" start_char="1506" end_char="1511">survey</TOKEN>
				<TOKEN id="token-12-3" start_char="1513" end_char="1515">was</TOKEN>
				<TOKEN id="token-12-4" start_char="1517" end_char="1525">conducted</TOKEN>
				<TOKEN id="token-12-5" start_char="1527" end_char="1531">March</TOKEN>
				<TOKEN id="token-12-6" start_char="1533" end_char="1534">10</TOKEN>
				<TOKEN id="token-12-7" start_char="1535" end_char="1535">-</TOKEN>
				<TOKEN id="token-12-8" start_char="1536" end_char="1537">16</TOKEN>
				<TOKEN id="token-12-9" start_char="1539" end_char="1541">and</TOKEN>
				<TOKEN id="token-12-10" start_char="1543" end_char="1550">gathered</TOKEN>
				<TOKEN id="token-12-11" start_char="1552" end_char="1562">information</TOKEN>
				<TOKEN id="token-12-12" start_char="1564" end_char="1567">from</TOKEN>
				<TOKEN id="token-12-13" start_char="1569" end_char="1569">8</TOKEN>
				<TOKEN id="token-12-14" start_char="1570" end_char="1570">,</TOKEN>
				<TOKEN id="token-12-15" start_char="1571" end_char="1573">914</TOKEN>
				<TOKEN id="token-12-16" start_char="1575" end_char="1575">U</TOKEN>
				<TOKEN id="token-12-17" start_char="1576" end_char="1576">.</TOKEN>
				<TOKEN id="token-12-18" start_char="1577" end_char="1577">S</TOKEN>
				<TOKEN id="token-12-19" start_char="1578" end_char="1578">.</TOKEN>
				<TOKEN id="token-12-20" start_char="1580" end_char="1585">adults</TOKEN>
				<TOKEN id="token-12-21" start_char="1586" end_char="1586">,</TOKEN>
				<TOKEN id="token-12-22" start_char="1588" end_char="1591">with</TOKEN>
				<TOKEN id="token-12-23" start_char="1593" end_char="1593">a</TOKEN>
				<TOKEN id="token-12-24" start_char="1595" end_char="1600">margin</TOKEN>
				<TOKEN id="token-12-25" start_char="1602" end_char="1603">of</TOKEN>
				<TOKEN id="token-12-26" start_char="1605" end_char="1609">error</TOKEN>
				<TOKEN id="token-12-27" start_char="1611" end_char="1612">of</TOKEN>
				<TOKEN id="token-12-28" start_char="1614" end_char="1614">1</TOKEN>
				<TOKEN id="token-12-29" start_char="1615" end_char="1615">.</TOKEN>
				<TOKEN id="token-12-30" start_char="1616" end_char="1616">6</TOKEN>
				<TOKEN id="token-12-31" start_char="1617" end_char="1618">%.</TOKEN>
			</SEG>
		</TEXT>
	</DOC>
</LCTL_TEXT>
