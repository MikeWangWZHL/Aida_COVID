<?xml version="1.0" encoding="utf-8"?>
<LCTL_TEXT>
	<DOC id="covid19scenario-163">
		<TEXT>
			<SEG id="covid19scenario-163-0" start_char="0" end_char="215">
				<ORIGINAL_TEXT>The Public Health Agency of Canada is denying any connection between the National Microbiology Lab in Winnipeg, two scientists who were escorted out of the building last summer, and the coronavirus outbreak in China.</ORIGINAL_TEXT>
				<TOKEN id="token-0-0" start_char="0" end_char="2">The</TOKEN>
				<TOKEN id="token-0-1" start_char="4" end_char="9">Public</TOKEN>
				<TOKEN id="token-0-2" start_char="11" end_char="16">Health</TOKEN>
				<TOKEN id="token-0-3" start_char="18" end_char="23">Agency</TOKEN>
				<TOKEN id="token-0-4" start_char="25" end_char="26">of</TOKEN>
				<TOKEN id="token-0-5" start_char="28" end_char="33">Canada</TOKEN>
				<TOKEN id="token-0-6" start_char="35" end_char="36">is</TOKEN>
				<TOKEN id="token-0-7" start_char="38" end_char="44">denying</TOKEN>
				<TOKEN id="token-0-8" start_char="46" end_char="48">any</TOKEN>
				<TOKEN id="token-0-9" start_char="50" end_char="59">connection</TOKEN>
				<TOKEN id="token-0-10" start_char="61" end_char="67">between</TOKEN>
				<TOKEN id="token-0-11" start_char="69" end_char="71">the</TOKEN>
				<TOKEN id="token-0-12" start_char="73" end_char="80">National</TOKEN>
				<TOKEN id="token-0-13" start_char="82" end_char="93">Microbiology</TOKEN>
				<TOKEN id="token-0-14" start_char="95" end_char="97">Lab</TOKEN>
				<TOKEN id="token-0-15" start_char="99" end_char="100">in</TOKEN>
				<TOKEN id="token-0-16" start_char="102" end_char="109">Winnipeg</TOKEN>
				<TOKEN id="token-0-17" start_char="110" end_char="110">,</TOKEN>
				<TOKEN id="token-0-18" start_char="112" end_char="114">two</TOKEN>
				<TOKEN id="token-0-19" start_char="116" end_char="125">scientists</TOKEN>
				<TOKEN id="token-0-20" start_char="127" end_char="129">who</TOKEN>
				<TOKEN id="token-0-21" start_char="131" end_char="134">were</TOKEN>
				<TOKEN id="token-0-22" start_char="136" end_char="143">escorted</TOKEN>
				<TOKEN id="token-0-23" start_char="145" end_char="147">out</TOKEN>
				<TOKEN id="token-0-24" start_char="149" end_char="150">of</TOKEN>
				<TOKEN id="token-0-25" start_char="152" end_char="154">the</TOKEN>
				<TOKEN id="token-0-26" start_char="156" end_char="163">building</TOKEN>
				<TOKEN id="token-0-27" start_char="165" end_char="168">last</TOKEN>
				<TOKEN id="token-0-28" start_char="170" end_char="175">summer</TOKEN>
				<TOKEN id="token-0-29" start_char="176" end_char="176">,</TOKEN>
				<TOKEN id="token-0-30" start_char="178" end_char="180">and</TOKEN>
				<TOKEN id="token-0-31" start_char="182" end_char="184">the</TOKEN>
				<TOKEN id="token-0-32" start_char="186" end_char="196">coronavirus</TOKEN>
				<TOKEN id="token-0-33" start_char="198" end_char="205">outbreak</TOKEN>
				<TOKEN id="token-0-34" start_char="207" end_char="208">in</TOKEN>
				<TOKEN id="token-0-35" start_char="210" end_char="214">China</TOKEN>
				<TOKEN id="token-0-36" start_char="215" end_char="215">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-1" start_char="217" end_char="459">
				<ORIGINAL_TEXT>Baseless stories claiming that the two scientists are Chinese spies and that they smuggled the coronavirus to China's only Level 4 lab in Wuhan last year have been spreading on all major social media platforms and on conspiracy theorist blogs.</ORIGINAL_TEXT>
				<TOKEN id="token-1-0" start_char="217" end_char="224">Baseless</TOKEN>
				<TOKEN id="token-1-1" start_char="226" end_char="232">stories</TOKEN>
				<TOKEN id="token-1-2" start_char="234" end_char="241">claiming</TOKEN>
				<TOKEN id="token-1-3" start_char="243" end_char="246">that</TOKEN>
				<TOKEN id="token-1-4" start_char="248" end_char="250">the</TOKEN>
				<TOKEN id="token-1-5" start_char="252" end_char="254">two</TOKEN>
				<TOKEN id="token-1-6" start_char="256" end_char="265">scientists</TOKEN>
				<TOKEN id="token-1-7" start_char="267" end_char="269">are</TOKEN>
				<TOKEN id="token-1-8" start_char="271" end_char="277">Chinese</TOKEN>
				<TOKEN id="token-1-9" start_char="279" end_char="283">spies</TOKEN>
				<TOKEN id="token-1-10" start_char="285" end_char="287">and</TOKEN>
				<TOKEN id="token-1-11" start_char="289" end_char="292">that</TOKEN>
				<TOKEN id="token-1-12" start_char="294" end_char="297">they</TOKEN>
				<TOKEN id="token-1-13" start_char="299" end_char="306">smuggled</TOKEN>
				<TOKEN id="token-1-14" start_char="308" end_char="310">the</TOKEN>
				<TOKEN id="token-1-15" start_char="312" end_char="322">coronavirus</TOKEN>
				<TOKEN id="token-1-16" start_char="324" end_char="325">to</TOKEN>
				<TOKEN id="token-1-17" start_char="327" end_char="331">China</TOKEN>
				<TOKEN id="token-1-18" start_char="332" end_char="332">'</TOKEN>
				<TOKEN id="token-1-19" start_char="333" end_char="333">s</TOKEN>
				<TOKEN id="token-1-20" start_char="335" end_char="338">only</TOKEN>
				<TOKEN id="token-1-21" start_char="340" end_char="344">Level</TOKEN>
				<TOKEN id="token-1-22" start_char="346" end_char="346">4</TOKEN>
				<TOKEN id="token-1-23" start_char="348" end_char="350">lab</TOKEN>
				<TOKEN id="token-1-24" start_char="352" end_char="353">in</TOKEN>
				<TOKEN id="token-1-25" start_char="355" end_char="359">Wuhan</TOKEN>
				<TOKEN id="token-1-26" start_char="361" end_char="364">last</TOKEN>
				<TOKEN id="token-1-27" start_char="366" end_char="369">year</TOKEN>
				<TOKEN id="token-1-28" start_char="371" end_char="374">have</TOKEN>
				<TOKEN id="token-1-29" start_char="376" end_char="379">been</TOKEN>
				<TOKEN id="token-1-30" start_char="381" end_char="389">spreading</TOKEN>
				<TOKEN id="token-1-31" start_char="391" end_char="392">on</TOKEN>
				<TOKEN id="token-1-32" start_char="394" end_char="396">all</TOKEN>
				<TOKEN id="token-1-33" start_char="398" end_char="402">major</TOKEN>
				<TOKEN id="token-1-34" start_char="404" end_char="409">social</TOKEN>
				<TOKEN id="token-1-35" start_char="411" end_char="415">media</TOKEN>
				<TOKEN id="token-1-36" start_char="417" end_char="425">platforms</TOKEN>
				<TOKEN id="token-1-37" start_char="427" end_char="429">and</TOKEN>
				<TOKEN id="token-1-38" start_char="431" end_char="432">on</TOKEN>
				<TOKEN id="token-1-39" start_char="434" end_char="443">conspiracy</TOKEN>
				<TOKEN id="token-1-40" start_char="445" end_char="452">theorist</TOKEN>
				<TOKEN id="token-1-41" start_char="454" end_char="458">blogs</TOKEN>
				<TOKEN id="token-1-42" start_char="459" end_char="459">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-2" start_char="461" end_char="550">
				<ORIGINAL_TEXT>One article from a conspiracy blog was shared more than 6,000 times on Facebook on Monday.</ORIGINAL_TEXT>
				<TOKEN id="token-2-0" start_char="461" end_char="463">One</TOKEN>
				<TOKEN id="token-2-1" start_char="465" end_char="471">article</TOKEN>
				<TOKEN id="token-2-2" start_char="473" end_char="476">from</TOKEN>
				<TOKEN id="token-2-3" start_char="478" end_char="478">a</TOKEN>
				<TOKEN id="token-2-4" start_char="480" end_char="489">conspiracy</TOKEN>
				<TOKEN id="token-2-5" start_char="491" end_char="494">blog</TOKEN>
				<TOKEN id="token-2-6" start_char="496" end_char="498">was</TOKEN>
				<TOKEN id="token-2-7" start_char="500" end_char="505">shared</TOKEN>
				<TOKEN id="token-2-8" start_char="507" end_char="510">more</TOKEN>
				<TOKEN id="token-2-9" start_char="512" end_char="515">than</TOKEN>
				<TOKEN id="token-2-10" start_char="517" end_char="517">6</TOKEN>
				<TOKEN id="token-2-11" start_char="518" end_char="518">,</TOKEN>
				<TOKEN id="token-2-12" start_char="519" end_char="521">000</TOKEN>
				<TOKEN id="token-2-13" start_char="523" end_char="527">times</TOKEN>
				<TOKEN id="token-2-14" start_char="529" end_char="530">on</TOKEN>
				<TOKEN id="token-2-15" start_char="532" end_char="539">Facebook</TOKEN>
				<TOKEN id="token-2-16" start_char="541" end_char="542">on</TOKEN>
				<TOKEN id="token-2-17" start_char="544" end_char="549">Monday</TOKEN>
				<TOKEN id="token-2-18" start_char="550" end_char="550">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-3" start_char="552" end_char="692">
				<ORIGINAL_TEXT>The story even made its way on Chinese-owned social media app TikTok, where a video pushing these claims was watched more than 350,000 times.</ORIGINAL_TEXT>
				<TOKEN id="token-3-0" start_char="552" end_char="554">The</TOKEN>
				<TOKEN id="token-3-1" start_char="556" end_char="560">story</TOKEN>
				<TOKEN id="token-3-2" start_char="562" end_char="565">even</TOKEN>
				<TOKEN id="token-3-3" start_char="567" end_char="570">made</TOKEN>
				<TOKEN id="token-3-4" start_char="572" end_char="574">its</TOKEN>
				<TOKEN id="token-3-5" start_char="576" end_char="578">way</TOKEN>
				<TOKEN id="token-3-6" start_char="580" end_char="581">on</TOKEN>
				<TOKEN id="token-3-7" start_char="583" end_char="589">Chinese</TOKEN>
				<TOKEN id="token-3-8" start_char="590" end_char="590">-</TOKEN>
				<TOKEN id="token-3-9" start_char="591" end_char="595">owned</TOKEN>
				<TOKEN id="token-3-10" start_char="597" end_char="602">social</TOKEN>
				<TOKEN id="token-3-11" start_char="604" end_char="608">media</TOKEN>
				<TOKEN id="token-3-12" start_char="610" end_char="612">app</TOKEN>
				<TOKEN id="token-3-13" start_char="614" end_char="619">TikTok</TOKEN>
				<TOKEN id="token-3-14" start_char="620" end_char="620">,</TOKEN>
				<TOKEN id="token-3-15" start_char="622" end_char="626">where</TOKEN>
				<TOKEN id="token-3-16" start_char="628" end_char="628">a</TOKEN>
				<TOKEN id="token-3-17" start_char="630" end_char="634">video</TOKEN>
				<TOKEN id="token-3-18" start_char="636" end_char="642">pushing</TOKEN>
				<TOKEN id="token-3-19" start_char="644" end_char="648">these</TOKEN>
				<TOKEN id="token-3-20" start_char="650" end_char="655">claims</TOKEN>
				<TOKEN id="token-3-21" start_char="657" end_char="659">was</TOKEN>
				<TOKEN id="token-3-22" start_char="661" end_char="667">watched</TOKEN>
				<TOKEN id="token-3-23" start_char="669" end_char="672">more</TOKEN>
				<TOKEN id="token-3-24" start_char="674" end_char="677">than</TOKEN>
				<TOKEN id="token-3-25" start_char="679" end_char="681">350</TOKEN>
				<TOKEN id="token-3-26" start_char="682" end_char="682">,</TOKEN>
				<TOKEN id="token-3-27" start_char="683" end_char="685">000</TOKEN>
				<TOKEN id="token-3-28" start_char="687" end_char="691">times</TOKEN>
				<TOKEN id="token-3-29" start_char="692" end_char="692">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-4" start_char="694" end_char="927">
				<ORIGINAL_TEXT>&quot;This is misinformation and there is no factual basis for claims being made on social media,&quot; Eric Morrissette, chief of media relations for Health Canada and the Public Health Agency of Canada said in response to queries by CBC News.</ORIGINAL_TEXT>
				<TOKEN id="token-4-0" start_char="694" end_char="694">&quot;</TOKEN>
				<TOKEN id="token-4-1" start_char="695" end_char="698">This</TOKEN>
				<TOKEN id="token-4-2" start_char="700" end_char="701">is</TOKEN>
				<TOKEN id="token-4-3" start_char="703" end_char="716">misinformation</TOKEN>
				<TOKEN id="token-4-4" start_char="718" end_char="720">and</TOKEN>
				<TOKEN id="token-4-5" start_char="722" end_char="726">there</TOKEN>
				<TOKEN id="token-4-6" start_char="728" end_char="729">is</TOKEN>
				<TOKEN id="token-4-7" start_char="731" end_char="732">no</TOKEN>
				<TOKEN id="token-4-8" start_char="734" end_char="740">factual</TOKEN>
				<TOKEN id="token-4-9" start_char="742" end_char="746">basis</TOKEN>
				<TOKEN id="token-4-10" start_char="748" end_char="750">for</TOKEN>
				<TOKEN id="token-4-11" start_char="752" end_char="757">claims</TOKEN>
				<TOKEN id="token-4-12" start_char="759" end_char="763">being</TOKEN>
				<TOKEN id="token-4-13" start_char="765" end_char="768">made</TOKEN>
				<TOKEN id="token-4-14" start_char="770" end_char="771">on</TOKEN>
				<TOKEN id="token-4-15" start_char="773" end_char="778">social</TOKEN>
				<TOKEN id="token-4-16" start_char="780" end_char="784">media</TOKEN>
				<TOKEN id="token-4-17" start_char="785" end_char="786">,&quot;</TOKEN>
				<TOKEN id="token-4-18" start_char="788" end_char="791">Eric</TOKEN>
				<TOKEN id="token-4-19" start_char="793" end_char="803">Morrissette</TOKEN>
				<TOKEN id="token-4-20" start_char="804" end_char="804">,</TOKEN>
				<TOKEN id="token-4-21" start_char="806" end_char="810">chief</TOKEN>
				<TOKEN id="token-4-22" start_char="812" end_char="813">of</TOKEN>
				<TOKEN id="token-4-23" start_char="815" end_char="819">media</TOKEN>
				<TOKEN id="token-4-24" start_char="821" end_char="829">relations</TOKEN>
				<TOKEN id="token-4-25" start_char="831" end_char="833">for</TOKEN>
				<TOKEN id="token-4-26" start_char="835" end_char="840">Health</TOKEN>
				<TOKEN id="token-4-27" start_char="842" end_char="847">Canada</TOKEN>
				<TOKEN id="token-4-28" start_char="849" end_char="851">and</TOKEN>
				<TOKEN id="token-4-29" start_char="853" end_char="855">the</TOKEN>
				<TOKEN id="token-4-30" start_char="857" end_char="862">Public</TOKEN>
				<TOKEN id="token-4-31" start_char="864" end_char="869">Health</TOKEN>
				<TOKEN id="token-4-32" start_char="871" end_char="876">Agency</TOKEN>
				<TOKEN id="token-4-33" start_char="878" end_char="879">of</TOKEN>
				<TOKEN id="token-4-34" start_char="881" end_char="886">Canada</TOKEN>
				<TOKEN id="token-4-35" start_char="888" end_char="891">said</TOKEN>
				<TOKEN id="token-4-36" start_char="893" end_char="894">in</TOKEN>
				<TOKEN id="token-4-37" start_char="896" end_char="903">response</TOKEN>
				<TOKEN id="token-4-38" start_char="905" end_char="906">to</TOKEN>
				<TOKEN id="token-4-39" start_char="908" end_char="914">queries</TOKEN>
				<TOKEN id="token-4-40" start_char="916" end_char="917">by</TOKEN>
				<TOKEN id="token-4-41" start_char="919" end_char="921">CBC</TOKEN>
				<TOKEN id="token-4-42" start_char="923" end_char="926">News</TOKEN>
				<TOKEN id="token-4-43" start_char="927" end_char="927">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-5" start_char="929" end_char="1041">
				<ORIGINAL_TEXT>The conspiracy theory seems to be based on a distorted reading of reporting from CBC News published last summer .</ORIGINAL_TEXT>
				<TOKEN id="token-5-0" start_char="929" end_char="931">The</TOKEN>
				<TOKEN id="token-5-1" start_char="933" end_char="942">conspiracy</TOKEN>
				<TOKEN id="token-5-2" start_char="944" end_char="949">theory</TOKEN>
				<TOKEN id="token-5-3" start_char="951" end_char="955">seems</TOKEN>
				<TOKEN id="token-5-4" start_char="957" end_char="958">to</TOKEN>
				<TOKEN id="token-5-5" start_char="960" end_char="961">be</TOKEN>
				<TOKEN id="token-5-6" start_char="963" end_char="967">based</TOKEN>
				<TOKEN id="token-5-7" start_char="969" end_char="970">on</TOKEN>
				<TOKEN id="token-5-8" start_char="972" end_char="972">a</TOKEN>
				<TOKEN id="token-5-9" start_char="974" end_char="982">distorted</TOKEN>
				<TOKEN id="token-5-10" start_char="984" end_char="990">reading</TOKEN>
				<TOKEN id="token-5-11" start_char="992" end_char="993">of</TOKEN>
				<TOKEN id="token-5-12" start_char="995" end_char="1003">reporting</TOKEN>
				<TOKEN id="token-5-13" start_char="1005" end_char="1008">from</TOKEN>
				<TOKEN id="token-5-14" start_char="1010" end_char="1012">CBC</TOKEN>
				<TOKEN id="token-5-15" start_char="1014" end_char="1017">News</TOKEN>
				<TOKEN id="token-5-16" start_char="1019" end_char="1027">published</TOKEN>
				<TOKEN id="token-5-17" start_char="1029" end_char="1032">last</TOKEN>
				<TOKEN id="token-5-18" start_char="1034" end_char="1039">summer</TOKEN>
				<TOKEN id="token-5-19" start_char="1041" end_char="1041">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-6" start_char="1043" end_char="1296">
				<ORIGINAL_TEXT>One of the first mentions occurred Saturday on Twitter, where businessman Kyle Bass claimed that &quot;a husband and wife Chinese spy team were recently removed from a Level 4 Infectious Disease facility in Canada for sending pathogens to the Wuhan facility.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-6-0" start_char="1043" end_char="1045">One</TOKEN>
				<TOKEN id="token-6-1" start_char="1047" end_char="1048">of</TOKEN>
				<TOKEN id="token-6-2" start_char="1050" end_char="1052">the</TOKEN>
				<TOKEN id="token-6-3" start_char="1054" end_char="1058">first</TOKEN>
				<TOKEN id="token-6-4" start_char="1060" end_char="1067">mentions</TOKEN>
				<TOKEN id="token-6-5" start_char="1069" end_char="1076">occurred</TOKEN>
				<TOKEN id="token-6-6" start_char="1078" end_char="1085">Saturday</TOKEN>
				<TOKEN id="token-6-7" start_char="1087" end_char="1088">on</TOKEN>
				<TOKEN id="token-6-8" start_char="1090" end_char="1096">Twitter</TOKEN>
				<TOKEN id="token-6-9" start_char="1097" end_char="1097">,</TOKEN>
				<TOKEN id="token-6-10" start_char="1099" end_char="1103">where</TOKEN>
				<TOKEN id="token-6-11" start_char="1105" end_char="1115">businessman</TOKEN>
				<TOKEN id="token-6-12" start_char="1117" end_char="1120">Kyle</TOKEN>
				<TOKEN id="token-6-13" start_char="1122" end_char="1125">Bass</TOKEN>
				<TOKEN id="token-6-14" start_char="1127" end_char="1133">claimed</TOKEN>
				<TOKEN id="token-6-15" start_char="1135" end_char="1138">that</TOKEN>
				<TOKEN id="token-6-16" start_char="1140" end_char="1140">&quot;</TOKEN>
				<TOKEN id="token-6-17" start_char="1141" end_char="1141">a</TOKEN>
				<TOKEN id="token-6-18" start_char="1143" end_char="1149">husband</TOKEN>
				<TOKEN id="token-6-19" start_char="1151" end_char="1153">and</TOKEN>
				<TOKEN id="token-6-20" start_char="1155" end_char="1158">wife</TOKEN>
				<TOKEN id="token-6-21" start_char="1160" end_char="1166">Chinese</TOKEN>
				<TOKEN id="token-6-22" start_char="1168" end_char="1170">spy</TOKEN>
				<TOKEN id="token-6-23" start_char="1172" end_char="1175">team</TOKEN>
				<TOKEN id="token-6-24" start_char="1177" end_char="1180">were</TOKEN>
				<TOKEN id="token-6-25" start_char="1182" end_char="1189">recently</TOKEN>
				<TOKEN id="token-6-26" start_char="1191" end_char="1197">removed</TOKEN>
				<TOKEN id="token-6-27" start_char="1199" end_char="1202">from</TOKEN>
				<TOKEN id="token-6-28" start_char="1204" end_char="1204">a</TOKEN>
				<TOKEN id="token-6-29" start_char="1206" end_char="1210">Level</TOKEN>
				<TOKEN id="token-6-30" start_char="1212" end_char="1212">4</TOKEN>
				<TOKEN id="token-6-31" start_char="1214" end_char="1223">Infectious</TOKEN>
				<TOKEN id="token-6-32" start_char="1225" end_char="1231">Disease</TOKEN>
				<TOKEN id="token-6-33" start_char="1233" end_char="1240">facility</TOKEN>
				<TOKEN id="token-6-34" start_char="1242" end_char="1243">in</TOKEN>
				<TOKEN id="token-6-35" start_char="1245" end_char="1250">Canada</TOKEN>
				<TOKEN id="token-6-36" start_char="1252" end_char="1254">for</TOKEN>
				<TOKEN id="token-6-37" start_char="1256" end_char="1262">sending</TOKEN>
				<TOKEN id="token-6-38" start_char="1264" end_char="1272">pathogens</TOKEN>
				<TOKEN id="token-6-39" start_char="1274" end_char="1275">to</TOKEN>
				<TOKEN id="token-6-40" start_char="1277" end_char="1279">the</TOKEN>
				<TOKEN id="token-6-41" start_char="1281" end_char="1285">Wuhan</TOKEN>
				<TOKEN id="token-6-42" start_char="1287" end_char="1294">facility</TOKEN>
				<TOKEN id="token-6-43" start_char="1295" end_char="1296">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-7" start_char="1298" end_char="1440">
				<ORIGINAL_TEXT>This photo of medical staff attending to patients was uploaded to the Weibo social media platform by the Central Hospital of Wuhan on Saturday.</ORIGINAL_TEXT>
				<TOKEN id="token-7-0" start_char="1298" end_char="1301">This</TOKEN>
				<TOKEN id="token-7-1" start_char="1303" end_char="1307">photo</TOKEN>
				<TOKEN id="token-7-2" start_char="1309" end_char="1310">of</TOKEN>
				<TOKEN id="token-7-3" start_char="1312" end_char="1318">medical</TOKEN>
				<TOKEN id="token-7-4" start_char="1320" end_char="1324">staff</TOKEN>
				<TOKEN id="token-7-5" start_char="1326" end_char="1334">attending</TOKEN>
				<TOKEN id="token-7-6" start_char="1336" end_char="1337">to</TOKEN>
				<TOKEN id="token-7-7" start_char="1339" end_char="1346">patients</TOKEN>
				<TOKEN id="token-7-8" start_char="1348" end_char="1350">was</TOKEN>
				<TOKEN id="token-7-9" start_char="1352" end_char="1359">uploaded</TOKEN>
				<TOKEN id="token-7-10" start_char="1361" end_char="1362">to</TOKEN>
				<TOKEN id="token-7-11" start_char="1364" end_char="1366">the</TOKEN>
				<TOKEN id="token-7-12" start_char="1368" end_char="1372">Weibo</TOKEN>
				<TOKEN id="token-7-13" start_char="1374" end_char="1379">social</TOKEN>
				<TOKEN id="token-7-14" start_char="1381" end_char="1385">media</TOKEN>
				<TOKEN id="token-7-15" start_char="1387" end_char="1394">platform</TOKEN>
				<TOKEN id="token-7-16" start_char="1396" end_char="1397">by</TOKEN>
				<TOKEN id="token-7-17" start_char="1399" end_char="1401">the</TOKEN>
				<TOKEN id="token-7-18" start_char="1403" end_char="1409">Central</TOKEN>
				<TOKEN id="token-7-19" start_char="1411" end_char="1418">Hospital</TOKEN>
				<TOKEN id="token-7-20" start_char="1420" end_char="1421">of</TOKEN>
				<TOKEN id="token-7-21" start_char="1423" end_char="1427">Wuhan</TOKEN>
				<TOKEN id="token-7-22" start_char="1429" end_char="1430">on</TOKEN>
				<TOKEN id="token-7-23" start_char="1432" end_char="1439">Saturday</TOKEN>
				<TOKEN id="token-7-24" start_char="1440" end_char="1440">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-8" start_char="1442" end_char="1504">
				<ORIGINAL_TEXT>The city of Wuhan is the epicentre of the coronavirus outbreak.</ORIGINAL_TEXT>
				<TOKEN id="token-8-0" start_char="1442" end_char="1444">The</TOKEN>
				<TOKEN id="token-8-1" start_char="1446" end_char="1449">city</TOKEN>
				<TOKEN id="token-8-2" start_char="1451" end_char="1452">of</TOKEN>
				<TOKEN id="token-8-3" start_char="1454" end_char="1458">Wuhan</TOKEN>
				<TOKEN id="token-8-4" start_char="1460" end_char="1461">is</TOKEN>
				<TOKEN id="token-8-5" start_char="1463" end_char="1465">the</TOKEN>
				<TOKEN id="token-8-6" start_char="1467" end_char="1475">epicentre</TOKEN>
				<TOKEN id="token-8-7" start_char="1477" end_char="1478">of</TOKEN>
				<TOKEN id="token-8-8" start_char="1480" end_char="1482">the</TOKEN>
				<TOKEN id="token-8-9" start_char="1484" end_char="1494">coronavirus</TOKEN>
				<TOKEN id="token-8-10" start_char="1496" end_char="1503">outbreak</TOKEN>
				<TOKEN id="token-8-11" start_char="1504" end_char="1504">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-9" start_char="1506" end_char="1554">
				<ORIGINAL_TEXT>(The Central Hospital of Wuhan via Weibo/Reuters)</ORIGINAL_TEXT>
				<TOKEN id="token-9-0" start_char="1506" end_char="1506">(</TOKEN>
				<TOKEN id="token-9-1" start_char="1507" end_char="1509">The</TOKEN>
				<TOKEN id="token-9-2" start_char="1511" end_char="1517">Central</TOKEN>
				<TOKEN id="token-9-3" start_char="1519" end_char="1526">Hospital</TOKEN>
				<TOKEN id="token-9-4" start_char="1528" end_char="1529">of</TOKEN>
				<TOKEN id="token-9-5" start_char="1531" end_char="1535">Wuhan</TOKEN>
				<TOKEN id="token-9-6" start_char="1537" end_char="1539">via</TOKEN>
				<TOKEN id="token-9-7" start_char="1541" end_char="1545">Weibo</TOKEN>
				<TOKEN id="token-9-8" start_char="1546" end_char="1546">/</TOKEN>
				<TOKEN id="token-9-9" start_char="1547" end_char="1553">Reuters</TOKEN>
				<TOKEN id="token-9-10" start_char="1554" end_char="1554">)</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-10" start_char="1556" end_char="1911">
				<ORIGINAL_TEXT>In the tweet, which was shared over 12,000 times, he linked to a story CBC News broke in July, revealing that a researcher, her husband, and some of their graduate students, were escorted out of the National Microbiology Lab (NML) in Winnipeg amid an RCMP investigation into what's being described as a possible &quot;policy breach&quot; and &quot;administrative matter.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-10-0" start_char="1556" end_char="1557">In</TOKEN>
				<TOKEN id="token-10-1" start_char="1559" end_char="1561">the</TOKEN>
				<TOKEN id="token-10-2" start_char="1563" end_char="1567">tweet</TOKEN>
				<TOKEN id="token-10-3" start_char="1568" end_char="1568">,</TOKEN>
				<TOKEN id="token-10-4" start_char="1570" end_char="1574">which</TOKEN>
				<TOKEN id="token-10-5" start_char="1576" end_char="1578">was</TOKEN>
				<TOKEN id="token-10-6" start_char="1580" end_char="1585">shared</TOKEN>
				<TOKEN id="token-10-7" start_char="1587" end_char="1590">over</TOKEN>
				<TOKEN id="token-10-8" start_char="1592" end_char="1593">12</TOKEN>
				<TOKEN id="token-10-9" start_char="1594" end_char="1594">,</TOKEN>
				<TOKEN id="token-10-10" start_char="1595" end_char="1597">000</TOKEN>
				<TOKEN id="token-10-11" start_char="1599" end_char="1603">times</TOKEN>
				<TOKEN id="token-10-12" start_char="1604" end_char="1604">,</TOKEN>
				<TOKEN id="token-10-13" start_char="1606" end_char="1607">he</TOKEN>
				<TOKEN id="token-10-14" start_char="1609" end_char="1614">linked</TOKEN>
				<TOKEN id="token-10-15" start_char="1616" end_char="1617">to</TOKEN>
				<TOKEN id="token-10-16" start_char="1619" end_char="1619">a</TOKEN>
				<TOKEN id="token-10-17" start_char="1621" end_char="1625">story</TOKEN>
				<TOKEN id="token-10-18" start_char="1627" end_char="1629">CBC</TOKEN>
				<TOKEN id="token-10-19" start_char="1631" end_char="1634">News</TOKEN>
				<TOKEN id="token-10-20" start_char="1636" end_char="1640">broke</TOKEN>
				<TOKEN id="token-10-21" start_char="1642" end_char="1643">in</TOKEN>
				<TOKEN id="token-10-22" start_char="1645" end_char="1648">July</TOKEN>
				<TOKEN id="token-10-23" start_char="1649" end_char="1649">,</TOKEN>
				<TOKEN id="token-10-24" start_char="1651" end_char="1659">revealing</TOKEN>
				<TOKEN id="token-10-25" start_char="1661" end_char="1664">that</TOKEN>
				<TOKEN id="token-10-26" start_char="1666" end_char="1666">a</TOKEN>
				<TOKEN id="token-10-27" start_char="1668" end_char="1677">researcher</TOKEN>
				<TOKEN id="token-10-28" start_char="1678" end_char="1678">,</TOKEN>
				<TOKEN id="token-10-29" start_char="1680" end_char="1682">her</TOKEN>
				<TOKEN id="token-10-30" start_char="1684" end_char="1690">husband</TOKEN>
				<TOKEN id="token-10-31" start_char="1691" end_char="1691">,</TOKEN>
				<TOKEN id="token-10-32" start_char="1693" end_char="1695">and</TOKEN>
				<TOKEN id="token-10-33" start_char="1697" end_char="1700">some</TOKEN>
				<TOKEN id="token-10-34" start_char="1702" end_char="1703">of</TOKEN>
				<TOKEN id="token-10-35" start_char="1705" end_char="1709">their</TOKEN>
				<TOKEN id="token-10-36" start_char="1711" end_char="1718">graduate</TOKEN>
				<TOKEN id="token-10-37" start_char="1720" end_char="1727">students</TOKEN>
				<TOKEN id="token-10-38" start_char="1728" end_char="1728">,</TOKEN>
				<TOKEN id="token-10-39" start_char="1730" end_char="1733">were</TOKEN>
				<TOKEN id="token-10-40" start_char="1735" end_char="1742">escorted</TOKEN>
				<TOKEN id="token-10-41" start_char="1744" end_char="1746">out</TOKEN>
				<TOKEN id="token-10-42" start_char="1748" end_char="1749">of</TOKEN>
				<TOKEN id="token-10-43" start_char="1751" end_char="1753">the</TOKEN>
				<TOKEN id="token-10-44" start_char="1755" end_char="1762">National</TOKEN>
				<TOKEN id="token-10-45" start_char="1764" end_char="1775">Microbiology</TOKEN>
				<TOKEN id="token-10-46" start_char="1777" end_char="1779">Lab</TOKEN>
				<TOKEN id="token-10-47" start_char="1781" end_char="1781">(</TOKEN>
				<TOKEN id="token-10-48" start_char="1782" end_char="1784">NML</TOKEN>
				<TOKEN id="token-10-49" start_char="1785" end_char="1785">)</TOKEN>
				<TOKEN id="token-10-50" start_char="1787" end_char="1788">in</TOKEN>
				<TOKEN id="token-10-51" start_char="1790" end_char="1797">Winnipeg</TOKEN>
				<TOKEN id="token-10-52" start_char="1799" end_char="1802">amid</TOKEN>
				<TOKEN id="token-10-53" start_char="1804" end_char="1805">an</TOKEN>
				<TOKEN id="token-10-54" start_char="1807" end_char="1810">RCMP</TOKEN>
				<TOKEN id="token-10-55" start_char="1812" end_char="1824">investigation</TOKEN>
				<TOKEN id="token-10-56" start_char="1826" end_char="1829">into</TOKEN>
				<TOKEN id="token-10-57" start_char="1831" end_char="1834">what</TOKEN>
				<TOKEN id="token-10-58" start_char="1835" end_char="1835">'</TOKEN>
				<TOKEN id="token-10-59" start_char="1836" end_char="1836">s</TOKEN>
				<TOKEN id="token-10-60" start_char="1838" end_char="1842">being</TOKEN>
				<TOKEN id="token-10-61" start_char="1844" end_char="1852">described</TOKEN>
				<TOKEN id="token-10-62" start_char="1854" end_char="1855">as</TOKEN>
				<TOKEN id="token-10-63" start_char="1857" end_char="1857">a</TOKEN>
				<TOKEN id="token-10-64" start_char="1859" end_char="1866">possible</TOKEN>
				<TOKEN id="token-10-65" start_char="1868" end_char="1868">&quot;</TOKEN>
				<TOKEN id="token-10-66" start_char="1869" end_char="1874">policy</TOKEN>
				<TOKEN id="token-10-67" start_char="1876" end_char="1881">breach</TOKEN>
				<TOKEN id="token-10-68" start_char="1882" end_char="1882">&quot;</TOKEN>
				<TOKEN id="token-10-69" start_char="1884" end_char="1886">and</TOKEN>
				<TOKEN id="token-10-70" start_char="1888" end_char="1888">&quot;</TOKEN>
				<TOKEN id="token-10-71" start_char="1889" end_char="1902">administrative</TOKEN>
				<TOKEN id="token-10-72" start_char="1904" end_char="1909">matter</TOKEN>
				<TOKEN id="token-10-73" start_char="1910" end_char="1911">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-11" start_char="1913" end_char="2001">
				<ORIGINAL_TEXT>The RCMP and Health Canada have both stressed that there was no danger for public safety.</ORIGINAL_TEXT>
				<TOKEN id="token-11-0" start_char="1913" end_char="1915">The</TOKEN>
				<TOKEN id="token-11-1" start_char="1917" end_char="1920">RCMP</TOKEN>
				<TOKEN id="token-11-2" start_char="1922" end_char="1924">and</TOKEN>
				<TOKEN id="token-11-3" start_char="1926" end_char="1931">Health</TOKEN>
				<TOKEN id="token-11-4" start_char="1933" end_char="1938">Canada</TOKEN>
				<TOKEN id="token-11-5" start_char="1940" end_char="1943">have</TOKEN>
				<TOKEN id="token-11-6" start_char="1945" end_char="1948">both</TOKEN>
				<TOKEN id="token-11-7" start_char="1950" end_char="1957">stressed</TOKEN>
				<TOKEN id="token-11-8" start_char="1959" end_char="1962">that</TOKEN>
				<TOKEN id="token-11-9" start_char="1964" end_char="1968">there</TOKEN>
				<TOKEN id="token-11-10" start_char="1970" end_char="1972">was</TOKEN>
				<TOKEN id="token-11-11" start_char="1974" end_char="1975">no</TOKEN>
				<TOKEN id="token-11-12" start_char="1977" end_char="1982">danger</TOKEN>
				<TOKEN id="token-11-13" start_char="1984" end_char="1986">for</TOKEN>
				<TOKEN id="token-11-14" start_char="1988" end_char="1993">public</TOKEN>
				<TOKEN id="token-11-15" start_char="1995" end_char="2000">safety</TOKEN>
				<TOKEN id="token-11-16" start_char="2001" end_char="2001">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-12" start_char="2003" end_char="2133">
				<ORIGINAL_TEXT>CBC reporting never claimed the two scientists were spies, or that they brought any version of the coronavirus to the lab in Wuhan.</ORIGINAL_TEXT>
				<TOKEN id="token-12-0" start_char="2003" end_char="2005">CBC</TOKEN>
				<TOKEN id="token-12-1" start_char="2007" end_char="2015">reporting</TOKEN>
				<TOKEN id="token-12-2" start_char="2017" end_char="2021">never</TOKEN>
				<TOKEN id="token-12-3" start_char="2023" end_char="2029">claimed</TOKEN>
				<TOKEN id="token-12-4" start_char="2031" end_char="2033">the</TOKEN>
				<TOKEN id="token-12-5" start_char="2035" end_char="2037">two</TOKEN>
				<TOKEN id="token-12-6" start_char="2039" end_char="2048">scientists</TOKEN>
				<TOKEN id="token-12-7" start_char="2050" end_char="2053">were</TOKEN>
				<TOKEN id="token-12-8" start_char="2055" end_char="2059">spies</TOKEN>
				<TOKEN id="token-12-9" start_char="2060" end_char="2060">,</TOKEN>
				<TOKEN id="token-12-10" start_char="2062" end_char="2063">or</TOKEN>
				<TOKEN id="token-12-11" start_char="2065" end_char="2068">that</TOKEN>
				<TOKEN id="token-12-12" start_char="2070" end_char="2073">they</TOKEN>
				<TOKEN id="token-12-13" start_char="2075" end_char="2081">brought</TOKEN>
				<TOKEN id="token-12-14" start_char="2083" end_char="2085">any</TOKEN>
				<TOKEN id="token-12-15" start_char="2087" end_char="2093">version</TOKEN>
				<TOKEN id="token-12-16" start_char="2095" end_char="2096">of</TOKEN>
				<TOKEN id="token-12-17" start_char="2098" end_char="2100">the</TOKEN>
				<TOKEN id="token-12-18" start_char="2102" end_char="2112">coronavirus</TOKEN>
				<TOKEN id="token-12-19" start_char="2114" end_char="2115">to</TOKEN>
				<TOKEN id="token-12-20" start_char="2117" end_char="2119">the</TOKEN>
				<TOKEN id="token-12-21" start_char="2121" end_char="2123">lab</TOKEN>
				<TOKEN id="token-12-22" start_char="2125" end_char="2126">in</TOKEN>
				<TOKEN id="token-12-23" start_char="2128" end_char="2132">Wuhan</TOKEN>
				<TOKEN id="token-12-24" start_char="2133" end_char="2133">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-13" start_char="2135" end_char="2201">
				<ORIGINAL_TEXT>Experts say the disinformation is creating a &quot;social panic&quot; online.</ORIGINAL_TEXT>
				<TOKEN id="token-13-0" start_char="2135" end_char="2141">Experts</TOKEN>
				<TOKEN id="token-13-1" start_char="2143" end_char="2145">say</TOKEN>
				<TOKEN id="token-13-2" start_char="2147" end_char="2149">the</TOKEN>
				<TOKEN id="token-13-3" start_char="2151" end_char="2164">disinformation</TOKEN>
				<TOKEN id="token-13-4" start_char="2166" end_char="2167">is</TOKEN>
				<TOKEN id="token-13-5" start_char="2169" end_char="2176">creating</TOKEN>
				<TOKEN id="token-13-6" start_char="2178" end_char="2178">a</TOKEN>
				<TOKEN id="token-13-7" start_char="2180" end_char="2180">&quot;</TOKEN>
				<TOKEN id="token-13-8" start_char="2181" end_char="2186">social</TOKEN>
				<TOKEN id="token-13-9" start_char="2188" end_char="2192">panic</TOKEN>
				<TOKEN id="token-13-10" start_char="2193" end_char="2193">&quot;</TOKEN>
				<TOKEN id="token-13-11" start_char="2195" end_char="2200">online</TOKEN>
				<TOKEN id="token-13-12" start_char="2201" end_char="2201">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-14" start_char="2203" end_char="2582">
				<ORIGINAL_TEXT>&quot;We've seen already on Twitter and Reddit and other platforms that there have been calls to ban travellers from China from entering North American or Europe — that there have been individuals targeted to be supposedly pulled off flights or stopped at the Canadian border or the U.S. border,&quot; says Fuyuki Kurasawa, director of the Global Digital Citizenship Lab at York University.</ORIGINAL_TEXT>
				<TOKEN id="token-14-0" start_char="2203" end_char="2203">&quot;</TOKEN>
				<TOKEN id="token-14-1" start_char="2204" end_char="2205">We</TOKEN>
				<TOKEN id="token-14-2" start_char="2206" end_char="2206">'</TOKEN>
				<TOKEN id="token-14-3" start_char="2207" end_char="2208">ve</TOKEN>
				<TOKEN id="token-14-4" start_char="2210" end_char="2213">seen</TOKEN>
				<TOKEN id="token-14-5" start_char="2215" end_char="2221">already</TOKEN>
				<TOKEN id="token-14-6" start_char="2223" end_char="2224">on</TOKEN>
				<TOKEN id="token-14-7" start_char="2226" end_char="2232">Twitter</TOKEN>
				<TOKEN id="token-14-8" start_char="2234" end_char="2236">and</TOKEN>
				<TOKEN id="token-14-9" start_char="2238" end_char="2243">Reddit</TOKEN>
				<TOKEN id="token-14-10" start_char="2245" end_char="2247">and</TOKEN>
				<TOKEN id="token-14-11" start_char="2249" end_char="2253">other</TOKEN>
				<TOKEN id="token-14-12" start_char="2255" end_char="2263">platforms</TOKEN>
				<TOKEN id="token-14-13" start_char="2265" end_char="2268">that</TOKEN>
				<TOKEN id="token-14-14" start_char="2270" end_char="2274">there</TOKEN>
				<TOKEN id="token-14-15" start_char="2276" end_char="2279">have</TOKEN>
				<TOKEN id="token-14-16" start_char="2281" end_char="2284">been</TOKEN>
				<TOKEN id="token-14-17" start_char="2286" end_char="2290">calls</TOKEN>
				<TOKEN id="token-14-18" start_char="2292" end_char="2293">to</TOKEN>
				<TOKEN id="token-14-19" start_char="2295" end_char="2297">ban</TOKEN>
				<TOKEN id="token-14-20" start_char="2299" end_char="2308">travellers</TOKEN>
				<TOKEN id="token-14-21" start_char="2310" end_char="2313">from</TOKEN>
				<TOKEN id="token-14-22" start_char="2315" end_char="2319">China</TOKEN>
				<TOKEN id="token-14-23" start_char="2321" end_char="2324">from</TOKEN>
				<TOKEN id="token-14-24" start_char="2326" end_char="2333">entering</TOKEN>
				<TOKEN id="token-14-25" start_char="2335" end_char="2339">North</TOKEN>
				<TOKEN id="token-14-26" start_char="2341" end_char="2348">American</TOKEN>
				<TOKEN id="token-14-27" start_char="2350" end_char="2351">or</TOKEN>
				<TOKEN id="token-14-28" start_char="2353" end_char="2358">Europe</TOKEN>
				<TOKEN id="token-14-29" start_char="2360" end_char="2360">—</TOKEN>
				<TOKEN id="token-14-30" start_char="2362" end_char="2365">that</TOKEN>
				<TOKEN id="token-14-31" start_char="2367" end_char="2371">there</TOKEN>
				<TOKEN id="token-14-32" start_char="2373" end_char="2376">have</TOKEN>
				<TOKEN id="token-14-33" start_char="2378" end_char="2381">been</TOKEN>
				<TOKEN id="token-14-34" start_char="2383" end_char="2393">individuals</TOKEN>
				<TOKEN id="token-14-35" start_char="2395" end_char="2402">targeted</TOKEN>
				<TOKEN id="token-14-36" start_char="2404" end_char="2405">to</TOKEN>
				<TOKEN id="token-14-37" start_char="2407" end_char="2408">be</TOKEN>
				<TOKEN id="token-14-38" start_char="2410" end_char="2419">supposedly</TOKEN>
				<TOKEN id="token-14-39" start_char="2421" end_char="2426">pulled</TOKEN>
				<TOKEN id="token-14-40" start_char="2428" end_char="2430">off</TOKEN>
				<TOKEN id="token-14-41" start_char="2432" end_char="2438">flights</TOKEN>
				<TOKEN id="token-14-42" start_char="2440" end_char="2441">or</TOKEN>
				<TOKEN id="token-14-43" start_char="2443" end_char="2449">stopped</TOKEN>
				<TOKEN id="token-14-44" start_char="2451" end_char="2452">at</TOKEN>
				<TOKEN id="token-14-45" start_char="2454" end_char="2456">the</TOKEN>
				<TOKEN id="token-14-46" start_char="2458" end_char="2465">Canadian</TOKEN>
				<TOKEN id="token-14-47" start_char="2467" end_char="2472">border</TOKEN>
				<TOKEN id="token-14-48" start_char="2474" end_char="2475">or</TOKEN>
				<TOKEN id="token-14-49" start_char="2477" end_char="2479">the</TOKEN>
				<TOKEN id="token-14-50" start_char="2481" end_char="2481">U</TOKEN>
				<TOKEN id="token-14-51" start_char="2482" end_char="2482">.</TOKEN>
				<TOKEN id="token-14-52" start_char="2483" end_char="2483">S</TOKEN>
				<TOKEN id="token-14-53" start_char="2484" end_char="2484">.</TOKEN>
				<TOKEN id="token-14-54" start_char="2486" end_char="2491">border</TOKEN>
				<TOKEN id="token-14-55" start_char="2492" end_char="2493">,&quot;</TOKEN>
				<TOKEN id="token-14-56" start_char="2495" end_char="2498">says</TOKEN>
				<TOKEN id="token-14-57" start_char="2500" end_char="2505">Fuyuki</TOKEN>
				<TOKEN id="token-14-58" start_char="2507" end_char="2514">Kurasawa</TOKEN>
				<TOKEN id="token-14-59" start_char="2515" end_char="2515">,</TOKEN>
				<TOKEN id="token-14-60" start_char="2517" end_char="2524">director</TOKEN>
				<TOKEN id="token-14-61" start_char="2526" end_char="2527">of</TOKEN>
				<TOKEN id="token-14-62" start_char="2529" end_char="2531">the</TOKEN>
				<TOKEN id="token-14-63" start_char="2533" end_char="2538">Global</TOKEN>
				<TOKEN id="token-14-64" start_char="2540" end_char="2546">Digital</TOKEN>
				<TOKEN id="token-14-65" start_char="2548" end_char="2558">Citizenship</TOKEN>
				<TOKEN id="token-14-66" start_char="2560" end_char="2562">Lab</TOKEN>
				<TOKEN id="token-14-67" start_char="2564" end_char="2565">at</TOKEN>
				<TOKEN id="token-14-68" start_char="2567" end_char="2570">York</TOKEN>
				<TOKEN id="token-14-69" start_char="2572" end_char="2581">University</TOKEN>
				<TOKEN id="token-14-70" start_char="2582" end_char="2582">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-15" start_char="2584" end_char="2917">
				<ORIGINAL_TEXT>&quot;The broader damage is that there grows a mistrust toward both government authorities, public health officials, the media, authoritative sources of media, and there there becomes a social media environment where speculation, rumour and conspiracy theories take over and wash out the factual information that is being promoted online.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-15-0" start_char="2584" end_char="2584">&quot;</TOKEN>
				<TOKEN id="token-15-1" start_char="2585" end_char="2587">The</TOKEN>
				<TOKEN id="token-15-2" start_char="2589" end_char="2595">broader</TOKEN>
				<TOKEN id="token-15-3" start_char="2597" end_char="2602">damage</TOKEN>
				<TOKEN id="token-15-4" start_char="2604" end_char="2605">is</TOKEN>
				<TOKEN id="token-15-5" start_char="2607" end_char="2610">that</TOKEN>
				<TOKEN id="token-15-6" start_char="2612" end_char="2616">there</TOKEN>
				<TOKEN id="token-15-7" start_char="2618" end_char="2622">grows</TOKEN>
				<TOKEN id="token-15-8" start_char="2624" end_char="2624">a</TOKEN>
				<TOKEN id="token-15-9" start_char="2626" end_char="2633">mistrust</TOKEN>
				<TOKEN id="token-15-10" start_char="2635" end_char="2640">toward</TOKEN>
				<TOKEN id="token-15-11" start_char="2642" end_char="2645">both</TOKEN>
				<TOKEN id="token-15-12" start_char="2647" end_char="2656">government</TOKEN>
				<TOKEN id="token-15-13" start_char="2658" end_char="2668">authorities</TOKEN>
				<TOKEN id="token-15-14" start_char="2669" end_char="2669">,</TOKEN>
				<TOKEN id="token-15-15" start_char="2671" end_char="2676">public</TOKEN>
				<TOKEN id="token-15-16" start_char="2678" end_char="2683">health</TOKEN>
				<TOKEN id="token-15-17" start_char="2685" end_char="2693">officials</TOKEN>
				<TOKEN id="token-15-18" start_char="2694" end_char="2694">,</TOKEN>
				<TOKEN id="token-15-19" start_char="2696" end_char="2698">the</TOKEN>
				<TOKEN id="token-15-20" start_char="2700" end_char="2704">media</TOKEN>
				<TOKEN id="token-15-21" start_char="2705" end_char="2705">,</TOKEN>
				<TOKEN id="token-15-22" start_char="2707" end_char="2719">authoritative</TOKEN>
				<TOKEN id="token-15-23" start_char="2721" end_char="2727">sources</TOKEN>
				<TOKEN id="token-15-24" start_char="2729" end_char="2730">of</TOKEN>
				<TOKEN id="token-15-25" start_char="2732" end_char="2736">media</TOKEN>
				<TOKEN id="token-15-26" start_char="2737" end_char="2737">,</TOKEN>
				<TOKEN id="token-15-27" start_char="2739" end_char="2741">and</TOKEN>
				<TOKEN id="token-15-28" start_char="2743" end_char="2747">there</TOKEN>
				<TOKEN id="token-15-29" start_char="2749" end_char="2753">there</TOKEN>
				<TOKEN id="token-15-30" start_char="2755" end_char="2761">becomes</TOKEN>
				<TOKEN id="token-15-31" start_char="2763" end_char="2763">a</TOKEN>
				<TOKEN id="token-15-32" start_char="2765" end_char="2770">social</TOKEN>
				<TOKEN id="token-15-33" start_char="2772" end_char="2776">media</TOKEN>
				<TOKEN id="token-15-34" start_char="2778" end_char="2788">environment</TOKEN>
				<TOKEN id="token-15-35" start_char="2790" end_char="2794">where</TOKEN>
				<TOKEN id="token-15-36" start_char="2796" end_char="2806">speculation</TOKEN>
				<TOKEN id="token-15-37" start_char="2807" end_char="2807">,</TOKEN>
				<TOKEN id="token-15-38" start_char="2809" end_char="2814">rumour</TOKEN>
				<TOKEN id="token-15-39" start_char="2816" end_char="2818">and</TOKEN>
				<TOKEN id="token-15-40" start_char="2820" end_char="2829">conspiracy</TOKEN>
				<TOKEN id="token-15-41" start_char="2831" end_char="2838">theories</TOKEN>
				<TOKEN id="token-15-42" start_char="2840" end_char="2843">take</TOKEN>
				<TOKEN id="token-15-43" start_char="2845" end_char="2848">over</TOKEN>
				<TOKEN id="token-15-44" start_char="2850" end_char="2852">and</TOKEN>
				<TOKEN id="token-15-45" start_char="2854" end_char="2857">wash</TOKEN>
				<TOKEN id="token-15-46" start_char="2859" end_char="2861">out</TOKEN>
				<TOKEN id="token-15-47" start_char="2863" end_char="2865">the</TOKEN>
				<TOKEN id="token-15-48" start_char="2867" end_char="2873">factual</TOKEN>
				<TOKEN id="token-15-49" start_char="2875" end_char="2885">information</TOKEN>
				<TOKEN id="token-15-50" start_char="2887" end_char="2890">that</TOKEN>
				<TOKEN id="token-15-51" start_char="2892" end_char="2893">is</TOKEN>
				<TOKEN id="token-15-52" start_char="2895" end_char="2899">being</TOKEN>
				<TOKEN id="token-15-53" start_char="2901" end_char="2908">promoted</TOKEN>
				<TOKEN id="token-15-54" start_char="2910" end_char="2915">online</TOKEN>
				<TOKEN id="token-15-55" start_char="2916" end_char="2917">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-16" start_char="2919" end_char="2997">
				<ORIGINAL_TEXT>Kurasawa is already seeing that spread from the online world to the real world.</ORIGINAL_TEXT>
				<TOKEN id="token-16-0" start_char="2919" end_char="2926">Kurasawa</TOKEN>
				<TOKEN id="token-16-1" start_char="2928" end_char="2929">is</TOKEN>
				<TOKEN id="token-16-2" start_char="2931" end_char="2937">already</TOKEN>
				<TOKEN id="token-16-3" start_char="2939" end_char="2944">seeing</TOKEN>
				<TOKEN id="token-16-4" start_char="2946" end_char="2949">that</TOKEN>
				<TOKEN id="token-16-5" start_char="2951" end_char="2956">spread</TOKEN>
				<TOKEN id="token-16-6" start_char="2958" end_char="2961">from</TOKEN>
				<TOKEN id="token-16-7" start_char="2963" end_char="2965">the</TOKEN>
				<TOKEN id="token-16-8" start_char="2967" end_char="2972">online</TOKEN>
				<TOKEN id="token-16-9" start_char="2974" end_char="2978">world</TOKEN>
				<TOKEN id="token-16-10" start_char="2980" end_char="2981">to</TOKEN>
				<TOKEN id="token-16-11" start_char="2983" end_char="2985">the</TOKEN>
				<TOKEN id="token-16-12" start_char="2987" end_char="2990">real</TOKEN>
				<TOKEN id="token-16-13" start_char="2992" end_char="2996">world</TOKEN>
				<TOKEN id="token-16-14" start_char="2997" end_char="2997">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-17" start_char="2999" end_char="3376">
				<ORIGINAL_TEXT>&quot;Individuals will take it on themselves to become vigilantes, where they'll try to spot someone who supposedly is either holding the truth about some hidden truth about the coronavirus or a person who may be a carrier or supposed carrier of the virus because they appear to have certain symptoms, and then they'll ask the general public to take matters into own hands,&quot; he says.</ORIGINAL_TEXT>
				<TOKEN id="token-17-0" start_char="2999" end_char="2999">&quot;</TOKEN>
				<TOKEN id="token-17-1" start_char="3000" end_char="3010">Individuals</TOKEN>
				<TOKEN id="token-17-2" start_char="3012" end_char="3015">will</TOKEN>
				<TOKEN id="token-17-3" start_char="3017" end_char="3020">take</TOKEN>
				<TOKEN id="token-17-4" start_char="3022" end_char="3023">it</TOKEN>
				<TOKEN id="token-17-5" start_char="3025" end_char="3026">on</TOKEN>
				<TOKEN id="token-17-6" start_char="3028" end_char="3037">themselves</TOKEN>
				<TOKEN id="token-17-7" start_char="3039" end_char="3040">to</TOKEN>
				<TOKEN id="token-17-8" start_char="3042" end_char="3047">become</TOKEN>
				<TOKEN id="token-17-9" start_char="3049" end_char="3058">vigilantes</TOKEN>
				<TOKEN id="token-17-10" start_char="3059" end_char="3059">,</TOKEN>
				<TOKEN id="token-17-11" start_char="3061" end_char="3065">where</TOKEN>
				<TOKEN id="token-17-12" start_char="3067" end_char="3070">they</TOKEN>
				<TOKEN id="token-17-13" start_char="3071" end_char="3071">'</TOKEN>
				<TOKEN id="token-17-14" start_char="3072" end_char="3073">ll</TOKEN>
				<TOKEN id="token-17-15" start_char="3075" end_char="3077">try</TOKEN>
				<TOKEN id="token-17-16" start_char="3079" end_char="3080">to</TOKEN>
				<TOKEN id="token-17-17" start_char="3082" end_char="3085">spot</TOKEN>
				<TOKEN id="token-17-18" start_char="3087" end_char="3093">someone</TOKEN>
				<TOKEN id="token-17-19" start_char="3095" end_char="3097">who</TOKEN>
				<TOKEN id="token-17-20" start_char="3099" end_char="3108">supposedly</TOKEN>
				<TOKEN id="token-17-21" start_char="3110" end_char="3111">is</TOKEN>
				<TOKEN id="token-17-22" start_char="3113" end_char="3118">either</TOKEN>
				<TOKEN id="token-17-23" start_char="3120" end_char="3126">holding</TOKEN>
				<TOKEN id="token-17-24" start_char="3128" end_char="3130">the</TOKEN>
				<TOKEN id="token-17-25" start_char="3132" end_char="3136">truth</TOKEN>
				<TOKEN id="token-17-26" start_char="3138" end_char="3142">about</TOKEN>
				<TOKEN id="token-17-27" start_char="3144" end_char="3147">some</TOKEN>
				<TOKEN id="token-17-28" start_char="3149" end_char="3154">hidden</TOKEN>
				<TOKEN id="token-17-29" start_char="3156" end_char="3160">truth</TOKEN>
				<TOKEN id="token-17-30" start_char="3162" end_char="3166">about</TOKEN>
				<TOKEN id="token-17-31" start_char="3168" end_char="3170">the</TOKEN>
				<TOKEN id="token-17-32" start_char="3172" end_char="3182">coronavirus</TOKEN>
				<TOKEN id="token-17-33" start_char="3184" end_char="3185">or</TOKEN>
				<TOKEN id="token-17-34" start_char="3187" end_char="3187">a</TOKEN>
				<TOKEN id="token-17-35" start_char="3189" end_char="3194">person</TOKEN>
				<TOKEN id="token-17-36" start_char="3196" end_char="3198">who</TOKEN>
				<TOKEN id="token-17-37" start_char="3200" end_char="3202">may</TOKEN>
				<TOKEN id="token-17-38" start_char="3204" end_char="3205">be</TOKEN>
				<TOKEN id="token-17-39" start_char="3207" end_char="3207">a</TOKEN>
				<TOKEN id="token-17-40" start_char="3209" end_char="3215">carrier</TOKEN>
				<TOKEN id="token-17-41" start_char="3217" end_char="3218">or</TOKEN>
				<TOKEN id="token-17-42" start_char="3220" end_char="3227">supposed</TOKEN>
				<TOKEN id="token-17-43" start_char="3229" end_char="3235">carrier</TOKEN>
				<TOKEN id="token-17-44" start_char="3237" end_char="3238">of</TOKEN>
				<TOKEN id="token-17-45" start_char="3240" end_char="3242">the</TOKEN>
				<TOKEN id="token-17-46" start_char="3244" end_char="3248">virus</TOKEN>
				<TOKEN id="token-17-47" start_char="3250" end_char="3256">because</TOKEN>
				<TOKEN id="token-17-48" start_char="3258" end_char="3261">they</TOKEN>
				<TOKEN id="token-17-49" start_char="3263" end_char="3268">appear</TOKEN>
				<TOKEN id="token-17-50" start_char="3270" end_char="3271">to</TOKEN>
				<TOKEN id="token-17-51" start_char="3273" end_char="3276">have</TOKEN>
				<TOKEN id="token-17-52" start_char="3278" end_char="3284">certain</TOKEN>
				<TOKEN id="token-17-53" start_char="3286" end_char="3293">symptoms</TOKEN>
				<TOKEN id="token-17-54" start_char="3294" end_char="3294">,</TOKEN>
				<TOKEN id="token-17-55" start_char="3296" end_char="3298">and</TOKEN>
				<TOKEN id="token-17-56" start_char="3300" end_char="3303">then</TOKEN>
				<TOKEN id="token-17-57" start_char="3305" end_char="3308">they</TOKEN>
				<TOKEN id="token-17-58" start_char="3309" end_char="3309">'</TOKEN>
				<TOKEN id="token-17-59" start_char="3310" end_char="3311">ll</TOKEN>
				<TOKEN id="token-17-60" start_char="3313" end_char="3315">ask</TOKEN>
				<TOKEN id="token-17-61" start_char="3317" end_char="3319">the</TOKEN>
				<TOKEN id="token-17-62" start_char="3321" end_char="3327">general</TOKEN>
				<TOKEN id="token-17-63" start_char="3329" end_char="3334">public</TOKEN>
				<TOKEN id="token-17-64" start_char="3336" end_char="3337">to</TOKEN>
				<TOKEN id="token-17-65" start_char="3339" end_char="3342">take</TOKEN>
				<TOKEN id="token-17-66" start_char="3344" end_char="3350">matters</TOKEN>
				<TOKEN id="token-17-67" start_char="3352" end_char="3355">into</TOKEN>
				<TOKEN id="token-17-68" start_char="3357" end_char="3359">own</TOKEN>
				<TOKEN id="token-17-69" start_char="3361" end_char="3365">hands</TOKEN>
				<TOKEN id="token-17-70" start_char="3366" end_char="3367">,&quot;</TOKEN>
				<TOKEN id="token-17-71" start_char="3369" end_char="3370">he</TOKEN>
				<TOKEN id="token-17-72" start_char="3372" end_char="3375">says</TOKEN>
				<TOKEN id="token-17-73" start_char="3376" end_char="3376">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-18" start_char="3378" end_char="3551">
				<ORIGINAL_TEXT>Experts like Fuyuki Kurasawa, director of the Global Digital Citizenship Lab at York University, say disinformation about the coronavirus is creating a 'social panic' online.</ORIGINAL_TEXT>
				<TOKEN id="token-18-0" start_char="3378" end_char="3384">Experts</TOKEN>
				<TOKEN id="token-18-1" start_char="3386" end_char="3389">like</TOKEN>
				<TOKEN id="token-18-2" start_char="3391" end_char="3396">Fuyuki</TOKEN>
				<TOKEN id="token-18-3" start_char="3398" end_char="3405">Kurasawa</TOKEN>
				<TOKEN id="token-18-4" start_char="3406" end_char="3406">,</TOKEN>
				<TOKEN id="token-18-5" start_char="3408" end_char="3415">director</TOKEN>
				<TOKEN id="token-18-6" start_char="3417" end_char="3418">of</TOKEN>
				<TOKEN id="token-18-7" start_char="3420" end_char="3422">the</TOKEN>
				<TOKEN id="token-18-8" start_char="3424" end_char="3429">Global</TOKEN>
				<TOKEN id="token-18-9" start_char="3431" end_char="3437">Digital</TOKEN>
				<TOKEN id="token-18-10" start_char="3439" end_char="3449">Citizenship</TOKEN>
				<TOKEN id="token-18-11" start_char="3451" end_char="3453">Lab</TOKEN>
				<TOKEN id="token-18-12" start_char="3455" end_char="3456">at</TOKEN>
				<TOKEN id="token-18-13" start_char="3458" end_char="3461">York</TOKEN>
				<TOKEN id="token-18-14" start_char="3463" end_char="3472">University</TOKEN>
				<TOKEN id="token-18-15" start_char="3473" end_char="3473">,</TOKEN>
				<TOKEN id="token-18-16" start_char="3475" end_char="3477">say</TOKEN>
				<TOKEN id="token-18-17" start_char="3479" end_char="3492">disinformation</TOKEN>
				<TOKEN id="token-18-18" start_char="3494" end_char="3498">about</TOKEN>
				<TOKEN id="token-18-19" start_char="3500" end_char="3502">the</TOKEN>
				<TOKEN id="token-18-20" start_char="3504" end_char="3514">coronavirus</TOKEN>
				<TOKEN id="token-18-21" start_char="3516" end_char="3517">is</TOKEN>
				<TOKEN id="token-18-22" start_char="3519" end_char="3526">creating</TOKEN>
				<TOKEN id="token-18-23" start_char="3528" end_char="3528">a</TOKEN>
				<TOKEN id="token-18-24" start_char="3530" end_char="3530">'</TOKEN>
				<TOKEN id="token-18-25" start_char="3531" end_char="3536">social</TOKEN>
				<TOKEN id="token-18-26" start_char="3538" end_char="3542">panic</TOKEN>
				<TOKEN id="token-18-27" start_char="3543" end_char="3543">'</TOKEN>
				<TOKEN id="token-18-28" start_char="3545" end_char="3550">online</TOKEN>
				<TOKEN id="token-18-29" start_char="3551" end_char="3551">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-19" start_char="3553" end_char="3570">
				<ORIGINAL_TEXT>(Derek Hooper/CBC)</ORIGINAL_TEXT>
				<TOKEN id="token-19-0" start_char="3553" end_char="3553">(</TOKEN>
				<TOKEN id="token-19-1" start_char="3554" end_char="3558">Derek</TOKEN>
				<TOKEN id="token-19-2" start_char="3560" end_char="3565">Hooper</TOKEN>
				<TOKEN id="token-19-3" start_char="3566" end_char="3566">/</TOKEN>
				<TOKEN id="token-19-4" start_char="3567" end_char="3569">CBC</TOKEN>
				<TOKEN id="token-19-5" start_char="3570" end_char="3570">)</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-20" start_char="3572" end_char="3605">
				<ORIGINAL_TEXT>Kernels of truth in disinformation</ORIGINAL_TEXT>
				<TOKEN id="token-20-0" start_char="3572" end_char="3578">Kernels</TOKEN>
				<TOKEN id="token-20-1" start_char="3580" end_char="3581">of</TOKEN>
				<TOKEN id="token-20-2" start_char="3583" end_char="3587">truth</TOKEN>
				<TOKEN id="token-20-3" start_char="3589" end_char="3590">in</TOKEN>
				<TOKEN id="token-20-4" start_char="3592" end_char="3605">disinformation</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-21" start_char="3607" end_char="3727">
				<ORIGINAL_TEXT>Dr. Xiangguo Qiu is a medical doctor and virologist from Tianjin, China, who came to Canada for graduate studies in 1996.</ORIGINAL_TEXT>
				<TOKEN id="token-21-0" start_char="3607" end_char="3608">Dr</TOKEN>
				<TOKEN id="token-21-1" start_char="3609" end_char="3609">.</TOKEN>
				<TOKEN id="token-21-2" start_char="3611" end_char="3618">Xiangguo</TOKEN>
				<TOKEN id="token-21-3" start_char="3620" end_char="3622">Qiu</TOKEN>
				<TOKEN id="token-21-4" start_char="3624" end_char="3625">is</TOKEN>
				<TOKEN id="token-21-5" start_char="3627" end_char="3627">a</TOKEN>
				<TOKEN id="token-21-6" start_char="3629" end_char="3635">medical</TOKEN>
				<TOKEN id="token-21-7" start_char="3637" end_char="3642">doctor</TOKEN>
				<TOKEN id="token-21-8" start_char="3644" end_char="3646">and</TOKEN>
				<TOKEN id="token-21-9" start_char="3648" end_char="3657">virologist</TOKEN>
				<TOKEN id="token-21-10" start_char="3659" end_char="3662">from</TOKEN>
				<TOKEN id="token-21-11" start_char="3664" end_char="3670">Tianjin</TOKEN>
				<TOKEN id="token-21-12" start_char="3671" end_char="3671">,</TOKEN>
				<TOKEN id="token-21-13" start_char="3673" end_char="3677">China</TOKEN>
				<TOKEN id="token-21-14" start_char="3678" end_char="3678">,</TOKEN>
				<TOKEN id="token-21-15" start_char="3680" end_char="3682">who</TOKEN>
				<TOKEN id="token-21-16" start_char="3684" end_char="3687">came</TOKEN>
				<TOKEN id="token-21-17" start_char="3689" end_char="3690">to</TOKEN>
				<TOKEN id="token-21-18" start_char="3692" end_char="3697">Canada</TOKEN>
				<TOKEN id="token-21-19" start_char="3699" end_char="3701">for</TOKEN>
				<TOKEN id="token-21-20" start_char="3703" end_char="3710">graduate</TOKEN>
				<TOKEN id="token-21-21" start_char="3712" end_char="3718">studies</TOKEN>
				<TOKEN id="token-21-22" start_char="3720" end_char="3721">in</TOKEN>
				<TOKEN id="token-21-23" start_char="3723" end_char="3726">1996</TOKEN>
				<TOKEN id="token-21-24" start_char="3727" end_char="3727">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-22" start_char="3729" end_char="3848">
				<ORIGINAL_TEXT>Qiu is still affiliated with the university there and has brought in many students over the years to help with her work.</ORIGINAL_TEXT>
				<TOKEN id="token-22-0" start_char="3729" end_char="3731">Qiu</TOKEN>
				<TOKEN id="token-22-1" start_char="3733" end_char="3734">is</TOKEN>
				<TOKEN id="token-22-2" start_char="3736" end_char="3740">still</TOKEN>
				<TOKEN id="token-22-3" start_char="3742" end_char="3751">affiliated</TOKEN>
				<TOKEN id="token-22-4" start_char="3753" end_char="3756">with</TOKEN>
				<TOKEN id="token-22-5" start_char="3758" end_char="3760">the</TOKEN>
				<TOKEN id="token-22-6" start_char="3762" end_char="3771">university</TOKEN>
				<TOKEN id="token-22-7" start_char="3773" end_char="3777">there</TOKEN>
				<TOKEN id="token-22-8" start_char="3779" end_char="3781">and</TOKEN>
				<TOKEN id="token-22-9" start_char="3783" end_char="3785">has</TOKEN>
				<TOKEN id="token-22-10" start_char="3787" end_char="3793">brought</TOKEN>
				<TOKEN id="token-22-11" start_char="3795" end_char="3796">in</TOKEN>
				<TOKEN id="token-22-12" start_char="3798" end_char="3801">many</TOKEN>
				<TOKEN id="token-22-13" start_char="3803" end_char="3810">students</TOKEN>
				<TOKEN id="token-22-14" start_char="3812" end_char="3815">over</TOKEN>
				<TOKEN id="token-22-15" start_char="3817" end_char="3819">the</TOKEN>
				<TOKEN id="token-22-16" start_char="3821" end_char="3825">years</TOKEN>
				<TOKEN id="token-22-17" start_char="3827" end_char="3828">to</TOKEN>
				<TOKEN id="token-22-18" start_char="3830" end_char="3833">help</TOKEN>
				<TOKEN id="token-22-19" start_char="3835" end_char="3838">with</TOKEN>
				<TOKEN id="token-22-20" start_char="3840" end_char="3842">her</TOKEN>
				<TOKEN id="token-22-21" start_char="3844" end_char="3847">work</TOKEN>
				<TOKEN id="token-22-22" start_char="3848" end_char="3848">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-23" start_char="3850" end_char="3984">
				<ORIGINAL_TEXT>She helped develop ZMapp, a treatment for the deadly Ebola virus which killed more than 11,000 people in West Africa between 2014-2016.</ORIGINAL_TEXT>
				<TOKEN id="token-23-0" start_char="3850" end_char="3852">She</TOKEN>
				<TOKEN id="token-23-1" start_char="3854" end_char="3859">helped</TOKEN>
				<TOKEN id="token-23-2" start_char="3861" end_char="3867">develop</TOKEN>
				<TOKEN id="token-23-3" start_char="3869" end_char="3873">ZMapp</TOKEN>
				<TOKEN id="token-23-4" start_char="3874" end_char="3874">,</TOKEN>
				<TOKEN id="token-23-5" start_char="3876" end_char="3876">a</TOKEN>
				<TOKEN id="token-23-6" start_char="3878" end_char="3886">treatment</TOKEN>
				<TOKEN id="token-23-7" start_char="3888" end_char="3890">for</TOKEN>
				<TOKEN id="token-23-8" start_char="3892" end_char="3894">the</TOKEN>
				<TOKEN id="token-23-9" start_char="3896" end_char="3901">deadly</TOKEN>
				<TOKEN id="token-23-10" start_char="3903" end_char="3907">Ebola</TOKEN>
				<TOKEN id="token-23-11" start_char="3909" end_char="3913">virus</TOKEN>
				<TOKEN id="token-23-12" start_char="3915" end_char="3919">which</TOKEN>
				<TOKEN id="token-23-13" start_char="3921" end_char="3926">killed</TOKEN>
				<TOKEN id="token-23-14" start_char="3928" end_char="3931">more</TOKEN>
				<TOKEN id="token-23-15" start_char="3933" end_char="3936">than</TOKEN>
				<TOKEN id="token-23-16" start_char="3938" end_char="3939">11</TOKEN>
				<TOKEN id="token-23-17" start_char="3940" end_char="3940">,</TOKEN>
				<TOKEN id="token-23-18" start_char="3941" end_char="3943">000</TOKEN>
				<TOKEN id="token-23-19" start_char="3945" end_char="3950">people</TOKEN>
				<TOKEN id="token-23-20" start_char="3952" end_char="3953">in</TOKEN>
				<TOKEN id="token-23-21" start_char="3955" end_char="3958">West</TOKEN>
				<TOKEN id="token-23-22" start_char="3960" end_char="3965">Africa</TOKEN>
				<TOKEN id="token-23-23" start_char="3967" end_char="3973">between</TOKEN>
				<TOKEN id="token-23-24" start_char="3975" end_char="3978">2014</TOKEN>
				<TOKEN id="token-23-25" start_char="3979" end_char="3979">-</TOKEN>
				<TOKEN id="token-23-26" start_char="3980" end_char="3983">2016</TOKEN>
				<TOKEN id="token-23-27" start_char="3984" end_char="3984">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-24" start_char="3986" end_char="4051">
				<ORIGINAL_TEXT>Her husband Keding Cheng works at the Winnipeg lab as a biologist.</ORIGINAL_TEXT>
				<TOKEN id="token-24-0" start_char="3986" end_char="3988">Her</TOKEN>
				<TOKEN id="token-24-1" start_char="3990" end_char="3996">husband</TOKEN>
				<TOKEN id="token-24-2" start_char="3998" end_char="4003">Keding</TOKEN>
				<TOKEN id="token-24-3" start_char="4005" end_char="4009">Cheng</TOKEN>
				<TOKEN id="token-24-4" start_char="4011" end_char="4015">works</TOKEN>
				<TOKEN id="token-24-5" start_char="4017" end_char="4018">at</TOKEN>
				<TOKEN id="token-24-6" start_char="4020" end_char="4022">the</TOKEN>
				<TOKEN id="token-24-7" start_char="4024" end_char="4031">Winnipeg</TOKEN>
				<TOKEN id="token-24-8" start_char="4033" end_char="4035">lab</TOKEN>
				<TOKEN id="token-24-9" start_char="4037" end_char="4038">as</TOKEN>
				<TOKEN id="token-24-10" start_char="4040" end_char="4040">a</TOKEN>
				<TOKEN id="token-24-11" start_char="4042" end_char="4050">biologist</TOKEN>
				<TOKEN id="token-24-12" start_char="4051" end_char="4051">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-25" start_char="4053" end_char="4195">
				<ORIGINAL_TEXT>He has published research papers on HIV infections, severe acute respiratory syndrome (SARS), E. coli infections and Creutzfeldt-Jakob disease.</ORIGINAL_TEXT>
				<TOKEN id="token-25-0" start_char="4053" end_char="4054">He</TOKEN>
				<TOKEN id="token-25-1" start_char="4056" end_char="4058">has</TOKEN>
				<TOKEN id="token-25-2" start_char="4060" end_char="4068">published</TOKEN>
				<TOKEN id="token-25-3" start_char="4070" end_char="4077">research</TOKEN>
				<TOKEN id="token-25-4" start_char="4079" end_char="4084">papers</TOKEN>
				<TOKEN id="token-25-5" start_char="4086" end_char="4087">on</TOKEN>
				<TOKEN id="token-25-6" start_char="4089" end_char="4091">HIV</TOKEN>
				<TOKEN id="token-25-7" start_char="4093" end_char="4102">infections</TOKEN>
				<TOKEN id="token-25-8" start_char="4103" end_char="4103">,</TOKEN>
				<TOKEN id="token-25-9" start_char="4105" end_char="4110">severe</TOKEN>
				<TOKEN id="token-25-10" start_char="4112" end_char="4116">acute</TOKEN>
				<TOKEN id="token-25-11" start_char="4118" end_char="4128">respiratory</TOKEN>
				<TOKEN id="token-25-12" start_char="4130" end_char="4137">syndrome</TOKEN>
				<TOKEN id="token-25-13" start_char="4139" end_char="4139">(</TOKEN>
				<TOKEN id="token-25-14" start_char="4140" end_char="4143">SARS</TOKEN>
				<TOKEN id="token-25-15" start_char="4144" end_char="4145">),</TOKEN>
				<TOKEN id="token-25-16" start_char="4147" end_char="4147">E</TOKEN>
				<TOKEN id="token-25-17" start_char="4148" end_char="4148">.</TOKEN>
				<TOKEN id="token-25-18" start_char="4150" end_char="4153">coli</TOKEN>
				<TOKEN id="token-25-19" start_char="4155" end_char="4164">infections</TOKEN>
				<TOKEN id="token-25-20" start_char="4166" end_char="4168">and</TOKEN>
				<TOKEN id="token-25-21" start_char="4170" end_char="4180">Creutzfeldt</TOKEN>
				<TOKEN id="token-25-22" start_char="4181" end_char="4181">-</TOKEN>
				<TOKEN id="token-25-23" start_char="4182" end_char="4186">Jakob</TOKEN>
				<TOKEN id="token-25-24" start_char="4188" end_char="4194">disease</TOKEN>
				<TOKEN id="token-25-25" start_char="4195" end_char="4195">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-26" start_char="4197" end_char="4335">
				<ORIGINAL_TEXT>One month later, CBC discovered that scientists at the NML sent live Ebola and Henipah viruses to Beijing on an Air Canada flight March 31.</ORIGINAL_TEXT>
				<TOKEN id="token-26-0" start_char="4197" end_char="4199">One</TOKEN>
				<TOKEN id="token-26-1" start_char="4201" end_char="4205">month</TOKEN>
				<TOKEN id="token-26-2" start_char="4207" end_char="4211">later</TOKEN>
				<TOKEN id="token-26-3" start_char="4212" end_char="4212">,</TOKEN>
				<TOKEN id="token-26-4" start_char="4214" end_char="4216">CBC</TOKEN>
				<TOKEN id="token-26-5" start_char="4218" end_char="4227">discovered</TOKEN>
				<TOKEN id="token-26-6" start_char="4229" end_char="4232">that</TOKEN>
				<TOKEN id="token-26-7" start_char="4234" end_char="4243">scientists</TOKEN>
				<TOKEN id="token-26-8" start_char="4245" end_char="4246">at</TOKEN>
				<TOKEN id="token-26-9" start_char="4248" end_char="4250">the</TOKEN>
				<TOKEN id="token-26-10" start_char="4252" end_char="4254">NML</TOKEN>
				<TOKEN id="token-26-11" start_char="4256" end_char="4259">sent</TOKEN>
				<TOKEN id="token-26-12" start_char="4261" end_char="4264">live</TOKEN>
				<TOKEN id="token-26-13" start_char="4266" end_char="4270">Ebola</TOKEN>
				<TOKEN id="token-26-14" start_char="4272" end_char="4274">and</TOKEN>
				<TOKEN id="token-26-15" start_char="4276" end_char="4282">Henipah</TOKEN>
				<TOKEN id="token-26-16" start_char="4284" end_char="4290">viruses</TOKEN>
				<TOKEN id="token-26-17" start_char="4292" end_char="4293">to</TOKEN>
				<TOKEN id="token-26-18" start_char="4295" end_char="4301">Beijing</TOKEN>
				<TOKEN id="token-26-19" start_char="4303" end_char="4304">on</TOKEN>
				<TOKEN id="token-26-20" start_char="4306" end_char="4307">an</TOKEN>
				<TOKEN id="token-26-21" start_char="4309" end_char="4311">Air</TOKEN>
				<TOKEN id="token-26-22" start_char="4313" end_char="4318">Canada</TOKEN>
				<TOKEN id="token-26-23" start_char="4320" end_char="4325">flight</TOKEN>
				<TOKEN id="token-26-24" start_char="4327" end_char="4331">March</TOKEN>
				<TOKEN id="token-26-25" start_char="4333" end_char="4334">31</TOKEN>
				<TOKEN id="token-26-26" start_char="4335" end_char="4335">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-27" start_char="4337" end_char="4411">
				<ORIGINAL_TEXT>The Public Health Agency of Canada says all federal policies were followed.</ORIGINAL_TEXT>
				<TOKEN id="token-27-0" start_char="4337" end_char="4339">The</TOKEN>
				<TOKEN id="token-27-1" start_char="4341" end_char="4346">Public</TOKEN>
				<TOKEN id="token-27-2" start_char="4348" end_char="4353">Health</TOKEN>
				<TOKEN id="token-27-3" start_char="4355" end_char="4360">Agency</TOKEN>
				<TOKEN id="token-27-4" start_char="4362" end_char="4363">of</TOKEN>
				<TOKEN id="token-27-5" start_char="4365" end_char="4370">Canada</TOKEN>
				<TOKEN id="token-27-6" start_char="4372" end_char="4375">says</TOKEN>
				<TOKEN id="token-27-7" start_char="4377" end_char="4379">all</TOKEN>
				<TOKEN id="token-27-8" start_char="4381" end_char="4387">federal</TOKEN>
				<TOKEN id="token-27-9" start_char="4389" end_char="4396">policies</TOKEN>
				<TOKEN id="token-27-10" start_char="4398" end_char="4401">were</TOKEN>
				<TOKEN id="token-27-11" start_char="4403" end_char="4410">followed</TOKEN>
				<TOKEN id="token-27-12" start_char="4411" end_char="4411">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-28" start_char="4413" end_char="4493">
				<ORIGINAL_TEXT>PHAC will not confirm if the March 31 shipment is part of the RCMP investigation.</ORIGINAL_TEXT>
				<TOKEN id="token-28-0" start_char="4413" end_char="4416">PHAC</TOKEN>
				<TOKEN id="token-28-1" start_char="4418" end_char="4421">will</TOKEN>
				<TOKEN id="token-28-2" start_char="4423" end_char="4425">not</TOKEN>
				<TOKEN id="token-28-3" start_char="4427" end_char="4433">confirm</TOKEN>
				<TOKEN id="token-28-4" start_char="4435" end_char="4436">if</TOKEN>
				<TOKEN id="token-28-5" start_char="4438" end_char="4440">the</TOKEN>
				<TOKEN id="token-28-6" start_char="4442" end_char="4446">March</TOKEN>
				<TOKEN id="token-28-7" start_char="4448" end_char="4449">31</TOKEN>
				<TOKEN id="token-28-8" start_char="4451" end_char="4458">shipment</TOKEN>
				<TOKEN id="token-28-9" start_char="4460" end_char="4461">is</TOKEN>
				<TOKEN id="token-28-10" start_char="4463" end_char="4466">part</TOKEN>
				<TOKEN id="token-28-11" start_char="4468" end_char="4469">of</TOKEN>
				<TOKEN id="token-28-12" start_char="4471" end_char="4473">the</TOKEN>
				<TOKEN id="token-28-13" start_char="4475" end_char="4478">RCMP</TOKEN>
				<TOKEN id="token-28-14" start_char="4480" end_char="4492">investigation</TOKEN>
				<TOKEN id="token-28-15" start_char="4493" end_char="4493">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-29" start_char="4495" end_char="4570">
				<ORIGINAL_TEXT>Contrary to posts on Twitter, the coronavirus was not part of this shipment.</ORIGINAL_TEXT>
				<TOKEN id="token-29-0" start_char="4495" end_char="4502">Contrary</TOKEN>
				<TOKEN id="token-29-1" start_char="4504" end_char="4505">to</TOKEN>
				<TOKEN id="token-29-2" start_char="4507" end_char="4511">posts</TOKEN>
				<TOKEN id="token-29-3" start_char="4513" end_char="4514">on</TOKEN>
				<TOKEN id="token-29-4" start_char="4516" end_char="4522">Twitter</TOKEN>
				<TOKEN id="token-29-5" start_char="4523" end_char="4523">,</TOKEN>
				<TOKEN id="token-29-6" start_char="4525" end_char="4527">the</TOKEN>
				<TOKEN id="token-29-7" start_char="4529" end_char="4539">coronavirus</TOKEN>
				<TOKEN id="token-29-8" start_char="4541" end_char="4543">was</TOKEN>
				<TOKEN id="token-29-9" start_char="4545" end_char="4547">not</TOKEN>
				<TOKEN id="token-29-10" start_char="4549" end_char="4552">part</TOKEN>
				<TOKEN id="token-29-11" start_char="4554" end_char="4555">of</TOKEN>
				<TOKEN id="token-29-12" start_char="4557" end_char="4560">this</TOKEN>
				<TOKEN id="token-29-13" start_char="4562" end_char="4569">shipment</TOKEN>
				<TOKEN id="token-29-14" start_char="4570" end_char="4570">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-30" start_char="4572" end_char="4653">
				<ORIGINAL_TEXT>And there is no confirmation Qiu or Cheng were the scientists behind the shipment.</ORIGINAL_TEXT>
				<TOKEN id="token-30-0" start_char="4572" end_char="4574">And</TOKEN>
				<TOKEN id="token-30-1" start_char="4576" end_char="4580">there</TOKEN>
				<TOKEN id="token-30-2" start_char="4582" end_char="4583">is</TOKEN>
				<TOKEN id="token-30-3" start_char="4585" end_char="4586">no</TOKEN>
				<TOKEN id="token-30-4" start_char="4588" end_char="4599">confirmation</TOKEN>
				<TOKEN id="token-30-5" start_char="4601" end_char="4603">Qiu</TOKEN>
				<TOKEN id="token-30-6" start_char="4605" end_char="4606">or</TOKEN>
				<TOKEN id="token-30-7" start_char="4608" end_char="4612">Cheng</TOKEN>
				<TOKEN id="token-30-8" start_char="4614" end_char="4617">were</TOKEN>
				<TOKEN id="token-30-9" start_char="4619" end_char="4621">the</TOKEN>
				<TOKEN id="token-30-10" start_char="4623" end_char="4632">scientists</TOKEN>
				<TOKEN id="token-30-11" start_char="4634" end_char="4639">behind</TOKEN>
				<TOKEN id="token-30-12" start_char="4641" end_char="4643">the</TOKEN>
				<TOKEN id="token-30-13" start_char="4645" end_char="4652">shipment</TOKEN>
				<TOKEN id="token-30-14" start_char="4653" end_char="4653">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-31" start_char="4655" end_char="4904">
				<ORIGINAL_TEXT>In another followup story using travel documents obtained in Access to Information requests, CBC reported that Qiu made at least five trips to China in 2017-18, including one to train scientists and technicians at China's newly certified Level 4 lab.</ORIGINAL_TEXT>
				<TOKEN id="token-31-0" start_char="4655" end_char="4656">In</TOKEN>
				<TOKEN id="token-31-1" start_char="4658" end_char="4664">another</TOKEN>
				<TOKEN id="token-31-2" start_char="4666" end_char="4673">followup</TOKEN>
				<TOKEN id="token-31-3" start_char="4675" end_char="4679">story</TOKEN>
				<TOKEN id="token-31-4" start_char="4681" end_char="4685">using</TOKEN>
				<TOKEN id="token-31-5" start_char="4687" end_char="4692">travel</TOKEN>
				<TOKEN id="token-31-6" start_char="4694" end_char="4702">documents</TOKEN>
				<TOKEN id="token-31-7" start_char="4704" end_char="4711">obtained</TOKEN>
				<TOKEN id="token-31-8" start_char="4713" end_char="4714">in</TOKEN>
				<TOKEN id="token-31-9" start_char="4716" end_char="4721">Access</TOKEN>
				<TOKEN id="token-31-10" start_char="4723" end_char="4724">to</TOKEN>
				<TOKEN id="token-31-11" start_char="4726" end_char="4736">Information</TOKEN>
				<TOKEN id="token-31-12" start_char="4738" end_char="4745">requests</TOKEN>
				<TOKEN id="token-31-13" start_char="4746" end_char="4746">,</TOKEN>
				<TOKEN id="token-31-14" start_char="4748" end_char="4750">CBC</TOKEN>
				<TOKEN id="token-31-15" start_char="4752" end_char="4759">reported</TOKEN>
				<TOKEN id="token-31-16" start_char="4761" end_char="4764">that</TOKEN>
				<TOKEN id="token-31-17" start_char="4766" end_char="4768">Qiu</TOKEN>
				<TOKEN id="token-31-18" start_char="4770" end_char="4773">made</TOKEN>
				<TOKEN id="token-31-19" start_char="4775" end_char="4776">at</TOKEN>
				<TOKEN id="token-31-20" start_char="4778" end_char="4782">least</TOKEN>
				<TOKEN id="token-31-21" start_char="4784" end_char="4787">five</TOKEN>
				<TOKEN id="token-31-22" start_char="4789" end_char="4793">trips</TOKEN>
				<TOKEN id="token-31-23" start_char="4795" end_char="4796">to</TOKEN>
				<TOKEN id="token-31-24" start_char="4798" end_char="4802">China</TOKEN>
				<TOKEN id="token-31-25" start_char="4804" end_char="4805">in</TOKEN>
				<TOKEN id="token-31-26" start_char="4807" end_char="4810">2017</TOKEN>
				<TOKEN id="token-31-27" start_char="4811" end_char="4811">-</TOKEN>
				<TOKEN id="token-31-28" start_char="4812" end_char="4813">18</TOKEN>
				<TOKEN id="token-31-29" start_char="4814" end_char="4814">,</TOKEN>
				<TOKEN id="token-31-30" start_char="4816" end_char="4824">including</TOKEN>
				<TOKEN id="token-31-31" start_char="4826" end_char="4828">one</TOKEN>
				<TOKEN id="token-31-32" start_char="4830" end_char="4831">to</TOKEN>
				<TOKEN id="token-31-33" start_char="4833" end_char="4837">train</TOKEN>
				<TOKEN id="token-31-34" start_char="4839" end_char="4848">scientists</TOKEN>
				<TOKEN id="token-31-35" start_char="4850" end_char="4852">and</TOKEN>
				<TOKEN id="token-31-36" start_char="4854" end_char="4864">technicians</TOKEN>
				<TOKEN id="token-31-37" start_char="4866" end_char="4867">at</TOKEN>
				<TOKEN id="token-31-38" start_char="4869" end_char="4873">China</TOKEN>
				<TOKEN id="token-31-39" start_char="4874" end_char="4874">'</TOKEN>
				<TOKEN id="token-31-40" start_char="4875" end_char="4875">s</TOKEN>
				<TOKEN id="token-31-41" start_char="4877" end_char="4881">newly</TOKEN>
				<TOKEN id="token-31-42" start_char="4883" end_char="4891">certified</TOKEN>
				<TOKEN id="token-31-43" start_char="4893" end_char="4897">Level</TOKEN>
				<TOKEN id="token-31-44" start_char="4899" end_char="4899">4</TOKEN>
				<TOKEN id="token-31-45" start_char="4901" end_char="4903">lab</TOKEN>
				<TOKEN id="token-31-46" start_char="4904" end_char="4904">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-32" start_char="4906" end_char="5063">
				<ORIGINAL_TEXT>She was invited to visit the Wuhan National Biosafety Laboratory of the Chinese Academy of Sciences twice a year for two years, for up to two weeks each time.</ORIGINAL_TEXT>
				<TOKEN id="token-32-0" start_char="4906" end_char="4908">She</TOKEN>
				<TOKEN id="token-32-1" start_char="4910" end_char="4912">was</TOKEN>
				<TOKEN id="token-32-2" start_char="4914" end_char="4920">invited</TOKEN>
				<TOKEN id="token-32-3" start_char="4922" end_char="4923">to</TOKEN>
				<TOKEN id="token-32-4" start_char="4925" end_char="4929">visit</TOKEN>
				<TOKEN id="token-32-5" start_char="4931" end_char="4933">the</TOKEN>
				<TOKEN id="token-32-6" start_char="4935" end_char="4939">Wuhan</TOKEN>
				<TOKEN id="token-32-7" start_char="4941" end_char="4948">National</TOKEN>
				<TOKEN id="token-32-8" start_char="4950" end_char="4958">Biosafety</TOKEN>
				<TOKEN id="token-32-9" start_char="4960" end_char="4969">Laboratory</TOKEN>
				<TOKEN id="token-32-10" start_char="4971" end_char="4972">of</TOKEN>
				<TOKEN id="token-32-11" start_char="4974" end_char="4976">the</TOKEN>
				<TOKEN id="token-32-12" start_char="4978" end_char="4984">Chinese</TOKEN>
				<TOKEN id="token-32-13" start_char="4986" end_char="4992">Academy</TOKEN>
				<TOKEN id="token-32-14" start_char="4994" end_char="4995">of</TOKEN>
				<TOKEN id="token-32-15" start_char="4997" end_char="5004">Sciences</TOKEN>
				<TOKEN id="token-32-16" start_char="5006" end_char="5010">twice</TOKEN>
				<TOKEN id="token-32-17" start_char="5012" end_char="5012">a</TOKEN>
				<TOKEN id="token-32-18" start_char="5014" end_char="5017">year</TOKEN>
				<TOKEN id="token-32-19" start_char="5019" end_char="5021">for</TOKEN>
				<TOKEN id="token-32-20" start_char="5023" end_char="5025">two</TOKEN>
				<TOKEN id="token-32-21" start_char="5027" end_char="5031">years</TOKEN>
				<TOKEN id="token-32-22" start_char="5032" end_char="5032">,</TOKEN>
				<TOKEN id="token-32-23" start_char="5034" end_char="5036">for</TOKEN>
				<TOKEN id="token-32-24" start_char="5038" end_char="5039">up</TOKEN>
				<TOKEN id="token-32-25" start_char="5041" end_char="5042">to</TOKEN>
				<TOKEN id="token-32-26" start_char="5044" end_char="5046">two</TOKEN>
				<TOKEN id="token-32-27" start_char="5048" end_char="5052">weeks</TOKEN>
				<TOKEN id="token-32-28" start_char="5054" end_char="5057">each</TOKEN>
				<TOKEN id="token-32-29" start_char="5059" end_char="5062">time</TOKEN>
				<TOKEN id="token-32-30" start_char="5063" end_char="5063">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-33" start_char="5065" end_char="5117">
				<ORIGINAL_TEXT>The lab does research with the most deadly pathogens.</ORIGINAL_TEXT>
				<TOKEN id="token-33-0" start_char="5065" end_char="5067">The</TOKEN>
				<TOKEN id="token-33-1" start_char="5069" end_char="5071">lab</TOKEN>
				<TOKEN id="token-33-2" start_char="5073" end_char="5076">does</TOKEN>
				<TOKEN id="token-33-3" start_char="5078" end_char="5085">research</TOKEN>
				<TOKEN id="token-33-4" start_char="5087" end_char="5090">with</TOKEN>
				<TOKEN id="token-33-5" start_char="5092" end_char="5094">the</TOKEN>
				<TOKEN id="token-33-6" start_char="5096" end_char="5099">most</TOKEN>
				<TOKEN id="token-33-7" start_char="5101" end_char="5106">deadly</TOKEN>
				<TOKEN id="token-33-8" start_char="5108" end_char="5116">pathogens</TOKEN>
				<TOKEN id="token-33-9" start_char="5117" end_char="5117">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-34" start_char="5119" end_char="5259">
				<ORIGINAL_TEXT>PHAC has denied any connection between the RCMP investigation, Qiu's visits to Wuhan or any Canadian research, with the coronavirus outbreak.</ORIGINAL_TEXT>
				<TOKEN id="token-34-0" start_char="5119" end_char="5122">PHAC</TOKEN>
				<TOKEN id="token-34-1" start_char="5124" end_char="5126">has</TOKEN>
				<TOKEN id="token-34-2" start_char="5128" end_char="5133">denied</TOKEN>
				<TOKEN id="token-34-3" start_char="5135" end_char="5137">any</TOKEN>
				<TOKEN id="token-34-4" start_char="5139" end_char="5148">connection</TOKEN>
				<TOKEN id="token-34-5" start_char="5150" end_char="5156">between</TOKEN>
				<TOKEN id="token-34-6" start_char="5158" end_char="5160">the</TOKEN>
				<TOKEN id="token-34-7" start_char="5162" end_char="5165">RCMP</TOKEN>
				<TOKEN id="token-34-8" start_char="5167" end_char="5179">investigation</TOKEN>
				<TOKEN id="token-34-9" start_char="5180" end_char="5180">,</TOKEN>
				<TOKEN id="token-34-10" start_char="5182" end_char="5184">Qiu</TOKEN>
				<TOKEN id="token-34-11" start_char="5185" end_char="5185">'</TOKEN>
				<TOKEN id="token-34-12" start_char="5186" end_char="5186">s</TOKEN>
				<TOKEN id="token-34-13" start_char="5188" end_char="5193">visits</TOKEN>
				<TOKEN id="token-34-14" start_char="5195" end_char="5196">to</TOKEN>
				<TOKEN id="token-34-15" start_char="5198" end_char="5202">Wuhan</TOKEN>
				<TOKEN id="token-34-16" start_char="5204" end_char="5205">or</TOKEN>
				<TOKEN id="token-34-17" start_char="5207" end_char="5209">any</TOKEN>
				<TOKEN id="token-34-18" start_char="5211" end_char="5218">Canadian</TOKEN>
				<TOKEN id="token-34-19" start_char="5220" end_char="5227">research</TOKEN>
				<TOKEN id="token-34-20" start_char="5228" end_char="5228">,</TOKEN>
				<TOKEN id="token-34-21" start_char="5230" end_char="5233">with</TOKEN>
				<TOKEN id="token-34-22" start_char="5235" end_char="5237">the</TOKEN>
				<TOKEN id="token-34-23" start_char="5239" end_char="5249">coronavirus</TOKEN>
				<TOKEN id="token-34-24" start_char="5251" end_char="5258">outbreak</TOKEN>
				<TOKEN id="token-34-25" start_char="5259" end_char="5259">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-35" start_char="5261" end_char="5355">
				<ORIGINAL_TEXT>However, PHAC would not comment on the current status of Qiu and Cheng, citing privacy reasons.</ORIGINAL_TEXT>
				<TOKEN id="token-35-0" start_char="5261" end_char="5267">However</TOKEN>
				<TOKEN id="token-35-1" start_char="5268" end_char="5268">,</TOKEN>
				<TOKEN id="token-35-2" start_char="5270" end_char="5273">PHAC</TOKEN>
				<TOKEN id="token-35-3" start_char="5275" end_char="5279">would</TOKEN>
				<TOKEN id="token-35-4" start_char="5281" end_char="5283">not</TOKEN>
				<TOKEN id="token-35-5" start_char="5285" end_char="5291">comment</TOKEN>
				<TOKEN id="token-35-6" start_char="5293" end_char="5294">on</TOKEN>
				<TOKEN id="token-35-7" start_char="5296" end_char="5298">the</TOKEN>
				<TOKEN id="token-35-8" start_char="5300" end_char="5306">current</TOKEN>
				<TOKEN id="token-35-9" start_char="5308" end_char="5313">status</TOKEN>
				<TOKEN id="token-35-10" start_char="5315" end_char="5316">of</TOKEN>
				<TOKEN id="token-35-11" start_char="5318" end_char="5320">Qiu</TOKEN>
				<TOKEN id="token-35-12" start_char="5322" end_char="5324">and</TOKEN>
				<TOKEN id="token-35-13" start_char="5326" end_char="5330">Cheng</TOKEN>
				<TOKEN id="token-35-14" start_char="5331" end_char="5331">,</TOKEN>
				<TOKEN id="token-35-15" start_char="5333" end_char="5338">citing</TOKEN>
				<TOKEN id="token-35-16" start_char="5340" end_char="5346">privacy</TOKEN>
				<TOKEN id="token-35-17" start_char="5348" end_char="5354">reasons</TOKEN>
				<TOKEN id="token-35-18" start_char="5355" end_char="5355">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-36" start_char="5357" end_char="5384">
				<ORIGINAL_TEXT>Communicate more effectively</ORIGINAL_TEXT>
				<TOKEN id="token-36-0" start_char="5357" end_char="5367">Communicate</TOKEN>
				<TOKEN id="token-36-1" start_char="5369" end_char="5372">more</TOKEN>
				<TOKEN id="token-36-2" start_char="5374" end_char="5384">effectively</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-37" start_char="5386" end_char="5652">
				<ORIGINAL_TEXT>Heidi Tworek, assistant professor in international history at the University of British Columbia, says governments and public health authorities need to do a better job of communicating facts at times like this, including in the languages of the communities impacted.</ORIGINAL_TEXT>
				<TOKEN id="token-37-0" start_char="5386" end_char="5390">Heidi</TOKEN>
				<TOKEN id="token-37-1" start_char="5392" end_char="5397">Tworek</TOKEN>
				<TOKEN id="token-37-2" start_char="5398" end_char="5398">,</TOKEN>
				<TOKEN id="token-37-3" start_char="5400" end_char="5408">assistant</TOKEN>
				<TOKEN id="token-37-4" start_char="5410" end_char="5418">professor</TOKEN>
				<TOKEN id="token-37-5" start_char="5420" end_char="5421">in</TOKEN>
				<TOKEN id="token-37-6" start_char="5423" end_char="5435">international</TOKEN>
				<TOKEN id="token-37-7" start_char="5437" end_char="5443">history</TOKEN>
				<TOKEN id="token-37-8" start_char="5445" end_char="5446">at</TOKEN>
				<TOKEN id="token-37-9" start_char="5448" end_char="5450">the</TOKEN>
				<TOKEN id="token-37-10" start_char="5452" end_char="5461">University</TOKEN>
				<TOKEN id="token-37-11" start_char="5463" end_char="5464">of</TOKEN>
				<TOKEN id="token-37-12" start_char="5466" end_char="5472">British</TOKEN>
				<TOKEN id="token-37-13" start_char="5474" end_char="5481">Columbia</TOKEN>
				<TOKEN id="token-37-14" start_char="5482" end_char="5482">,</TOKEN>
				<TOKEN id="token-37-15" start_char="5484" end_char="5487">says</TOKEN>
				<TOKEN id="token-37-16" start_char="5489" end_char="5499">governments</TOKEN>
				<TOKEN id="token-37-17" start_char="5501" end_char="5503">and</TOKEN>
				<TOKEN id="token-37-18" start_char="5505" end_char="5510">public</TOKEN>
				<TOKEN id="token-37-19" start_char="5512" end_char="5517">health</TOKEN>
				<TOKEN id="token-37-20" start_char="5519" end_char="5529">authorities</TOKEN>
				<TOKEN id="token-37-21" start_char="5531" end_char="5534">need</TOKEN>
				<TOKEN id="token-37-22" start_char="5536" end_char="5537">to</TOKEN>
				<TOKEN id="token-37-23" start_char="5539" end_char="5540">do</TOKEN>
				<TOKEN id="token-37-24" start_char="5542" end_char="5542">a</TOKEN>
				<TOKEN id="token-37-25" start_char="5544" end_char="5549">better</TOKEN>
				<TOKEN id="token-37-26" start_char="5551" end_char="5553">job</TOKEN>
				<TOKEN id="token-37-27" start_char="5555" end_char="5556">of</TOKEN>
				<TOKEN id="token-37-28" start_char="5558" end_char="5570">communicating</TOKEN>
				<TOKEN id="token-37-29" start_char="5572" end_char="5576">facts</TOKEN>
				<TOKEN id="token-37-30" start_char="5578" end_char="5579">at</TOKEN>
				<TOKEN id="token-37-31" start_char="5581" end_char="5585">times</TOKEN>
				<TOKEN id="token-37-32" start_char="5587" end_char="5590">like</TOKEN>
				<TOKEN id="token-37-33" start_char="5592" end_char="5595">this</TOKEN>
				<TOKEN id="token-37-34" start_char="5596" end_char="5596">,</TOKEN>
				<TOKEN id="token-37-35" start_char="5598" end_char="5606">including</TOKEN>
				<TOKEN id="token-37-36" start_char="5608" end_char="5609">in</TOKEN>
				<TOKEN id="token-37-37" start_char="5611" end_char="5613">the</TOKEN>
				<TOKEN id="token-37-38" start_char="5615" end_char="5623">languages</TOKEN>
				<TOKEN id="token-37-39" start_char="5625" end_char="5626">of</TOKEN>
				<TOKEN id="token-37-40" start_char="5628" end_char="5630">the</TOKEN>
				<TOKEN id="token-37-41" start_char="5632" end_char="5642">communities</TOKEN>
				<TOKEN id="token-37-42" start_char="5644" end_char="5651">impacted</TOKEN>
				<TOKEN id="token-37-43" start_char="5652" end_char="5652">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-38" start_char="5654" end_char="5904">
				<ORIGINAL_TEXT>Heidi Tworek, an assistant professor in international history at University of British Columbia, says governments and public health agencies have to be more effective at communicating to the public because disinformation will spread faster than facts.</ORIGINAL_TEXT>
				<TOKEN id="token-38-0" start_char="5654" end_char="5658">Heidi</TOKEN>
				<TOKEN id="token-38-1" start_char="5660" end_char="5665">Tworek</TOKEN>
				<TOKEN id="token-38-2" start_char="5666" end_char="5666">,</TOKEN>
				<TOKEN id="token-38-3" start_char="5668" end_char="5669">an</TOKEN>
				<TOKEN id="token-38-4" start_char="5671" end_char="5679">assistant</TOKEN>
				<TOKEN id="token-38-5" start_char="5681" end_char="5689">professor</TOKEN>
				<TOKEN id="token-38-6" start_char="5691" end_char="5692">in</TOKEN>
				<TOKEN id="token-38-7" start_char="5694" end_char="5706">international</TOKEN>
				<TOKEN id="token-38-8" start_char="5708" end_char="5714">history</TOKEN>
				<TOKEN id="token-38-9" start_char="5716" end_char="5717">at</TOKEN>
				<TOKEN id="token-38-10" start_char="5719" end_char="5728">University</TOKEN>
				<TOKEN id="token-38-11" start_char="5730" end_char="5731">of</TOKEN>
				<TOKEN id="token-38-12" start_char="5733" end_char="5739">British</TOKEN>
				<TOKEN id="token-38-13" start_char="5741" end_char="5748">Columbia</TOKEN>
				<TOKEN id="token-38-14" start_char="5749" end_char="5749">,</TOKEN>
				<TOKEN id="token-38-15" start_char="5751" end_char="5754">says</TOKEN>
				<TOKEN id="token-38-16" start_char="5756" end_char="5766">governments</TOKEN>
				<TOKEN id="token-38-17" start_char="5768" end_char="5770">and</TOKEN>
				<TOKEN id="token-38-18" start_char="5772" end_char="5777">public</TOKEN>
				<TOKEN id="token-38-19" start_char="5779" end_char="5784">health</TOKEN>
				<TOKEN id="token-38-20" start_char="5786" end_char="5793">agencies</TOKEN>
				<TOKEN id="token-38-21" start_char="5795" end_char="5798">have</TOKEN>
				<TOKEN id="token-38-22" start_char="5800" end_char="5801">to</TOKEN>
				<TOKEN id="token-38-23" start_char="5803" end_char="5804">be</TOKEN>
				<TOKEN id="token-38-24" start_char="5806" end_char="5809">more</TOKEN>
				<TOKEN id="token-38-25" start_char="5811" end_char="5819">effective</TOKEN>
				<TOKEN id="token-38-26" start_char="5821" end_char="5822">at</TOKEN>
				<TOKEN id="token-38-27" start_char="5824" end_char="5836">communicating</TOKEN>
				<TOKEN id="token-38-28" start_char="5838" end_char="5839">to</TOKEN>
				<TOKEN id="token-38-29" start_char="5841" end_char="5843">the</TOKEN>
				<TOKEN id="token-38-30" start_char="5845" end_char="5850">public</TOKEN>
				<TOKEN id="token-38-31" start_char="5852" end_char="5858">because</TOKEN>
				<TOKEN id="token-38-32" start_char="5860" end_char="5873">disinformation</TOKEN>
				<TOKEN id="token-38-33" start_char="5875" end_char="5878">will</TOKEN>
				<TOKEN id="token-38-34" start_char="5880" end_char="5885">spread</TOKEN>
				<TOKEN id="token-38-35" start_char="5887" end_char="5892">faster</TOKEN>
				<TOKEN id="token-38-36" start_char="5894" end_char="5897">than</TOKEN>
				<TOKEN id="token-38-37" start_char="5899" end_char="5903">facts</TOKEN>
				<TOKEN id="token-38-38" start_char="5904" end_char="5904">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-39" start_char="5906" end_char="5926">
				<ORIGINAL_TEXT>(Glen Kugelstadt/CBC)</ORIGINAL_TEXT>
				<TOKEN id="token-39-0" start_char="5906" end_char="5906">(</TOKEN>
				<TOKEN id="token-39-1" start_char="5907" end_char="5910">Glen</TOKEN>
				<TOKEN id="token-39-2" start_char="5912" end_char="5921">Kugelstadt</TOKEN>
				<TOKEN id="token-39-3" start_char="5922" end_char="5922">/</TOKEN>
				<TOKEN id="token-39-4" start_char="5923" end_char="5925">CBC</TOKEN>
				<TOKEN id="token-39-5" start_char="5926" end_char="5926">)</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-40" start_char="5928" end_char="6276">
				<ORIGINAL_TEXT>&quot;It's incredibly challenging during fast-moving outbreaks of any disease to balance between information to keep the public safe and prevent something from becoming a massive epidemic and also trying to provide truthful information and also providing enough so you don't end up with a vacuum, which is where disinformation can flourish,&quot; Tworek says.</ORIGINAL_TEXT>
				<TOKEN id="token-40-0" start_char="5928" end_char="5928">&quot;</TOKEN>
				<TOKEN id="token-40-1" start_char="5929" end_char="5930">It</TOKEN>
				<TOKEN id="token-40-2" start_char="5931" end_char="5931">'</TOKEN>
				<TOKEN id="token-40-3" start_char="5932" end_char="5932">s</TOKEN>
				<TOKEN id="token-40-4" start_char="5934" end_char="5943">incredibly</TOKEN>
				<TOKEN id="token-40-5" start_char="5945" end_char="5955">challenging</TOKEN>
				<TOKEN id="token-40-6" start_char="5957" end_char="5962">during</TOKEN>
				<TOKEN id="token-40-7" start_char="5964" end_char="5967">fast</TOKEN>
				<TOKEN id="token-40-8" start_char="5968" end_char="5968">-</TOKEN>
				<TOKEN id="token-40-9" start_char="5969" end_char="5974">moving</TOKEN>
				<TOKEN id="token-40-10" start_char="5976" end_char="5984">outbreaks</TOKEN>
				<TOKEN id="token-40-11" start_char="5986" end_char="5987">of</TOKEN>
				<TOKEN id="token-40-12" start_char="5989" end_char="5991">any</TOKEN>
				<TOKEN id="token-40-13" start_char="5993" end_char="5999">disease</TOKEN>
				<TOKEN id="token-40-14" start_char="6001" end_char="6002">to</TOKEN>
				<TOKEN id="token-40-15" start_char="6004" end_char="6010">balance</TOKEN>
				<TOKEN id="token-40-16" start_char="6012" end_char="6018">between</TOKEN>
				<TOKEN id="token-40-17" start_char="6020" end_char="6030">information</TOKEN>
				<TOKEN id="token-40-18" start_char="6032" end_char="6033">to</TOKEN>
				<TOKEN id="token-40-19" start_char="6035" end_char="6038">keep</TOKEN>
				<TOKEN id="token-40-20" start_char="6040" end_char="6042">the</TOKEN>
				<TOKEN id="token-40-21" start_char="6044" end_char="6049">public</TOKEN>
				<TOKEN id="token-40-22" start_char="6051" end_char="6054">safe</TOKEN>
				<TOKEN id="token-40-23" start_char="6056" end_char="6058">and</TOKEN>
				<TOKEN id="token-40-24" start_char="6060" end_char="6066">prevent</TOKEN>
				<TOKEN id="token-40-25" start_char="6068" end_char="6076">something</TOKEN>
				<TOKEN id="token-40-26" start_char="6078" end_char="6081">from</TOKEN>
				<TOKEN id="token-40-27" start_char="6083" end_char="6090">becoming</TOKEN>
				<TOKEN id="token-40-28" start_char="6092" end_char="6092">a</TOKEN>
				<TOKEN id="token-40-29" start_char="6094" end_char="6100">massive</TOKEN>
				<TOKEN id="token-40-30" start_char="6102" end_char="6109">epidemic</TOKEN>
				<TOKEN id="token-40-31" start_char="6111" end_char="6113">and</TOKEN>
				<TOKEN id="token-40-32" start_char="6115" end_char="6118">also</TOKEN>
				<TOKEN id="token-40-33" start_char="6120" end_char="6125">trying</TOKEN>
				<TOKEN id="token-40-34" start_char="6127" end_char="6128">to</TOKEN>
				<TOKEN id="token-40-35" start_char="6130" end_char="6136">provide</TOKEN>
				<TOKEN id="token-40-36" start_char="6138" end_char="6145">truthful</TOKEN>
				<TOKEN id="token-40-37" start_char="6147" end_char="6157">information</TOKEN>
				<TOKEN id="token-40-38" start_char="6159" end_char="6161">and</TOKEN>
				<TOKEN id="token-40-39" start_char="6163" end_char="6166">also</TOKEN>
				<TOKEN id="token-40-40" start_char="6168" end_char="6176">providing</TOKEN>
				<TOKEN id="token-40-41" start_char="6178" end_char="6183">enough</TOKEN>
				<TOKEN id="token-40-42" start_char="6185" end_char="6186">so</TOKEN>
				<TOKEN id="token-40-43" start_char="6188" end_char="6190">you</TOKEN>
				<TOKEN id="token-40-44" start_char="6192" end_char="6194">don</TOKEN>
				<TOKEN id="token-40-45" start_char="6195" end_char="6195">'</TOKEN>
				<TOKEN id="token-40-46" start_char="6196" end_char="6196">t</TOKEN>
				<TOKEN id="token-40-47" start_char="6198" end_char="6200">end</TOKEN>
				<TOKEN id="token-40-48" start_char="6202" end_char="6203">up</TOKEN>
				<TOKEN id="token-40-49" start_char="6205" end_char="6208">with</TOKEN>
				<TOKEN id="token-40-50" start_char="6210" end_char="6210">a</TOKEN>
				<TOKEN id="token-40-51" start_char="6212" end_char="6217">vacuum</TOKEN>
				<TOKEN id="token-40-52" start_char="6218" end_char="6218">,</TOKEN>
				<TOKEN id="token-40-53" start_char="6220" end_char="6224">which</TOKEN>
				<TOKEN id="token-40-54" start_char="6226" end_char="6227">is</TOKEN>
				<TOKEN id="token-40-55" start_char="6229" end_char="6233">where</TOKEN>
				<TOKEN id="token-40-56" start_char="6235" end_char="6248">disinformation</TOKEN>
				<TOKEN id="token-40-57" start_char="6250" end_char="6252">can</TOKEN>
				<TOKEN id="token-40-58" start_char="6254" end_char="6261">flourish</TOKEN>
				<TOKEN id="token-40-59" start_char="6262" end_char="6263">,&quot;</TOKEN>
				<TOKEN id="token-40-60" start_char="6265" end_char="6270">Tworek</TOKEN>
				<TOKEN id="token-40-61" start_char="6272" end_char="6275">says</TOKEN>
				<TOKEN id="token-40-62" start_char="6276" end_char="6276">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-41" start_char="6278" end_char="6558">
				<ORIGINAL_TEXT>&quot;We've seen in previous outbreaks it's been difficult to get this right, but I'd emphasize this is actually a crucial element of what we need to be thinking about into the future — how do we actually communicate well and swiftly with general public with all types of health scares?</ORIGINAL_TEXT>
				<TOKEN id="token-41-0" start_char="6278" end_char="6278">&quot;</TOKEN>
				<TOKEN id="token-41-1" start_char="6279" end_char="6280">We</TOKEN>
				<TOKEN id="token-41-2" start_char="6281" end_char="6281">'</TOKEN>
				<TOKEN id="token-41-3" start_char="6282" end_char="6283">ve</TOKEN>
				<TOKEN id="token-41-4" start_char="6285" end_char="6288">seen</TOKEN>
				<TOKEN id="token-41-5" start_char="6290" end_char="6291">in</TOKEN>
				<TOKEN id="token-41-6" start_char="6293" end_char="6300">previous</TOKEN>
				<TOKEN id="token-41-7" start_char="6302" end_char="6310">outbreaks</TOKEN>
				<TOKEN id="token-41-8" start_char="6312" end_char="6313">it</TOKEN>
				<TOKEN id="token-41-9" start_char="6314" end_char="6314">'</TOKEN>
				<TOKEN id="token-41-10" start_char="6315" end_char="6315">s</TOKEN>
				<TOKEN id="token-41-11" start_char="6317" end_char="6320">been</TOKEN>
				<TOKEN id="token-41-12" start_char="6322" end_char="6330">difficult</TOKEN>
				<TOKEN id="token-41-13" start_char="6332" end_char="6333">to</TOKEN>
				<TOKEN id="token-41-14" start_char="6335" end_char="6337">get</TOKEN>
				<TOKEN id="token-41-15" start_char="6339" end_char="6342">this</TOKEN>
				<TOKEN id="token-41-16" start_char="6344" end_char="6348">right</TOKEN>
				<TOKEN id="token-41-17" start_char="6349" end_char="6349">,</TOKEN>
				<TOKEN id="token-41-18" start_char="6351" end_char="6353">but</TOKEN>
				<TOKEN id="token-41-19" start_char="6355" end_char="6355">I</TOKEN>
				<TOKEN id="token-41-20" start_char="6356" end_char="6356">'</TOKEN>
				<TOKEN id="token-41-21" start_char="6357" end_char="6357">d</TOKEN>
				<TOKEN id="token-41-22" start_char="6359" end_char="6367">emphasize</TOKEN>
				<TOKEN id="token-41-23" start_char="6369" end_char="6372">this</TOKEN>
				<TOKEN id="token-41-24" start_char="6374" end_char="6375">is</TOKEN>
				<TOKEN id="token-41-25" start_char="6377" end_char="6384">actually</TOKEN>
				<TOKEN id="token-41-26" start_char="6386" end_char="6386">a</TOKEN>
				<TOKEN id="token-41-27" start_char="6388" end_char="6394">crucial</TOKEN>
				<TOKEN id="token-41-28" start_char="6396" end_char="6402">element</TOKEN>
				<TOKEN id="token-41-29" start_char="6404" end_char="6405">of</TOKEN>
				<TOKEN id="token-41-30" start_char="6407" end_char="6410">what</TOKEN>
				<TOKEN id="token-41-31" start_char="6412" end_char="6413">we</TOKEN>
				<TOKEN id="token-41-32" start_char="6415" end_char="6418">need</TOKEN>
				<TOKEN id="token-41-33" start_char="6420" end_char="6421">to</TOKEN>
				<TOKEN id="token-41-34" start_char="6423" end_char="6424">be</TOKEN>
				<TOKEN id="token-41-35" start_char="6426" end_char="6433">thinking</TOKEN>
				<TOKEN id="token-41-36" start_char="6435" end_char="6439">about</TOKEN>
				<TOKEN id="token-41-37" start_char="6441" end_char="6444">into</TOKEN>
				<TOKEN id="token-41-38" start_char="6446" end_char="6448">the</TOKEN>
				<TOKEN id="token-41-39" start_char="6450" end_char="6455">future</TOKEN>
				<TOKEN id="token-41-40" start_char="6457" end_char="6457">—</TOKEN>
				<TOKEN id="token-41-41" start_char="6459" end_char="6461">how</TOKEN>
				<TOKEN id="token-41-42" start_char="6463" end_char="6464">do</TOKEN>
				<TOKEN id="token-41-43" start_char="6466" end_char="6467">we</TOKEN>
				<TOKEN id="token-41-44" start_char="6469" end_char="6476">actually</TOKEN>
				<TOKEN id="token-41-45" start_char="6478" end_char="6488">communicate</TOKEN>
				<TOKEN id="token-41-46" start_char="6490" end_char="6493">well</TOKEN>
				<TOKEN id="token-41-47" start_char="6495" end_char="6497">and</TOKEN>
				<TOKEN id="token-41-48" start_char="6499" end_char="6505">swiftly</TOKEN>
				<TOKEN id="token-41-49" start_char="6507" end_char="6510">with</TOKEN>
				<TOKEN id="token-41-50" start_char="6512" end_char="6518">general</TOKEN>
				<TOKEN id="token-41-51" start_char="6520" end_char="6525">public</TOKEN>
				<TOKEN id="token-41-52" start_char="6527" end_char="6530">with</TOKEN>
				<TOKEN id="token-41-53" start_char="6532" end_char="6534">all</TOKEN>
				<TOKEN id="token-41-54" start_char="6536" end_char="6540">types</TOKEN>
				<TOKEN id="token-41-55" start_char="6542" end_char="6543">of</TOKEN>
				<TOKEN id="token-41-56" start_char="6545" end_char="6550">health</TOKEN>
				<TOKEN id="token-41-57" start_char="6552" end_char="6557">scares</TOKEN>
				<TOKEN id="token-41-58" start_char="6558" end_char="6558">?</TOKEN>
			</SEG>
			<SEG id="covid19scenario-163-42" start_char="6560" end_char="6642">
				<ORIGINAL_TEXT>This will not be the last time we face disinformation during a potential epidemic.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-42-0" start_char="6560" end_char="6563">This</TOKEN>
				<TOKEN id="token-42-1" start_char="6565" end_char="6568">will</TOKEN>
				<TOKEN id="token-42-2" start_char="6570" end_char="6572">not</TOKEN>
				<TOKEN id="token-42-3" start_char="6574" end_char="6575">be</TOKEN>
				<TOKEN id="token-42-4" start_char="6577" end_char="6579">the</TOKEN>
				<TOKEN id="token-42-5" start_char="6581" end_char="6584">last</TOKEN>
				<TOKEN id="token-42-6" start_char="6586" end_char="6589">time</TOKEN>
				<TOKEN id="token-42-7" start_char="6591" end_char="6592">we</TOKEN>
				<TOKEN id="token-42-8" start_char="6594" end_char="6597">face</TOKEN>
				<TOKEN id="token-42-9" start_char="6599" end_char="6612">disinformation</TOKEN>
				<TOKEN id="token-42-10" start_char="6614" end_char="6619">during</TOKEN>
				<TOKEN id="token-42-11" start_char="6621" end_char="6621">a</TOKEN>
				<TOKEN id="token-42-12" start_char="6623" end_char="6631">potential</TOKEN>
				<TOKEN id="token-42-13" start_char="6633" end_char="6640">epidemic</TOKEN>
				<TOKEN id="token-42-14" start_char="6641" end_char="6642">.&quot;</TOKEN>
			</SEG>
		</TEXT>
	</DOC>
</LCTL_TEXT>
