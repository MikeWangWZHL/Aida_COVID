<?xml version="1.0" encoding="utf-8"?>
<LCTL_TEXT>
	<DOC id="covid19scenario-227">
		<TEXT>
			<SEG id="covid19scenario-227-0" start_char="0" end_char="137">
				<ORIGINAL_TEXT>Researchers wearing positive pressure personnel suits at a US National Institute of Allergy and Infectious Diseases biosafety level 4 lab.</ORIGINAL_TEXT>
				<TOKEN id="token-0-0" start_char="0" end_char="10">Researchers</TOKEN>
				<TOKEN id="token-0-1" start_char="12" end_char="18">wearing</TOKEN>
				<TOKEN id="token-0-2" start_char="20" end_char="27">positive</TOKEN>
				<TOKEN id="token-0-3" start_char="29" end_char="36">pressure</TOKEN>
				<TOKEN id="token-0-4" start_char="38" end_char="46">personnel</TOKEN>
				<TOKEN id="token-0-5" start_char="48" end_char="52">suits</TOKEN>
				<TOKEN id="token-0-6" start_char="54" end_char="55">at</TOKEN>
				<TOKEN id="token-0-7" start_char="57" end_char="57">a</TOKEN>
				<TOKEN id="token-0-8" start_char="59" end_char="60">US</TOKEN>
				<TOKEN id="token-0-9" start_char="62" end_char="69">National</TOKEN>
				<TOKEN id="token-0-10" start_char="71" end_char="79">Institute</TOKEN>
				<TOKEN id="token-0-11" start_char="81" end_char="82">of</TOKEN>
				<TOKEN id="token-0-12" start_char="84" end_char="90">Allergy</TOKEN>
				<TOKEN id="token-0-13" start_char="92" end_char="94">and</TOKEN>
				<TOKEN id="token-0-14" start_char="96" end_char="105">Infectious</TOKEN>
				<TOKEN id="token-0-15" start_char="107" end_char="114">Diseases</TOKEN>
				<TOKEN id="token-0-16" start_char="116" end_char="124">biosafety</TOKEN>
				<TOKEN id="token-0-17" start_char="126" end_char="130">level</TOKEN>
				<TOKEN id="token-0-18" start_char="132" end_char="132">4</TOKEN>
				<TOKEN id="token-0-19" start_char="134" end_char="136">lab</TOKEN>
				<TOKEN id="token-0-20" start_char="137" end_char="137">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-1" start_char="139" end_char="200">
				<ORIGINAL_TEXT>Credit: National Institute of Allergy and Infectious Diseases.</ORIGINAL_TEXT>
				<TOKEN id="token-1-0" start_char="139" end_char="144">Credit</TOKEN>
				<TOKEN id="token-1-1" start_char="145" end_char="145">:</TOKEN>
				<TOKEN id="token-1-2" start_char="147" end_char="154">National</TOKEN>
				<TOKEN id="token-1-3" start_char="156" end_char="164">Institute</TOKEN>
				<TOKEN id="token-1-4" start_char="166" end_char="167">of</TOKEN>
				<TOKEN id="token-1-5" start_char="169" end_char="175">Allergy</TOKEN>
				<TOKEN id="token-1-6" start_char="177" end_char="179">and</TOKEN>
				<TOKEN id="token-1-7" start_char="181" end_char="190">Infectious</TOKEN>
				<TOKEN id="token-1-8" start_char="192" end_char="199">Diseases</TOKEN>
				<TOKEN id="token-1-9" start_char="200" end_char="200">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-2" start_char="202" end_char="250">
				<ORIGINAL_TEXT>Much remains uncertain about the new coronavirus.</ORIGINAL_TEXT>
				<TOKEN id="token-2-0" start_char="202" end_char="205">Much</TOKEN>
				<TOKEN id="token-2-1" start_char="207" end_char="213">remains</TOKEN>
				<TOKEN id="token-2-2" start_char="215" end_char="223">uncertain</TOKEN>
				<TOKEN id="token-2-3" start_char="225" end_char="229">about</TOKEN>
				<TOKEN id="token-2-4" start_char="231" end_char="233">the</TOKEN>
				<TOKEN id="token-2-5" start_char="235" end_char="237">new</TOKEN>
				<TOKEN id="token-2-6" start_char="239" end_char="249">coronavirus</TOKEN>
				<TOKEN id="token-2-7" start_char="250" end_char="250">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-3" start_char="252" end_char="305">
				<ORIGINAL_TEXT>What treatments will prove effective against COVID-19?</ORIGINAL_TEXT>
				<TOKEN id="token-3-0" start_char="252" end_char="255">What</TOKEN>
				<TOKEN id="token-3-1" start_char="257" end_char="266">treatments</TOKEN>
				<TOKEN id="token-3-2" start_char="268" end_char="271">will</TOKEN>
				<TOKEN id="token-3-3" start_char="273" end_char="277">prove</TOKEN>
				<TOKEN id="token-3-4" start_char="279" end_char="287">effective</TOKEN>
				<TOKEN id="token-3-5" start_char="289" end_char="295">against</TOKEN>
				<TOKEN id="token-3-6" start_char="297" end_char="301">COVID</TOKEN>
				<TOKEN id="token-3-7" start_char="302" end_char="302">-</TOKEN>
				<TOKEN id="token-3-8" start_char="303" end_char="304">19</TOKEN>
				<TOKEN id="token-3-9" start_char="305" end_char="305">?</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-4" start_char="307" end_char="351">
				<ORIGINAL_TEXT>When will a vaccine for the disease be ready?</ORIGINAL_TEXT>
				<TOKEN id="token-4-0" start_char="307" end_char="310">When</TOKEN>
				<TOKEN id="token-4-1" start_char="312" end_char="315">will</TOKEN>
				<TOKEN id="token-4-2" start_char="317" end_char="317">a</TOKEN>
				<TOKEN id="token-4-3" start_char="319" end_char="325">vaccine</TOKEN>
				<TOKEN id="token-4-4" start_char="327" end_char="329">for</TOKEN>
				<TOKEN id="token-4-5" start_char="331" end_char="333">the</TOKEN>
				<TOKEN id="token-4-6" start_char="335" end_char="341">disease</TOKEN>
				<TOKEN id="token-4-7" start_char="343" end_char="344">be</TOKEN>
				<TOKEN id="token-4-8" start_char="346" end_char="350">ready</TOKEN>
				<TOKEN id="token-4-9" start_char="351" end_char="351">?</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-5" start_char="353" end_char="457">
				<ORIGINAL_TEXT>What level of social distancing will be required to tame the outbreak, and how long will it need to last?</ORIGINAL_TEXT>
				<TOKEN id="token-5-0" start_char="353" end_char="356">What</TOKEN>
				<TOKEN id="token-5-1" start_char="358" end_char="362">level</TOKEN>
				<TOKEN id="token-5-2" start_char="364" end_char="365">of</TOKEN>
				<TOKEN id="token-5-3" start_char="367" end_char="372">social</TOKEN>
				<TOKEN id="token-5-4" start_char="374" end_char="383">distancing</TOKEN>
				<TOKEN id="token-5-5" start_char="385" end_char="388">will</TOKEN>
				<TOKEN id="token-5-6" start_char="390" end_char="391">be</TOKEN>
				<TOKEN id="token-5-7" start_char="393" end_char="400">required</TOKEN>
				<TOKEN id="token-5-8" start_char="402" end_char="403">to</TOKEN>
				<TOKEN id="token-5-9" start_char="405" end_char="408">tame</TOKEN>
				<TOKEN id="token-5-10" start_char="410" end_char="412">the</TOKEN>
				<TOKEN id="token-5-11" start_char="414" end_char="421">outbreak</TOKEN>
				<TOKEN id="token-5-12" start_char="422" end_char="422">,</TOKEN>
				<TOKEN id="token-5-13" start_char="424" end_char="426">and</TOKEN>
				<TOKEN id="token-5-14" start_char="428" end_char="430">how</TOKEN>
				<TOKEN id="token-5-15" start_char="432" end_char="435">long</TOKEN>
				<TOKEN id="token-5-16" start_char="437" end_char="440">will</TOKEN>
				<TOKEN id="token-5-17" start_char="442" end_char="443">it</TOKEN>
				<TOKEN id="token-5-18" start_char="445" end_char="448">need</TOKEN>
				<TOKEN id="token-5-19" start_char="450" end_char="451">to</TOKEN>
				<TOKEN id="token-5-20" start_char="453" end_char="456">last</TOKEN>
				<TOKEN id="token-5-21" start_char="457" end_char="457">?</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-6" start_char="459" end_char="487">
				<ORIGINAL_TEXT>Will outbreaks come in waves?</ORIGINAL_TEXT>
				<TOKEN id="token-6-0" start_char="459" end_char="462">Will</TOKEN>
				<TOKEN id="token-6-1" start_char="464" end_char="472">outbreaks</TOKEN>
				<TOKEN id="token-6-2" start_char="474" end_char="477">come</TOKEN>
				<TOKEN id="token-6-3" start_char="479" end_char="480">in</TOKEN>
				<TOKEN id="token-6-4" start_char="482" end_char="486">waves</TOKEN>
				<TOKEN id="token-6-5" start_char="487" end_char="487">?</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-7" start_char="489" end_char="672">
				<ORIGINAL_TEXT>Amid all these vital forward-looking questions remains a more retrospective but still important one: Where did SARS-CoV-2, the virus that causes COVID-19, come from in the first place?</ORIGINAL_TEXT>
				<TOKEN id="token-7-0" start_char="489" end_char="492">Amid</TOKEN>
				<TOKEN id="token-7-1" start_char="494" end_char="496">all</TOKEN>
				<TOKEN id="token-7-2" start_char="498" end_char="502">these</TOKEN>
				<TOKEN id="token-7-3" start_char="504" end_char="508">vital</TOKEN>
				<TOKEN id="token-7-4" start_char="510" end_char="516">forward</TOKEN>
				<TOKEN id="token-7-5" start_char="517" end_char="517">-</TOKEN>
				<TOKEN id="token-7-6" start_char="518" end_char="524">looking</TOKEN>
				<TOKEN id="token-7-7" start_char="526" end_char="534">questions</TOKEN>
				<TOKEN id="token-7-8" start_char="536" end_char="542">remains</TOKEN>
				<TOKEN id="token-7-9" start_char="544" end_char="544">a</TOKEN>
				<TOKEN id="token-7-10" start_char="546" end_char="549">more</TOKEN>
				<TOKEN id="token-7-11" start_char="551" end_char="563">retrospective</TOKEN>
				<TOKEN id="token-7-12" start_char="565" end_char="567">but</TOKEN>
				<TOKEN id="token-7-13" start_char="569" end_char="573">still</TOKEN>
				<TOKEN id="token-7-14" start_char="575" end_char="583">important</TOKEN>
				<TOKEN id="token-7-15" start_char="585" end_char="587">one</TOKEN>
				<TOKEN id="token-7-16" start_char="588" end_char="588">:</TOKEN>
				<TOKEN id="token-7-17" start_char="590" end_char="594">Where</TOKEN>
				<TOKEN id="token-7-18" start_char="596" end_char="598">did</TOKEN>
				<TOKEN id="token-7-19" start_char="600" end_char="603">SARS</TOKEN>
				<TOKEN id="token-7-20" start_char="604" end_char="604">-</TOKEN>
				<TOKEN id="token-7-21" start_char="605" end_char="607">CoV</TOKEN>
				<TOKEN id="token-7-22" start_char="608" end_char="608">-</TOKEN>
				<TOKEN id="token-7-23" start_char="609" end_char="609">2</TOKEN>
				<TOKEN id="token-7-24" start_char="610" end_char="610">,</TOKEN>
				<TOKEN id="token-7-25" start_char="612" end_char="614">the</TOKEN>
				<TOKEN id="token-7-26" start_char="616" end_char="620">virus</TOKEN>
				<TOKEN id="token-7-27" start_char="622" end_char="625">that</TOKEN>
				<TOKEN id="token-7-28" start_char="627" end_char="632">causes</TOKEN>
				<TOKEN id="token-7-29" start_char="634" end_char="638">COVID</TOKEN>
				<TOKEN id="token-7-30" start_char="639" end_char="639">-</TOKEN>
				<TOKEN id="token-7-31" start_char="640" end_char="641">19</TOKEN>
				<TOKEN id="token-7-32" start_char="642" end_char="642">,</TOKEN>
				<TOKEN id="token-7-33" start_char="644" end_char="647">come</TOKEN>
				<TOKEN id="token-7-34" start_char="649" end_char="652">from</TOKEN>
				<TOKEN id="token-7-35" start_char="654" end_char="655">in</TOKEN>
				<TOKEN id="token-7-36" start_char="657" end_char="659">the</TOKEN>
				<TOKEN id="token-7-37" start_char="661" end_char="665">first</TOKEN>
				<TOKEN id="token-7-38" start_char="667" end_char="671">place</TOKEN>
				<TOKEN id="token-7-39" start_char="672" end_char="672">?</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-8" start_char="674" end_char="738">
				<ORIGINAL_TEXT>Experts seem to agree it wasn’t the product of human engineering.</ORIGINAL_TEXT>
				<TOKEN id="token-8-0" start_char="674" end_char="680">Experts</TOKEN>
				<TOKEN id="token-8-1" start_char="682" end_char="685">seem</TOKEN>
				<TOKEN id="token-8-2" start_char="687" end_char="688">to</TOKEN>
				<TOKEN id="token-8-3" start_char="690" end_char="694">agree</TOKEN>
				<TOKEN id="token-8-4" start_char="696" end_char="697">it</TOKEN>
				<TOKEN id="token-8-5" start_char="699" end_char="702">wasn</TOKEN>
				<TOKEN id="token-8-6" start_char="703" end_char="703">’</TOKEN>
				<TOKEN id="token-8-7" start_char="704" end_char="704">t</TOKEN>
				<TOKEN id="token-8-8" start_char="706" end_char="708">the</TOKEN>
				<TOKEN id="token-8-9" start_char="710" end_char="716">product</TOKEN>
				<TOKEN id="token-8-10" start_char="718" end_char="719">of</TOKEN>
				<TOKEN id="token-8-11" start_char="721" end_char="725">human</TOKEN>
				<TOKEN id="token-8-12" start_char="727" end_char="737">engineering</TOKEN>
				<TOKEN id="token-8-13" start_char="738" end_char="738">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-9" start_char="740" end_char="922">
				<ORIGINAL_TEXT>Much research has been focused on the hypothesis that bats passed a virus to some intermediate host—perhaps pangolins, scaly ant-eating mammals—which subsequently passed it to humans.</ORIGINAL_TEXT>
				<TOKEN id="token-9-0" start_char="740" end_char="743">Much</TOKEN>
				<TOKEN id="token-9-1" start_char="745" end_char="752">research</TOKEN>
				<TOKEN id="token-9-2" start_char="754" end_char="756">has</TOKEN>
				<TOKEN id="token-9-3" start_char="758" end_char="761">been</TOKEN>
				<TOKEN id="token-9-4" start_char="763" end_char="769">focused</TOKEN>
				<TOKEN id="token-9-5" start_char="771" end_char="772">on</TOKEN>
				<TOKEN id="token-9-6" start_char="774" end_char="776">the</TOKEN>
				<TOKEN id="token-9-7" start_char="778" end_char="787">hypothesis</TOKEN>
				<TOKEN id="token-9-8" start_char="789" end_char="792">that</TOKEN>
				<TOKEN id="token-9-9" start_char="794" end_char="797">bats</TOKEN>
				<TOKEN id="token-9-10" start_char="799" end_char="804">passed</TOKEN>
				<TOKEN id="token-9-11" start_char="806" end_char="806">a</TOKEN>
				<TOKEN id="token-9-12" start_char="808" end_char="812">virus</TOKEN>
				<TOKEN id="token-9-13" start_char="814" end_char="815">to</TOKEN>
				<TOKEN id="token-9-14" start_char="817" end_char="820">some</TOKEN>
				<TOKEN id="token-9-15" start_char="822" end_char="833">intermediate</TOKEN>
				<TOKEN id="token-9-16" start_char="835" end_char="838">host</TOKEN>
				<TOKEN id="token-9-17" start_char="839" end_char="839">—</TOKEN>
				<TOKEN id="token-9-18" start_char="840" end_char="846">perhaps</TOKEN>
				<TOKEN id="token-9-19" start_char="848" end_char="856">pangolins</TOKEN>
				<TOKEN id="token-9-20" start_char="857" end_char="857">,</TOKEN>
				<TOKEN id="token-9-21" start_char="859" end_char="863">scaly</TOKEN>
				<TOKEN id="token-9-22" start_char="865" end_char="867">ant</TOKEN>
				<TOKEN id="token-9-23" start_char="868" end_char="868">-</TOKEN>
				<TOKEN id="token-9-24" start_char="869" end_char="874">eating</TOKEN>
				<TOKEN id="token-9-25" start_char="876" end_char="882">mammals</TOKEN>
				<TOKEN id="token-9-26" start_char="883" end_char="883">—</TOKEN>
				<TOKEN id="token-9-27" start_char="884" end_char="888">which</TOKEN>
				<TOKEN id="token-9-28" start_char="890" end_char="901">subsequently</TOKEN>
				<TOKEN id="token-9-29" start_char="903" end_char="908">passed</TOKEN>
				<TOKEN id="token-9-30" start_char="910" end_char="911">it</TOKEN>
				<TOKEN id="token-9-31" start_char="913" end_char="914">to</TOKEN>
				<TOKEN id="token-9-32" start_char="916" end_char="921">humans</TOKEN>
				<TOKEN id="token-9-33" start_char="922" end_char="922">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-10" start_char="924" end_char="980">
				<ORIGINAL_TEXT>But the pangolin theory has not been conclusively proven.</ORIGINAL_TEXT>
				<TOKEN id="token-10-0" start_char="924" end_char="926">But</TOKEN>
				<TOKEN id="token-10-1" start_char="928" end_char="930">the</TOKEN>
				<TOKEN id="token-10-2" start_char="932" end_char="939">pangolin</TOKEN>
				<TOKEN id="token-10-3" start_char="941" end_char="946">theory</TOKEN>
				<TOKEN id="token-10-4" start_char="948" end_char="950">has</TOKEN>
				<TOKEN id="token-10-5" start_char="952" end_char="954">not</TOKEN>
				<TOKEN id="token-10-6" start_char="956" end_char="959">been</TOKEN>
				<TOKEN id="token-10-7" start_char="961" end_char="972">conclusively</TOKEN>
				<TOKEN id="token-10-8" start_char="974" end_char="979">proven</TOKEN>
				<TOKEN id="token-10-9" start_char="980" end_char="980">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-11" start_char="982" end_char="1115">
				<ORIGINAL_TEXT>Some experts wonder whether a virus under study at a lab could have been accidentally released, something that’s happened in the past.</ORIGINAL_TEXT>
				<TOKEN id="token-11-0" start_char="982" end_char="985">Some</TOKEN>
				<TOKEN id="token-11-1" start_char="987" end_char="993">experts</TOKEN>
				<TOKEN id="token-11-2" start_char="995" end_char="1000">wonder</TOKEN>
				<TOKEN id="token-11-3" start_char="1002" end_char="1008">whether</TOKEN>
				<TOKEN id="token-11-4" start_char="1010" end_char="1010">a</TOKEN>
				<TOKEN id="token-11-5" start_char="1012" end_char="1016">virus</TOKEN>
				<TOKEN id="token-11-6" start_char="1018" end_char="1022">under</TOKEN>
				<TOKEN id="token-11-7" start_char="1024" end_char="1028">study</TOKEN>
				<TOKEN id="token-11-8" start_char="1030" end_char="1031">at</TOKEN>
				<TOKEN id="token-11-9" start_char="1033" end_char="1033">a</TOKEN>
				<TOKEN id="token-11-10" start_char="1035" end_char="1037">lab</TOKEN>
				<TOKEN id="token-11-11" start_char="1039" end_char="1043">could</TOKEN>
				<TOKEN id="token-11-12" start_char="1045" end_char="1048">have</TOKEN>
				<TOKEN id="token-11-13" start_char="1050" end_char="1053">been</TOKEN>
				<TOKEN id="token-11-14" start_char="1055" end_char="1066">accidentally</TOKEN>
				<TOKEN id="token-11-15" start_char="1068" end_char="1075">released</TOKEN>
				<TOKEN id="token-11-16" start_char="1076" end_char="1076">,</TOKEN>
				<TOKEN id="token-11-17" start_char="1078" end_char="1086">something</TOKEN>
				<TOKEN id="token-11-18" start_char="1088" end_char="1091">that</TOKEN>
				<TOKEN id="token-11-19" start_char="1092" end_char="1092">’</TOKEN>
				<TOKEN id="token-11-20" start_char="1093" end_char="1093">s</TOKEN>
				<TOKEN id="token-11-21" start_char="1095" end_char="1102">happened</TOKEN>
				<TOKEN id="token-11-22" start_char="1104" end_char="1105">in</TOKEN>
				<TOKEN id="token-11-23" start_char="1107" end_char="1109">the</TOKEN>
				<TOKEN id="token-11-24" start_char="1111" end_char="1114">past</TOKEN>
				<TOKEN id="token-11-25" start_char="1115" end_char="1115">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-12" start_char="1117" end_char="1362">
				<ORIGINAL_TEXT>Among the latest entrants to the debate about the provenance of SARS-CoV-2 are the authors of a March 17 Nature Medicine piece that takes a look at the virus’s characteristics—including the sites on the virus that allow it to bind to human cells.</ORIGINAL_TEXT>
				<TOKEN id="token-12-0" start_char="1117" end_char="1121">Among</TOKEN>
				<TOKEN id="token-12-1" start_char="1123" end_char="1125">the</TOKEN>
				<TOKEN id="token-12-2" start_char="1127" end_char="1132">latest</TOKEN>
				<TOKEN id="token-12-3" start_char="1134" end_char="1141">entrants</TOKEN>
				<TOKEN id="token-12-4" start_char="1143" end_char="1144">to</TOKEN>
				<TOKEN id="token-12-5" start_char="1146" end_char="1148">the</TOKEN>
				<TOKEN id="token-12-6" start_char="1150" end_char="1155">debate</TOKEN>
				<TOKEN id="token-12-7" start_char="1157" end_char="1161">about</TOKEN>
				<TOKEN id="token-12-8" start_char="1163" end_char="1165">the</TOKEN>
				<TOKEN id="token-12-9" start_char="1167" end_char="1176">provenance</TOKEN>
				<TOKEN id="token-12-10" start_char="1178" end_char="1179">of</TOKEN>
				<TOKEN id="token-12-11" start_char="1181" end_char="1184">SARS</TOKEN>
				<TOKEN id="token-12-12" start_char="1185" end_char="1185">-</TOKEN>
				<TOKEN id="token-12-13" start_char="1186" end_char="1188">CoV</TOKEN>
				<TOKEN id="token-12-14" start_char="1189" end_char="1189">-</TOKEN>
				<TOKEN id="token-12-15" start_char="1190" end_char="1190">2</TOKEN>
				<TOKEN id="token-12-16" start_char="1192" end_char="1194">are</TOKEN>
				<TOKEN id="token-12-17" start_char="1196" end_char="1198">the</TOKEN>
				<TOKEN id="token-12-18" start_char="1200" end_char="1206">authors</TOKEN>
				<TOKEN id="token-12-19" start_char="1208" end_char="1209">of</TOKEN>
				<TOKEN id="token-12-20" start_char="1211" end_char="1211">a</TOKEN>
				<TOKEN id="token-12-21" start_char="1213" end_char="1217">March</TOKEN>
				<TOKEN id="token-12-22" start_char="1219" end_char="1220">17</TOKEN>
				<TOKEN id="token-12-23" start_char="1222" end_char="1227">Nature</TOKEN>
				<TOKEN id="token-12-24" start_char="1229" end_char="1236">Medicine</TOKEN>
				<TOKEN id="token-12-25" start_char="1238" end_char="1242">piece</TOKEN>
				<TOKEN id="token-12-26" start_char="1244" end_char="1247">that</TOKEN>
				<TOKEN id="token-12-27" start_char="1249" end_char="1253">takes</TOKEN>
				<TOKEN id="token-12-28" start_char="1255" end_char="1255">a</TOKEN>
				<TOKEN id="token-12-29" start_char="1257" end_char="1260">look</TOKEN>
				<TOKEN id="token-12-30" start_char="1262" end_char="1263">at</TOKEN>
				<TOKEN id="token-12-31" start_char="1265" end_char="1267">the</TOKEN>
				<TOKEN id="token-12-32" start_char="1269" end_char="1273">virus</TOKEN>
				<TOKEN id="token-12-33" start_char="1274" end_char="1274">’</TOKEN>
				<TOKEN id="token-12-34" start_char="1275" end_char="1275">s</TOKEN>
				<TOKEN id="token-12-35" start_char="1277" end_char="1291">characteristics</TOKEN>
				<TOKEN id="token-12-36" start_char="1292" end_char="1292">—</TOKEN>
				<TOKEN id="token-12-37" start_char="1293" end_char="1301">including</TOKEN>
				<TOKEN id="token-12-38" start_char="1303" end_char="1305">the</TOKEN>
				<TOKEN id="token-12-39" start_char="1307" end_char="1311">sites</TOKEN>
				<TOKEN id="token-12-40" start_char="1313" end_char="1314">on</TOKEN>
				<TOKEN id="token-12-41" start_char="1316" end_char="1318">the</TOKEN>
				<TOKEN id="token-12-42" start_char="1320" end_char="1324">virus</TOKEN>
				<TOKEN id="token-12-43" start_char="1326" end_char="1329">that</TOKEN>
				<TOKEN id="token-12-44" start_char="1331" end_char="1335">allow</TOKEN>
				<TOKEN id="token-12-45" start_char="1337" end_char="1338">it</TOKEN>
				<TOKEN id="token-12-46" start_char="1340" end_char="1341">to</TOKEN>
				<TOKEN id="token-12-47" start_char="1343" end_char="1346">bind</TOKEN>
				<TOKEN id="token-12-48" start_char="1348" end_char="1349">to</TOKEN>
				<TOKEN id="token-12-49" start_char="1351" end_char="1355">human</TOKEN>
				<TOKEN id="token-12-50" start_char="1357" end_char="1361">cells</TOKEN>
				<TOKEN id="token-12-51" start_char="1362" end_char="1362">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-13" start_char="1364" end_char="1483">
				<ORIGINAL_TEXT>They looked at whether the virus was engineered by humans and present what appears to be convincing evidence it was not.</ORIGINAL_TEXT>
				<TOKEN id="token-13-0" start_char="1364" end_char="1367">They</TOKEN>
				<TOKEN id="token-13-1" start_char="1369" end_char="1374">looked</TOKEN>
				<TOKEN id="token-13-2" start_char="1376" end_char="1377">at</TOKEN>
				<TOKEN id="token-13-3" start_char="1379" end_char="1385">whether</TOKEN>
				<TOKEN id="token-13-4" start_char="1387" end_char="1389">the</TOKEN>
				<TOKEN id="token-13-5" start_char="1391" end_char="1395">virus</TOKEN>
				<TOKEN id="token-13-6" start_char="1397" end_char="1399">was</TOKEN>
				<TOKEN id="token-13-7" start_char="1401" end_char="1410">engineered</TOKEN>
				<TOKEN id="token-13-8" start_char="1412" end_char="1413">by</TOKEN>
				<TOKEN id="token-13-9" start_char="1415" end_char="1420">humans</TOKEN>
				<TOKEN id="token-13-10" start_char="1422" end_char="1424">and</TOKEN>
				<TOKEN id="token-13-11" start_char="1426" end_char="1432">present</TOKEN>
				<TOKEN id="token-13-12" start_char="1434" end_char="1437">what</TOKEN>
				<TOKEN id="token-13-13" start_char="1439" end_char="1445">appears</TOKEN>
				<TOKEN id="token-13-14" start_char="1447" end_char="1448">to</TOKEN>
				<TOKEN id="token-13-15" start_char="1450" end_char="1451">be</TOKEN>
				<TOKEN id="token-13-16" start_char="1453" end_char="1462">convincing</TOKEN>
				<TOKEN id="token-13-17" start_char="1464" end_char="1471">evidence</TOKEN>
				<TOKEN id="token-13-18" start_char="1473" end_char="1474">it</TOKEN>
				<TOKEN id="token-13-19" start_char="1476" end_char="1478">was</TOKEN>
				<TOKEN id="token-13-20" start_char="1480" end_char="1482">not</TOKEN>
				<TOKEN id="token-13-21" start_char="1483" end_char="1483">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-14" start_char="1485" end_char="1704">
				<ORIGINAL_TEXT>They also considered the possibility that the outbreak could have resulted from an inadvertent lab release of a virus under study but concluded “we do not believe that any type of laboratory-based scenario is plausible.”</ORIGINAL_TEXT>
				<TOKEN id="token-14-0" start_char="1485" end_char="1488">They</TOKEN>
				<TOKEN id="token-14-1" start_char="1490" end_char="1493">also</TOKEN>
				<TOKEN id="token-14-2" start_char="1495" end_char="1504">considered</TOKEN>
				<TOKEN id="token-14-3" start_char="1506" end_char="1508">the</TOKEN>
				<TOKEN id="token-14-4" start_char="1510" end_char="1520">possibility</TOKEN>
				<TOKEN id="token-14-5" start_char="1522" end_char="1525">that</TOKEN>
				<TOKEN id="token-14-6" start_char="1527" end_char="1529">the</TOKEN>
				<TOKEN id="token-14-7" start_char="1531" end_char="1538">outbreak</TOKEN>
				<TOKEN id="token-14-8" start_char="1540" end_char="1544">could</TOKEN>
				<TOKEN id="token-14-9" start_char="1546" end_char="1549">have</TOKEN>
				<TOKEN id="token-14-10" start_char="1551" end_char="1558">resulted</TOKEN>
				<TOKEN id="token-14-11" start_char="1560" end_char="1563">from</TOKEN>
				<TOKEN id="token-14-12" start_char="1565" end_char="1566">an</TOKEN>
				<TOKEN id="token-14-13" start_char="1568" end_char="1578">inadvertent</TOKEN>
				<TOKEN id="token-14-14" start_char="1580" end_char="1582">lab</TOKEN>
				<TOKEN id="token-14-15" start_char="1584" end_char="1590">release</TOKEN>
				<TOKEN id="token-14-16" start_char="1592" end_char="1593">of</TOKEN>
				<TOKEN id="token-14-17" start_char="1595" end_char="1595">a</TOKEN>
				<TOKEN id="token-14-18" start_char="1597" end_char="1601">virus</TOKEN>
				<TOKEN id="token-14-19" start_char="1603" end_char="1607">under</TOKEN>
				<TOKEN id="token-14-20" start_char="1609" end_char="1613">study</TOKEN>
				<TOKEN id="token-14-21" start_char="1615" end_char="1617">but</TOKEN>
				<TOKEN id="token-14-22" start_char="1619" end_char="1627">concluded</TOKEN>
				<TOKEN id="token-14-23" start_char="1629" end_char="1629">“</TOKEN>
				<TOKEN id="token-14-24" start_char="1630" end_char="1631">we</TOKEN>
				<TOKEN id="token-14-25" start_char="1633" end_char="1634">do</TOKEN>
				<TOKEN id="token-14-26" start_char="1636" end_char="1638">not</TOKEN>
				<TOKEN id="token-14-27" start_char="1640" end_char="1646">believe</TOKEN>
				<TOKEN id="token-14-28" start_char="1648" end_char="1651">that</TOKEN>
				<TOKEN id="token-14-29" start_char="1653" end_char="1655">any</TOKEN>
				<TOKEN id="token-14-30" start_char="1657" end_char="1660">type</TOKEN>
				<TOKEN id="token-14-31" start_char="1662" end_char="1663">of</TOKEN>
				<TOKEN id="token-14-32" start_char="1665" end_char="1674">laboratory</TOKEN>
				<TOKEN id="token-14-33" start_char="1675" end_char="1675">-</TOKEN>
				<TOKEN id="token-14-34" start_char="1676" end_char="1680">based</TOKEN>
				<TOKEN id="token-14-35" start_char="1682" end_char="1689">scenario</TOKEN>
				<TOKEN id="token-14-36" start_char="1691" end_char="1692">is</TOKEN>
				<TOKEN id="token-14-37" start_char="1694" end_char="1702">plausible</TOKEN>
				<TOKEN id="token-14-38" start_char="1703" end_char="1704">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-15" start_char="1706" end_char="1727">
				<ORIGINAL_TEXT>Not all experts agree.</ORIGINAL_TEXT>
				<TOKEN id="token-15-0" start_char="1706" end_char="1708">Not</TOKEN>
				<TOKEN id="token-15-1" start_char="1710" end_char="1712">all</TOKEN>
				<TOKEN id="token-15-2" start_char="1714" end_char="1720">experts</TOKEN>
				<TOKEN id="token-15-3" start_char="1722" end_char="1726">agree</TOKEN>
				<TOKEN id="token-15-4" start_char="1727" end_char="1727">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-16" start_char="1729" end_char="2064">
				<ORIGINAL_TEXT>Professor Richard Ebright of Rutgers University’s Waksman Institute of Microbiology, a biosecurity expert who has been speaking out on lab safety since the early 2000s, does agree with the Nature Medicine authors’ argument that the new coronavirus wasn’t purposefully manipulated by humans, calling their arguments on this score strong.</ORIGINAL_TEXT>
				<TOKEN id="token-16-0" start_char="1729" end_char="1737">Professor</TOKEN>
				<TOKEN id="token-16-1" start_char="1739" end_char="1745">Richard</TOKEN>
				<TOKEN id="token-16-2" start_char="1747" end_char="1753">Ebright</TOKEN>
				<TOKEN id="token-16-3" start_char="1755" end_char="1756">of</TOKEN>
				<TOKEN id="token-16-4" start_char="1758" end_char="1764">Rutgers</TOKEN>
				<TOKEN id="token-16-5" start_char="1766" end_char="1775">University</TOKEN>
				<TOKEN id="token-16-6" start_char="1776" end_char="1776">’</TOKEN>
				<TOKEN id="token-16-7" start_char="1777" end_char="1777">s</TOKEN>
				<TOKEN id="token-16-8" start_char="1779" end_char="1785">Waksman</TOKEN>
				<TOKEN id="token-16-9" start_char="1787" end_char="1795">Institute</TOKEN>
				<TOKEN id="token-16-10" start_char="1797" end_char="1798">of</TOKEN>
				<TOKEN id="token-16-11" start_char="1800" end_char="1811">Microbiology</TOKEN>
				<TOKEN id="token-16-12" start_char="1812" end_char="1812">,</TOKEN>
				<TOKEN id="token-16-13" start_char="1814" end_char="1814">a</TOKEN>
				<TOKEN id="token-16-14" start_char="1816" end_char="1826">biosecurity</TOKEN>
				<TOKEN id="token-16-15" start_char="1828" end_char="1833">expert</TOKEN>
				<TOKEN id="token-16-16" start_char="1835" end_char="1837">who</TOKEN>
				<TOKEN id="token-16-17" start_char="1839" end_char="1841">has</TOKEN>
				<TOKEN id="token-16-18" start_char="1843" end_char="1846">been</TOKEN>
				<TOKEN id="token-16-19" start_char="1848" end_char="1855">speaking</TOKEN>
				<TOKEN id="token-16-20" start_char="1857" end_char="1859">out</TOKEN>
				<TOKEN id="token-16-21" start_char="1861" end_char="1862">on</TOKEN>
				<TOKEN id="token-16-22" start_char="1864" end_char="1866">lab</TOKEN>
				<TOKEN id="token-16-23" start_char="1868" end_char="1873">safety</TOKEN>
				<TOKEN id="token-16-24" start_char="1875" end_char="1879">since</TOKEN>
				<TOKEN id="token-16-25" start_char="1881" end_char="1883">the</TOKEN>
				<TOKEN id="token-16-26" start_char="1885" end_char="1889">early</TOKEN>
				<TOKEN id="token-16-27" start_char="1891" end_char="1895">2000s</TOKEN>
				<TOKEN id="token-16-28" start_char="1896" end_char="1896">,</TOKEN>
				<TOKEN id="token-16-29" start_char="1898" end_char="1901">does</TOKEN>
				<TOKEN id="token-16-30" start_char="1903" end_char="1907">agree</TOKEN>
				<TOKEN id="token-16-31" start_char="1909" end_char="1912">with</TOKEN>
				<TOKEN id="token-16-32" start_char="1914" end_char="1916">the</TOKEN>
				<TOKEN id="token-16-33" start_char="1918" end_char="1923">Nature</TOKEN>
				<TOKEN id="token-16-34" start_char="1925" end_char="1932">Medicine</TOKEN>
				<TOKEN id="token-16-35" start_char="1934" end_char="1940">authors</TOKEN>
				<TOKEN id="token-16-36" start_char="1941" end_char="1941">’</TOKEN>
				<TOKEN id="token-16-37" start_char="1943" end_char="1950">argument</TOKEN>
				<TOKEN id="token-16-38" start_char="1952" end_char="1955">that</TOKEN>
				<TOKEN id="token-16-39" start_char="1957" end_char="1959">the</TOKEN>
				<TOKEN id="token-16-40" start_char="1961" end_char="1963">new</TOKEN>
				<TOKEN id="token-16-41" start_char="1965" end_char="1975">coronavirus</TOKEN>
				<TOKEN id="token-16-42" start_char="1977" end_char="1980">wasn</TOKEN>
				<TOKEN id="token-16-43" start_char="1981" end_char="1981">’</TOKEN>
				<TOKEN id="token-16-44" start_char="1982" end_char="1982">t</TOKEN>
				<TOKEN id="token-16-45" start_char="1984" end_char="1995">purposefully</TOKEN>
				<TOKEN id="token-16-46" start_char="1997" end_char="2007">manipulated</TOKEN>
				<TOKEN id="token-16-47" start_char="2009" end_char="2010">by</TOKEN>
				<TOKEN id="token-16-48" start_char="2012" end_char="2017">humans</TOKEN>
				<TOKEN id="token-16-49" start_char="2018" end_char="2018">,</TOKEN>
				<TOKEN id="token-16-50" start_char="2020" end_char="2026">calling</TOKEN>
				<TOKEN id="token-16-51" start_char="2028" end_char="2032">their</TOKEN>
				<TOKEN id="token-16-52" start_char="2034" end_char="2042">arguments</TOKEN>
				<TOKEN id="token-16-53" start_char="2044" end_char="2045">on</TOKEN>
				<TOKEN id="token-16-54" start_char="2047" end_char="2050">this</TOKEN>
				<TOKEN id="token-16-55" start_char="2052" end_char="2056">score</TOKEN>
				<TOKEN id="token-16-56" start_char="2058" end_char="2063">strong</TOKEN>
				<TOKEN id="token-16-57" start_char="2064" end_char="2064">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-17" start_char="2066" end_char="2309">
				<ORIGINAL_TEXT>Ebright helped The Washington Post debunk a claim that the COVID-19 outbreak can somehow be tied to bioweapons activity, a conspiracy theory that’s been promoted or endorsed by the likes of US Sen. Tom Cotton, Iran’s supreme leader, and others.</ORIGINAL_TEXT>
				<TOKEN id="token-17-0" start_char="2066" end_char="2072">Ebright</TOKEN>
				<TOKEN id="token-17-1" start_char="2074" end_char="2079">helped</TOKEN>
				<TOKEN id="token-17-2" start_char="2081" end_char="2083">The</TOKEN>
				<TOKEN id="token-17-3" start_char="2085" end_char="2094">Washington</TOKEN>
				<TOKEN id="token-17-4" start_char="2096" end_char="2099">Post</TOKEN>
				<TOKEN id="token-17-5" start_char="2101" end_char="2106">debunk</TOKEN>
				<TOKEN id="token-17-6" start_char="2108" end_char="2108">a</TOKEN>
				<TOKEN id="token-17-7" start_char="2110" end_char="2114">claim</TOKEN>
				<TOKEN id="token-17-8" start_char="2116" end_char="2119">that</TOKEN>
				<TOKEN id="token-17-9" start_char="2121" end_char="2123">the</TOKEN>
				<TOKEN id="token-17-10" start_char="2125" end_char="2129">COVID</TOKEN>
				<TOKEN id="token-17-11" start_char="2130" end_char="2130">-</TOKEN>
				<TOKEN id="token-17-12" start_char="2131" end_char="2132">19</TOKEN>
				<TOKEN id="token-17-13" start_char="2134" end_char="2141">outbreak</TOKEN>
				<TOKEN id="token-17-14" start_char="2143" end_char="2145">can</TOKEN>
				<TOKEN id="token-17-15" start_char="2147" end_char="2153">somehow</TOKEN>
				<TOKEN id="token-17-16" start_char="2155" end_char="2156">be</TOKEN>
				<TOKEN id="token-17-17" start_char="2158" end_char="2161">tied</TOKEN>
				<TOKEN id="token-17-18" start_char="2163" end_char="2164">to</TOKEN>
				<TOKEN id="token-17-19" start_char="2166" end_char="2175">bioweapons</TOKEN>
				<TOKEN id="token-17-20" start_char="2177" end_char="2184">activity</TOKEN>
				<TOKEN id="token-17-21" start_char="2185" end_char="2185">,</TOKEN>
				<TOKEN id="token-17-22" start_char="2187" end_char="2187">a</TOKEN>
				<TOKEN id="token-17-23" start_char="2189" end_char="2198">conspiracy</TOKEN>
				<TOKEN id="token-17-24" start_char="2200" end_char="2205">theory</TOKEN>
				<TOKEN id="token-17-25" start_char="2207" end_char="2210">that</TOKEN>
				<TOKEN id="token-17-26" start_char="2211" end_char="2211">’</TOKEN>
				<TOKEN id="token-17-27" start_char="2212" end_char="2212">s</TOKEN>
				<TOKEN id="token-17-28" start_char="2214" end_char="2217">been</TOKEN>
				<TOKEN id="token-17-29" start_char="2219" end_char="2226">promoted</TOKEN>
				<TOKEN id="token-17-30" start_char="2228" end_char="2229">or</TOKEN>
				<TOKEN id="token-17-31" start_char="2231" end_char="2238">endorsed</TOKEN>
				<TOKEN id="token-17-32" start_char="2240" end_char="2241">by</TOKEN>
				<TOKEN id="token-17-33" start_char="2243" end_char="2245">the</TOKEN>
				<TOKEN id="token-17-34" start_char="2247" end_char="2251">likes</TOKEN>
				<TOKEN id="token-17-35" start_char="2253" end_char="2254">of</TOKEN>
				<TOKEN id="token-17-36" start_char="2256" end_char="2257">US</TOKEN>
				<TOKEN id="token-17-37" start_char="2259" end_char="2261">Sen</TOKEN>
				<TOKEN id="token-17-38" start_char="2262" end_char="2262">.</TOKEN>
				<TOKEN id="token-17-39" start_char="2264" end_char="2266">Tom</TOKEN>
				<TOKEN id="token-17-40" start_char="2268" end_char="2273">Cotton</TOKEN>
				<TOKEN id="token-17-41" start_char="2274" end_char="2274">,</TOKEN>
				<TOKEN id="token-17-42" start_char="2276" end_char="2279">Iran</TOKEN>
				<TOKEN id="token-17-43" start_char="2280" end_char="2280">’</TOKEN>
				<TOKEN id="token-17-44" start_char="2281" end_char="2281">s</TOKEN>
				<TOKEN id="token-17-45" start_char="2283" end_char="2289">supreme</TOKEN>
				<TOKEN id="token-17-46" start_char="2291" end_char="2296">leader</TOKEN>
				<TOKEN id="token-17-47" start_char="2297" end_char="2297">,</TOKEN>
				<TOKEN id="token-17-48" start_char="2299" end_char="2301">and</TOKEN>
				<TOKEN id="token-17-49" start_char="2303" end_char="2308">others</TOKEN>
				<TOKEN id="token-17-50" start_char="2309" end_char="2309">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-18" start_char="2311" end_char="2509">
				<ORIGINAL_TEXT>But Ebright thinks that it is possible the COVID-19 pandemic started as an accidental release from a laboratory such as one of the two in Wuhan that are known to have been studying bat coronaviruses.</ORIGINAL_TEXT>
				<TOKEN id="token-18-0" start_char="2311" end_char="2313">But</TOKEN>
				<TOKEN id="token-18-1" start_char="2315" end_char="2321">Ebright</TOKEN>
				<TOKEN id="token-18-2" start_char="2323" end_char="2328">thinks</TOKEN>
				<TOKEN id="token-18-3" start_char="2330" end_char="2333">that</TOKEN>
				<TOKEN id="token-18-4" start_char="2335" end_char="2336">it</TOKEN>
				<TOKEN id="token-18-5" start_char="2338" end_char="2339">is</TOKEN>
				<TOKEN id="token-18-6" start_char="2341" end_char="2348">possible</TOKEN>
				<TOKEN id="token-18-7" start_char="2350" end_char="2352">the</TOKEN>
				<TOKEN id="token-18-8" start_char="2354" end_char="2358">COVID</TOKEN>
				<TOKEN id="token-18-9" start_char="2359" end_char="2359">-</TOKEN>
				<TOKEN id="token-18-10" start_char="2360" end_char="2361">19</TOKEN>
				<TOKEN id="token-18-11" start_char="2363" end_char="2370">pandemic</TOKEN>
				<TOKEN id="token-18-12" start_char="2372" end_char="2378">started</TOKEN>
				<TOKEN id="token-18-13" start_char="2380" end_char="2381">as</TOKEN>
				<TOKEN id="token-18-14" start_char="2383" end_char="2384">an</TOKEN>
				<TOKEN id="token-18-15" start_char="2386" end_char="2395">accidental</TOKEN>
				<TOKEN id="token-18-16" start_char="2397" end_char="2403">release</TOKEN>
				<TOKEN id="token-18-17" start_char="2405" end_char="2408">from</TOKEN>
				<TOKEN id="token-18-18" start_char="2410" end_char="2410">a</TOKEN>
				<TOKEN id="token-18-19" start_char="2412" end_char="2421">laboratory</TOKEN>
				<TOKEN id="token-18-20" start_char="2423" end_char="2426">such</TOKEN>
				<TOKEN id="token-18-21" start_char="2428" end_char="2429">as</TOKEN>
				<TOKEN id="token-18-22" start_char="2431" end_char="2433">one</TOKEN>
				<TOKEN id="token-18-23" start_char="2435" end_char="2436">of</TOKEN>
				<TOKEN id="token-18-24" start_char="2438" end_char="2440">the</TOKEN>
				<TOKEN id="token-18-25" start_char="2442" end_char="2444">two</TOKEN>
				<TOKEN id="token-18-26" start_char="2446" end_char="2447">in</TOKEN>
				<TOKEN id="token-18-27" start_char="2449" end_char="2453">Wuhan</TOKEN>
				<TOKEN id="token-18-28" start_char="2455" end_char="2458">that</TOKEN>
				<TOKEN id="token-18-29" start_char="2460" end_char="2462">are</TOKEN>
				<TOKEN id="token-18-30" start_char="2464" end_char="2468">known</TOKEN>
				<TOKEN id="token-18-31" start_char="2470" end_char="2471">to</TOKEN>
				<TOKEN id="token-18-32" start_char="2473" end_char="2476">have</TOKEN>
				<TOKEN id="token-18-33" start_char="2478" end_char="2481">been</TOKEN>
				<TOKEN id="token-18-34" start_char="2483" end_char="2490">studying</TOKEN>
				<TOKEN id="token-18-35" start_char="2492" end_char="2494">bat</TOKEN>
				<TOKEN id="token-18-36" start_char="2496" end_char="2508">coronaviruses</TOKEN>
				<TOKEN id="token-18-37" start_char="2509" end_char="2509">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-19" start_char="2511" end_char="2741">
				<ORIGINAL_TEXT>Except for SARS-CoV and MERS-CoV, two deadly viruses that have caused outbreaks in the past, coronaviruses have been studied at laboratories that are labelled as operating at a moderate biosafety level known as BSL-2, Ebright says.</ORIGINAL_TEXT>
				<TOKEN id="token-19-0" start_char="2511" end_char="2516">Except</TOKEN>
				<TOKEN id="token-19-1" start_char="2518" end_char="2520">for</TOKEN>
				<TOKEN id="token-19-2" start_char="2522" end_char="2525">SARS</TOKEN>
				<TOKEN id="token-19-3" start_char="2526" end_char="2526">-</TOKEN>
				<TOKEN id="token-19-4" start_char="2527" end_char="2529">CoV</TOKEN>
				<TOKEN id="token-19-5" start_char="2531" end_char="2533">and</TOKEN>
				<TOKEN id="token-19-6" start_char="2535" end_char="2538">MERS</TOKEN>
				<TOKEN id="token-19-7" start_char="2539" end_char="2539">-</TOKEN>
				<TOKEN id="token-19-8" start_char="2540" end_char="2542">CoV</TOKEN>
				<TOKEN id="token-19-9" start_char="2543" end_char="2543">,</TOKEN>
				<TOKEN id="token-19-10" start_char="2545" end_char="2547">two</TOKEN>
				<TOKEN id="token-19-11" start_char="2549" end_char="2554">deadly</TOKEN>
				<TOKEN id="token-19-12" start_char="2556" end_char="2562">viruses</TOKEN>
				<TOKEN id="token-19-13" start_char="2564" end_char="2567">that</TOKEN>
				<TOKEN id="token-19-14" start_char="2569" end_char="2572">have</TOKEN>
				<TOKEN id="token-19-15" start_char="2574" end_char="2579">caused</TOKEN>
				<TOKEN id="token-19-16" start_char="2581" end_char="2589">outbreaks</TOKEN>
				<TOKEN id="token-19-17" start_char="2591" end_char="2592">in</TOKEN>
				<TOKEN id="token-19-18" start_char="2594" end_char="2596">the</TOKEN>
				<TOKEN id="token-19-19" start_char="2598" end_char="2601">past</TOKEN>
				<TOKEN id="token-19-20" start_char="2602" end_char="2602">,</TOKEN>
				<TOKEN id="token-19-21" start_char="2604" end_char="2616">coronaviruses</TOKEN>
				<TOKEN id="token-19-22" start_char="2618" end_char="2621">have</TOKEN>
				<TOKEN id="token-19-23" start_char="2623" end_char="2626">been</TOKEN>
				<TOKEN id="token-19-24" start_char="2628" end_char="2634">studied</TOKEN>
				<TOKEN id="token-19-25" start_char="2636" end_char="2637">at</TOKEN>
				<TOKEN id="token-19-26" start_char="2639" end_char="2650">laboratories</TOKEN>
				<TOKEN id="token-19-27" start_char="2652" end_char="2655">that</TOKEN>
				<TOKEN id="token-19-28" start_char="2657" end_char="2659">are</TOKEN>
				<TOKEN id="token-19-29" start_char="2661" end_char="2668">labelled</TOKEN>
				<TOKEN id="token-19-30" start_char="2670" end_char="2671">as</TOKEN>
				<TOKEN id="token-19-31" start_char="2673" end_char="2681">operating</TOKEN>
				<TOKEN id="token-19-32" start_char="2683" end_char="2684">at</TOKEN>
				<TOKEN id="token-19-33" start_char="2686" end_char="2686">a</TOKEN>
				<TOKEN id="token-19-34" start_char="2688" end_char="2695">moderate</TOKEN>
				<TOKEN id="token-19-35" start_char="2697" end_char="2705">biosafety</TOKEN>
				<TOKEN id="token-19-36" start_char="2707" end_char="2711">level</TOKEN>
				<TOKEN id="token-19-37" start_char="2713" end_char="2717">known</TOKEN>
				<TOKEN id="token-19-38" start_char="2719" end_char="2720">as</TOKEN>
				<TOKEN id="token-19-39" start_char="2722" end_char="2724">BSL</TOKEN>
				<TOKEN id="token-19-40" start_char="2725" end_char="2725">-</TOKEN>
				<TOKEN id="token-19-41" start_char="2726" end_char="2726">2</TOKEN>
				<TOKEN id="token-19-42" start_char="2727" end_char="2727">,</TOKEN>
				<TOKEN id="token-19-43" start_char="2729" end_char="2735">Ebright</TOKEN>
				<TOKEN id="token-19-44" start_char="2737" end_char="2740">says</TOKEN>
				<TOKEN id="token-19-45" start_char="2741" end_char="2741">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-20" start_char="2743" end_char="2873">
				<ORIGINAL_TEXT>And, he says, bat coronaviruses have been studied at such labs in and around Wuhan, China, where the new coronavirus first emerged.</ORIGINAL_TEXT>
				<TOKEN id="token-20-0" start_char="2743" end_char="2745">And</TOKEN>
				<TOKEN id="token-20-1" start_char="2746" end_char="2746">,</TOKEN>
				<TOKEN id="token-20-2" start_char="2748" end_char="2749">he</TOKEN>
				<TOKEN id="token-20-3" start_char="2751" end_char="2754">says</TOKEN>
				<TOKEN id="token-20-4" start_char="2755" end_char="2755">,</TOKEN>
				<TOKEN id="token-20-5" start_char="2757" end_char="2759">bat</TOKEN>
				<TOKEN id="token-20-6" start_char="2761" end_char="2773">coronaviruses</TOKEN>
				<TOKEN id="token-20-7" start_char="2775" end_char="2778">have</TOKEN>
				<TOKEN id="token-20-8" start_char="2780" end_char="2783">been</TOKEN>
				<TOKEN id="token-20-9" start_char="2785" end_char="2791">studied</TOKEN>
				<TOKEN id="token-20-10" start_char="2793" end_char="2794">at</TOKEN>
				<TOKEN id="token-20-11" start_char="2796" end_char="2799">such</TOKEN>
				<TOKEN id="token-20-12" start_char="2801" end_char="2804">labs</TOKEN>
				<TOKEN id="token-20-13" start_char="2806" end_char="2807">in</TOKEN>
				<TOKEN id="token-20-14" start_char="2809" end_char="2811">and</TOKEN>
				<TOKEN id="token-20-15" start_char="2813" end_char="2818">around</TOKEN>
				<TOKEN id="token-20-16" start_char="2820" end_char="2824">Wuhan</TOKEN>
				<TOKEN id="token-20-17" start_char="2825" end_char="2825">,</TOKEN>
				<TOKEN id="token-20-18" start_char="2827" end_char="2831">China</TOKEN>
				<TOKEN id="token-20-19" start_char="2832" end_char="2832">,</TOKEN>
				<TOKEN id="token-20-20" start_char="2834" end_char="2838">where</TOKEN>
				<TOKEN id="token-20-21" start_char="2840" end_char="2842">the</TOKEN>
				<TOKEN id="token-20-22" start_char="2844" end_char="2846">new</TOKEN>
				<TOKEN id="token-20-23" start_char="2848" end_char="2858">coronavirus</TOKEN>
				<TOKEN id="token-20-24" start_char="2860" end_char="2864">first</TOKEN>
				<TOKEN id="token-20-25" start_char="2866" end_char="2872">emerged</TOKEN>
				<TOKEN id="token-20-26" start_char="2873" end_char="2873">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-21" start_char="2875" end_char="3113">
				<ORIGINAL_TEXT>“As a result,” Ebright says, “bat coronaviruses at Wuhan [Center for Disease Control] and Wuhan Institute of Virology routinely were collected and studied at BSL-2, which provides only minimal protections against infection of lab workers.”</ORIGINAL_TEXT>
				<TOKEN id="token-21-0" start_char="2875" end_char="2875">“</TOKEN>
				<TOKEN id="token-21-1" start_char="2876" end_char="2877">As</TOKEN>
				<TOKEN id="token-21-2" start_char="2879" end_char="2879">a</TOKEN>
				<TOKEN id="token-21-3" start_char="2881" end_char="2886">result</TOKEN>
				<TOKEN id="token-21-4" start_char="2887" end_char="2888">,”</TOKEN>
				<TOKEN id="token-21-5" start_char="2890" end_char="2896">Ebright</TOKEN>
				<TOKEN id="token-21-6" start_char="2898" end_char="2901">says</TOKEN>
				<TOKEN id="token-21-7" start_char="2902" end_char="2902">,</TOKEN>
				<TOKEN id="token-21-8" start_char="2904" end_char="2904">“</TOKEN>
				<TOKEN id="token-21-9" start_char="2905" end_char="2907">bat</TOKEN>
				<TOKEN id="token-21-10" start_char="2909" end_char="2921">coronaviruses</TOKEN>
				<TOKEN id="token-21-11" start_char="2923" end_char="2924">at</TOKEN>
				<TOKEN id="token-21-12" start_char="2926" end_char="2930">Wuhan</TOKEN>
				<TOKEN id="token-21-13" start_char="2932" end_char="2932">[</TOKEN>
				<TOKEN id="token-21-14" start_char="2933" end_char="2938">Center</TOKEN>
				<TOKEN id="token-21-15" start_char="2940" end_char="2942">for</TOKEN>
				<TOKEN id="token-21-16" start_char="2944" end_char="2950">Disease</TOKEN>
				<TOKEN id="token-21-17" start_char="2952" end_char="2958">Control</TOKEN>
				<TOKEN id="token-21-18" start_char="2959" end_char="2959">]</TOKEN>
				<TOKEN id="token-21-19" start_char="2961" end_char="2963">and</TOKEN>
				<TOKEN id="token-21-20" start_char="2965" end_char="2969">Wuhan</TOKEN>
				<TOKEN id="token-21-21" start_char="2971" end_char="2979">Institute</TOKEN>
				<TOKEN id="token-21-22" start_char="2981" end_char="2982">of</TOKEN>
				<TOKEN id="token-21-23" start_char="2984" end_char="2991">Virology</TOKEN>
				<TOKEN id="token-21-24" start_char="2993" end_char="3001">routinely</TOKEN>
				<TOKEN id="token-21-25" start_char="3003" end_char="3006">were</TOKEN>
				<TOKEN id="token-21-26" start_char="3008" end_char="3016">collected</TOKEN>
				<TOKEN id="token-21-27" start_char="3018" end_char="3020">and</TOKEN>
				<TOKEN id="token-21-28" start_char="3022" end_char="3028">studied</TOKEN>
				<TOKEN id="token-21-29" start_char="3030" end_char="3031">at</TOKEN>
				<TOKEN id="token-21-30" start_char="3033" end_char="3035">BSL</TOKEN>
				<TOKEN id="token-21-31" start_char="3036" end_char="3036">-</TOKEN>
				<TOKEN id="token-21-32" start_char="3037" end_char="3037">2</TOKEN>
				<TOKEN id="token-21-33" start_char="3038" end_char="3038">,</TOKEN>
				<TOKEN id="token-21-34" start_char="3040" end_char="3044">which</TOKEN>
				<TOKEN id="token-21-35" start_char="3046" end_char="3053">provides</TOKEN>
				<TOKEN id="token-21-36" start_char="3055" end_char="3058">only</TOKEN>
				<TOKEN id="token-21-37" start_char="3060" end_char="3066">minimal</TOKEN>
				<TOKEN id="token-21-38" start_char="3068" end_char="3078">protections</TOKEN>
				<TOKEN id="token-21-39" start_char="3080" end_char="3086">against</TOKEN>
				<TOKEN id="token-21-40" start_char="3088" end_char="3096">infection</TOKEN>
				<TOKEN id="token-21-41" start_char="3098" end_char="3099">of</TOKEN>
				<TOKEN id="token-21-42" start_char="3101" end_char="3103">lab</TOKEN>
				<TOKEN id="token-21-43" start_char="3105" end_char="3111">workers</TOKEN>
				<TOKEN id="token-21-44" start_char="3112" end_char="3113">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-22" start_char="3115" end_char="3249">
				<ORIGINAL_TEXT>Higher safety-level labs would be appropriate for a virus with the characteristics of the new coronavirus causing the current pandemic.</ORIGINAL_TEXT>
				<TOKEN id="token-22-0" start_char="3115" end_char="3120">Higher</TOKEN>
				<TOKEN id="token-22-1" start_char="3122" end_char="3127">safety</TOKEN>
				<TOKEN id="token-22-2" start_char="3128" end_char="3128">-</TOKEN>
				<TOKEN id="token-22-3" start_char="3129" end_char="3133">level</TOKEN>
				<TOKEN id="token-22-4" start_char="3135" end_char="3138">labs</TOKEN>
				<TOKEN id="token-22-5" start_char="3140" end_char="3144">would</TOKEN>
				<TOKEN id="token-22-6" start_char="3146" end_char="3147">be</TOKEN>
				<TOKEN id="token-22-7" start_char="3149" end_char="3159">appropriate</TOKEN>
				<TOKEN id="token-22-8" start_char="3161" end_char="3163">for</TOKEN>
				<TOKEN id="token-22-9" start_char="3165" end_char="3165">a</TOKEN>
				<TOKEN id="token-22-10" start_char="3167" end_char="3171">virus</TOKEN>
				<TOKEN id="token-22-11" start_char="3173" end_char="3176">with</TOKEN>
				<TOKEN id="token-22-12" start_char="3178" end_char="3180">the</TOKEN>
				<TOKEN id="token-22-13" start_char="3182" end_char="3196">characteristics</TOKEN>
				<TOKEN id="token-22-14" start_char="3198" end_char="3199">of</TOKEN>
				<TOKEN id="token-22-15" start_char="3201" end_char="3203">the</TOKEN>
				<TOKEN id="token-22-16" start_char="3205" end_char="3207">new</TOKEN>
				<TOKEN id="token-22-17" start_char="3209" end_char="3219">coronavirus</TOKEN>
				<TOKEN id="token-22-18" start_char="3221" end_char="3227">causing</TOKEN>
				<TOKEN id="token-22-19" start_char="3229" end_char="3231">the</TOKEN>
				<TOKEN id="token-22-20" start_char="3233" end_char="3239">current</TOKEN>
				<TOKEN id="token-22-21" start_char="3241" end_char="3248">pandemic</TOKEN>
				<TOKEN id="token-22-22" start_char="3249" end_char="3249">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-23" start_char="3251" end_char="3502">
				<ORIGINAL_TEXT>“Virus collection, culture, isolation, or animal infection at BSL-2 with a virus having the transmission characteristics of the outbreak virus would pose substantial risk of infection of a lab worker, and from the lab worker, the public,” Ebright says.</ORIGINAL_TEXT>
				<TOKEN id="token-23-0" start_char="3251" end_char="3251">“</TOKEN>
				<TOKEN id="token-23-1" start_char="3252" end_char="3256">Virus</TOKEN>
				<TOKEN id="token-23-2" start_char="3258" end_char="3267">collection</TOKEN>
				<TOKEN id="token-23-3" start_char="3268" end_char="3268">,</TOKEN>
				<TOKEN id="token-23-4" start_char="3270" end_char="3276">culture</TOKEN>
				<TOKEN id="token-23-5" start_char="3277" end_char="3277">,</TOKEN>
				<TOKEN id="token-23-6" start_char="3279" end_char="3287">isolation</TOKEN>
				<TOKEN id="token-23-7" start_char="3288" end_char="3288">,</TOKEN>
				<TOKEN id="token-23-8" start_char="3290" end_char="3291">or</TOKEN>
				<TOKEN id="token-23-9" start_char="3293" end_char="3298">animal</TOKEN>
				<TOKEN id="token-23-10" start_char="3300" end_char="3308">infection</TOKEN>
				<TOKEN id="token-23-11" start_char="3310" end_char="3311">at</TOKEN>
				<TOKEN id="token-23-12" start_char="3313" end_char="3315">BSL</TOKEN>
				<TOKEN id="token-23-13" start_char="3316" end_char="3316">-</TOKEN>
				<TOKEN id="token-23-14" start_char="3317" end_char="3317">2</TOKEN>
				<TOKEN id="token-23-15" start_char="3319" end_char="3322">with</TOKEN>
				<TOKEN id="token-23-16" start_char="3324" end_char="3324">a</TOKEN>
				<TOKEN id="token-23-17" start_char="3326" end_char="3330">virus</TOKEN>
				<TOKEN id="token-23-18" start_char="3332" end_char="3337">having</TOKEN>
				<TOKEN id="token-23-19" start_char="3339" end_char="3341">the</TOKEN>
				<TOKEN id="token-23-20" start_char="3343" end_char="3354">transmission</TOKEN>
				<TOKEN id="token-23-21" start_char="3356" end_char="3370">characteristics</TOKEN>
				<TOKEN id="token-23-22" start_char="3372" end_char="3373">of</TOKEN>
				<TOKEN id="token-23-23" start_char="3375" end_char="3377">the</TOKEN>
				<TOKEN id="token-23-24" start_char="3379" end_char="3386">outbreak</TOKEN>
				<TOKEN id="token-23-25" start_char="3388" end_char="3392">virus</TOKEN>
				<TOKEN id="token-23-26" start_char="3394" end_char="3398">would</TOKEN>
				<TOKEN id="token-23-27" start_char="3400" end_char="3403">pose</TOKEN>
				<TOKEN id="token-23-28" start_char="3405" end_char="3415">substantial</TOKEN>
				<TOKEN id="token-23-29" start_char="3417" end_char="3420">risk</TOKEN>
				<TOKEN id="token-23-30" start_char="3422" end_char="3423">of</TOKEN>
				<TOKEN id="token-23-31" start_char="3425" end_char="3433">infection</TOKEN>
				<TOKEN id="token-23-32" start_char="3435" end_char="3436">of</TOKEN>
				<TOKEN id="token-23-33" start_char="3438" end_char="3438">a</TOKEN>
				<TOKEN id="token-23-34" start_char="3440" end_char="3442">lab</TOKEN>
				<TOKEN id="token-23-35" start_char="3444" end_char="3449">worker</TOKEN>
				<TOKEN id="token-23-36" start_char="3450" end_char="3450">,</TOKEN>
				<TOKEN id="token-23-37" start_char="3452" end_char="3454">and</TOKEN>
				<TOKEN id="token-23-38" start_char="3456" end_char="3459">from</TOKEN>
				<TOKEN id="token-23-39" start_char="3461" end_char="3463">the</TOKEN>
				<TOKEN id="token-23-40" start_char="3465" end_char="3467">lab</TOKEN>
				<TOKEN id="token-23-41" start_char="3469" end_char="3474">worker</TOKEN>
				<TOKEN id="token-23-42" start_char="3475" end_char="3475">,</TOKEN>
				<TOKEN id="token-23-43" start_char="3477" end_char="3479">the</TOKEN>
				<TOKEN id="token-23-44" start_char="3481" end_char="3486">public</TOKEN>
				<TOKEN id="token-23-45" start_char="3487" end_char="3488">,”</TOKEN>
				<TOKEN id="token-23-46" start_char="3490" end_char="3496">Ebright</TOKEN>
				<TOKEN id="token-23-47" start_char="3498" end_char="3501">says</TOKEN>
				<TOKEN id="token-23-48" start_char="3502" end_char="3502">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-24" start_char="3504" end_char="3667">
				<ORIGINAL_TEXT>Ebright points out that scientists in Wuhan have collected and publicized a bat coronavirus called RaTG13, one that is 96 percent genetically similar to SARS-CoV-2.</ORIGINAL_TEXT>
				<TOKEN id="token-24-0" start_char="3504" end_char="3510">Ebright</TOKEN>
				<TOKEN id="token-24-1" start_char="3512" end_char="3517">points</TOKEN>
				<TOKEN id="token-24-2" start_char="3519" end_char="3521">out</TOKEN>
				<TOKEN id="token-24-3" start_char="3523" end_char="3526">that</TOKEN>
				<TOKEN id="token-24-4" start_char="3528" end_char="3537">scientists</TOKEN>
				<TOKEN id="token-24-5" start_char="3539" end_char="3540">in</TOKEN>
				<TOKEN id="token-24-6" start_char="3542" end_char="3546">Wuhan</TOKEN>
				<TOKEN id="token-24-7" start_char="3548" end_char="3551">have</TOKEN>
				<TOKEN id="token-24-8" start_char="3553" end_char="3561">collected</TOKEN>
				<TOKEN id="token-24-9" start_char="3563" end_char="3565">and</TOKEN>
				<TOKEN id="token-24-10" start_char="3567" end_char="3576">publicized</TOKEN>
				<TOKEN id="token-24-11" start_char="3578" end_char="3578">a</TOKEN>
				<TOKEN id="token-24-12" start_char="3580" end_char="3582">bat</TOKEN>
				<TOKEN id="token-24-13" start_char="3584" end_char="3594">coronavirus</TOKEN>
				<TOKEN id="token-24-14" start_char="3596" end_char="3601">called</TOKEN>
				<TOKEN id="token-24-15" start_char="3603" end_char="3608">RaTG13</TOKEN>
				<TOKEN id="token-24-16" start_char="3609" end_char="3609">,</TOKEN>
				<TOKEN id="token-24-17" start_char="3611" end_char="3613">one</TOKEN>
				<TOKEN id="token-24-18" start_char="3615" end_char="3618">that</TOKEN>
				<TOKEN id="token-24-19" start_char="3620" end_char="3621">is</TOKEN>
				<TOKEN id="token-24-20" start_char="3623" end_char="3624">96</TOKEN>
				<TOKEN id="token-24-21" start_char="3626" end_char="3632">percent</TOKEN>
				<TOKEN id="token-24-22" start_char="3634" end_char="3644">genetically</TOKEN>
				<TOKEN id="token-24-23" start_char="3646" end_char="3652">similar</TOKEN>
				<TOKEN id="token-24-24" start_char="3654" end_char="3655">to</TOKEN>
				<TOKEN id="token-24-25" start_char="3657" end_char="3660">SARS</TOKEN>
				<TOKEN id="token-24-26" start_char="3661" end_char="3661">-</TOKEN>
				<TOKEN id="token-24-27" start_char="3662" end_char="3664">CoV</TOKEN>
				<TOKEN id="token-24-28" start_char="3665" end_char="3665">-</TOKEN>
				<TOKEN id="token-24-29" start_char="3666" end_char="3666">2</TOKEN>
				<TOKEN id="token-24-30" start_char="3667" end_char="3667">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-25" start_char="3669" end_char="4160">
				<ORIGINAL_TEXT>The Nature Medicine authors are arguing “against the hypothesis that the published, lab-collected, lab-stored bat coronavirus RaTG13 could be a proximal progenitor of the outbreak virus.” But, Ebright says, the authors relied on assumptions about when the viral ancestor of SARS-CoV-2 jumped to humans; how fast it evolved before that; how fast it evolved as it adapted to humans; and the possibility that that the virus may have mutated in cell cultures or experimental animals inside a lab.</ORIGINAL_TEXT>
				<TOKEN id="token-25-0" start_char="3669" end_char="3671">The</TOKEN>
				<TOKEN id="token-25-1" start_char="3673" end_char="3678">Nature</TOKEN>
				<TOKEN id="token-25-2" start_char="3680" end_char="3687">Medicine</TOKEN>
				<TOKEN id="token-25-3" start_char="3689" end_char="3695">authors</TOKEN>
				<TOKEN id="token-25-4" start_char="3697" end_char="3699">are</TOKEN>
				<TOKEN id="token-25-5" start_char="3701" end_char="3707">arguing</TOKEN>
				<TOKEN id="token-25-6" start_char="3709" end_char="3709">“</TOKEN>
				<TOKEN id="token-25-7" start_char="3710" end_char="3716">against</TOKEN>
				<TOKEN id="token-25-8" start_char="3718" end_char="3720">the</TOKEN>
				<TOKEN id="token-25-9" start_char="3722" end_char="3731">hypothesis</TOKEN>
				<TOKEN id="token-25-10" start_char="3733" end_char="3736">that</TOKEN>
				<TOKEN id="token-25-11" start_char="3738" end_char="3740">the</TOKEN>
				<TOKEN id="token-25-12" start_char="3742" end_char="3750">published</TOKEN>
				<TOKEN id="token-25-13" start_char="3751" end_char="3751">,</TOKEN>
				<TOKEN id="token-25-14" start_char="3753" end_char="3755">lab</TOKEN>
				<TOKEN id="token-25-15" start_char="3756" end_char="3756">-</TOKEN>
				<TOKEN id="token-25-16" start_char="3757" end_char="3765">collected</TOKEN>
				<TOKEN id="token-25-17" start_char="3766" end_char="3766">,</TOKEN>
				<TOKEN id="token-25-18" start_char="3768" end_char="3770">lab</TOKEN>
				<TOKEN id="token-25-19" start_char="3771" end_char="3771">-</TOKEN>
				<TOKEN id="token-25-20" start_char="3772" end_char="3777">stored</TOKEN>
				<TOKEN id="token-25-21" start_char="3779" end_char="3781">bat</TOKEN>
				<TOKEN id="token-25-22" start_char="3783" end_char="3793">coronavirus</TOKEN>
				<TOKEN id="token-25-23" start_char="3795" end_char="3800">RaTG13</TOKEN>
				<TOKEN id="token-25-24" start_char="3802" end_char="3806">could</TOKEN>
				<TOKEN id="token-25-25" start_char="3808" end_char="3809">be</TOKEN>
				<TOKEN id="token-25-26" start_char="3811" end_char="3811">a</TOKEN>
				<TOKEN id="token-25-27" start_char="3813" end_char="3820">proximal</TOKEN>
				<TOKEN id="token-25-28" start_char="3822" end_char="3831">progenitor</TOKEN>
				<TOKEN id="token-25-29" start_char="3833" end_char="3834">of</TOKEN>
				<TOKEN id="token-25-30" start_char="3836" end_char="3838">the</TOKEN>
				<TOKEN id="token-25-31" start_char="3840" end_char="3847">outbreak</TOKEN>
				<TOKEN id="token-25-32" start_char="3849" end_char="3853">virus</TOKEN>
				<TOKEN id="token-25-33" start_char="3854" end_char="3855">.”</TOKEN>
				<TOKEN id="token-25-34" start_char="3857" end_char="3859">But</TOKEN>
				<TOKEN id="token-25-35" start_char="3860" end_char="3860">,</TOKEN>
				<TOKEN id="token-25-36" start_char="3862" end_char="3868">Ebright</TOKEN>
				<TOKEN id="token-25-37" start_char="3870" end_char="3873">says</TOKEN>
				<TOKEN id="token-25-38" start_char="3874" end_char="3874">,</TOKEN>
				<TOKEN id="token-25-39" start_char="3876" end_char="3878">the</TOKEN>
				<TOKEN id="token-25-40" start_char="3880" end_char="3886">authors</TOKEN>
				<TOKEN id="token-25-41" start_char="3888" end_char="3893">relied</TOKEN>
				<TOKEN id="token-25-42" start_char="3895" end_char="3896">on</TOKEN>
				<TOKEN id="token-25-43" start_char="3898" end_char="3908">assumptions</TOKEN>
				<TOKEN id="token-25-44" start_char="3910" end_char="3914">about</TOKEN>
				<TOKEN id="token-25-45" start_char="3916" end_char="3919">when</TOKEN>
				<TOKEN id="token-25-46" start_char="3921" end_char="3923">the</TOKEN>
				<TOKEN id="token-25-47" start_char="3925" end_char="3929">viral</TOKEN>
				<TOKEN id="token-25-48" start_char="3931" end_char="3938">ancestor</TOKEN>
				<TOKEN id="token-25-49" start_char="3940" end_char="3941">of</TOKEN>
				<TOKEN id="token-25-50" start_char="3943" end_char="3946">SARS</TOKEN>
				<TOKEN id="token-25-51" start_char="3947" end_char="3947">-</TOKEN>
				<TOKEN id="token-25-52" start_char="3948" end_char="3950">CoV</TOKEN>
				<TOKEN id="token-25-53" start_char="3951" end_char="3951">-</TOKEN>
				<TOKEN id="token-25-54" start_char="3952" end_char="3952">2</TOKEN>
				<TOKEN id="token-25-55" start_char="3954" end_char="3959">jumped</TOKEN>
				<TOKEN id="token-25-56" start_char="3961" end_char="3962">to</TOKEN>
				<TOKEN id="token-25-57" start_char="3964" end_char="3969">humans</TOKEN>
				<TOKEN id="token-25-58" start_char="3970" end_char="3970">;</TOKEN>
				<TOKEN id="token-25-59" start_char="3972" end_char="3974">how</TOKEN>
				<TOKEN id="token-25-60" start_char="3976" end_char="3979">fast</TOKEN>
				<TOKEN id="token-25-61" start_char="3981" end_char="3982">it</TOKEN>
				<TOKEN id="token-25-62" start_char="3984" end_char="3990">evolved</TOKEN>
				<TOKEN id="token-25-63" start_char="3992" end_char="3997">before</TOKEN>
				<TOKEN id="token-25-64" start_char="3999" end_char="4002">that</TOKEN>
				<TOKEN id="token-25-65" start_char="4003" end_char="4003">;</TOKEN>
				<TOKEN id="token-25-66" start_char="4005" end_char="4007">how</TOKEN>
				<TOKEN id="token-25-67" start_char="4009" end_char="4012">fast</TOKEN>
				<TOKEN id="token-25-68" start_char="4014" end_char="4015">it</TOKEN>
				<TOKEN id="token-25-69" start_char="4017" end_char="4023">evolved</TOKEN>
				<TOKEN id="token-25-70" start_char="4025" end_char="4026">as</TOKEN>
				<TOKEN id="token-25-71" start_char="4028" end_char="4029">it</TOKEN>
				<TOKEN id="token-25-72" start_char="4031" end_char="4037">adapted</TOKEN>
				<TOKEN id="token-25-73" start_char="4039" end_char="4040">to</TOKEN>
				<TOKEN id="token-25-74" start_char="4042" end_char="4047">humans</TOKEN>
				<TOKEN id="token-25-75" start_char="4048" end_char="4048">;</TOKEN>
				<TOKEN id="token-25-76" start_char="4050" end_char="4052">and</TOKEN>
				<TOKEN id="token-25-77" start_char="4054" end_char="4056">the</TOKEN>
				<TOKEN id="token-25-78" start_char="4058" end_char="4068">possibility</TOKEN>
				<TOKEN id="token-25-79" start_char="4070" end_char="4073">that</TOKEN>
				<TOKEN id="token-25-80" start_char="4075" end_char="4078">that</TOKEN>
				<TOKEN id="token-25-81" start_char="4080" end_char="4082">the</TOKEN>
				<TOKEN id="token-25-82" start_char="4084" end_char="4088">virus</TOKEN>
				<TOKEN id="token-25-83" start_char="4090" end_char="4092">may</TOKEN>
				<TOKEN id="token-25-84" start_char="4094" end_char="4097">have</TOKEN>
				<TOKEN id="token-25-85" start_char="4099" end_char="4105">mutated</TOKEN>
				<TOKEN id="token-25-86" start_char="4107" end_char="4108">in</TOKEN>
				<TOKEN id="token-25-87" start_char="4110" end_char="4113">cell</TOKEN>
				<TOKEN id="token-25-88" start_char="4115" end_char="4122">cultures</TOKEN>
				<TOKEN id="token-25-89" start_char="4124" end_char="4125">or</TOKEN>
				<TOKEN id="token-25-90" start_char="4127" end_char="4138">experimental</TOKEN>
				<TOKEN id="token-25-91" start_char="4140" end_char="4146">animals</TOKEN>
				<TOKEN id="token-25-92" start_char="4148" end_char="4153">inside</TOKEN>
				<TOKEN id="token-25-93" start_char="4155" end_char="4155">a</TOKEN>
				<TOKEN id="token-25-94" start_char="4157" end_char="4159">lab</TOKEN>
				<TOKEN id="token-25-95" start_char="4160" end_char="4160">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-26" start_char="4162" end_char="4342">
				<ORIGINAL_TEXT>The Nature Medicine authors “leave us where we were before: with a basis to rule out [a coronavirus that is] a lab construct, but no basis to rule out a lab accident,” Ebright says.</ORIGINAL_TEXT>
				<TOKEN id="token-26-0" start_char="4162" end_char="4164">The</TOKEN>
				<TOKEN id="token-26-1" start_char="4166" end_char="4171">Nature</TOKEN>
				<TOKEN id="token-26-2" start_char="4173" end_char="4180">Medicine</TOKEN>
				<TOKEN id="token-26-3" start_char="4182" end_char="4188">authors</TOKEN>
				<TOKEN id="token-26-4" start_char="4190" end_char="4190">“</TOKEN>
				<TOKEN id="token-26-5" start_char="4191" end_char="4195">leave</TOKEN>
				<TOKEN id="token-26-6" start_char="4197" end_char="4198">us</TOKEN>
				<TOKEN id="token-26-7" start_char="4200" end_char="4204">where</TOKEN>
				<TOKEN id="token-26-8" start_char="4206" end_char="4207">we</TOKEN>
				<TOKEN id="token-26-9" start_char="4209" end_char="4212">were</TOKEN>
				<TOKEN id="token-26-10" start_char="4214" end_char="4219">before</TOKEN>
				<TOKEN id="token-26-11" start_char="4220" end_char="4220">:</TOKEN>
				<TOKEN id="token-26-12" start_char="4222" end_char="4225">with</TOKEN>
				<TOKEN id="token-26-13" start_char="4227" end_char="4227">a</TOKEN>
				<TOKEN id="token-26-14" start_char="4229" end_char="4233">basis</TOKEN>
				<TOKEN id="token-26-15" start_char="4235" end_char="4236">to</TOKEN>
				<TOKEN id="token-26-16" start_char="4238" end_char="4241">rule</TOKEN>
				<TOKEN id="token-26-17" start_char="4243" end_char="4245">out</TOKEN>
				<TOKEN id="token-26-18" start_char="4247" end_char="4247">[</TOKEN>
				<TOKEN id="token-26-19" start_char="4248" end_char="4248">a</TOKEN>
				<TOKEN id="token-26-20" start_char="4250" end_char="4260">coronavirus</TOKEN>
				<TOKEN id="token-26-21" start_char="4262" end_char="4265">that</TOKEN>
				<TOKEN id="token-26-22" start_char="4267" end_char="4268">is</TOKEN>
				<TOKEN id="token-26-23" start_char="4269" end_char="4269">]</TOKEN>
				<TOKEN id="token-26-24" start_char="4271" end_char="4271">a</TOKEN>
				<TOKEN id="token-26-25" start_char="4273" end_char="4275">lab</TOKEN>
				<TOKEN id="token-26-26" start_char="4277" end_char="4285">construct</TOKEN>
				<TOKEN id="token-26-27" start_char="4286" end_char="4286">,</TOKEN>
				<TOKEN id="token-26-28" start_char="4288" end_char="4290">but</TOKEN>
				<TOKEN id="token-26-29" start_char="4292" end_char="4293">no</TOKEN>
				<TOKEN id="token-26-30" start_char="4295" end_char="4299">basis</TOKEN>
				<TOKEN id="token-26-31" start_char="4301" end_char="4302">to</TOKEN>
				<TOKEN id="token-26-32" start_char="4304" end_char="4307">rule</TOKEN>
				<TOKEN id="token-26-33" start_char="4309" end_char="4311">out</TOKEN>
				<TOKEN id="token-26-34" start_char="4313" end_char="4313">a</TOKEN>
				<TOKEN id="token-26-35" start_char="4315" end_char="4317">lab</TOKEN>
				<TOKEN id="token-26-36" start_char="4319" end_char="4326">accident</TOKEN>
				<TOKEN id="token-26-37" start_char="4327" end_char="4328">,”</TOKEN>
				<TOKEN id="token-26-38" start_char="4330" end_char="4336">Ebright</TOKEN>
				<TOKEN id="token-26-39" start_char="4338" end_char="4341">says</TOKEN>
				<TOKEN id="token-26-40" start_char="4342" end_char="4342">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-27" start_char="4344" end_char="4656">
				<ORIGINAL_TEXT>Yanzhong Huang, a senior fellow for Global Health at the Council on Foreign Relations, recently wrote an article for Foreign Affairs that is dismissive of conspiracy theories about the origins of the pandemic but also mentions circumstantial evidence that supports the possibility that a lab release was involved.</ORIGINAL_TEXT>
				<TOKEN id="token-27-0" start_char="4344" end_char="4351">Yanzhong</TOKEN>
				<TOKEN id="token-27-1" start_char="4353" end_char="4357">Huang</TOKEN>
				<TOKEN id="token-27-2" start_char="4358" end_char="4358">,</TOKEN>
				<TOKEN id="token-27-3" start_char="4360" end_char="4360">a</TOKEN>
				<TOKEN id="token-27-4" start_char="4362" end_char="4367">senior</TOKEN>
				<TOKEN id="token-27-5" start_char="4369" end_char="4374">fellow</TOKEN>
				<TOKEN id="token-27-6" start_char="4376" end_char="4378">for</TOKEN>
				<TOKEN id="token-27-7" start_char="4380" end_char="4385">Global</TOKEN>
				<TOKEN id="token-27-8" start_char="4387" end_char="4392">Health</TOKEN>
				<TOKEN id="token-27-9" start_char="4394" end_char="4395">at</TOKEN>
				<TOKEN id="token-27-10" start_char="4397" end_char="4399">the</TOKEN>
				<TOKEN id="token-27-11" start_char="4401" end_char="4407">Council</TOKEN>
				<TOKEN id="token-27-12" start_char="4409" end_char="4410">on</TOKEN>
				<TOKEN id="token-27-13" start_char="4412" end_char="4418">Foreign</TOKEN>
				<TOKEN id="token-27-14" start_char="4420" end_char="4428">Relations</TOKEN>
				<TOKEN id="token-27-15" start_char="4429" end_char="4429">,</TOKEN>
				<TOKEN id="token-27-16" start_char="4431" end_char="4438">recently</TOKEN>
				<TOKEN id="token-27-17" start_char="4440" end_char="4444">wrote</TOKEN>
				<TOKEN id="token-27-18" start_char="4446" end_char="4447">an</TOKEN>
				<TOKEN id="token-27-19" start_char="4449" end_char="4455">article</TOKEN>
				<TOKEN id="token-27-20" start_char="4457" end_char="4459">for</TOKEN>
				<TOKEN id="token-27-21" start_char="4461" end_char="4467">Foreign</TOKEN>
				<TOKEN id="token-27-22" start_char="4469" end_char="4475">Affairs</TOKEN>
				<TOKEN id="token-27-23" start_char="4477" end_char="4480">that</TOKEN>
				<TOKEN id="token-27-24" start_char="4482" end_char="4483">is</TOKEN>
				<TOKEN id="token-27-25" start_char="4485" end_char="4494">dismissive</TOKEN>
				<TOKEN id="token-27-26" start_char="4496" end_char="4497">of</TOKEN>
				<TOKEN id="token-27-27" start_char="4499" end_char="4508">conspiracy</TOKEN>
				<TOKEN id="token-27-28" start_char="4510" end_char="4517">theories</TOKEN>
				<TOKEN id="token-27-29" start_char="4519" end_char="4523">about</TOKEN>
				<TOKEN id="token-27-30" start_char="4525" end_char="4527">the</TOKEN>
				<TOKEN id="token-27-31" start_char="4529" end_char="4535">origins</TOKEN>
				<TOKEN id="token-27-32" start_char="4537" end_char="4538">of</TOKEN>
				<TOKEN id="token-27-33" start_char="4540" end_char="4542">the</TOKEN>
				<TOKEN id="token-27-34" start_char="4544" end_char="4551">pandemic</TOKEN>
				<TOKEN id="token-27-35" start_char="4553" end_char="4555">but</TOKEN>
				<TOKEN id="token-27-36" start_char="4557" end_char="4560">also</TOKEN>
				<TOKEN id="token-27-37" start_char="4562" end_char="4569">mentions</TOKEN>
				<TOKEN id="token-27-38" start_char="4571" end_char="4584">circumstantial</TOKEN>
				<TOKEN id="token-27-39" start_char="4586" end_char="4593">evidence</TOKEN>
				<TOKEN id="token-27-40" start_char="4595" end_char="4598">that</TOKEN>
				<TOKEN id="token-27-41" start_char="4600" end_char="4607">supports</TOKEN>
				<TOKEN id="token-27-42" start_char="4609" end_char="4611">the</TOKEN>
				<TOKEN id="token-27-43" start_char="4613" end_char="4623">possibility</TOKEN>
				<TOKEN id="token-27-44" start_char="4625" end_char="4628">that</TOKEN>
				<TOKEN id="token-27-45" start_char="4630" end_char="4630">a</TOKEN>
				<TOKEN id="token-27-46" start_char="4632" end_char="4634">lab</TOKEN>
				<TOKEN id="token-27-47" start_char="4636" end_char="4642">release</TOKEN>
				<TOKEN id="token-27-48" start_char="4644" end_char="4646">was</TOKEN>
				<TOKEN id="token-27-49" start_char="4648" end_char="4655">involved</TOKEN>
				<TOKEN id="token-27-50" start_char="4656" end_char="4656">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-28" start_char="4658" end_char="4966">
				<ORIGINAL_TEXT>That evidence includes a study “conducted by the South China University of Technology, [that] concluded that the coronavirus ‘probably’ originated in the Wuhan Center for Disease Control and Prevention,” located just 280 meters from the Hunan Seafood Market often cited as the source of the original outbreak.</ORIGINAL_TEXT>
				<TOKEN id="token-28-0" start_char="4658" end_char="4661">That</TOKEN>
				<TOKEN id="token-28-1" start_char="4663" end_char="4670">evidence</TOKEN>
				<TOKEN id="token-28-2" start_char="4672" end_char="4679">includes</TOKEN>
				<TOKEN id="token-28-3" start_char="4681" end_char="4681">a</TOKEN>
				<TOKEN id="token-28-4" start_char="4683" end_char="4687">study</TOKEN>
				<TOKEN id="token-28-5" start_char="4689" end_char="4689">“</TOKEN>
				<TOKEN id="token-28-6" start_char="4690" end_char="4698">conducted</TOKEN>
				<TOKEN id="token-28-7" start_char="4700" end_char="4701">by</TOKEN>
				<TOKEN id="token-28-8" start_char="4703" end_char="4705">the</TOKEN>
				<TOKEN id="token-28-9" start_char="4707" end_char="4711">South</TOKEN>
				<TOKEN id="token-28-10" start_char="4713" end_char="4717">China</TOKEN>
				<TOKEN id="token-28-11" start_char="4719" end_char="4728">University</TOKEN>
				<TOKEN id="token-28-12" start_char="4730" end_char="4731">of</TOKEN>
				<TOKEN id="token-28-13" start_char="4733" end_char="4742">Technology</TOKEN>
				<TOKEN id="token-28-14" start_char="4743" end_char="4743">,</TOKEN>
				<TOKEN id="token-28-15" start_char="4745" end_char="4745">[</TOKEN>
				<TOKEN id="token-28-16" start_char="4746" end_char="4749">that</TOKEN>
				<TOKEN id="token-28-17" start_char="4750" end_char="4750">]</TOKEN>
				<TOKEN id="token-28-18" start_char="4752" end_char="4760">concluded</TOKEN>
				<TOKEN id="token-28-19" start_char="4762" end_char="4765">that</TOKEN>
				<TOKEN id="token-28-20" start_char="4767" end_char="4769">the</TOKEN>
				<TOKEN id="token-28-21" start_char="4771" end_char="4781">coronavirus</TOKEN>
				<TOKEN id="token-28-22" start_char="4783" end_char="4783">‘</TOKEN>
				<TOKEN id="token-28-23" start_char="4784" end_char="4791">probably</TOKEN>
				<TOKEN id="token-28-24" start_char="4792" end_char="4792">’</TOKEN>
				<TOKEN id="token-28-25" start_char="4794" end_char="4803">originated</TOKEN>
				<TOKEN id="token-28-26" start_char="4805" end_char="4806">in</TOKEN>
				<TOKEN id="token-28-27" start_char="4808" end_char="4810">the</TOKEN>
				<TOKEN id="token-28-28" start_char="4812" end_char="4816">Wuhan</TOKEN>
				<TOKEN id="token-28-29" start_char="4818" end_char="4823">Center</TOKEN>
				<TOKEN id="token-28-30" start_char="4825" end_char="4827">for</TOKEN>
				<TOKEN id="token-28-31" start_char="4829" end_char="4835">Disease</TOKEN>
				<TOKEN id="token-28-32" start_char="4837" end_char="4843">Control</TOKEN>
				<TOKEN id="token-28-33" start_char="4845" end_char="4847">and</TOKEN>
				<TOKEN id="token-28-34" start_char="4849" end_char="4858">Prevention</TOKEN>
				<TOKEN id="token-28-35" start_char="4859" end_char="4860">,”</TOKEN>
				<TOKEN id="token-28-36" start_char="4862" end_char="4868">located</TOKEN>
				<TOKEN id="token-28-37" start_char="4870" end_char="4873">just</TOKEN>
				<TOKEN id="token-28-38" start_char="4875" end_char="4877">280</TOKEN>
				<TOKEN id="token-28-39" start_char="4879" end_char="4884">meters</TOKEN>
				<TOKEN id="token-28-40" start_char="4886" end_char="4889">from</TOKEN>
				<TOKEN id="token-28-41" start_char="4891" end_char="4893">the</TOKEN>
				<TOKEN id="token-28-42" start_char="4895" end_char="4899">Hunan</TOKEN>
				<TOKEN id="token-28-43" start_char="4901" end_char="4907">Seafood</TOKEN>
				<TOKEN id="token-28-44" start_char="4909" end_char="4914">Market</TOKEN>
				<TOKEN id="token-28-45" start_char="4916" end_char="4920">often</TOKEN>
				<TOKEN id="token-28-46" start_char="4922" end_char="4926">cited</TOKEN>
				<TOKEN id="token-28-47" start_char="4928" end_char="4929">as</TOKEN>
				<TOKEN id="token-28-48" start_char="4931" end_char="4933">the</TOKEN>
				<TOKEN id="token-28-49" start_char="4935" end_char="4940">source</TOKEN>
				<TOKEN id="token-28-50" start_char="4942" end_char="4943">of</TOKEN>
				<TOKEN id="token-28-51" start_char="4945" end_char="4947">the</TOKEN>
				<TOKEN id="token-28-52" start_char="4949" end_char="4956">original</TOKEN>
				<TOKEN id="token-28-53" start_char="4958" end_char="4965">outbreak</TOKEN>
				<TOKEN id="token-28-54" start_char="4966" end_char="4966">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-29" start_char="4968" end_char="5112">
				<ORIGINAL_TEXT>“The paper was later removed from ResearchGate, a commercial social-networking site for scientists and researchers to share papers,” Huang wrote.</ORIGINAL_TEXT>
				<TOKEN id="token-29-0" start_char="4968" end_char="4968">“</TOKEN>
				<TOKEN id="token-29-1" start_char="4969" end_char="4971">The</TOKEN>
				<TOKEN id="token-29-2" start_char="4973" end_char="4977">paper</TOKEN>
				<TOKEN id="token-29-3" start_char="4979" end_char="4981">was</TOKEN>
				<TOKEN id="token-29-4" start_char="4983" end_char="4987">later</TOKEN>
				<TOKEN id="token-29-5" start_char="4989" end_char="4995">removed</TOKEN>
				<TOKEN id="token-29-6" start_char="4997" end_char="5000">from</TOKEN>
				<TOKEN id="token-29-7" start_char="5002" end_char="5013">ResearchGate</TOKEN>
				<TOKEN id="token-29-8" start_char="5014" end_char="5014">,</TOKEN>
				<TOKEN id="token-29-9" start_char="5016" end_char="5016">a</TOKEN>
				<TOKEN id="token-29-10" start_char="5018" end_char="5027">commercial</TOKEN>
				<TOKEN id="token-29-11" start_char="5029" end_char="5034">social</TOKEN>
				<TOKEN id="token-29-12" start_char="5035" end_char="5035">-</TOKEN>
				<TOKEN id="token-29-13" start_char="5036" end_char="5045">networking</TOKEN>
				<TOKEN id="token-29-14" start_char="5047" end_char="5050">site</TOKEN>
				<TOKEN id="token-29-15" start_char="5052" end_char="5054">for</TOKEN>
				<TOKEN id="token-29-16" start_char="5056" end_char="5065">scientists</TOKEN>
				<TOKEN id="token-29-17" start_char="5067" end_char="5069">and</TOKEN>
				<TOKEN id="token-29-18" start_char="5071" end_char="5081">researchers</TOKEN>
				<TOKEN id="token-29-19" start_char="5083" end_char="5084">to</TOKEN>
				<TOKEN id="token-29-20" start_char="5086" end_char="5090">share</TOKEN>
				<TOKEN id="token-29-21" start_char="5092" end_char="5097">papers</TOKEN>
				<TOKEN id="token-29-22" start_char="5098" end_char="5099">,”</TOKEN>
				<TOKEN id="token-29-23" start_char="5101" end_char="5105">Huang</TOKEN>
				<TOKEN id="token-29-24" start_char="5107" end_char="5111">wrote</TOKEN>
				<TOKEN id="token-29-25" start_char="5112" end_char="5112">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-30" start_char="5114" end_char="5186">
				<ORIGINAL_TEXT>“Thus far, no scientists have confirmed or refuted the paper’s findings.”</ORIGINAL_TEXT>
				<TOKEN id="token-30-0" start_char="5114" end_char="5114">“</TOKEN>
				<TOKEN id="token-30-1" start_char="5115" end_char="5118">Thus</TOKEN>
				<TOKEN id="token-30-2" start_char="5120" end_char="5122">far</TOKEN>
				<TOKEN id="token-30-3" start_char="5123" end_char="5123">,</TOKEN>
				<TOKEN id="token-30-4" start_char="5125" end_char="5126">no</TOKEN>
				<TOKEN id="token-30-5" start_char="5128" end_char="5137">scientists</TOKEN>
				<TOKEN id="token-30-6" start_char="5139" end_char="5142">have</TOKEN>
				<TOKEN id="token-30-7" start_char="5144" end_char="5152">confirmed</TOKEN>
				<TOKEN id="token-30-8" start_char="5154" end_char="5155">or</TOKEN>
				<TOKEN id="token-30-9" start_char="5157" end_char="5163">refuted</TOKEN>
				<TOKEN id="token-30-10" start_char="5165" end_char="5167">the</TOKEN>
				<TOKEN id="token-30-11" start_char="5169" end_char="5173">paper</TOKEN>
				<TOKEN id="token-30-12" start_char="5174" end_char="5174">’</TOKEN>
				<TOKEN id="token-30-13" start_char="5175" end_char="5175">s</TOKEN>
				<TOKEN id="token-30-14" start_char="5177" end_char="5184">findings</TOKEN>
				<TOKEN id="token-30-15" start_char="5185" end_char="5186">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-31" start_char="5188" end_char="5355">
				<ORIGINAL_TEXT>While vaccines, treatments, and social distancing strategies are critical to fighting the COVID-19 pandemic, figuring out where this new coronavirus originated is, too.</ORIGINAL_TEXT>
				<TOKEN id="token-31-0" start_char="5188" end_char="5192">While</TOKEN>
				<TOKEN id="token-31-1" start_char="5194" end_char="5201">vaccines</TOKEN>
				<TOKEN id="token-31-2" start_char="5202" end_char="5202">,</TOKEN>
				<TOKEN id="token-31-3" start_char="5204" end_char="5213">treatments</TOKEN>
				<TOKEN id="token-31-4" start_char="5214" end_char="5214">,</TOKEN>
				<TOKEN id="token-31-5" start_char="5216" end_char="5218">and</TOKEN>
				<TOKEN id="token-31-6" start_char="5220" end_char="5225">social</TOKEN>
				<TOKEN id="token-31-7" start_char="5227" end_char="5236">distancing</TOKEN>
				<TOKEN id="token-31-8" start_char="5238" end_char="5247">strategies</TOKEN>
				<TOKEN id="token-31-9" start_char="5249" end_char="5251">are</TOKEN>
				<TOKEN id="token-31-10" start_char="5253" end_char="5260">critical</TOKEN>
				<TOKEN id="token-31-11" start_char="5262" end_char="5263">to</TOKEN>
				<TOKEN id="token-31-12" start_char="5265" end_char="5272">fighting</TOKEN>
				<TOKEN id="token-31-13" start_char="5274" end_char="5276">the</TOKEN>
				<TOKEN id="token-31-14" start_char="5278" end_char="5282">COVID</TOKEN>
				<TOKEN id="token-31-15" start_char="5283" end_char="5283">-</TOKEN>
				<TOKEN id="token-31-16" start_char="5284" end_char="5285">19</TOKEN>
				<TOKEN id="token-31-17" start_char="5287" end_char="5294">pandemic</TOKEN>
				<TOKEN id="token-31-18" start_char="5295" end_char="5295">,</TOKEN>
				<TOKEN id="token-31-19" start_char="5297" end_char="5304">figuring</TOKEN>
				<TOKEN id="token-31-20" start_char="5306" end_char="5308">out</TOKEN>
				<TOKEN id="token-31-21" start_char="5310" end_char="5314">where</TOKEN>
				<TOKEN id="token-31-22" start_char="5316" end_char="5319">this</TOKEN>
				<TOKEN id="token-31-23" start_char="5321" end_char="5323">new</TOKEN>
				<TOKEN id="token-31-24" start_char="5325" end_char="5335">coronavirus</TOKEN>
				<TOKEN id="token-31-25" start_char="5337" end_char="5346">originated</TOKEN>
				<TOKEN id="token-31-26" start_char="5348" end_char="5349">is</TOKEN>
				<TOKEN id="token-31-27" start_char="5350" end_char="5350">,</TOKEN>
				<TOKEN id="token-31-28" start_char="5352" end_char="5354">too</TOKEN>
				<TOKEN id="token-31-29" start_char="5355" end_char="5355">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-32" start_char="5357" end_char="5459">
				<ORIGINAL_TEXT>“It is reasonable to wonder why the origins of the pandemic matter,” the Nature Medicine authors write.</ORIGINAL_TEXT>
				<TOKEN id="token-32-0" start_char="5357" end_char="5357">“</TOKEN>
				<TOKEN id="token-32-1" start_char="5358" end_char="5359">It</TOKEN>
				<TOKEN id="token-32-2" start_char="5361" end_char="5362">is</TOKEN>
				<TOKEN id="token-32-3" start_char="5364" end_char="5373">reasonable</TOKEN>
				<TOKEN id="token-32-4" start_char="5375" end_char="5376">to</TOKEN>
				<TOKEN id="token-32-5" start_char="5378" end_char="5383">wonder</TOKEN>
				<TOKEN id="token-32-6" start_char="5385" end_char="5387">why</TOKEN>
				<TOKEN id="token-32-7" start_char="5389" end_char="5391">the</TOKEN>
				<TOKEN id="token-32-8" start_char="5393" end_char="5399">origins</TOKEN>
				<TOKEN id="token-32-9" start_char="5401" end_char="5402">of</TOKEN>
				<TOKEN id="token-32-10" start_char="5404" end_char="5406">the</TOKEN>
				<TOKEN id="token-32-11" start_char="5408" end_char="5415">pandemic</TOKEN>
				<TOKEN id="token-32-12" start_char="5417" end_char="5422">matter</TOKEN>
				<TOKEN id="token-32-13" start_char="5423" end_char="5424">,”</TOKEN>
				<TOKEN id="token-32-14" start_char="5426" end_char="5428">the</TOKEN>
				<TOKEN id="token-32-15" start_char="5430" end_char="5435">Nature</TOKEN>
				<TOKEN id="token-32-16" start_char="5437" end_char="5444">Medicine</TOKEN>
				<TOKEN id="token-32-17" start_char="5446" end_char="5452">authors</TOKEN>
				<TOKEN id="token-32-18" start_char="5454" end_char="5458">write</TOKEN>
				<TOKEN id="token-32-19" start_char="5459" end_char="5459">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-33" start_char="5461" end_char="5639">
				<ORIGINAL_TEXT>“Detailed understanding of how an animal virus jumped species boundaries to infect humans so productively will help in the prevention of future [animal to people transfer] events.</ORIGINAL_TEXT>
				<TOKEN id="token-33-0" start_char="5461" end_char="5461">“</TOKEN>
				<TOKEN id="token-33-1" start_char="5462" end_char="5469">Detailed</TOKEN>
				<TOKEN id="token-33-2" start_char="5471" end_char="5483">understanding</TOKEN>
				<TOKEN id="token-33-3" start_char="5485" end_char="5486">of</TOKEN>
				<TOKEN id="token-33-4" start_char="5488" end_char="5490">how</TOKEN>
				<TOKEN id="token-33-5" start_char="5492" end_char="5493">an</TOKEN>
				<TOKEN id="token-33-6" start_char="5495" end_char="5500">animal</TOKEN>
				<TOKEN id="token-33-7" start_char="5502" end_char="5506">virus</TOKEN>
				<TOKEN id="token-33-8" start_char="5508" end_char="5513">jumped</TOKEN>
				<TOKEN id="token-33-9" start_char="5515" end_char="5521">species</TOKEN>
				<TOKEN id="token-33-10" start_char="5523" end_char="5532">boundaries</TOKEN>
				<TOKEN id="token-33-11" start_char="5534" end_char="5535">to</TOKEN>
				<TOKEN id="token-33-12" start_char="5537" end_char="5542">infect</TOKEN>
				<TOKEN id="token-33-13" start_char="5544" end_char="5549">humans</TOKEN>
				<TOKEN id="token-33-14" start_char="5551" end_char="5552">so</TOKEN>
				<TOKEN id="token-33-15" start_char="5554" end_char="5565">productively</TOKEN>
				<TOKEN id="token-33-16" start_char="5567" end_char="5570">will</TOKEN>
				<TOKEN id="token-33-17" start_char="5572" end_char="5575">help</TOKEN>
				<TOKEN id="token-33-18" start_char="5577" end_char="5578">in</TOKEN>
				<TOKEN id="token-33-19" start_char="5580" end_char="5582">the</TOKEN>
				<TOKEN id="token-33-20" start_char="5584" end_char="5593">prevention</TOKEN>
				<TOKEN id="token-33-21" start_char="5595" end_char="5596">of</TOKEN>
				<TOKEN id="token-33-22" start_char="5598" end_char="5603">future</TOKEN>
				<TOKEN id="token-33-23" start_char="5605" end_char="5605">[</TOKEN>
				<TOKEN id="token-33-24" start_char="5606" end_char="5611">animal</TOKEN>
				<TOKEN id="token-33-25" start_char="5613" end_char="5614">to</TOKEN>
				<TOKEN id="token-33-26" start_char="5616" end_char="5621">people</TOKEN>
				<TOKEN id="token-33-27" start_char="5623" end_char="5630">transfer</TOKEN>
				<TOKEN id="token-33-28" start_char="5631" end_char="5631">]</TOKEN>
				<TOKEN id="token-33-29" start_char="5633" end_char="5638">events</TOKEN>
				<TOKEN id="token-33-30" start_char="5639" end_char="5639">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-34" start_char="5641" end_char="5759">
				<ORIGINAL_TEXT>For example, if SARS-CoV-2 pre-adapted in another animal species, then there is the risk of future re-emergence events.</ORIGINAL_TEXT>
				<TOKEN id="token-34-0" start_char="5641" end_char="5643">For</TOKEN>
				<TOKEN id="token-34-1" start_char="5645" end_char="5651">example</TOKEN>
				<TOKEN id="token-34-2" start_char="5652" end_char="5652">,</TOKEN>
				<TOKEN id="token-34-3" start_char="5654" end_char="5655">if</TOKEN>
				<TOKEN id="token-34-4" start_char="5657" end_char="5660">SARS</TOKEN>
				<TOKEN id="token-34-5" start_char="5661" end_char="5661">-</TOKEN>
				<TOKEN id="token-34-6" start_char="5662" end_char="5664">CoV</TOKEN>
				<TOKEN id="token-34-7" start_char="5665" end_char="5665">-</TOKEN>
				<TOKEN id="token-34-8" start_char="5666" end_char="5666">2</TOKEN>
				<TOKEN id="token-34-9" start_char="5668" end_char="5670">pre</TOKEN>
				<TOKEN id="token-34-10" start_char="5671" end_char="5671">-</TOKEN>
				<TOKEN id="token-34-11" start_char="5672" end_char="5678">adapted</TOKEN>
				<TOKEN id="token-34-12" start_char="5680" end_char="5681">in</TOKEN>
				<TOKEN id="token-34-13" start_char="5683" end_char="5689">another</TOKEN>
				<TOKEN id="token-34-14" start_char="5691" end_char="5696">animal</TOKEN>
				<TOKEN id="token-34-15" start_char="5698" end_char="5704">species</TOKEN>
				<TOKEN id="token-34-16" start_char="5705" end_char="5705">,</TOKEN>
				<TOKEN id="token-34-17" start_char="5707" end_char="5710">then</TOKEN>
				<TOKEN id="token-34-18" start_char="5712" end_char="5716">there</TOKEN>
				<TOKEN id="token-34-19" start_char="5718" end_char="5719">is</TOKEN>
				<TOKEN id="token-34-20" start_char="5721" end_char="5723">the</TOKEN>
				<TOKEN id="token-34-21" start_char="5725" end_char="5728">risk</TOKEN>
				<TOKEN id="token-34-22" start_char="5730" end_char="5731">of</TOKEN>
				<TOKEN id="token-34-23" start_char="5733" end_char="5738">future</TOKEN>
				<TOKEN id="token-34-24" start_char="5740" end_char="5741">re</TOKEN>
				<TOKEN id="token-34-25" start_char="5742" end_char="5742">-</TOKEN>
				<TOKEN id="token-34-26" start_char="5743" end_char="5751">emergence</TOKEN>
				<TOKEN id="token-34-27" start_char="5753" end_char="5758">events</TOKEN>
				<TOKEN id="token-34-28" start_char="5759" end_char="5759">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-35" start_char="5761" end_char="5933">
				<ORIGINAL_TEXT>In contrast, if the adaptive process occurred in humans, then even if repeated zoonotic transfers occur, they are unlikely to take off without the same series of mutations.”</ORIGINAL_TEXT>
				<TOKEN id="token-35-0" start_char="5761" end_char="5762">In</TOKEN>
				<TOKEN id="token-35-1" start_char="5764" end_char="5771">contrast</TOKEN>
				<TOKEN id="token-35-2" start_char="5772" end_char="5772">,</TOKEN>
				<TOKEN id="token-35-3" start_char="5774" end_char="5775">if</TOKEN>
				<TOKEN id="token-35-4" start_char="5777" end_char="5779">the</TOKEN>
				<TOKEN id="token-35-5" start_char="5781" end_char="5788">adaptive</TOKEN>
				<TOKEN id="token-35-6" start_char="5790" end_char="5796">process</TOKEN>
				<TOKEN id="token-35-7" start_char="5798" end_char="5805">occurred</TOKEN>
				<TOKEN id="token-35-8" start_char="5807" end_char="5808">in</TOKEN>
				<TOKEN id="token-35-9" start_char="5810" end_char="5815">humans</TOKEN>
				<TOKEN id="token-35-10" start_char="5816" end_char="5816">,</TOKEN>
				<TOKEN id="token-35-11" start_char="5818" end_char="5821">then</TOKEN>
				<TOKEN id="token-35-12" start_char="5823" end_char="5826">even</TOKEN>
				<TOKEN id="token-35-13" start_char="5828" end_char="5829">if</TOKEN>
				<TOKEN id="token-35-14" start_char="5831" end_char="5838">repeated</TOKEN>
				<TOKEN id="token-35-15" start_char="5840" end_char="5847">zoonotic</TOKEN>
				<TOKEN id="token-35-16" start_char="5849" end_char="5857">transfers</TOKEN>
				<TOKEN id="token-35-17" start_char="5859" end_char="5863">occur</TOKEN>
				<TOKEN id="token-35-18" start_char="5864" end_char="5864">,</TOKEN>
				<TOKEN id="token-35-19" start_char="5866" end_char="5869">they</TOKEN>
				<TOKEN id="token-35-20" start_char="5871" end_char="5873">are</TOKEN>
				<TOKEN id="token-35-21" start_char="5875" end_char="5882">unlikely</TOKEN>
				<TOKEN id="token-35-22" start_char="5884" end_char="5885">to</TOKEN>
				<TOKEN id="token-35-23" start_char="5887" end_char="5890">take</TOKEN>
				<TOKEN id="token-35-24" start_char="5892" end_char="5894">off</TOKEN>
				<TOKEN id="token-35-25" start_char="5896" end_char="5902">without</TOKEN>
				<TOKEN id="token-35-26" start_char="5904" end_char="5906">the</TOKEN>
				<TOKEN id="token-35-27" start_char="5908" end_char="5911">same</TOKEN>
				<TOKEN id="token-35-28" start_char="5913" end_char="5918">series</TOKEN>
				<TOKEN id="token-35-29" start_char="5920" end_char="5921">of</TOKEN>
				<TOKEN id="token-35-30" start_char="5923" end_char="5931">mutations</TOKEN>
				<TOKEN id="token-35-31" start_char="5932" end_char="5933">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-36" start_char="5935" end_char="6141">
				<ORIGINAL_TEXT>Kristian Andersen, the lead author of the Nature Medicine piece, did not respond to a request for comment on the article, and W. Ian Lipkin, another of the authors, declined to answer any questions about it.</ORIGINAL_TEXT>
				<TOKEN id="token-36-0" start_char="5935" end_char="5942">Kristian</TOKEN>
				<TOKEN id="token-36-1" start_char="5944" end_char="5951">Andersen</TOKEN>
				<TOKEN id="token-36-2" start_char="5952" end_char="5952">,</TOKEN>
				<TOKEN id="token-36-3" start_char="5954" end_char="5956">the</TOKEN>
				<TOKEN id="token-36-4" start_char="5958" end_char="5961">lead</TOKEN>
				<TOKEN id="token-36-5" start_char="5963" end_char="5968">author</TOKEN>
				<TOKEN id="token-36-6" start_char="5970" end_char="5971">of</TOKEN>
				<TOKEN id="token-36-7" start_char="5973" end_char="5975">the</TOKEN>
				<TOKEN id="token-36-8" start_char="5977" end_char="5982">Nature</TOKEN>
				<TOKEN id="token-36-9" start_char="5984" end_char="5991">Medicine</TOKEN>
				<TOKEN id="token-36-10" start_char="5993" end_char="5997">piece</TOKEN>
				<TOKEN id="token-36-11" start_char="5998" end_char="5998">,</TOKEN>
				<TOKEN id="token-36-12" start_char="6000" end_char="6002">did</TOKEN>
				<TOKEN id="token-36-13" start_char="6004" end_char="6006">not</TOKEN>
				<TOKEN id="token-36-14" start_char="6008" end_char="6014">respond</TOKEN>
				<TOKEN id="token-36-15" start_char="6016" end_char="6017">to</TOKEN>
				<TOKEN id="token-36-16" start_char="6019" end_char="6019">a</TOKEN>
				<TOKEN id="token-36-17" start_char="6021" end_char="6027">request</TOKEN>
				<TOKEN id="token-36-18" start_char="6029" end_char="6031">for</TOKEN>
				<TOKEN id="token-36-19" start_char="6033" end_char="6039">comment</TOKEN>
				<TOKEN id="token-36-20" start_char="6041" end_char="6042">on</TOKEN>
				<TOKEN id="token-36-21" start_char="6044" end_char="6046">the</TOKEN>
				<TOKEN id="token-36-22" start_char="6048" end_char="6054">article</TOKEN>
				<TOKEN id="token-36-23" start_char="6055" end_char="6055">,</TOKEN>
				<TOKEN id="token-36-24" start_char="6057" end_char="6059">and</TOKEN>
				<TOKEN id="token-36-25" start_char="6061" end_char="6061">W</TOKEN>
				<TOKEN id="token-36-26" start_char="6062" end_char="6062">.</TOKEN>
				<TOKEN id="token-36-27" start_char="6064" end_char="6066">Ian</TOKEN>
				<TOKEN id="token-36-28" start_char="6068" end_char="6073">Lipkin</TOKEN>
				<TOKEN id="token-36-29" start_char="6074" end_char="6074">,</TOKEN>
				<TOKEN id="token-36-30" start_char="6076" end_char="6082">another</TOKEN>
				<TOKEN id="token-36-31" start_char="6084" end_char="6085">of</TOKEN>
				<TOKEN id="token-36-32" start_char="6087" end_char="6089">the</TOKEN>
				<TOKEN id="token-36-33" start_char="6091" end_char="6097">authors</TOKEN>
				<TOKEN id="token-36-34" start_char="6098" end_char="6098">,</TOKEN>
				<TOKEN id="token-36-35" start_char="6100" end_char="6107">declined</TOKEN>
				<TOKEN id="token-36-36" start_char="6109" end_char="6110">to</TOKEN>
				<TOKEN id="token-36-37" start_char="6112" end_char="6117">answer</TOKEN>
				<TOKEN id="token-36-38" start_char="6119" end_char="6121">any</TOKEN>
				<TOKEN id="token-36-39" start_char="6123" end_char="6131">questions</TOKEN>
				<TOKEN id="token-36-40" start_char="6133" end_char="6137">about</TOKEN>
				<TOKEN id="token-36-41" start_char="6139" end_char="6140">it</TOKEN>
				<TOKEN id="token-36-42" start_char="6141" end_char="6141">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-37" start_char="6143" end_char="6305">
				<ORIGINAL_TEXT>Thomas Gallagher, a virus expert and professor at Loyola University of Chicago, seconded the authors in dismissing the idea that the pandemic could have lab roots.</ORIGINAL_TEXT>
				<TOKEN id="token-37-0" start_char="6143" end_char="6148">Thomas</TOKEN>
				<TOKEN id="token-37-1" start_char="6150" end_char="6158">Gallagher</TOKEN>
				<TOKEN id="token-37-2" start_char="6159" end_char="6159">,</TOKEN>
				<TOKEN id="token-37-3" start_char="6161" end_char="6161">a</TOKEN>
				<TOKEN id="token-37-4" start_char="6163" end_char="6167">virus</TOKEN>
				<TOKEN id="token-37-5" start_char="6169" end_char="6174">expert</TOKEN>
				<TOKEN id="token-37-6" start_char="6176" end_char="6178">and</TOKEN>
				<TOKEN id="token-37-7" start_char="6180" end_char="6188">professor</TOKEN>
				<TOKEN id="token-37-8" start_char="6190" end_char="6191">at</TOKEN>
				<TOKEN id="token-37-9" start_char="6193" end_char="6198">Loyola</TOKEN>
				<TOKEN id="token-37-10" start_char="6200" end_char="6209">University</TOKEN>
				<TOKEN id="token-37-11" start_char="6211" end_char="6212">of</TOKEN>
				<TOKEN id="token-37-12" start_char="6214" end_char="6220">Chicago</TOKEN>
				<TOKEN id="token-37-13" start_char="6221" end_char="6221">,</TOKEN>
				<TOKEN id="token-37-14" start_char="6223" end_char="6230">seconded</TOKEN>
				<TOKEN id="token-37-15" start_char="6232" end_char="6234">the</TOKEN>
				<TOKEN id="token-37-16" start_char="6236" end_char="6242">authors</TOKEN>
				<TOKEN id="token-37-17" start_char="6244" end_char="6245">in</TOKEN>
				<TOKEN id="token-37-18" start_char="6247" end_char="6256">dismissing</TOKEN>
				<TOKEN id="token-37-19" start_char="6258" end_char="6260">the</TOKEN>
				<TOKEN id="token-37-20" start_char="6262" end_char="6265">idea</TOKEN>
				<TOKEN id="token-37-21" start_char="6267" end_char="6270">that</TOKEN>
				<TOKEN id="token-37-22" start_char="6272" end_char="6274">the</TOKEN>
				<TOKEN id="token-37-23" start_char="6276" end_char="6283">pandemic</TOKEN>
				<TOKEN id="token-37-24" start_char="6285" end_char="6289">could</TOKEN>
				<TOKEN id="token-37-25" start_char="6291" end_char="6294">have</TOKEN>
				<TOKEN id="token-37-26" start_char="6296" end_char="6298">lab</TOKEN>
				<TOKEN id="token-37-27" start_char="6300" end_char="6304">roots</TOKEN>
				<TOKEN id="token-37-28" start_char="6305" end_char="6305">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-38" start_char="6307" end_char="6457">
				<ORIGINAL_TEXT>“The authors of the new letter in Nature Medicine are arguing that the SARS-CoV-2 originated in animals, not in a research laboratory,” Gallagher says.</ORIGINAL_TEXT>
				<TOKEN id="token-38-0" start_char="6307" end_char="6307">“</TOKEN>
				<TOKEN id="token-38-1" start_char="6308" end_char="6310">The</TOKEN>
				<TOKEN id="token-38-2" start_char="6312" end_char="6318">authors</TOKEN>
				<TOKEN id="token-38-3" start_char="6320" end_char="6321">of</TOKEN>
				<TOKEN id="token-38-4" start_char="6323" end_char="6325">the</TOKEN>
				<TOKEN id="token-38-5" start_char="6327" end_char="6329">new</TOKEN>
				<TOKEN id="token-38-6" start_char="6331" end_char="6336">letter</TOKEN>
				<TOKEN id="token-38-7" start_char="6338" end_char="6339">in</TOKEN>
				<TOKEN id="token-38-8" start_char="6341" end_char="6346">Nature</TOKEN>
				<TOKEN id="token-38-9" start_char="6348" end_char="6355">Medicine</TOKEN>
				<TOKEN id="token-38-10" start_char="6357" end_char="6359">are</TOKEN>
				<TOKEN id="token-38-11" start_char="6361" end_char="6367">arguing</TOKEN>
				<TOKEN id="token-38-12" start_char="6369" end_char="6372">that</TOKEN>
				<TOKEN id="token-38-13" start_char="6374" end_char="6376">the</TOKEN>
				<TOKEN id="token-38-14" start_char="6378" end_char="6381">SARS</TOKEN>
				<TOKEN id="token-38-15" start_char="6382" end_char="6382">-</TOKEN>
				<TOKEN id="token-38-16" start_char="6383" end_char="6385">CoV</TOKEN>
				<TOKEN id="token-38-17" start_char="6386" end_char="6386">-</TOKEN>
				<TOKEN id="token-38-18" start_char="6387" end_char="6387">2</TOKEN>
				<TOKEN id="token-38-19" start_char="6389" end_char="6398">originated</TOKEN>
				<TOKEN id="token-38-20" start_char="6400" end_char="6401">in</TOKEN>
				<TOKEN id="token-38-21" start_char="6403" end_char="6409">animals</TOKEN>
				<TOKEN id="token-38-22" start_char="6410" end_char="6410">,</TOKEN>
				<TOKEN id="token-38-23" start_char="6412" end_char="6414">not</TOKEN>
				<TOKEN id="token-38-24" start_char="6416" end_char="6417">in</TOKEN>
				<TOKEN id="token-38-25" start_char="6419" end_char="6419">a</TOKEN>
				<TOKEN id="token-38-26" start_char="6421" end_char="6428">research</TOKEN>
				<TOKEN id="token-38-27" start_char="6430" end_char="6439">laboratory</TOKEN>
				<TOKEN id="token-38-28" start_char="6440" end_char="6441">,”</TOKEN>
				<TOKEN id="token-38-29" start_char="6443" end_char="6451">Gallagher</TOKEN>
				<TOKEN id="token-38-30" start_char="6453" end_char="6456">says</TOKEN>
				<TOKEN id="token-38-31" start_char="6457" end_char="6457">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-39" start_char="6459" end_char="6507">
				<ORIGINAL_TEXT>“I agree completely with the authors’ statement.”</ORIGINAL_TEXT>
				<TOKEN id="token-39-0" start_char="6459" end_char="6459">“</TOKEN>
				<TOKEN id="token-39-1" start_char="6460" end_char="6460">I</TOKEN>
				<TOKEN id="token-39-2" start_char="6462" end_char="6466">agree</TOKEN>
				<TOKEN id="token-39-3" start_char="6468" end_char="6477">completely</TOKEN>
				<TOKEN id="token-39-4" start_char="6479" end_char="6482">with</TOKEN>
				<TOKEN id="token-39-5" start_char="6484" end_char="6486">the</TOKEN>
				<TOKEN id="token-39-6" start_char="6488" end_char="6494">authors</TOKEN>
				<TOKEN id="token-39-7" start_char="6495" end_char="6495">’</TOKEN>
				<TOKEN id="token-39-8" start_char="6497" end_char="6505">statement</TOKEN>
				<TOKEN id="token-39-9" start_char="6506" end_char="6507">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-40" start_char="6509" end_char="6721">
				<ORIGINAL_TEXT>“Suggesting that SARS-CoV-2 is a purposely manipulated laboratory virus or a product of an accidental laboratory release would be utterly defenseless, truly unhelpful, and extremely inappropriate,” Gallagher says.</ORIGINAL_TEXT>
				<TOKEN id="token-40-0" start_char="6509" end_char="6509">“</TOKEN>
				<TOKEN id="token-40-1" start_char="6510" end_char="6519">Suggesting</TOKEN>
				<TOKEN id="token-40-2" start_char="6521" end_char="6524">that</TOKEN>
				<TOKEN id="token-40-3" start_char="6526" end_char="6529">SARS</TOKEN>
				<TOKEN id="token-40-4" start_char="6530" end_char="6530">-</TOKEN>
				<TOKEN id="token-40-5" start_char="6531" end_char="6533">CoV</TOKEN>
				<TOKEN id="token-40-6" start_char="6534" end_char="6534">-</TOKEN>
				<TOKEN id="token-40-7" start_char="6535" end_char="6535">2</TOKEN>
				<TOKEN id="token-40-8" start_char="6537" end_char="6538">is</TOKEN>
				<TOKEN id="token-40-9" start_char="6540" end_char="6540">a</TOKEN>
				<TOKEN id="token-40-10" start_char="6542" end_char="6550">purposely</TOKEN>
				<TOKEN id="token-40-11" start_char="6552" end_char="6562">manipulated</TOKEN>
				<TOKEN id="token-40-12" start_char="6564" end_char="6573">laboratory</TOKEN>
				<TOKEN id="token-40-13" start_char="6575" end_char="6579">virus</TOKEN>
				<TOKEN id="token-40-14" start_char="6581" end_char="6582">or</TOKEN>
				<TOKEN id="token-40-15" start_char="6584" end_char="6584">a</TOKEN>
				<TOKEN id="token-40-16" start_char="6586" end_char="6592">product</TOKEN>
				<TOKEN id="token-40-17" start_char="6594" end_char="6595">of</TOKEN>
				<TOKEN id="token-40-18" start_char="6597" end_char="6598">an</TOKEN>
				<TOKEN id="token-40-19" start_char="6600" end_char="6609">accidental</TOKEN>
				<TOKEN id="token-40-20" start_char="6611" end_char="6620">laboratory</TOKEN>
				<TOKEN id="token-40-21" start_char="6622" end_char="6628">release</TOKEN>
				<TOKEN id="token-40-22" start_char="6630" end_char="6634">would</TOKEN>
				<TOKEN id="token-40-23" start_char="6636" end_char="6637">be</TOKEN>
				<TOKEN id="token-40-24" start_char="6639" end_char="6645">utterly</TOKEN>
				<TOKEN id="token-40-25" start_char="6647" end_char="6657">defenseless</TOKEN>
				<TOKEN id="token-40-26" start_char="6658" end_char="6658">,</TOKEN>
				<TOKEN id="token-40-27" start_char="6660" end_char="6664">truly</TOKEN>
				<TOKEN id="token-40-28" start_char="6666" end_char="6674">unhelpful</TOKEN>
				<TOKEN id="token-40-29" start_char="6675" end_char="6675">,</TOKEN>
				<TOKEN id="token-40-30" start_char="6677" end_char="6679">and</TOKEN>
				<TOKEN id="token-40-31" start_char="6681" end_char="6689">extremely</TOKEN>
				<TOKEN id="token-40-32" start_char="6691" end_char="6703">inappropriate</TOKEN>
				<TOKEN id="token-40-33" start_char="6704" end_char="6705">,”</TOKEN>
				<TOKEN id="token-40-34" start_char="6707" end_char="6715">Gallagher</TOKEN>
				<TOKEN id="token-40-35" start_char="6717" end_char="6720">says</TOKEN>
				<TOKEN id="token-40-36" start_char="6721" end_char="6721">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-41" start_char="6723" end_char="6768">
				<ORIGINAL_TEXT>Still, lab safety has been a problem in China.</ORIGINAL_TEXT>
				<TOKEN id="token-41-0" start_char="6723" end_char="6727">Still</TOKEN>
				<TOKEN id="token-41-1" start_char="6728" end_char="6728">,</TOKEN>
				<TOKEN id="token-41-2" start_char="6730" end_char="6732">lab</TOKEN>
				<TOKEN id="token-41-3" start_char="6734" end_char="6739">safety</TOKEN>
				<TOKEN id="token-41-4" start_char="6741" end_char="6743">has</TOKEN>
				<TOKEN id="token-41-5" start_char="6745" end_char="6748">been</TOKEN>
				<TOKEN id="token-41-6" start_char="6750" end_char="6750">a</TOKEN>
				<TOKEN id="token-41-7" start_char="6752" end_char="6758">problem</TOKEN>
				<TOKEN id="token-41-8" start_char="6760" end_char="6761">in</TOKEN>
				<TOKEN id="token-41-9" start_char="6763" end_char="6767">China</TOKEN>
				<TOKEN id="token-41-10" start_char="6768" end_char="6768">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-42" start_char="6770" end_char="6939">
				<ORIGINAL_TEXT>“A safety breach at a Chinese Center for Disease Control and Prevention lab is believed to have caused four suspected SARS cases, including one death, in Beijing in 2004.</ORIGINAL_TEXT>
				<TOKEN id="token-42-0" start_char="6770" end_char="6770">“</TOKEN>
				<TOKEN id="token-42-1" start_char="6771" end_char="6771">A</TOKEN>
				<TOKEN id="token-42-2" start_char="6773" end_char="6778">safety</TOKEN>
				<TOKEN id="token-42-3" start_char="6780" end_char="6785">breach</TOKEN>
				<TOKEN id="token-42-4" start_char="6787" end_char="6788">at</TOKEN>
				<TOKEN id="token-42-5" start_char="6790" end_char="6790">a</TOKEN>
				<TOKEN id="token-42-6" start_char="6792" end_char="6798">Chinese</TOKEN>
				<TOKEN id="token-42-7" start_char="6800" end_char="6805">Center</TOKEN>
				<TOKEN id="token-42-8" start_char="6807" end_char="6809">for</TOKEN>
				<TOKEN id="token-42-9" start_char="6811" end_char="6817">Disease</TOKEN>
				<TOKEN id="token-42-10" start_char="6819" end_char="6825">Control</TOKEN>
				<TOKEN id="token-42-11" start_char="6827" end_char="6829">and</TOKEN>
				<TOKEN id="token-42-12" start_char="6831" end_char="6840">Prevention</TOKEN>
				<TOKEN id="token-42-13" start_char="6842" end_char="6844">lab</TOKEN>
				<TOKEN id="token-42-14" start_char="6846" end_char="6847">is</TOKEN>
				<TOKEN id="token-42-15" start_char="6849" end_char="6856">believed</TOKEN>
				<TOKEN id="token-42-16" start_char="6858" end_char="6859">to</TOKEN>
				<TOKEN id="token-42-17" start_char="6861" end_char="6864">have</TOKEN>
				<TOKEN id="token-42-18" start_char="6866" end_char="6871">caused</TOKEN>
				<TOKEN id="token-42-19" start_char="6873" end_char="6876">four</TOKEN>
				<TOKEN id="token-42-20" start_char="6878" end_char="6886">suspected</TOKEN>
				<TOKEN id="token-42-21" start_char="6888" end_char="6891">SARS</TOKEN>
				<TOKEN id="token-42-22" start_char="6893" end_char="6897">cases</TOKEN>
				<TOKEN id="token-42-23" start_char="6898" end_char="6898">,</TOKEN>
				<TOKEN id="token-42-24" start_char="6900" end_char="6908">including</TOKEN>
				<TOKEN id="token-42-25" start_char="6910" end_char="6912">one</TOKEN>
				<TOKEN id="token-42-26" start_char="6914" end_char="6918">death</TOKEN>
				<TOKEN id="token-42-27" start_char="6919" end_char="6919">,</TOKEN>
				<TOKEN id="token-42-28" start_char="6921" end_char="6922">in</TOKEN>
				<TOKEN id="token-42-29" start_char="6924" end_char="6930">Beijing</TOKEN>
				<TOKEN id="token-42-30" start_char="6932" end_char="6933">in</TOKEN>
				<TOKEN id="token-42-31" start_char="6935" end_char="6938">2004</TOKEN>
				<TOKEN id="token-42-32" start_char="6939" end_char="6939">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-43" start_char="6941" end_char="7085">
				<ORIGINAL_TEXT>A similar accident caused 65 lab workers of Lanzhou Veterinary Research Institute to be infected with brucellosis in December 2019,” Huang wrote.</ORIGINAL_TEXT>
				<TOKEN id="token-43-0" start_char="6941" end_char="6941">A</TOKEN>
				<TOKEN id="token-43-1" start_char="6943" end_char="6949">similar</TOKEN>
				<TOKEN id="token-43-2" start_char="6951" end_char="6958">accident</TOKEN>
				<TOKEN id="token-43-3" start_char="6960" end_char="6965">caused</TOKEN>
				<TOKEN id="token-43-4" start_char="6967" end_char="6968">65</TOKEN>
				<TOKEN id="token-43-5" start_char="6970" end_char="6972">lab</TOKEN>
				<TOKEN id="token-43-6" start_char="6974" end_char="6980">workers</TOKEN>
				<TOKEN id="token-43-7" start_char="6982" end_char="6983">of</TOKEN>
				<TOKEN id="token-43-8" start_char="6985" end_char="6991">Lanzhou</TOKEN>
				<TOKEN id="token-43-9" start_char="6993" end_char="7002">Veterinary</TOKEN>
				<TOKEN id="token-43-10" start_char="7004" end_char="7011">Research</TOKEN>
				<TOKEN id="token-43-11" start_char="7013" end_char="7021">Institute</TOKEN>
				<TOKEN id="token-43-12" start_char="7023" end_char="7024">to</TOKEN>
				<TOKEN id="token-43-13" start_char="7026" end_char="7027">be</TOKEN>
				<TOKEN id="token-43-14" start_char="7029" end_char="7036">infected</TOKEN>
				<TOKEN id="token-43-15" start_char="7038" end_char="7041">with</TOKEN>
				<TOKEN id="token-43-16" start_char="7043" end_char="7053">brucellosis</TOKEN>
				<TOKEN id="token-43-17" start_char="7055" end_char="7056">in</TOKEN>
				<TOKEN id="token-43-18" start_char="7058" end_char="7065">December</TOKEN>
				<TOKEN id="token-43-19" start_char="7067" end_char="7070">2019</TOKEN>
				<TOKEN id="token-43-20" start_char="7071" end_char="7072">,”</TOKEN>
				<TOKEN id="token-43-21" start_char="7074" end_char="7078">Huang</TOKEN>
				<TOKEN id="token-43-22" start_char="7080" end_char="7084">wrote</TOKEN>
				<TOKEN id="token-43-23" start_char="7085" end_char="7085">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-44" start_char="7087" end_char="7229">
				<ORIGINAL_TEXT>“In January 2020, a renowned Chinese scientist, Li Ning, was sentenced to 12 years in prison for selling experimental animals to local markets.</ORIGINAL_TEXT>
				<TOKEN id="token-44-0" start_char="7087" end_char="7087">“</TOKEN>
				<TOKEN id="token-44-1" start_char="7088" end_char="7089">In</TOKEN>
				<TOKEN id="token-44-2" start_char="7091" end_char="7097">January</TOKEN>
				<TOKEN id="token-44-3" start_char="7099" end_char="7102">2020</TOKEN>
				<TOKEN id="token-44-4" start_char="7103" end_char="7103">,</TOKEN>
				<TOKEN id="token-44-5" start_char="7105" end_char="7105">a</TOKEN>
				<TOKEN id="token-44-6" start_char="7107" end_char="7114">renowned</TOKEN>
				<TOKEN id="token-44-7" start_char="7116" end_char="7122">Chinese</TOKEN>
				<TOKEN id="token-44-8" start_char="7124" end_char="7132">scientist</TOKEN>
				<TOKEN id="token-44-9" start_char="7133" end_char="7133">,</TOKEN>
				<TOKEN id="token-44-10" start_char="7135" end_char="7136">Li</TOKEN>
				<TOKEN id="token-44-11" start_char="7138" end_char="7141">Ning</TOKEN>
				<TOKEN id="token-44-12" start_char="7142" end_char="7142">,</TOKEN>
				<TOKEN id="token-44-13" start_char="7144" end_char="7146">was</TOKEN>
				<TOKEN id="token-44-14" start_char="7148" end_char="7156">sentenced</TOKEN>
				<TOKEN id="token-44-15" start_char="7158" end_char="7159">to</TOKEN>
				<TOKEN id="token-44-16" start_char="7161" end_char="7162">12</TOKEN>
				<TOKEN id="token-44-17" start_char="7164" end_char="7168">years</TOKEN>
				<TOKEN id="token-44-18" start_char="7170" end_char="7171">in</TOKEN>
				<TOKEN id="token-44-19" start_char="7173" end_char="7178">prison</TOKEN>
				<TOKEN id="token-44-20" start_char="7180" end_char="7182">for</TOKEN>
				<TOKEN id="token-44-21" start_char="7184" end_char="7190">selling</TOKEN>
				<TOKEN id="token-44-22" start_char="7192" end_char="7203">experimental</TOKEN>
				<TOKEN id="token-44-23" start_char="7205" end_char="7211">animals</TOKEN>
				<TOKEN id="token-44-24" start_char="7213" end_char="7214">to</TOKEN>
				<TOKEN id="token-44-25" start_char="7216" end_char="7220">local</TOKEN>
				<TOKEN id="token-44-26" start_char="7222" end_char="7228">markets</TOKEN>
				<TOKEN id="token-44-27" start_char="7229" end_char="7229">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-45" start_char="7231" end_char="7294">
				<ORIGINAL_TEXT>And China is hardly the only place to experience such accidents.</ORIGINAL_TEXT>
				<TOKEN id="token-45-0" start_char="7231" end_char="7233">And</TOKEN>
				<TOKEN id="token-45-1" start_char="7235" end_char="7239">China</TOKEN>
				<TOKEN id="token-45-2" start_char="7241" end_char="7242">is</TOKEN>
				<TOKEN id="token-45-3" start_char="7244" end_char="7249">hardly</TOKEN>
				<TOKEN id="token-45-4" start_char="7251" end_char="7253">the</TOKEN>
				<TOKEN id="token-45-5" start_char="7255" end_char="7258">only</TOKEN>
				<TOKEN id="token-45-6" start_char="7260" end_char="7264">place</TOKEN>
				<TOKEN id="token-45-7" start_char="7266" end_char="7267">to</TOKEN>
				<TOKEN id="token-45-8" start_char="7269" end_char="7278">experience</TOKEN>
				<TOKEN id="token-45-9" start_char="7280" end_char="7283">such</TOKEN>
				<TOKEN id="token-45-10" start_char="7285" end_char="7293">accidents</TOKEN>
				<TOKEN id="token-45-11" start_char="7294" end_char="7294">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-46" start_char="7296" end_char="7602">
				<ORIGINAL_TEXT>A USA Today investigation in 2016, for instance, revealed an incident involving cascading equipment failures in a decontamination chamber as US Centers for Disease Control and Prevention researchers tried to leave a biosafety level 4 lab that likely stored samples of the viruses causing Ebola and smallpox.</ORIGINAL_TEXT>
				<TOKEN id="token-46-0" start_char="7296" end_char="7296">A</TOKEN>
				<TOKEN id="token-46-1" start_char="7298" end_char="7300">USA</TOKEN>
				<TOKEN id="token-46-2" start_char="7302" end_char="7306">Today</TOKEN>
				<TOKEN id="token-46-3" start_char="7308" end_char="7320">investigation</TOKEN>
				<TOKEN id="token-46-4" start_char="7322" end_char="7323">in</TOKEN>
				<TOKEN id="token-46-5" start_char="7325" end_char="7328">2016</TOKEN>
				<TOKEN id="token-46-6" start_char="7329" end_char="7329">,</TOKEN>
				<TOKEN id="token-46-7" start_char="7331" end_char="7333">for</TOKEN>
				<TOKEN id="token-46-8" start_char="7335" end_char="7342">instance</TOKEN>
				<TOKEN id="token-46-9" start_char="7343" end_char="7343">,</TOKEN>
				<TOKEN id="token-46-10" start_char="7345" end_char="7352">revealed</TOKEN>
				<TOKEN id="token-46-11" start_char="7354" end_char="7355">an</TOKEN>
				<TOKEN id="token-46-12" start_char="7357" end_char="7364">incident</TOKEN>
				<TOKEN id="token-46-13" start_char="7366" end_char="7374">involving</TOKEN>
				<TOKEN id="token-46-14" start_char="7376" end_char="7384">cascading</TOKEN>
				<TOKEN id="token-46-15" start_char="7386" end_char="7394">equipment</TOKEN>
				<TOKEN id="token-46-16" start_char="7396" end_char="7403">failures</TOKEN>
				<TOKEN id="token-46-17" start_char="7405" end_char="7406">in</TOKEN>
				<TOKEN id="token-46-18" start_char="7408" end_char="7408">a</TOKEN>
				<TOKEN id="token-46-19" start_char="7410" end_char="7424">decontamination</TOKEN>
				<TOKEN id="token-46-20" start_char="7426" end_char="7432">chamber</TOKEN>
				<TOKEN id="token-46-21" start_char="7434" end_char="7435">as</TOKEN>
				<TOKEN id="token-46-22" start_char="7437" end_char="7438">US</TOKEN>
				<TOKEN id="token-46-23" start_char="7440" end_char="7446">Centers</TOKEN>
				<TOKEN id="token-46-24" start_char="7448" end_char="7450">for</TOKEN>
				<TOKEN id="token-46-25" start_char="7452" end_char="7458">Disease</TOKEN>
				<TOKEN id="token-46-26" start_char="7460" end_char="7466">Control</TOKEN>
				<TOKEN id="token-46-27" start_char="7468" end_char="7470">and</TOKEN>
				<TOKEN id="token-46-28" start_char="7472" end_char="7481">Prevention</TOKEN>
				<TOKEN id="token-46-29" start_char="7483" end_char="7493">researchers</TOKEN>
				<TOKEN id="token-46-30" start_char="7495" end_char="7499">tried</TOKEN>
				<TOKEN id="token-46-31" start_char="7501" end_char="7502">to</TOKEN>
				<TOKEN id="token-46-32" start_char="7504" end_char="7508">leave</TOKEN>
				<TOKEN id="token-46-33" start_char="7510" end_char="7510">a</TOKEN>
				<TOKEN id="token-46-34" start_char="7512" end_char="7520">biosafety</TOKEN>
				<TOKEN id="token-46-35" start_char="7522" end_char="7526">level</TOKEN>
				<TOKEN id="token-46-36" start_char="7528" end_char="7528">4</TOKEN>
				<TOKEN id="token-46-37" start_char="7530" end_char="7532">lab</TOKEN>
				<TOKEN id="token-46-38" start_char="7534" end_char="7537">that</TOKEN>
				<TOKEN id="token-46-39" start_char="7539" end_char="7544">likely</TOKEN>
				<TOKEN id="token-46-40" start_char="7546" end_char="7551">stored</TOKEN>
				<TOKEN id="token-46-41" start_char="7553" end_char="7559">samples</TOKEN>
				<TOKEN id="token-46-42" start_char="7561" end_char="7562">of</TOKEN>
				<TOKEN id="token-46-43" start_char="7564" end_char="7566">the</TOKEN>
				<TOKEN id="token-46-44" start_char="7568" end_char="7574">viruses</TOKEN>
				<TOKEN id="token-46-45" start_char="7576" end_char="7582">causing</TOKEN>
				<TOKEN id="token-46-46" start_char="7584" end_char="7588">Ebola</TOKEN>
				<TOKEN id="token-46-47" start_char="7590" end_char="7592">and</TOKEN>
				<TOKEN id="token-46-48" start_char="7594" end_char="7601">smallpox</TOKEN>
				<TOKEN id="token-46-49" start_char="7602" end_char="7602">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-47" start_char="7604" end_char="7718">
				<ORIGINAL_TEXT>In 2014, the agency revealed that staff had accidently sent live anthrax between laboratories, exposing 84 workers.</ORIGINAL_TEXT>
				<TOKEN id="token-47-0" start_char="7604" end_char="7605">In</TOKEN>
				<TOKEN id="token-47-1" start_char="7607" end_char="7610">2014</TOKEN>
				<TOKEN id="token-47-2" start_char="7611" end_char="7611">,</TOKEN>
				<TOKEN id="token-47-3" start_char="7613" end_char="7615">the</TOKEN>
				<TOKEN id="token-47-4" start_char="7617" end_char="7622">agency</TOKEN>
				<TOKEN id="token-47-5" start_char="7624" end_char="7631">revealed</TOKEN>
				<TOKEN id="token-47-6" start_char="7633" end_char="7636">that</TOKEN>
				<TOKEN id="token-47-7" start_char="7638" end_char="7642">staff</TOKEN>
				<TOKEN id="token-47-8" start_char="7644" end_char="7646">had</TOKEN>
				<TOKEN id="token-47-9" start_char="7648" end_char="7657">accidently</TOKEN>
				<TOKEN id="token-47-10" start_char="7659" end_char="7662">sent</TOKEN>
				<TOKEN id="token-47-11" start_char="7664" end_char="7667">live</TOKEN>
				<TOKEN id="token-47-12" start_char="7669" end_char="7675">anthrax</TOKEN>
				<TOKEN id="token-47-13" start_char="7677" end_char="7683">between</TOKEN>
				<TOKEN id="token-47-14" start_char="7685" end_char="7696">laboratories</TOKEN>
				<TOKEN id="token-47-15" start_char="7697" end_char="7697">,</TOKEN>
				<TOKEN id="token-47-16" start_char="7699" end_char="7706">exposing</TOKEN>
				<TOKEN id="token-47-17" start_char="7708" end_char="7709">84</TOKEN>
				<TOKEN id="token-47-18" start_char="7711" end_char="7717">workers</TOKEN>
				<TOKEN id="token-47-19" start_char="7718" end_char="7718">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-48" start_char="7720" end_char="7812">
				<ORIGINAL_TEXT>In an investigation, officials found other mishaps that had occurred in the preceding decade.</ORIGINAL_TEXT>
				<TOKEN id="token-48-0" start_char="7720" end_char="7721">In</TOKEN>
				<TOKEN id="token-48-1" start_char="7723" end_char="7724">an</TOKEN>
				<TOKEN id="token-48-2" start_char="7726" end_char="7738">investigation</TOKEN>
				<TOKEN id="token-48-3" start_char="7739" end_char="7739">,</TOKEN>
				<TOKEN id="token-48-4" start_char="7741" end_char="7749">officials</TOKEN>
				<TOKEN id="token-48-5" start_char="7751" end_char="7755">found</TOKEN>
				<TOKEN id="token-48-6" start_char="7757" end_char="7761">other</TOKEN>
				<TOKEN id="token-48-7" start_char="7763" end_char="7769">mishaps</TOKEN>
				<TOKEN id="token-48-8" start_char="7771" end_char="7774">that</TOKEN>
				<TOKEN id="token-48-9" start_char="7776" end_char="7778">had</TOKEN>
				<TOKEN id="token-48-10" start_char="7780" end_char="7787">occurred</TOKEN>
				<TOKEN id="token-48-11" start_char="7789" end_char="7790">in</TOKEN>
				<TOKEN id="token-48-12" start_char="7792" end_char="7794">the</TOKEN>
				<TOKEN id="token-48-13" start_char="7796" end_char="7804">preceding</TOKEN>
				<TOKEN id="token-48-14" start_char="7806" end_char="7811">decade</TOKEN>
				<TOKEN id="token-48-15" start_char="7812" end_char="7812">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-49" start_char="7814" end_char="8052">
				<ORIGINAL_TEXT>Whether a lab accident could have led to the COVID-19 outbreak remains unclear, but making that determination is worthwhile, Ebright says: “Understanding the origin of the outbreak is a crucial step to reduce the risk of future outbreaks.”</ORIGINAL_TEXT>
				<TOKEN id="token-49-0" start_char="7814" end_char="7820">Whether</TOKEN>
				<TOKEN id="token-49-1" start_char="7822" end_char="7822">a</TOKEN>
				<TOKEN id="token-49-2" start_char="7824" end_char="7826">lab</TOKEN>
				<TOKEN id="token-49-3" start_char="7828" end_char="7835">accident</TOKEN>
				<TOKEN id="token-49-4" start_char="7837" end_char="7841">could</TOKEN>
				<TOKEN id="token-49-5" start_char="7843" end_char="7846">have</TOKEN>
				<TOKEN id="token-49-6" start_char="7848" end_char="7850">led</TOKEN>
				<TOKEN id="token-49-7" start_char="7852" end_char="7853">to</TOKEN>
				<TOKEN id="token-49-8" start_char="7855" end_char="7857">the</TOKEN>
				<TOKEN id="token-49-9" start_char="7859" end_char="7863">COVID</TOKEN>
				<TOKEN id="token-49-10" start_char="7864" end_char="7864">-</TOKEN>
				<TOKEN id="token-49-11" start_char="7865" end_char="7866">19</TOKEN>
				<TOKEN id="token-49-12" start_char="7868" end_char="7875">outbreak</TOKEN>
				<TOKEN id="token-49-13" start_char="7877" end_char="7883">remains</TOKEN>
				<TOKEN id="token-49-14" start_char="7885" end_char="7891">unclear</TOKEN>
				<TOKEN id="token-49-15" start_char="7892" end_char="7892">,</TOKEN>
				<TOKEN id="token-49-16" start_char="7894" end_char="7896">but</TOKEN>
				<TOKEN id="token-49-17" start_char="7898" end_char="7903">making</TOKEN>
				<TOKEN id="token-49-18" start_char="7905" end_char="7908">that</TOKEN>
				<TOKEN id="token-49-19" start_char="7910" end_char="7922">determination</TOKEN>
				<TOKEN id="token-49-20" start_char="7924" end_char="7925">is</TOKEN>
				<TOKEN id="token-49-21" start_char="7927" end_char="7936">worthwhile</TOKEN>
				<TOKEN id="token-49-22" start_char="7937" end_char="7937">,</TOKEN>
				<TOKEN id="token-49-23" start_char="7939" end_char="7945">Ebright</TOKEN>
				<TOKEN id="token-49-24" start_char="7947" end_char="7950">says</TOKEN>
				<TOKEN id="token-49-25" start_char="7951" end_char="7951">:</TOKEN>
				<TOKEN id="token-49-26" start_char="7953" end_char="7953">“</TOKEN>
				<TOKEN id="token-49-27" start_char="7954" end_char="7966">Understanding</TOKEN>
				<TOKEN id="token-49-28" start_char="7968" end_char="7970">the</TOKEN>
				<TOKEN id="token-49-29" start_char="7972" end_char="7977">origin</TOKEN>
				<TOKEN id="token-49-30" start_char="7979" end_char="7980">of</TOKEN>
				<TOKEN id="token-49-31" start_char="7982" end_char="7984">the</TOKEN>
				<TOKEN id="token-49-32" start_char="7986" end_char="7993">outbreak</TOKEN>
				<TOKEN id="token-49-33" start_char="7995" end_char="7996">is</TOKEN>
				<TOKEN id="token-49-34" start_char="7998" end_char="7998">a</TOKEN>
				<TOKEN id="token-49-35" start_char="8000" end_char="8006">crucial</TOKEN>
				<TOKEN id="token-49-36" start_char="8008" end_char="8011">step</TOKEN>
				<TOKEN id="token-49-37" start_char="8013" end_char="8014">to</TOKEN>
				<TOKEN id="token-49-38" start_char="8016" end_char="8021">reduce</TOKEN>
				<TOKEN id="token-49-39" start_char="8023" end_char="8025">the</TOKEN>
				<TOKEN id="token-49-40" start_char="8027" end_char="8030">risk</TOKEN>
				<TOKEN id="token-49-41" start_char="8032" end_char="8033">of</TOKEN>
				<TOKEN id="token-49-42" start_char="8035" end_char="8040">future</TOKEN>
				<TOKEN id="token-49-43" start_char="8042" end_char="8050">outbreaks</TOKEN>
				<TOKEN id="token-49-44" start_char="8051" end_char="8052">.”</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-50" start_char="8054" end_char="8256">
				<ORIGINAL_TEXT>Editors note: A previous version of this article implied that Lijian Zhao, a spokesman for China’s Ministry of Foreign Affairs, supported the false conspiracy theory that the coronavirus was a bioweapon.</ORIGINAL_TEXT>
				<TOKEN id="token-50-0" start_char="8054" end_char="8060">Editors</TOKEN>
				<TOKEN id="token-50-1" start_char="8062" end_char="8065">note</TOKEN>
				<TOKEN id="token-50-2" start_char="8066" end_char="8066">:</TOKEN>
				<TOKEN id="token-50-3" start_char="8068" end_char="8068">A</TOKEN>
				<TOKEN id="token-50-4" start_char="8070" end_char="8077">previous</TOKEN>
				<TOKEN id="token-50-5" start_char="8079" end_char="8085">version</TOKEN>
				<TOKEN id="token-50-6" start_char="8087" end_char="8088">of</TOKEN>
				<TOKEN id="token-50-7" start_char="8090" end_char="8093">this</TOKEN>
				<TOKEN id="token-50-8" start_char="8095" end_char="8101">article</TOKEN>
				<TOKEN id="token-50-9" start_char="8103" end_char="8109">implied</TOKEN>
				<TOKEN id="token-50-10" start_char="8111" end_char="8114">that</TOKEN>
				<TOKEN id="token-50-11" start_char="8116" end_char="8121">Lijian</TOKEN>
				<TOKEN id="token-50-12" start_char="8123" end_char="8126">Zhao</TOKEN>
				<TOKEN id="token-50-13" start_char="8127" end_char="8127">,</TOKEN>
				<TOKEN id="token-50-14" start_char="8129" end_char="8129">a</TOKEN>
				<TOKEN id="token-50-15" start_char="8131" end_char="8139">spokesman</TOKEN>
				<TOKEN id="token-50-16" start_char="8141" end_char="8143">for</TOKEN>
				<TOKEN id="token-50-17" start_char="8145" end_char="8149">China</TOKEN>
				<TOKEN id="token-50-18" start_char="8150" end_char="8150">’</TOKEN>
				<TOKEN id="token-50-19" start_char="8151" end_char="8151">s</TOKEN>
				<TOKEN id="token-50-20" start_char="8153" end_char="8160">Ministry</TOKEN>
				<TOKEN id="token-50-21" start_char="8162" end_char="8163">of</TOKEN>
				<TOKEN id="token-50-22" start_char="8165" end_char="8171">Foreign</TOKEN>
				<TOKEN id="token-50-23" start_char="8173" end_char="8179">Affairs</TOKEN>
				<TOKEN id="token-50-24" start_char="8180" end_char="8180">,</TOKEN>
				<TOKEN id="token-50-25" start_char="8182" end_char="8190">supported</TOKEN>
				<TOKEN id="token-50-26" start_char="8192" end_char="8194">the</TOKEN>
				<TOKEN id="token-50-27" start_char="8196" end_char="8200">false</TOKEN>
				<TOKEN id="token-50-28" start_char="8202" end_char="8211">conspiracy</TOKEN>
				<TOKEN id="token-50-29" start_char="8213" end_char="8218">theory</TOKEN>
				<TOKEN id="token-50-30" start_char="8220" end_char="8223">that</TOKEN>
				<TOKEN id="token-50-31" start_char="8225" end_char="8227">the</TOKEN>
				<TOKEN id="token-50-32" start_char="8229" end_char="8239">coronavirus</TOKEN>
				<TOKEN id="token-50-33" start_char="8241" end_char="8243">was</TOKEN>
				<TOKEN id="token-50-34" start_char="8245" end_char="8245">a</TOKEN>
				<TOKEN id="token-50-35" start_char="8247" end_char="8255">bioweapon</TOKEN>
				<TOKEN id="token-50-36" start_char="8256" end_char="8256">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-227-51" start_char="8258" end_char="8356">
				<ORIGINAL_TEXT>Instead, Zhao made an unfounded allegation that the US Army was involved in beginning the outbreak.</ORIGINAL_TEXT>
				<TOKEN id="token-51-0" start_char="8258" end_char="8264">Instead</TOKEN>
				<TOKEN id="token-51-1" start_char="8265" end_char="8265">,</TOKEN>
				<TOKEN id="token-51-2" start_char="8267" end_char="8270">Zhao</TOKEN>
				<TOKEN id="token-51-3" start_char="8272" end_char="8275">made</TOKEN>
				<TOKEN id="token-51-4" start_char="8277" end_char="8278">an</TOKEN>
				<TOKEN id="token-51-5" start_char="8280" end_char="8288">unfounded</TOKEN>
				<TOKEN id="token-51-6" start_char="8290" end_char="8299">allegation</TOKEN>
				<TOKEN id="token-51-7" start_char="8301" end_char="8304">that</TOKEN>
				<TOKEN id="token-51-8" start_char="8306" end_char="8308">the</TOKEN>
				<TOKEN id="token-51-9" start_char="8310" end_char="8311">US</TOKEN>
				<TOKEN id="token-51-10" start_char="8313" end_char="8316">Army</TOKEN>
				<TOKEN id="token-51-11" start_char="8318" end_char="8320">was</TOKEN>
				<TOKEN id="token-51-12" start_char="8322" end_char="8329">involved</TOKEN>
				<TOKEN id="token-51-13" start_char="8331" end_char="8332">in</TOKEN>
				<TOKEN id="token-51-14" start_char="8334" end_char="8342">beginning</TOKEN>
				<TOKEN id="token-51-15" start_char="8344" end_char="8346">the</TOKEN>
				<TOKEN id="token-51-16" start_char="8348" end_char="8355">outbreak</TOKEN>
				<TOKEN id="token-51-17" start_char="8356" end_char="8356">.</TOKEN>
			</SEG>
		</TEXT>
	</DOC>
</LCTL_TEXT>
