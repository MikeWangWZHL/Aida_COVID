<?xml version="1.0" encoding="utf-8"?>
<LCTL_TEXT>
	<DOC id="covid19scenario-113">
		<TEXT>
			<SEG id="covid19scenario-113-0" start_char="0" end_char="52">
				<ORIGINAL_TEXT>No, the new coronavirus didn't come from outer space.</ORIGINAL_TEXT>
				<TOKEN id="token-0-0" start_char="0" end_char="1">No</TOKEN>
				<TOKEN id="token-0-1" start_char="2" end_char="2">,</TOKEN>
				<TOKEN id="token-0-2" start_char="4" end_char="6">the</TOKEN>
				<TOKEN id="token-0-3" start_char="8" end_char="10">new</TOKEN>
				<TOKEN id="token-0-4" start_char="12" end_char="22">coronavirus</TOKEN>
				<TOKEN id="token-0-5" start_char="24" end_char="27">didn</TOKEN>
				<TOKEN id="token-0-6" start_char="28" end_char="28">'</TOKEN>
				<TOKEN id="token-0-7" start_char="29" end_char="29">t</TOKEN>
				<TOKEN id="token-0-8" start_char="31" end_char="34">come</TOKEN>
				<TOKEN id="token-0-9" start_char="36" end_char="39">from</TOKEN>
				<TOKEN id="token-0-10" start_char="41" end_char="45">outer</TOKEN>
				<TOKEN id="token-0-11" start_char="47" end_char="51">space</TOKEN>
				<TOKEN id="token-0-12" start_char="52" end_char="52">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-1" start_char="54" end_char="64">
				<ORIGINAL_TEXT>We promise.</ORIGINAL_TEXT>
				<TOKEN id="token-1-0" start_char="54" end_char="55">We</TOKEN>
				<TOKEN id="token-1-1" start_char="57" end_char="63">promise</TOKEN>
				<TOKEN id="token-1-2" start_char="64" end_char="64">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-2" start_char="66" end_char="204">
				<ORIGINAL_TEXT>With the coronavirus pandemic continuing to spread around the globe, people are panicked, and they're looking for answers and explanations.</ORIGINAL_TEXT>
				<TOKEN id="token-2-0" start_char="66" end_char="69">With</TOKEN>
				<TOKEN id="token-2-1" start_char="71" end_char="73">the</TOKEN>
				<TOKEN id="token-2-2" start_char="75" end_char="85">coronavirus</TOKEN>
				<TOKEN id="token-2-3" start_char="87" end_char="94">pandemic</TOKEN>
				<TOKEN id="token-2-4" start_char="96" end_char="105">continuing</TOKEN>
				<TOKEN id="token-2-5" start_char="107" end_char="108">to</TOKEN>
				<TOKEN id="token-2-6" start_char="110" end_char="115">spread</TOKEN>
				<TOKEN id="token-2-7" start_char="117" end_char="122">around</TOKEN>
				<TOKEN id="token-2-8" start_char="124" end_char="126">the</TOKEN>
				<TOKEN id="token-2-9" start_char="128" end_char="132">globe</TOKEN>
				<TOKEN id="token-2-10" start_char="133" end_char="133">,</TOKEN>
				<TOKEN id="token-2-11" start_char="135" end_char="140">people</TOKEN>
				<TOKEN id="token-2-12" start_char="142" end_char="144">are</TOKEN>
				<TOKEN id="token-2-13" start_char="146" end_char="153">panicked</TOKEN>
				<TOKEN id="token-2-14" start_char="154" end_char="154">,</TOKEN>
				<TOKEN id="token-2-15" start_char="156" end_char="158">and</TOKEN>
				<TOKEN id="token-2-16" start_char="160" end_char="163">they</TOKEN>
				<TOKEN id="token-2-17" start_char="164" end_char="164">'</TOKEN>
				<TOKEN id="token-2-18" start_char="165" end_char="166">re</TOKEN>
				<TOKEN id="token-2-19" start_char="168" end_char="174">looking</TOKEN>
				<TOKEN id="token-2-20" start_char="176" end_char="178">for</TOKEN>
				<TOKEN id="token-2-21" start_char="180" end_char="186">answers</TOKEN>
				<TOKEN id="token-2-22" start_char="188" end_char="190">and</TOKEN>
				<TOKEN id="token-2-23" start_char="192" end_char="203">explanations</TOKEN>
				<TOKEN id="token-2-24" start_char="204" end_char="204">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-3" start_char="206" end_char="292">
				<ORIGINAL_TEXT>One wild theory that has made its way around the web is that the virus came from space.</ORIGINAL_TEXT>
				<TOKEN id="token-3-0" start_char="206" end_char="208">One</TOKEN>
				<TOKEN id="token-3-1" start_char="210" end_char="213">wild</TOKEN>
				<TOKEN id="token-3-2" start_char="215" end_char="220">theory</TOKEN>
				<TOKEN id="token-3-3" start_char="222" end_char="225">that</TOKEN>
				<TOKEN id="token-3-4" start_char="227" end_char="229">has</TOKEN>
				<TOKEN id="token-3-5" start_char="231" end_char="234">made</TOKEN>
				<TOKEN id="token-3-6" start_char="236" end_char="238">its</TOKEN>
				<TOKEN id="token-3-7" start_char="240" end_char="242">way</TOKEN>
				<TOKEN id="token-3-8" start_char="244" end_char="249">around</TOKEN>
				<TOKEN id="token-3-9" start_char="251" end_char="253">the</TOKEN>
				<TOKEN id="token-3-10" start_char="255" end_char="257">web</TOKEN>
				<TOKEN id="token-3-11" start_char="259" end_char="260">is</TOKEN>
				<TOKEN id="token-3-12" start_char="262" end_char="265">that</TOKEN>
				<TOKEN id="token-3-13" start_char="267" end_char="269">the</TOKEN>
				<TOKEN id="token-3-14" start_char="271" end_char="275">virus</TOKEN>
				<TOKEN id="token-3-15" start_char="277" end_char="280">came</TOKEN>
				<TOKEN id="token-3-16" start_char="282" end_char="285">from</TOKEN>
				<TOKEN id="token-3-17" start_char="287" end_char="291">space</TOKEN>
				<TOKEN id="token-3-18" start_char="292" end_char="292">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-4" start_char="294" end_char="342">
				<ORIGINAL_TEXT>Spoiler alert: The virus did not come from space.</ORIGINAL_TEXT>
				<TOKEN id="token-4-0" start_char="294" end_char="300">Spoiler</TOKEN>
				<TOKEN id="token-4-1" start_char="302" end_char="306">alert</TOKEN>
				<TOKEN id="token-4-2" start_char="307" end_char="307">:</TOKEN>
				<TOKEN id="token-4-3" start_char="309" end_char="311">The</TOKEN>
				<TOKEN id="token-4-4" start_char="313" end_char="317">virus</TOKEN>
				<TOKEN id="token-4-5" start_char="319" end_char="321">did</TOKEN>
				<TOKEN id="token-4-6" start_char="323" end_char="325">not</TOKEN>
				<TOKEN id="token-4-7" start_char="327" end_char="330">come</TOKEN>
				<TOKEN id="token-4-8" start_char="332" end_char="335">from</TOKEN>
				<TOKEN id="token-4-9" start_char="337" end_char="341">space</TOKEN>
				<TOKEN id="token-4-10" start_char="342" end_char="342">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-5" start_char="344" end_char="593">
				<ORIGINAL_TEXT>Recently, Chandra Wickramasinghe, known for his work in astronomy and astrobiology, spread the idea that the virus was living on a comet and a piece of that space rock may have fallen to Earth during a brief fireball event over China in October 2019.</ORIGINAL_TEXT>
				<TOKEN id="token-5-0" start_char="344" end_char="351">Recently</TOKEN>
				<TOKEN id="token-5-1" start_char="352" end_char="352">,</TOKEN>
				<TOKEN id="token-5-2" start_char="354" end_char="360">Chandra</TOKEN>
				<TOKEN id="token-5-3" start_char="362" end_char="375">Wickramasinghe</TOKEN>
				<TOKEN id="token-5-4" start_char="376" end_char="376">,</TOKEN>
				<TOKEN id="token-5-5" start_char="378" end_char="382">known</TOKEN>
				<TOKEN id="token-5-6" start_char="384" end_char="386">for</TOKEN>
				<TOKEN id="token-5-7" start_char="388" end_char="390">his</TOKEN>
				<TOKEN id="token-5-8" start_char="392" end_char="395">work</TOKEN>
				<TOKEN id="token-5-9" start_char="397" end_char="398">in</TOKEN>
				<TOKEN id="token-5-10" start_char="400" end_char="408">astronomy</TOKEN>
				<TOKEN id="token-5-11" start_char="410" end_char="412">and</TOKEN>
				<TOKEN id="token-5-12" start_char="414" end_char="425">astrobiology</TOKEN>
				<TOKEN id="token-5-13" start_char="426" end_char="426">,</TOKEN>
				<TOKEN id="token-5-14" start_char="428" end_char="433">spread</TOKEN>
				<TOKEN id="token-5-15" start_char="435" end_char="437">the</TOKEN>
				<TOKEN id="token-5-16" start_char="439" end_char="442">idea</TOKEN>
				<TOKEN id="token-5-17" start_char="444" end_char="447">that</TOKEN>
				<TOKEN id="token-5-18" start_char="449" end_char="451">the</TOKEN>
				<TOKEN id="token-5-19" start_char="453" end_char="457">virus</TOKEN>
				<TOKEN id="token-5-20" start_char="459" end_char="461">was</TOKEN>
				<TOKEN id="token-5-21" start_char="463" end_char="468">living</TOKEN>
				<TOKEN id="token-5-22" start_char="470" end_char="471">on</TOKEN>
				<TOKEN id="token-5-23" start_char="473" end_char="473">a</TOKEN>
				<TOKEN id="token-5-24" start_char="475" end_char="479">comet</TOKEN>
				<TOKEN id="token-5-25" start_char="481" end_char="483">and</TOKEN>
				<TOKEN id="token-5-26" start_char="485" end_char="485">a</TOKEN>
				<TOKEN id="token-5-27" start_char="487" end_char="491">piece</TOKEN>
				<TOKEN id="token-5-28" start_char="493" end_char="494">of</TOKEN>
				<TOKEN id="token-5-29" start_char="496" end_char="499">that</TOKEN>
				<TOKEN id="token-5-30" start_char="501" end_char="505">space</TOKEN>
				<TOKEN id="token-5-31" start_char="507" end_char="510">rock</TOKEN>
				<TOKEN id="token-5-32" start_char="512" end_char="514">may</TOKEN>
				<TOKEN id="token-5-33" start_char="516" end_char="519">have</TOKEN>
				<TOKEN id="token-5-34" start_char="521" end_char="526">fallen</TOKEN>
				<TOKEN id="token-5-35" start_char="528" end_char="529">to</TOKEN>
				<TOKEN id="token-5-36" start_char="531" end_char="535">Earth</TOKEN>
				<TOKEN id="token-5-37" start_char="537" end_char="542">during</TOKEN>
				<TOKEN id="token-5-38" start_char="544" end_char="544">a</TOKEN>
				<TOKEN id="token-5-39" start_char="546" end_char="550">brief</TOKEN>
				<TOKEN id="token-5-40" start_char="552" end_char="559">fireball</TOKEN>
				<TOKEN id="token-5-41" start_char="561" end_char="565">event</TOKEN>
				<TOKEN id="token-5-42" start_char="567" end_char="570">over</TOKEN>
				<TOKEN id="token-5-43" start_char="572" end_char="576">China</TOKEN>
				<TOKEN id="token-5-44" start_char="578" end_char="579">in</TOKEN>
				<TOKEN id="token-5-45" start_char="581" end_char="587">October</TOKEN>
				<TOKEN id="token-5-46" start_char="589" end_char="592">2019</TOKEN>
				<TOKEN id="token-5-47" start_char="593" end_char="593">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-6" start_char="595" end_char="688">
				<ORIGINAL_TEXT>He further implied that comets carrying viruses may have caused outbreaks in the past as well.</ORIGINAL_TEXT>
				<TOKEN id="token-6-0" start_char="595" end_char="596">He</TOKEN>
				<TOKEN id="token-6-1" start_char="598" end_char="604">further</TOKEN>
				<TOKEN id="token-6-2" start_char="606" end_char="612">implied</TOKEN>
				<TOKEN id="token-6-3" start_char="614" end_char="617">that</TOKEN>
				<TOKEN id="token-6-4" start_char="619" end_char="624">comets</TOKEN>
				<TOKEN id="token-6-5" start_char="626" end_char="633">carrying</TOKEN>
				<TOKEN id="token-6-6" start_char="635" end_char="641">viruses</TOKEN>
				<TOKEN id="token-6-7" start_char="643" end_char="645">may</TOKEN>
				<TOKEN id="token-6-8" start_char="647" end_char="650">have</TOKEN>
				<TOKEN id="token-6-9" start_char="652" end_char="657">caused</TOKEN>
				<TOKEN id="token-6-10" start_char="659" end_char="667">outbreaks</TOKEN>
				<TOKEN id="token-6-11" start_char="669" end_char="670">in</TOKEN>
				<TOKEN id="token-6-12" start_char="672" end_char="674">the</TOKEN>
				<TOKEN id="token-6-13" start_char="676" end_char="679">past</TOKEN>
				<TOKEN id="token-6-14" start_char="681" end_char="682">as</TOKEN>
				<TOKEN id="token-6-15" start_char="684" end_char="687">well</TOKEN>
				<TOKEN id="token-6-16" start_char="688" end_char="688">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-7" start_char="690" end_char="745">
				<ORIGINAL_TEXT>Related: Live updates about the coronavirus and COVID-19</ORIGINAL_TEXT>
				<TOKEN id="token-7-0" start_char="690" end_char="696">Related</TOKEN>
				<TOKEN id="token-7-1" start_char="697" end_char="697">:</TOKEN>
				<TOKEN id="token-7-2" start_char="699" end_char="702">Live</TOKEN>
				<TOKEN id="token-7-3" start_char="704" end_char="710">updates</TOKEN>
				<TOKEN id="token-7-4" start_char="712" end_char="716">about</TOKEN>
				<TOKEN id="token-7-5" start_char="718" end_char="720">the</TOKEN>
				<TOKEN id="token-7-6" start_char="722" end_char="732">coronavirus</TOKEN>
				<TOKEN id="token-7-7" start_char="734" end_char="736">and</TOKEN>
				<TOKEN id="token-7-8" start_char="738" end_char="742">COVID</TOKEN>
				<TOKEN id="token-7-9" start_char="743" end_char="743">-</TOKEN>
				<TOKEN id="token-7-10" start_char="744" end_char="745">19</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-8" start_char="747" end_char="816">
				<ORIGINAL_TEXT>More: Free space projects for kids at home due to coronavirus outbreak</ORIGINAL_TEXT>
				<TOKEN id="token-8-0" start_char="747" end_char="750">More</TOKEN>
				<TOKEN id="token-8-1" start_char="751" end_char="751">:</TOKEN>
				<TOKEN id="token-8-2" start_char="753" end_char="756">Free</TOKEN>
				<TOKEN id="token-8-3" start_char="758" end_char="762">space</TOKEN>
				<TOKEN id="token-8-4" start_char="764" end_char="771">projects</TOKEN>
				<TOKEN id="token-8-5" start_char="773" end_char="775">for</TOKEN>
				<TOKEN id="token-8-6" start_char="777" end_char="780">kids</TOKEN>
				<TOKEN id="token-8-7" start_char="782" end_char="783">at</TOKEN>
				<TOKEN id="token-8-8" start_char="785" end_char="788">home</TOKEN>
				<TOKEN id="token-8-9" start_char="790" end_char="792">due</TOKEN>
				<TOKEN id="token-8-10" start_char="794" end_char="795">to</TOKEN>
				<TOKEN id="token-8-11" start_char="797" end_char="807">coronavirus</TOKEN>
				<TOKEN id="token-8-12" start_char="809" end_char="816">outbreak</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-9" start_char="818" end_char="942">
				<ORIGINAL_TEXT>In the past, Wickramasinghe has asserted that another disease, severe acute respiratory syndrome (SARS) also came from space.</ORIGINAL_TEXT>
				<TOKEN id="token-9-0" start_char="818" end_char="819">In</TOKEN>
				<TOKEN id="token-9-1" start_char="821" end_char="823">the</TOKEN>
				<TOKEN id="token-9-2" start_char="825" end_char="828">past</TOKEN>
				<TOKEN id="token-9-3" start_char="829" end_char="829">,</TOKEN>
				<TOKEN id="token-9-4" start_char="831" end_char="844">Wickramasinghe</TOKEN>
				<TOKEN id="token-9-5" start_char="846" end_char="848">has</TOKEN>
				<TOKEN id="token-9-6" start_char="850" end_char="857">asserted</TOKEN>
				<TOKEN id="token-9-7" start_char="859" end_char="862">that</TOKEN>
				<TOKEN id="token-9-8" start_char="864" end_char="870">another</TOKEN>
				<TOKEN id="token-9-9" start_char="872" end_char="878">disease</TOKEN>
				<TOKEN id="token-9-10" start_char="879" end_char="879">,</TOKEN>
				<TOKEN id="token-9-11" start_char="881" end_char="886">severe</TOKEN>
				<TOKEN id="token-9-12" start_char="888" end_char="892">acute</TOKEN>
				<TOKEN id="token-9-13" start_char="894" end_char="904">respiratory</TOKEN>
				<TOKEN id="token-9-14" start_char="906" end_char="913">syndrome</TOKEN>
				<TOKEN id="token-9-15" start_char="915" end_char="915">(</TOKEN>
				<TOKEN id="token-9-16" start_char="916" end_char="919">SARS</TOKEN>
				<TOKEN id="token-9-17" start_char="920" end_char="920">)</TOKEN>
				<TOKEN id="token-9-18" start_char="922" end_char="925">also</TOKEN>
				<TOKEN id="token-9-19" start_char="927" end_char="930">came</TOKEN>
				<TOKEN id="token-9-20" start_char="932" end_char="935">from</TOKEN>
				<TOKEN id="token-9-21" start_char="937" end_char="941">space</TOKEN>
				<TOKEN id="token-9-22" start_char="942" end_char="942">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-10" start_char="944" end_char="1120">
				<ORIGINAL_TEXT>He even co-wrote a book with Fred Hoyle in the 1970s called &quot;Diseases from Space&quot; and, for decades, has tried to prove that diseases like SARS or influenza have come from space.</ORIGINAL_TEXT>
				<TOKEN id="token-10-0" start_char="944" end_char="945">He</TOKEN>
				<TOKEN id="token-10-1" start_char="947" end_char="950">even</TOKEN>
				<TOKEN id="token-10-2" start_char="952" end_char="953">co</TOKEN>
				<TOKEN id="token-10-3" start_char="954" end_char="954">-</TOKEN>
				<TOKEN id="token-10-4" start_char="955" end_char="959">wrote</TOKEN>
				<TOKEN id="token-10-5" start_char="961" end_char="961">a</TOKEN>
				<TOKEN id="token-10-6" start_char="963" end_char="966">book</TOKEN>
				<TOKEN id="token-10-7" start_char="968" end_char="971">with</TOKEN>
				<TOKEN id="token-10-8" start_char="973" end_char="976">Fred</TOKEN>
				<TOKEN id="token-10-9" start_char="978" end_char="982">Hoyle</TOKEN>
				<TOKEN id="token-10-10" start_char="984" end_char="985">in</TOKEN>
				<TOKEN id="token-10-11" start_char="987" end_char="989">the</TOKEN>
				<TOKEN id="token-10-12" start_char="991" end_char="995">1970s</TOKEN>
				<TOKEN id="token-10-13" start_char="997" end_char="1002">called</TOKEN>
				<TOKEN id="token-10-14" start_char="1004" end_char="1004">&quot;</TOKEN>
				<TOKEN id="token-10-15" start_char="1005" end_char="1012">Diseases</TOKEN>
				<TOKEN id="token-10-16" start_char="1014" end_char="1017">from</TOKEN>
				<TOKEN id="token-10-17" start_char="1019" end_char="1023">Space</TOKEN>
				<TOKEN id="token-10-18" start_char="1024" end_char="1024">&quot;</TOKEN>
				<TOKEN id="token-10-19" start_char="1026" end_char="1028">and</TOKEN>
				<TOKEN id="token-10-20" start_char="1029" end_char="1029">,</TOKEN>
				<TOKEN id="token-10-21" start_char="1031" end_char="1033">for</TOKEN>
				<TOKEN id="token-10-22" start_char="1035" end_char="1041">decades</TOKEN>
				<TOKEN id="token-10-23" start_char="1042" end_char="1042">,</TOKEN>
				<TOKEN id="token-10-24" start_char="1044" end_char="1046">has</TOKEN>
				<TOKEN id="token-10-25" start_char="1048" end_char="1052">tried</TOKEN>
				<TOKEN id="token-10-26" start_char="1054" end_char="1055">to</TOKEN>
				<TOKEN id="token-10-27" start_char="1057" end_char="1061">prove</TOKEN>
				<TOKEN id="token-10-28" start_char="1063" end_char="1066">that</TOKEN>
				<TOKEN id="token-10-29" start_char="1068" end_char="1075">diseases</TOKEN>
				<TOKEN id="token-10-30" start_char="1077" end_char="1080">like</TOKEN>
				<TOKEN id="token-10-31" start_char="1082" end_char="1085">SARS</TOKEN>
				<TOKEN id="token-10-32" start_char="1087" end_char="1088">or</TOKEN>
				<TOKEN id="token-10-33" start_char="1090" end_char="1098">influenza</TOKEN>
				<TOKEN id="token-10-34" start_char="1100" end_char="1103">have</TOKEN>
				<TOKEN id="token-10-35" start_char="1105" end_char="1108">come</TOKEN>
				<TOKEN id="token-10-36" start_char="1110" end_char="1113">from</TOKEN>
				<TOKEN id="token-10-37" start_char="1115" end_char="1119">space</TOKEN>
				<TOKEN id="token-10-38" start_char="1120" end_char="1120">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-11" start_char="1122" end_char="1316">
				<ORIGINAL_TEXT>However, scientists have rebuked Wickramasinghe's suggestions that any such illness might have extraterrestrial origins, and his ideas have largely been considered pseudoscience or &quot;bad science.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-11-0" start_char="1122" end_char="1128">However</TOKEN>
				<TOKEN id="token-11-1" start_char="1129" end_char="1129">,</TOKEN>
				<TOKEN id="token-11-2" start_char="1131" end_char="1140">scientists</TOKEN>
				<TOKEN id="token-11-3" start_char="1142" end_char="1145">have</TOKEN>
				<TOKEN id="token-11-4" start_char="1147" end_char="1153">rebuked</TOKEN>
				<TOKEN id="token-11-5" start_char="1155" end_char="1168">Wickramasinghe</TOKEN>
				<TOKEN id="token-11-6" start_char="1169" end_char="1169">'</TOKEN>
				<TOKEN id="token-11-7" start_char="1170" end_char="1170">s</TOKEN>
				<TOKEN id="token-11-8" start_char="1172" end_char="1182">suggestions</TOKEN>
				<TOKEN id="token-11-9" start_char="1184" end_char="1187">that</TOKEN>
				<TOKEN id="token-11-10" start_char="1189" end_char="1191">any</TOKEN>
				<TOKEN id="token-11-11" start_char="1193" end_char="1196">such</TOKEN>
				<TOKEN id="token-11-12" start_char="1198" end_char="1204">illness</TOKEN>
				<TOKEN id="token-11-13" start_char="1206" end_char="1210">might</TOKEN>
				<TOKEN id="token-11-14" start_char="1212" end_char="1215">have</TOKEN>
				<TOKEN id="token-11-15" start_char="1217" end_char="1232">extraterrestrial</TOKEN>
				<TOKEN id="token-11-16" start_char="1234" end_char="1240">origins</TOKEN>
				<TOKEN id="token-11-17" start_char="1241" end_char="1241">,</TOKEN>
				<TOKEN id="token-11-18" start_char="1243" end_char="1245">and</TOKEN>
				<TOKEN id="token-11-19" start_char="1247" end_char="1249">his</TOKEN>
				<TOKEN id="token-11-20" start_char="1251" end_char="1255">ideas</TOKEN>
				<TOKEN id="token-11-21" start_char="1257" end_char="1260">have</TOKEN>
				<TOKEN id="token-11-22" start_char="1262" end_char="1268">largely</TOKEN>
				<TOKEN id="token-11-23" start_char="1270" end_char="1273">been</TOKEN>
				<TOKEN id="token-11-24" start_char="1275" end_char="1284">considered</TOKEN>
				<TOKEN id="token-11-25" start_char="1286" end_char="1298">pseudoscience</TOKEN>
				<TOKEN id="token-11-26" start_char="1300" end_char="1301">or</TOKEN>
				<TOKEN id="token-11-27" start_char="1303" end_char="1303">&quot;</TOKEN>
				<TOKEN id="token-11-28" start_char="1304" end_char="1306">bad</TOKEN>
				<TOKEN id="token-11-29" start_char="1308" end_char="1314">science</TOKEN>
				<TOKEN id="token-11-30" start_char="1315" end_char="1316">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-12" start_char="1318" end_char="1635">
				<ORIGINAL_TEXT>It would be unprecedented to discover that a virus could survive the radiation it would be exposed to on such a long journey through space (never mind the trip back to Earth) and still be able to infect humans after it landed, astrobiologist Graham Lau, who hosts NASA's &quot;Ask an Astrobiologist&quot; series, told Space.com.</ORIGINAL_TEXT>
				<TOKEN id="token-12-0" start_char="1318" end_char="1319">It</TOKEN>
				<TOKEN id="token-12-1" start_char="1321" end_char="1325">would</TOKEN>
				<TOKEN id="token-12-2" start_char="1327" end_char="1328">be</TOKEN>
				<TOKEN id="token-12-3" start_char="1330" end_char="1342">unprecedented</TOKEN>
				<TOKEN id="token-12-4" start_char="1344" end_char="1345">to</TOKEN>
				<TOKEN id="token-12-5" start_char="1347" end_char="1354">discover</TOKEN>
				<TOKEN id="token-12-6" start_char="1356" end_char="1359">that</TOKEN>
				<TOKEN id="token-12-7" start_char="1361" end_char="1361">a</TOKEN>
				<TOKEN id="token-12-8" start_char="1363" end_char="1367">virus</TOKEN>
				<TOKEN id="token-12-9" start_char="1369" end_char="1373">could</TOKEN>
				<TOKEN id="token-12-10" start_char="1375" end_char="1381">survive</TOKEN>
				<TOKEN id="token-12-11" start_char="1383" end_char="1385">the</TOKEN>
				<TOKEN id="token-12-12" start_char="1387" end_char="1395">radiation</TOKEN>
				<TOKEN id="token-12-13" start_char="1397" end_char="1398">it</TOKEN>
				<TOKEN id="token-12-14" start_char="1400" end_char="1404">would</TOKEN>
				<TOKEN id="token-12-15" start_char="1406" end_char="1407">be</TOKEN>
				<TOKEN id="token-12-16" start_char="1409" end_char="1415">exposed</TOKEN>
				<TOKEN id="token-12-17" start_char="1417" end_char="1418">to</TOKEN>
				<TOKEN id="token-12-18" start_char="1420" end_char="1421">on</TOKEN>
				<TOKEN id="token-12-19" start_char="1423" end_char="1426">such</TOKEN>
				<TOKEN id="token-12-20" start_char="1428" end_char="1428">a</TOKEN>
				<TOKEN id="token-12-21" start_char="1430" end_char="1433">long</TOKEN>
				<TOKEN id="token-12-22" start_char="1435" end_char="1441">journey</TOKEN>
				<TOKEN id="token-12-23" start_char="1443" end_char="1449">through</TOKEN>
				<TOKEN id="token-12-24" start_char="1451" end_char="1455">space</TOKEN>
				<TOKEN id="token-12-25" start_char="1457" end_char="1457">(</TOKEN>
				<TOKEN id="token-12-26" start_char="1458" end_char="1462">never</TOKEN>
				<TOKEN id="token-12-27" start_char="1464" end_char="1467">mind</TOKEN>
				<TOKEN id="token-12-28" start_char="1469" end_char="1471">the</TOKEN>
				<TOKEN id="token-12-29" start_char="1473" end_char="1476">trip</TOKEN>
				<TOKEN id="token-12-30" start_char="1478" end_char="1481">back</TOKEN>
				<TOKEN id="token-12-31" start_char="1483" end_char="1484">to</TOKEN>
				<TOKEN id="token-12-32" start_char="1486" end_char="1490">Earth</TOKEN>
				<TOKEN id="token-12-33" start_char="1491" end_char="1491">)</TOKEN>
				<TOKEN id="token-12-34" start_char="1493" end_char="1495">and</TOKEN>
				<TOKEN id="token-12-35" start_char="1497" end_char="1501">still</TOKEN>
				<TOKEN id="token-12-36" start_char="1503" end_char="1504">be</TOKEN>
				<TOKEN id="token-12-37" start_char="1506" end_char="1509">able</TOKEN>
				<TOKEN id="token-12-38" start_char="1511" end_char="1512">to</TOKEN>
				<TOKEN id="token-12-39" start_char="1514" end_char="1519">infect</TOKEN>
				<TOKEN id="token-12-40" start_char="1521" end_char="1526">humans</TOKEN>
				<TOKEN id="token-12-41" start_char="1528" end_char="1532">after</TOKEN>
				<TOKEN id="token-12-42" start_char="1534" end_char="1535">it</TOKEN>
				<TOKEN id="token-12-43" start_char="1537" end_char="1542">landed</TOKEN>
				<TOKEN id="token-12-44" start_char="1543" end_char="1543">,</TOKEN>
				<TOKEN id="token-12-45" start_char="1545" end_char="1558">astrobiologist</TOKEN>
				<TOKEN id="token-12-46" start_char="1560" end_char="1565">Graham</TOKEN>
				<TOKEN id="token-12-47" start_char="1567" end_char="1569">Lau</TOKEN>
				<TOKEN id="token-12-48" start_char="1570" end_char="1570">,</TOKEN>
				<TOKEN id="token-12-49" start_char="1572" end_char="1574">who</TOKEN>
				<TOKEN id="token-12-50" start_char="1576" end_char="1580">hosts</TOKEN>
				<TOKEN id="token-12-51" start_char="1582" end_char="1585">NASA</TOKEN>
				<TOKEN id="token-12-52" start_char="1586" end_char="1586">'</TOKEN>
				<TOKEN id="token-12-53" start_char="1587" end_char="1587">s</TOKEN>
				<TOKEN id="token-12-54" start_char="1589" end_char="1589">&quot;</TOKEN>
				<TOKEN id="token-12-55" start_char="1590" end_char="1592">Ask</TOKEN>
				<TOKEN id="token-12-56" start_char="1594" end_char="1595">an</TOKEN>
				<TOKEN id="token-12-57" start_char="1597" end_char="1610">Astrobiologist</TOKEN>
				<TOKEN id="token-12-58" start_char="1611" end_char="1611">&quot;</TOKEN>
				<TOKEN id="token-12-59" start_char="1613" end_char="1618">series</TOKEN>
				<TOKEN id="token-12-60" start_char="1619" end_char="1619">,</TOKEN>
				<TOKEN id="token-12-61" start_char="1621" end_char="1624">told</TOKEN>
				<TOKEN id="token-12-62" start_char="1626" end_char="1630">Space</TOKEN>
				<TOKEN id="token-12-63" start_char="1631" end_char="1631">.</TOKEN>
				<TOKEN id="token-12-64" start_char="1632" end_char="1634">com</TOKEN>
				<TOKEN id="token-12-65" start_char="1635" end_char="1635">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-13" start_char="1637" end_char="1807">
				<ORIGINAL_TEXT>However, while it would be an incredibly unique and groundbreaking finding if this were true, Wickramasinghe simply does not have evidence to support his claims, Lau said.</ORIGINAL_TEXT>
				<TOKEN id="token-13-0" start_char="1637" end_char="1643">However</TOKEN>
				<TOKEN id="token-13-1" start_char="1644" end_char="1644">,</TOKEN>
				<TOKEN id="token-13-2" start_char="1646" end_char="1650">while</TOKEN>
				<TOKEN id="token-13-3" start_char="1652" end_char="1653">it</TOKEN>
				<TOKEN id="token-13-4" start_char="1655" end_char="1659">would</TOKEN>
				<TOKEN id="token-13-5" start_char="1661" end_char="1662">be</TOKEN>
				<TOKEN id="token-13-6" start_char="1664" end_char="1665">an</TOKEN>
				<TOKEN id="token-13-7" start_char="1667" end_char="1676">incredibly</TOKEN>
				<TOKEN id="token-13-8" start_char="1678" end_char="1683">unique</TOKEN>
				<TOKEN id="token-13-9" start_char="1685" end_char="1687">and</TOKEN>
				<TOKEN id="token-13-10" start_char="1689" end_char="1702">groundbreaking</TOKEN>
				<TOKEN id="token-13-11" start_char="1704" end_char="1710">finding</TOKEN>
				<TOKEN id="token-13-12" start_char="1712" end_char="1713">if</TOKEN>
				<TOKEN id="token-13-13" start_char="1715" end_char="1718">this</TOKEN>
				<TOKEN id="token-13-14" start_char="1720" end_char="1723">were</TOKEN>
				<TOKEN id="token-13-15" start_char="1725" end_char="1728">true</TOKEN>
				<TOKEN id="token-13-16" start_char="1729" end_char="1729">,</TOKEN>
				<TOKEN id="token-13-17" start_char="1731" end_char="1744">Wickramasinghe</TOKEN>
				<TOKEN id="token-13-18" start_char="1746" end_char="1751">simply</TOKEN>
				<TOKEN id="token-13-19" start_char="1753" end_char="1756">does</TOKEN>
				<TOKEN id="token-13-20" start_char="1758" end_char="1760">not</TOKEN>
				<TOKEN id="token-13-21" start_char="1762" end_char="1765">have</TOKEN>
				<TOKEN id="token-13-22" start_char="1767" end_char="1774">evidence</TOKEN>
				<TOKEN id="token-13-23" start_char="1776" end_char="1777">to</TOKEN>
				<TOKEN id="token-13-24" start_char="1779" end_char="1785">support</TOKEN>
				<TOKEN id="token-13-25" start_char="1787" end_char="1789">his</TOKEN>
				<TOKEN id="token-13-26" start_char="1791" end_char="1796">claims</TOKEN>
				<TOKEN id="token-13-27" start_char="1797" end_char="1797">,</TOKEN>
				<TOKEN id="token-13-28" start_char="1799" end_char="1801">Lau</TOKEN>
				<TOKEN id="token-13-29" start_char="1803" end_char="1806">said</TOKEN>
				<TOKEN id="token-13-30" start_char="1807" end_char="1807">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-14" start_char="1809" end_char="1912">
				<ORIGINAL_TEXT>&quot;It's one of those cases where extraordinary claims require extraordinary evidence,&quot; Lau told Space.com.</ORIGINAL_TEXT>
				<TOKEN id="token-14-0" start_char="1809" end_char="1809">&quot;</TOKEN>
				<TOKEN id="token-14-1" start_char="1810" end_char="1811">It</TOKEN>
				<TOKEN id="token-14-2" start_char="1812" end_char="1812">'</TOKEN>
				<TOKEN id="token-14-3" start_char="1813" end_char="1813">s</TOKEN>
				<TOKEN id="token-14-4" start_char="1815" end_char="1817">one</TOKEN>
				<TOKEN id="token-14-5" start_char="1819" end_char="1820">of</TOKEN>
				<TOKEN id="token-14-6" start_char="1822" end_char="1826">those</TOKEN>
				<TOKEN id="token-14-7" start_char="1828" end_char="1832">cases</TOKEN>
				<TOKEN id="token-14-8" start_char="1834" end_char="1838">where</TOKEN>
				<TOKEN id="token-14-9" start_char="1840" end_char="1852">extraordinary</TOKEN>
				<TOKEN id="token-14-10" start_char="1854" end_char="1859">claims</TOKEN>
				<TOKEN id="token-14-11" start_char="1861" end_char="1867">require</TOKEN>
				<TOKEN id="token-14-12" start_char="1869" end_char="1881">extraordinary</TOKEN>
				<TOKEN id="token-14-13" start_char="1883" end_char="1890">evidence</TOKEN>
				<TOKEN id="token-14-14" start_char="1891" end_char="1892">,&quot;</TOKEN>
				<TOKEN id="token-14-15" start_char="1894" end_char="1896">Lau</TOKEN>
				<TOKEN id="token-14-16" start_char="1898" end_char="1901">told</TOKEN>
				<TOKEN id="token-14-17" start_char="1903" end_char="1907">Space</TOKEN>
				<TOKEN id="token-14-18" start_char="1908" end_char="1908">.</TOKEN>
				<TOKEN id="token-14-19" start_char="1909" end_char="1911">com</TOKEN>
				<TOKEN id="token-14-20" start_char="1912" end_char="1912">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-15" start_char="1914" end_char="2013">
				<ORIGINAL_TEXT>&quot;Even though it's an interesting idea, we just don't have any reason to embrace that idea right now.</ORIGINAL_TEXT>
				<TOKEN id="token-15-0" start_char="1914" end_char="1914">&quot;</TOKEN>
				<TOKEN id="token-15-1" start_char="1915" end_char="1918">Even</TOKEN>
				<TOKEN id="token-15-2" start_char="1920" end_char="1925">though</TOKEN>
				<TOKEN id="token-15-3" start_char="1927" end_char="1928">it</TOKEN>
				<TOKEN id="token-15-4" start_char="1929" end_char="1929">'</TOKEN>
				<TOKEN id="token-15-5" start_char="1930" end_char="1930">s</TOKEN>
				<TOKEN id="token-15-6" start_char="1932" end_char="1933">an</TOKEN>
				<TOKEN id="token-15-7" start_char="1935" end_char="1945">interesting</TOKEN>
				<TOKEN id="token-15-8" start_char="1947" end_char="1950">idea</TOKEN>
				<TOKEN id="token-15-9" start_char="1951" end_char="1951">,</TOKEN>
				<TOKEN id="token-15-10" start_char="1953" end_char="1954">we</TOKEN>
				<TOKEN id="token-15-11" start_char="1956" end_char="1959">just</TOKEN>
				<TOKEN id="token-15-12" start_char="1961" end_char="1963">don</TOKEN>
				<TOKEN id="token-15-13" start_char="1964" end_char="1964">'</TOKEN>
				<TOKEN id="token-15-14" start_char="1965" end_char="1965">t</TOKEN>
				<TOKEN id="token-15-15" start_char="1967" end_char="1970">have</TOKEN>
				<TOKEN id="token-15-16" start_char="1972" end_char="1974">any</TOKEN>
				<TOKEN id="token-15-17" start_char="1976" end_char="1981">reason</TOKEN>
				<TOKEN id="token-15-18" start_char="1983" end_char="1984">to</TOKEN>
				<TOKEN id="token-15-19" start_char="1986" end_char="1992">embrace</TOKEN>
				<TOKEN id="token-15-20" start_char="1994" end_char="1997">that</TOKEN>
				<TOKEN id="token-15-21" start_char="1999" end_char="2002">idea</TOKEN>
				<TOKEN id="token-15-22" start_char="2004" end_char="2008">right</TOKEN>
				<TOKEN id="token-15-23" start_char="2010" end_char="2012">now</TOKEN>
				<TOKEN id="token-15-24" start_char="2013" end_char="2013">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-16" start_char="2015" end_char="2110">
				<ORIGINAL_TEXT>&quot;I think it's important for scientists to point out pseudoscientists or bad science,&quot; Lau added.</ORIGINAL_TEXT>
				<TOKEN id="token-16-0" start_char="2015" end_char="2015">&quot;</TOKEN>
				<TOKEN id="token-16-1" start_char="2016" end_char="2016">I</TOKEN>
				<TOKEN id="token-16-2" start_char="2018" end_char="2022">think</TOKEN>
				<TOKEN id="token-16-3" start_char="2024" end_char="2025">it</TOKEN>
				<TOKEN id="token-16-4" start_char="2026" end_char="2026">'</TOKEN>
				<TOKEN id="token-16-5" start_char="2027" end_char="2027">s</TOKEN>
				<TOKEN id="token-16-6" start_char="2029" end_char="2037">important</TOKEN>
				<TOKEN id="token-16-7" start_char="2039" end_char="2041">for</TOKEN>
				<TOKEN id="token-16-8" start_char="2043" end_char="2052">scientists</TOKEN>
				<TOKEN id="token-16-9" start_char="2054" end_char="2055">to</TOKEN>
				<TOKEN id="token-16-10" start_char="2057" end_char="2061">point</TOKEN>
				<TOKEN id="token-16-11" start_char="2063" end_char="2065">out</TOKEN>
				<TOKEN id="token-16-12" start_char="2067" end_char="2082">pseudoscientists</TOKEN>
				<TOKEN id="token-16-13" start_char="2084" end_char="2085">or</TOKEN>
				<TOKEN id="token-16-14" start_char="2087" end_char="2089">bad</TOKEN>
				<TOKEN id="token-16-15" start_char="2091" end_char="2097">science</TOKEN>
				<TOKEN id="token-16-16" start_char="2098" end_char="2099">,&quot;</TOKEN>
				<TOKEN id="token-16-17" start_char="2101" end_char="2103">Lau</TOKEN>
				<TOKEN id="token-16-18" start_char="2105" end_char="2109">added</TOKEN>
				<TOKEN id="token-16-19" start_char="2110" end_char="2110">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-17" start_char="2112" end_char="2262">
				<ORIGINAL_TEXT>&quot;If this was real, it'd be great, but we just can't allow ourselves to jump to the feel-good conclusion without doing our due diligence as scientists.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-17-0" start_char="2112" end_char="2112">&quot;</TOKEN>
				<TOKEN id="token-17-1" start_char="2113" end_char="2114">If</TOKEN>
				<TOKEN id="token-17-2" start_char="2116" end_char="2119">this</TOKEN>
				<TOKEN id="token-17-3" start_char="2121" end_char="2123">was</TOKEN>
				<TOKEN id="token-17-4" start_char="2125" end_char="2128">real</TOKEN>
				<TOKEN id="token-17-5" start_char="2129" end_char="2129">,</TOKEN>
				<TOKEN id="token-17-6" start_char="2131" end_char="2132">it</TOKEN>
				<TOKEN id="token-17-7" start_char="2133" end_char="2133">'</TOKEN>
				<TOKEN id="token-17-8" start_char="2134" end_char="2134">d</TOKEN>
				<TOKEN id="token-17-9" start_char="2136" end_char="2137">be</TOKEN>
				<TOKEN id="token-17-10" start_char="2139" end_char="2143">great</TOKEN>
				<TOKEN id="token-17-11" start_char="2144" end_char="2144">,</TOKEN>
				<TOKEN id="token-17-12" start_char="2146" end_char="2148">but</TOKEN>
				<TOKEN id="token-17-13" start_char="2150" end_char="2151">we</TOKEN>
				<TOKEN id="token-17-14" start_char="2153" end_char="2156">just</TOKEN>
				<TOKEN id="token-17-15" start_char="2158" end_char="2160">can</TOKEN>
				<TOKEN id="token-17-16" start_char="2161" end_char="2161">'</TOKEN>
				<TOKEN id="token-17-17" start_char="2162" end_char="2162">t</TOKEN>
				<TOKEN id="token-17-18" start_char="2164" end_char="2168">allow</TOKEN>
				<TOKEN id="token-17-19" start_char="2170" end_char="2178">ourselves</TOKEN>
				<TOKEN id="token-17-20" start_char="2180" end_char="2181">to</TOKEN>
				<TOKEN id="token-17-21" start_char="2183" end_char="2186">jump</TOKEN>
				<TOKEN id="token-17-22" start_char="2188" end_char="2189">to</TOKEN>
				<TOKEN id="token-17-23" start_char="2191" end_char="2193">the</TOKEN>
				<TOKEN id="token-17-24" start_char="2195" end_char="2198">feel</TOKEN>
				<TOKEN id="token-17-25" start_char="2199" end_char="2199">-</TOKEN>
				<TOKEN id="token-17-26" start_char="2200" end_char="2203">good</TOKEN>
				<TOKEN id="token-17-27" start_char="2205" end_char="2214">conclusion</TOKEN>
				<TOKEN id="token-17-28" start_char="2216" end_char="2222">without</TOKEN>
				<TOKEN id="token-17-29" start_char="2224" end_char="2228">doing</TOKEN>
				<TOKEN id="token-17-30" start_char="2230" end_char="2232">our</TOKEN>
				<TOKEN id="token-17-31" start_char="2234" end_char="2236">due</TOKEN>
				<TOKEN id="token-17-32" start_char="2238" end_char="2246">diligence</TOKEN>
				<TOKEN id="token-17-33" start_char="2248" end_char="2249">as</TOKEN>
				<TOKEN id="token-17-34" start_char="2251" end_char="2260">scientists</TOKEN>
				<TOKEN id="token-17-35" start_char="2261" end_char="2262">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-18" start_char="2264" end_char="2338">
				<ORIGINAL_TEXT>More: Coronavirus outbreak shakes space industry: Here's the effects so far</ORIGINAL_TEXT>
				<TOKEN id="token-18-0" start_char="2264" end_char="2267">More</TOKEN>
				<TOKEN id="token-18-1" start_char="2268" end_char="2268">:</TOKEN>
				<TOKEN id="token-18-2" start_char="2270" end_char="2280">Coronavirus</TOKEN>
				<TOKEN id="token-18-3" start_char="2282" end_char="2289">outbreak</TOKEN>
				<TOKEN id="token-18-4" start_char="2291" end_char="2296">shakes</TOKEN>
				<TOKEN id="token-18-5" start_char="2298" end_char="2302">space</TOKEN>
				<TOKEN id="token-18-6" start_char="2304" end_char="2311">industry</TOKEN>
				<TOKEN id="token-18-7" start_char="2312" end_char="2312">:</TOKEN>
				<TOKEN id="token-18-8" start_char="2314" end_char="2317">Here</TOKEN>
				<TOKEN id="token-18-9" start_char="2318" end_char="2318">'</TOKEN>
				<TOKEN id="token-18-10" start_char="2319" end_char="2319">s</TOKEN>
				<TOKEN id="token-18-11" start_char="2321" end_char="2323">the</TOKEN>
				<TOKEN id="token-18-12" start_char="2325" end_char="2331">effects</TOKEN>
				<TOKEN id="token-18-13" start_char="2333" end_char="2334">so</TOKEN>
				<TOKEN id="token-18-14" start_char="2336" end_char="2338">far</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-19" start_char="2340" end_char="2473">
				<ORIGINAL_TEXT>Additionally, from what we know about the new coronavirus, called SARS-CoV-2, it lines up with what we know about terrestrial viruses.</ORIGINAL_TEXT>
				<TOKEN id="token-19-0" start_char="2340" end_char="2351">Additionally</TOKEN>
				<TOKEN id="token-19-1" start_char="2352" end_char="2352">,</TOKEN>
				<TOKEN id="token-19-2" start_char="2354" end_char="2357">from</TOKEN>
				<TOKEN id="token-19-3" start_char="2359" end_char="2362">what</TOKEN>
				<TOKEN id="token-19-4" start_char="2364" end_char="2365">we</TOKEN>
				<TOKEN id="token-19-5" start_char="2367" end_char="2370">know</TOKEN>
				<TOKEN id="token-19-6" start_char="2372" end_char="2376">about</TOKEN>
				<TOKEN id="token-19-7" start_char="2378" end_char="2380">the</TOKEN>
				<TOKEN id="token-19-8" start_char="2382" end_char="2384">new</TOKEN>
				<TOKEN id="token-19-9" start_char="2386" end_char="2396">coronavirus</TOKEN>
				<TOKEN id="token-19-10" start_char="2397" end_char="2397">,</TOKEN>
				<TOKEN id="token-19-11" start_char="2399" end_char="2404">called</TOKEN>
				<TOKEN id="token-19-12" start_char="2406" end_char="2409">SARS</TOKEN>
				<TOKEN id="token-19-13" start_char="2410" end_char="2410">-</TOKEN>
				<TOKEN id="token-19-14" start_char="2411" end_char="2413">CoV</TOKEN>
				<TOKEN id="token-19-15" start_char="2414" end_char="2414">-</TOKEN>
				<TOKEN id="token-19-16" start_char="2415" end_char="2415">2</TOKEN>
				<TOKEN id="token-19-17" start_char="2416" end_char="2416">,</TOKEN>
				<TOKEN id="token-19-18" start_char="2418" end_char="2419">it</TOKEN>
				<TOKEN id="token-19-19" start_char="2421" end_char="2425">lines</TOKEN>
				<TOKEN id="token-19-20" start_char="2427" end_char="2428">up</TOKEN>
				<TOKEN id="token-19-21" start_char="2430" end_char="2433">with</TOKEN>
				<TOKEN id="token-19-22" start_char="2435" end_char="2438">what</TOKEN>
				<TOKEN id="token-19-23" start_char="2440" end_char="2441">we</TOKEN>
				<TOKEN id="token-19-24" start_char="2443" end_char="2446">know</TOKEN>
				<TOKEN id="token-19-25" start_char="2448" end_char="2452">about</TOKEN>
				<TOKEN id="token-19-26" start_char="2454" end_char="2464">terrestrial</TOKEN>
				<TOKEN id="token-19-27" start_char="2466" end_char="2472">viruses</TOKEN>
				<TOKEN id="token-19-28" start_char="2473" end_char="2473">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-20" start_char="2475" end_char="2611">
				<ORIGINAL_TEXT>The virus is responsible for the disease COVID-19, which has infected more than 187,000 people globally, according to the New York Times.</ORIGINAL_TEXT>
				<TOKEN id="token-20-0" start_char="2475" end_char="2477">The</TOKEN>
				<TOKEN id="token-20-1" start_char="2479" end_char="2483">virus</TOKEN>
				<TOKEN id="token-20-2" start_char="2485" end_char="2486">is</TOKEN>
				<TOKEN id="token-20-3" start_char="2488" end_char="2498">responsible</TOKEN>
				<TOKEN id="token-20-4" start_char="2500" end_char="2502">for</TOKEN>
				<TOKEN id="token-20-5" start_char="2504" end_char="2506">the</TOKEN>
				<TOKEN id="token-20-6" start_char="2508" end_char="2514">disease</TOKEN>
				<TOKEN id="token-20-7" start_char="2516" end_char="2520">COVID</TOKEN>
				<TOKEN id="token-20-8" start_char="2521" end_char="2521">-</TOKEN>
				<TOKEN id="token-20-9" start_char="2522" end_char="2523">19</TOKEN>
				<TOKEN id="token-20-10" start_char="2524" end_char="2524">,</TOKEN>
				<TOKEN id="token-20-11" start_char="2526" end_char="2530">which</TOKEN>
				<TOKEN id="token-20-12" start_char="2532" end_char="2534">has</TOKEN>
				<TOKEN id="token-20-13" start_char="2536" end_char="2543">infected</TOKEN>
				<TOKEN id="token-20-14" start_char="2545" end_char="2548">more</TOKEN>
				<TOKEN id="token-20-15" start_char="2550" end_char="2553">than</TOKEN>
				<TOKEN id="token-20-16" start_char="2555" end_char="2557">187</TOKEN>
				<TOKEN id="token-20-17" start_char="2558" end_char="2558">,</TOKEN>
				<TOKEN id="token-20-18" start_char="2559" end_char="2561">000</TOKEN>
				<TOKEN id="token-20-19" start_char="2563" end_char="2568">people</TOKEN>
				<TOKEN id="token-20-20" start_char="2570" end_char="2577">globally</TOKEN>
				<TOKEN id="token-20-21" start_char="2578" end_char="2578">,</TOKEN>
				<TOKEN id="token-20-22" start_char="2580" end_char="2588">according</TOKEN>
				<TOKEN id="token-20-23" start_char="2590" end_char="2591">to</TOKEN>
				<TOKEN id="token-20-24" start_char="2593" end_char="2595">the</TOKEN>
				<TOKEN id="token-20-25" start_char="2597" end_char="2599">New</TOKEN>
				<TOKEN id="token-20-26" start_char="2601" end_char="2604">York</TOKEN>
				<TOKEN id="token-20-27" start_char="2606" end_char="2610">Times</TOKEN>
				<TOKEN id="token-20-28" start_char="2611" end_char="2611">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-21" start_char="2613" end_char="2814">
				<ORIGINAL_TEXT>&quot;If this thing had some different kind of biomolecule in it that's different from life as we know it,&quot; Lau said, then there might be reason to investigate whether the virus had extraterrestrial origins.</ORIGINAL_TEXT>
				<TOKEN id="token-21-0" start_char="2613" end_char="2613">&quot;</TOKEN>
				<TOKEN id="token-21-1" start_char="2614" end_char="2615">If</TOKEN>
				<TOKEN id="token-21-2" start_char="2617" end_char="2620">this</TOKEN>
				<TOKEN id="token-21-3" start_char="2622" end_char="2626">thing</TOKEN>
				<TOKEN id="token-21-4" start_char="2628" end_char="2630">had</TOKEN>
				<TOKEN id="token-21-5" start_char="2632" end_char="2635">some</TOKEN>
				<TOKEN id="token-21-6" start_char="2637" end_char="2645">different</TOKEN>
				<TOKEN id="token-21-7" start_char="2647" end_char="2650">kind</TOKEN>
				<TOKEN id="token-21-8" start_char="2652" end_char="2653">of</TOKEN>
				<TOKEN id="token-21-9" start_char="2655" end_char="2665">biomolecule</TOKEN>
				<TOKEN id="token-21-10" start_char="2667" end_char="2668">in</TOKEN>
				<TOKEN id="token-21-11" start_char="2670" end_char="2671">it</TOKEN>
				<TOKEN id="token-21-12" start_char="2673" end_char="2676">that</TOKEN>
				<TOKEN id="token-21-13" start_char="2677" end_char="2677">'</TOKEN>
				<TOKEN id="token-21-14" start_char="2678" end_char="2678">s</TOKEN>
				<TOKEN id="token-21-15" start_char="2680" end_char="2688">different</TOKEN>
				<TOKEN id="token-21-16" start_char="2690" end_char="2693">from</TOKEN>
				<TOKEN id="token-21-17" start_char="2695" end_char="2698">life</TOKEN>
				<TOKEN id="token-21-18" start_char="2700" end_char="2701">as</TOKEN>
				<TOKEN id="token-21-19" start_char="2703" end_char="2704">we</TOKEN>
				<TOKEN id="token-21-20" start_char="2706" end_char="2709">know</TOKEN>
				<TOKEN id="token-21-21" start_char="2711" end_char="2712">it</TOKEN>
				<TOKEN id="token-21-22" start_char="2713" end_char="2714">,&quot;</TOKEN>
				<TOKEN id="token-21-23" start_char="2716" end_char="2718">Lau</TOKEN>
				<TOKEN id="token-21-24" start_char="2720" end_char="2723">said</TOKEN>
				<TOKEN id="token-21-25" start_char="2724" end_char="2724">,</TOKEN>
				<TOKEN id="token-21-26" start_char="2726" end_char="2729">then</TOKEN>
				<TOKEN id="token-21-27" start_char="2731" end_char="2735">there</TOKEN>
				<TOKEN id="token-21-28" start_char="2737" end_char="2741">might</TOKEN>
				<TOKEN id="token-21-29" start_char="2743" end_char="2744">be</TOKEN>
				<TOKEN id="token-21-30" start_char="2746" end_char="2751">reason</TOKEN>
				<TOKEN id="token-21-31" start_char="2753" end_char="2754">to</TOKEN>
				<TOKEN id="token-21-32" start_char="2756" end_char="2766">investigate</TOKEN>
				<TOKEN id="token-21-33" start_char="2768" end_char="2774">whether</TOKEN>
				<TOKEN id="token-21-34" start_char="2776" end_char="2778">the</TOKEN>
				<TOKEN id="token-21-35" start_char="2780" end_char="2784">virus</TOKEN>
				<TOKEN id="token-21-36" start_char="2786" end_char="2788">had</TOKEN>
				<TOKEN id="token-21-37" start_char="2790" end_char="2805">extraterrestrial</TOKEN>
				<TOKEN id="token-21-38" start_char="2807" end_char="2813">origins</TOKEN>
				<TOKEN id="token-21-39" start_char="2814" end_char="2814">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-22" start_char="2816" end_char="2889">
				<ORIGINAL_TEXT>However, even in that case, there could be Earthly explanations, he added.</ORIGINAL_TEXT>
				<TOKEN id="token-22-0" start_char="2816" end_char="2822">However</TOKEN>
				<TOKEN id="token-22-1" start_char="2823" end_char="2823">,</TOKEN>
				<TOKEN id="token-22-2" start_char="2825" end_char="2828">even</TOKEN>
				<TOKEN id="token-22-3" start_char="2830" end_char="2831">in</TOKEN>
				<TOKEN id="token-22-4" start_char="2833" end_char="2836">that</TOKEN>
				<TOKEN id="token-22-5" start_char="2838" end_char="2841">case</TOKEN>
				<TOKEN id="token-22-6" start_char="2842" end_char="2842">,</TOKEN>
				<TOKEN id="token-22-7" start_char="2844" end_char="2848">there</TOKEN>
				<TOKEN id="token-22-8" start_char="2850" end_char="2854">could</TOKEN>
				<TOKEN id="token-22-9" start_char="2856" end_char="2857">be</TOKEN>
				<TOKEN id="token-22-10" start_char="2859" end_char="2865">Earthly</TOKEN>
				<TOKEN id="token-22-11" start_char="2867" end_char="2878">explanations</TOKEN>
				<TOKEN id="token-22-12" start_char="2879" end_char="2879">,</TOKEN>
				<TOKEN id="token-22-13" start_char="2881" end_char="2882">he</TOKEN>
				<TOKEN id="token-22-14" start_char="2884" end_char="2888">added</TOKEN>
				<TOKEN id="token-22-15" start_char="2889" end_char="2889">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-23" start_char="2891" end_char="3109">
				<ORIGINAL_TEXT>Wickramasinghe's claim ties into the theory of panspermia, a longstanding but not proven theory which poses that life on Earth originated with help from microorganisms and biological material from outer space, Lau said.</ORIGINAL_TEXT>
				<TOKEN id="token-23-0" start_char="2891" end_char="2904">Wickramasinghe</TOKEN>
				<TOKEN id="token-23-1" start_char="2905" end_char="2905">'</TOKEN>
				<TOKEN id="token-23-2" start_char="2906" end_char="2906">s</TOKEN>
				<TOKEN id="token-23-3" start_char="2908" end_char="2912">claim</TOKEN>
				<TOKEN id="token-23-4" start_char="2914" end_char="2917">ties</TOKEN>
				<TOKEN id="token-23-5" start_char="2919" end_char="2922">into</TOKEN>
				<TOKEN id="token-23-6" start_char="2924" end_char="2926">the</TOKEN>
				<TOKEN id="token-23-7" start_char="2928" end_char="2933">theory</TOKEN>
				<TOKEN id="token-23-8" start_char="2935" end_char="2936">of</TOKEN>
				<TOKEN id="token-23-9" start_char="2938" end_char="2947">panspermia</TOKEN>
				<TOKEN id="token-23-10" start_char="2948" end_char="2948">,</TOKEN>
				<TOKEN id="token-23-11" start_char="2950" end_char="2950">a</TOKEN>
				<TOKEN id="token-23-12" start_char="2952" end_char="2963">longstanding</TOKEN>
				<TOKEN id="token-23-13" start_char="2965" end_char="2967">but</TOKEN>
				<TOKEN id="token-23-14" start_char="2969" end_char="2971">not</TOKEN>
				<TOKEN id="token-23-15" start_char="2973" end_char="2978">proven</TOKEN>
				<TOKEN id="token-23-16" start_char="2980" end_char="2985">theory</TOKEN>
				<TOKEN id="token-23-17" start_char="2987" end_char="2991">which</TOKEN>
				<TOKEN id="token-23-18" start_char="2993" end_char="2997">poses</TOKEN>
				<TOKEN id="token-23-19" start_char="2999" end_char="3002">that</TOKEN>
				<TOKEN id="token-23-20" start_char="3004" end_char="3007">life</TOKEN>
				<TOKEN id="token-23-21" start_char="3009" end_char="3010">on</TOKEN>
				<TOKEN id="token-23-22" start_char="3012" end_char="3016">Earth</TOKEN>
				<TOKEN id="token-23-23" start_char="3018" end_char="3027">originated</TOKEN>
				<TOKEN id="token-23-24" start_char="3029" end_char="3032">with</TOKEN>
				<TOKEN id="token-23-25" start_char="3034" end_char="3037">help</TOKEN>
				<TOKEN id="token-23-26" start_char="3039" end_char="3042">from</TOKEN>
				<TOKEN id="token-23-27" start_char="3044" end_char="3057">microorganisms</TOKEN>
				<TOKEN id="token-23-28" start_char="3059" end_char="3061">and</TOKEN>
				<TOKEN id="token-23-29" start_char="3063" end_char="3072">biological</TOKEN>
				<TOKEN id="token-23-30" start_char="3074" end_char="3081">material</TOKEN>
				<TOKEN id="token-23-31" start_char="3083" end_char="3086">from</TOKEN>
				<TOKEN id="token-23-32" start_char="3088" end_char="3092">outer</TOKEN>
				<TOKEN id="token-23-33" start_char="3094" end_char="3098">space</TOKEN>
				<TOKEN id="token-23-34" start_char="3099" end_char="3099">,</TOKEN>
				<TOKEN id="token-23-35" start_char="3101" end_char="3103">Lau</TOKEN>
				<TOKEN id="token-23-36" start_char="3105" end_char="3108">said</TOKEN>
				<TOKEN id="token-23-37" start_char="3109" end_char="3109">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-24" start_char="3111" end_char="3259">
				<ORIGINAL_TEXT>And while there is not yet concrete evidence that panspermia has occurred here on Earth or is even possible, theoretically, it could happen, he said.</ORIGINAL_TEXT>
				<TOKEN id="token-24-0" start_char="3111" end_char="3113">And</TOKEN>
				<TOKEN id="token-24-1" start_char="3115" end_char="3119">while</TOKEN>
				<TOKEN id="token-24-2" start_char="3121" end_char="3125">there</TOKEN>
				<TOKEN id="token-24-3" start_char="3127" end_char="3128">is</TOKEN>
				<TOKEN id="token-24-4" start_char="3130" end_char="3132">not</TOKEN>
				<TOKEN id="token-24-5" start_char="3134" end_char="3136">yet</TOKEN>
				<TOKEN id="token-24-6" start_char="3138" end_char="3145">concrete</TOKEN>
				<TOKEN id="token-24-7" start_char="3147" end_char="3154">evidence</TOKEN>
				<TOKEN id="token-24-8" start_char="3156" end_char="3159">that</TOKEN>
				<TOKEN id="token-24-9" start_char="3161" end_char="3170">panspermia</TOKEN>
				<TOKEN id="token-24-10" start_char="3172" end_char="3174">has</TOKEN>
				<TOKEN id="token-24-11" start_char="3176" end_char="3183">occurred</TOKEN>
				<TOKEN id="token-24-12" start_char="3185" end_char="3188">here</TOKEN>
				<TOKEN id="token-24-13" start_char="3190" end_char="3191">on</TOKEN>
				<TOKEN id="token-24-14" start_char="3193" end_char="3197">Earth</TOKEN>
				<TOKEN id="token-24-15" start_char="3199" end_char="3200">or</TOKEN>
				<TOKEN id="token-24-16" start_char="3202" end_char="3203">is</TOKEN>
				<TOKEN id="token-24-17" start_char="3205" end_char="3208">even</TOKEN>
				<TOKEN id="token-24-18" start_char="3210" end_char="3217">possible</TOKEN>
				<TOKEN id="token-24-19" start_char="3218" end_char="3218">,</TOKEN>
				<TOKEN id="token-24-20" start_char="3220" end_char="3232">theoretically</TOKEN>
				<TOKEN id="token-24-21" start_char="3233" end_char="3233">,</TOKEN>
				<TOKEN id="token-24-22" start_char="3235" end_char="3236">it</TOKEN>
				<TOKEN id="token-24-23" start_char="3238" end_char="3242">could</TOKEN>
				<TOKEN id="token-24-24" start_char="3244" end_char="3249">happen</TOKEN>
				<TOKEN id="token-24-25" start_char="3250" end_char="3250">,</TOKEN>
				<TOKEN id="token-24-26" start_char="3252" end_char="3253">he</TOKEN>
				<TOKEN id="token-24-27" start_char="3255" end_char="3258">said</TOKEN>
				<TOKEN id="token-24-28" start_char="3259" end_char="3259">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-25" start_char="3261" end_char="3566">
				<ORIGINAL_TEXT>Theoretically, biological materials could survive on a space rock, lie dormant and continue to survive if they were properly shielded from the radiation in space and survive the process of impacting Earth, Lau said, noting that scientists have found organic molecules such as amino acids inside meteorites.</ORIGINAL_TEXT>
				<TOKEN id="token-25-0" start_char="3261" end_char="3273">Theoretically</TOKEN>
				<TOKEN id="token-25-1" start_char="3274" end_char="3274">,</TOKEN>
				<TOKEN id="token-25-2" start_char="3276" end_char="3285">biological</TOKEN>
				<TOKEN id="token-25-3" start_char="3287" end_char="3295">materials</TOKEN>
				<TOKEN id="token-25-4" start_char="3297" end_char="3301">could</TOKEN>
				<TOKEN id="token-25-5" start_char="3303" end_char="3309">survive</TOKEN>
				<TOKEN id="token-25-6" start_char="3311" end_char="3312">on</TOKEN>
				<TOKEN id="token-25-7" start_char="3314" end_char="3314">a</TOKEN>
				<TOKEN id="token-25-8" start_char="3316" end_char="3320">space</TOKEN>
				<TOKEN id="token-25-9" start_char="3322" end_char="3325">rock</TOKEN>
				<TOKEN id="token-25-10" start_char="3326" end_char="3326">,</TOKEN>
				<TOKEN id="token-25-11" start_char="3328" end_char="3330">lie</TOKEN>
				<TOKEN id="token-25-12" start_char="3332" end_char="3338">dormant</TOKEN>
				<TOKEN id="token-25-13" start_char="3340" end_char="3342">and</TOKEN>
				<TOKEN id="token-25-14" start_char="3344" end_char="3351">continue</TOKEN>
				<TOKEN id="token-25-15" start_char="3353" end_char="3354">to</TOKEN>
				<TOKEN id="token-25-16" start_char="3356" end_char="3362">survive</TOKEN>
				<TOKEN id="token-25-17" start_char="3364" end_char="3365">if</TOKEN>
				<TOKEN id="token-25-18" start_char="3367" end_char="3370">they</TOKEN>
				<TOKEN id="token-25-19" start_char="3372" end_char="3375">were</TOKEN>
				<TOKEN id="token-25-20" start_char="3377" end_char="3384">properly</TOKEN>
				<TOKEN id="token-25-21" start_char="3386" end_char="3393">shielded</TOKEN>
				<TOKEN id="token-25-22" start_char="3395" end_char="3398">from</TOKEN>
				<TOKEN id="token-25-23" start_char="3400" end_char="3402">the</TOKEN>
				<TOKEN id="token-25-24" start_char="3404" end_char="3412">radiation</TOKEN>
				<TOKEN id="token-25-25" start_char="3414" end_char="3415">in</TOKEN>
				<TOKEN id="token-25-26" start_char="3417" end_char="3421">space</TOKEN>
				<TOKEN id="token-25-27" start_char="3423" end_char="3425">and</TOKEN>
				<TOKEN id="token-25-28" start_char="3427" end_char="3433">survive</TOKEN>
				<TOKEN id="token-25-29" start_char="3435" end_char="3437">the</TOKEN>
				<TOKEN id="token-25-30" start_char="3439" end_char="3445">process</TOKEN>
				<TOKEN id="token-25-31" start_char="3447" end_char="3448">of</TOKEN>
				<TOKEN id="token-25-32" start_char="3450" end_char="3458">impacting</TOKEN>
				<TOKEN id="token-25-33" start_char="3460" end_char="3464">Earth</TOKEN>
				<TOKEN id="token-25-34" start_char="3465" end_char="3465">,</TOKEN>
				<TOKEN id="token-25-35" start_char="3467" end_char="3469">Lau</TOKEN>
				<TOKEN id="token-25-36" start_char="3471" end_char="3474">said</TOKEN>
				<TOKEN id="token-25-37" start_char="3475" end_char="3475">,</TOKEN>
				<TOKEN id="token-25-38" start_char="3477" end_char="3482">noting</TOKEN>
				<TOKEN id="token-25-39" start_char="3484" end_char="3487">that</TOKEN>
				<TOKEN id="token-25-40" start_char="3489" end_char="3498">scientists</TOKEN>
				<TOKEN id="token-25-41" start_char="3500" end_char="3503">have</TOKEN>
				<TOKEN id="token-25-42" start_char="3505" end_char="3509">found</TOKEN>
				<TOKEN id="token-25-43" start_char="3511" end_char="3517">organic</TOKEN>
				<TOKEN id="token-25-44" start_char="3519" end_char="3527">molecules</TOKEN>
				<TOKEN id="token-25-45" start_char="3529" end_char="3532">such</TOKEN>
				<TOKEN id="token-25-46" start_char="3534" end_char="3535">as</TOKEN>
				<TOKEN id="token-25-47" start_char="3537" end_char="3541">amino</TOKEN>
				<TOKEN id="token-25-48" start_char="3543" end_char="3547">acids</TOKEN>
				<TOKEN id="token-25-49" start_char="3549" end_char="3554">inside</TOKEN>
				<TOKEN id="token-25-50" start_char="3556" end_char="3565">meteorites</TOKEN>
				<TOKEN id="token-25-51" start_char="3566" end_char="3566">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-113-26" start_char="3568" end_char="3712">
				<ORIGINAL_TEXT>However, despite these theoretical possibilities, there is no credible evidence to show that the new coronavirus came from outer space, he added.</ORIGINAL_TEXT>
				<TOKEN id="token-26-0" start_char="3568" end_char="3574">However</TOKEN>
				<TOKEN id="token-26-1" start_char="3575" end_char="3575">,</TOKEN>
				<TOKEN id="token-26-2" start_char="3577" end_char="3583">despite</TOKEN>
				<TOKEN id="token-26-3" start_char="3585" end_char="3589">these</TOKEN>
				<TOKEN id="token-26-4" start_char="3591" end_char="3601">theoretical</TOKEN>
				<TOKEN id="token-26-5" start_char="3603" end_char="3615">possibilities</TOKEN>
				<TOKEN id="token-26-6" start_char="3616" end_char="3616">,</TOKEN>
				<TOKEN id="token-26-7" start_char="3618" end_char="3622">there</TOKEN>
				<TOKEN id="token-26-8" start_char="3624" end_char="3625">is</TOKEN>
				<TOKEN id="token-26-9" start_char="3627" end_char="3628">no</TOKEN>
				<TOKEN id="token-26-10" start_char="3630" end_char="3637">credible</TOKEN>
				<TOKEN id="token-26-11" start_char="3639" end_char="3646">evidence</TOKEN>
				<TOKEN id="token-26-12" start_char="3648" end_char="3649">to</TOKEN>
				<TOKEN id="token-26-13" start_char="3651" end_char="3654">show</TOKEN>
				<TOKEN id="token-26-14" start_char="3656" end_char="3659">that</TOKEN>
				<TOKEN id="token-26-15" start_char="3661" end_char="3663">the</TOKEN>
				<TOKEN id="token-26-16" start_char="3665" end_char="3667">new</TOKEN>
				<TOKEN id="token-26-17" start_char="3669" end_char="3679">coronavirus</TOKEN>
				<TOKEN id="token-26-18" start_char="3681" end_char="3684">came</TOKEN>
				<TOKEN id="token-26-19" start_char="3686" end_char="3689">from</TOKEN>
				<TOKEN id="token-26-20" start_char="3691" end_char="3695">outer</TOKEN>
				<TOKEN id="token-26-21" start_char="3697" end_char="3701">space</TOKEN>
				<TOKEN id="token-26-22" start_char="3702" end_char="3702">,</TOKEN>
				<TOKEN id="token-26-23" start_char="3704" end_char="3705">he</TOKEN>
				<TOKEN id="token-26-24" start_char="3707" end_char="3711">added</TOKEN>
				<TOKEN id="token-26-25" start_char="3712" end_char="3712">.</TOKEN>
			</SEG>
		</TEXT>
	</DOC>
</LCTL_TEXT>
