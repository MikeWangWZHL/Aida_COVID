<?xml version="1.0" encoding="utf-8"?>
<LCTL_TEXT>
	<DOC id="covid19scenario-0">
		<TEXT>
			<SEG id="covid19scenario-0-0" start_char="0" end_char="248">
				<ORIGINAL_TEXT>Newly-released access-to-information documents reveal details about a shipment of deadly pathogens last year from Canada's National Microbiology Lab to China — confirming for the first time who sent them, what exactly was shipped, and where it went.</ORIGINAL_TEXT>
				<TOKEN id="token-0-0" start_char="0" end_char="4">Newly</TOKEN>
				<TOKEN id="token-0-1" start_char="5" end_char="5">-</TOKEN>
				<TOKEN id="token-0-2" start_char="6" end_char="13">released</TOKEN>
				<TOKEN id="token-0-3" start_char="15" end_char="20">access</TOKEN>
				<TOKEN id="token-0-4" start_char="21" end_char="21">-</TOKEN>
				<TOKEN id="token-0-5" start_char="22" end_char="23">to</TOKEN>
				<TOKEN id="token-0-6" start_char="24" end_char="24">-</TOKEN>
				<TOKEN id="token-0-7" start_char="25" end_char="35">information</TOKEN>
				<TOKEN id="token-0-8" start_char="37" end_char="45">documents</TOKEN>
				<TOKEN id="token-0-9" start_char="47" end_char="52">reveal</TOKEN>
				<TOKEN id="token-0-10" start_char="54" end_char="60">details</TOKEN>
				<TOKEN id="token-0-11" start_char="62" end_char="66">about</TOKEN>
				<TOKEN id="token-0-12" start_char="68" end_char="68">a</TOKEN>
				<TOKEN id="token-0-13" start_char="70" end_char="77">shipment</TOKEN>
				<TOKEN id="token-0-14" start_char="79" end_char="80">of</TOKEN>
				<TOKEN id="token-0-15" start_char="82" end_char="87">deadly</TOKEN>
				<TOKEN id="token-0-16" start_char="89" end_char="97">pathogens</TOKEN>
				<TOKEN id="token-0-17" start_char="99" end_char="102">last</TOKEN>
				<TOKEN id="token-0-18" start_char="104" end_char="107">year</TOKEN>
				<TOKEN id="token-0-19" start_char="109" end_char="112">from</TOKEN>
				<TOKEN id="token-0-20" start_char="114" end_char="119">Canada</TOKEN>
				<TOKEN id="token-0-21" start_char="120" end_char="120">'</TOKEN>
				<TOKEN id="token-0-22" start_char="121" end_char="121">s</TOKEN>
				<TOKEN id="token-0-23" start_char="123" end_char="130">National</TOKEN>
				<TOKEN id="token-0-24" start_char="132" end_char="143">Microbiology</TOKEN>
				<TOKEN id="token-0-25" start_char="145" end_char="147">Lab</TOKEN>
				<TOKEN id="token-0-26" start_char="149" end_char="150">to</TOKEN>
				<TOKEN id="token-0-27" start_char="152" end_char="156">China</TOKEN>
				<TOKEN id="token-0-28" start_char="158" end_char="158">—</TOKEN>
				<TOKEN id="token-0-29" start_char="160" end_char="169">confirming</TOKEN>
				<TOKEN id="token-0-30" start_char="171" end_char="173">for</TOKEN>
				<TOKEN id="token-0-31" start_char="175" end_char="177">the</TOKEN>
				<TOKEN id="token-0-32" start_char="179" end_char="183">first</TOKEN>
				<TOKEN id="token-0-33" start_char="185" end_char="188">time</TOKEN>
				<TOKEN id="token-0-34" start_char="190" end_char="192">who</TOKEN>
				<TOKEN id="token-0-35" start_char="194" end_char="197">sent</TOKEN>
				<TOKEN id="token-0-36" start_char="199" end_char="202">them</TOKEN>
				<TOKEN id="token-0-37" start_char="203" end_char="203">,</TOKEN>
				<TOKEN id="token-0-38" start_char="205" end_char="208">what</TOKEN>
				<TOKEN id="token-0-39" start_char="210" end_char="216">exactly</TOKEN>
				<TOKEN id="token-0-40" start_char="218" end_char="220">was</TOKEN>
				<TOKEN id="token-0-41" start_char="222" end_char="228">shipped</TOKEN>
				<TOKEN id="token-0-42" start_char="229" end_char="229">,</TOKEN>
				<TOKEN id="token-0-43" start_char="231" end_char="233">and</TOKEN>
				<TOKEN id="token-0-44" start_char="235" end_char="239">where</TOKEN>
				<TOKEN id="token-0-45" start_char="241" end_char="242">it</TOKEN>
				<TOKEN id="token-0-46" start_char="244" end_char="247">went</TOKEN>
				<TOKEN id="token-0-47" start_char="248" end_char="248">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-1" start_char="250" end_char="548">
				<ORIGINAL_TEXT>CBC News had already reported about the shipment of Ebola and Henipah viruses but there's now confirmation one of the scientists escorted from the lab in Winnipeg amid an RCMP investigation last July was responsible for exporting the pathogens to the Wuhan Institute of Virology four months earlier.</ORIGINAL_TEXT>
				<TOKEN id="token-1-0" start_char="250" end_char="252">CBC</TOKEN>
				<TOKEN id="token-1-1" start_char="254" end_char="257">News</TOKEN>
				<TOKEN id="token-1-2" start_char="259" end_char="261">had</TOKEN>
				<TOKEN id="token-1-3" start_char="263" end_char="269">already</TOKEN>
				<TOKEN id="token-1-4" start_char="271" end_char="278">reported</TOKEN>
				<TOKEN id="token-1-5" start_char="280" end_char="284">about</TOKEN>
				<TOKEN id="token-1-6" start_char="286" end_char="288">the</TOKEN>
				<TOKEN id="token-1-7" start_char="290" end_char="297">shipment</TOKEN>
				<TOKEN id="token-1-8" start_char="299" end_char="300">of</TOKEN>
				<TOKEN id="token-1-9" start_char="302" end_char="306">Ebola</TOKEN>
				<TOKEN id="token-1-10" start_char="308" end_char="310">and</TOKEN>
				<TOKEN id="token-1-11" start_char="312" end_char="318">Henipah</TOKEN>
				<TOKEN id="token-1-12" start_char="320" end_char="326">viruses</TOKEN>
				<TOKEN id="token-1-13" start_char="328" end_char="330">but</TOKEN>
				<TOKEN id="token-1-14" start_char="332" end_char="336">there</TOKEN>
				<TOKEN id="token-1-15" start_char="337" end_char="337">'</TOKEN>
				<TOKEN id="token-1-16" start_char="338" end_char="338">s</TOKEN>
				<TOKEN id="token-1-17" start_char="340" end_char="342">now</TOKEN>
				<TOKEN id="token-1-18" start_char="344" end_char="355">confirmation</TOKEN>
				<TOKEN id="token-1-19" start_char="357" end_char="359">one</TOKEN>
				<TOKEN id="token-1-20" start_char="361" end_char="362">of</TOKEN>
				<TOKEN id="token-1-21" start_char="364" end_char="366">the</TOKEN>
				<TOKEN id="token-1-22" start_char="368" end_char="377">scientists</TOKEN>
				<TOKEN id="token-1-23" start_char="379" end_char="386">escorted</TOKEN>
				<TOKEN id="token-1-24" start_char="388" end_char="391">from</TOKEN>
				<TOKEN id="token-1-25" start_char="393" end_char="395">the</TOKEN>
				<TOKEN id="token-1-26" start_char="397" end_char="399">lab</TOKEN>
				<TOKEN id="token-1-27" start_char="401" end_char="402">in</TOKEN>
				<TOKEN id="token-1-28" start_char="404" end_char="411">Winnipeg</TOKEN>
				<TOKEN id="token-1-29" start_char="413" end_char="416">amid</TOKEN>
				<TOKEN id="token-1-30" start_char="418" end_char="419">an</TOKEN>
				<TOKEN id="token-1-31" start_char="421" end_char="424">RCMP</TOKEN>
				<TOKEN id="token-1-32" start_char="426" end_char="438">investigation</TOKEN>
				<TOKEN id="token-1-33" start_char="440" end_char="443">last</TOKEN>
				<TOKEN id="token-1-34" start_char="445" end_char="448">July</TOKEN>
				<TOKEN id="token-1-35" start_char="450" end_char="452">was</TOKEN>
				<TOKEN id="token-1-36" start_char="454" end_char="464">responsible</TOKEN>
				<TOKEN id="token-1-37" start_char="466" end_char="468">for</TOKEN>
				<TOKEN id="token-1-38" start_char="470" end_char="478">exporting</TOKEN>
				<TOKEN id="token-1-39" start_char="480" end_char="482">the</TOKEN>
				<TOKEN id="token-1-40" start_char="484" end_char="492">pathogens</TOKEN>
				<TOKEN id="token-1-41" start_char="494" end_char="495">to</TOKEN>
				<TOKEN id="token-1-42" start_char="497" end_char="499">the</TOKEN>
				<TOKEN id="token-1-43" start_char="501" end_char="505">Wuhan</TOKEN>
				<TOKEN id="token-1-44" start_char="507" end_char="515">Institute</TOKEN>
				<TOKEN id="token-1-45" start_char="517" end_char="518">of</TOKEN>
				<TOKEN id="token-1-46" start_char="520" end_char="527">Virology</TOKEN>
				<TOKEN id="token-1-47" start_char="529" end_char="532">four</TOKEN>
				<TOKEN id="token-1-48" start_char="534" end_char="539">months</TOKEN>
				<TOKEN id="token-1-49" start_char="541" end_char="547">earlier</TOKEN>
				<TOKEN id="token-1-50" start_char="548" end_char="548">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-2" start_char="550" end_char="716">
				<ORIGINAL_TEXT>Dr. Xiangguo Qiu, her husband Keding Cheng and her students from China were removed from Canada's only level-4 lab over what's described as a possible &quot;policy breach.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-2-0" start_char="550" end_char="551">Dr</TOKEN>
				<TOKEN id="token-2-1" start_char="552" end_char="552">.</TOKEN>
				<TOKEN id="token-2-2" start_char="554" end_char="561">Xiangguo</TOKEN>
				<TOKEN id="token-2-3" start_char="563" end_char="565">Qiu</TOKEN>
				<TOKEN id="token-2-4" start_char="566" end_char="566">,</TOKEN>
				<TOKEN id="token-2-5" start_char="568" end_char="570">her</TOKEN>
				<TOKEN id="token-2-6" start_char="572" end_char="578">husband</TOKEN>
				<TOKEN id="token-2-7" start_char="580" end_char="585">Keding</TOKEN>
				<TOKEN id="token-2-8" start_char="587" end_char="591">Cheng</TOKEN>
				<TOKEN id="token-2-9" start_char="593" end_char="595">and</TOKEN>
				<TOKEN id="token-2-10" start_char="597" end_char="599">her</TOKEN>
				<TOKEN id="token-2-11" start_char="601" end_char="608">students</TOKEN>
				<TOKEN id="token-2-12" start_char="610" end_char="613">from</TOKEN>
				<TOKEN id="token-2-13" start_char="615" end_char="619">China</TOKEN>
				<TOKEN id="token-2-14" start_char="621" end_char="624">were</TOKEN>
				<TOKEN id="token-2-15" start_char="626" end_char="632">removed</TOKEN>
				<TOKEN id="token-2-16" start_char="634" end_char="637">from</TOKEN>
				<TOKEN id="token-2-17" start_char="639" end_char="644">Canada</TOKEN>
				<TOKEN id="token-2-18" start_char="645" end_char="645">'</TOKEN>
				<TOKEN id="token-2-19" start_char="646" end_char="646">s</TOKEN>
				<TOKEN id="token-2-20" start_char="648" end_char="651">only</TOKEN>
				<TOKEN id="token-2-21" start_char="653" end_char="657">level</TOKEN>
				<TOKEN id="token-2-22" start_char="658" end_char="658">-</TOKEN>
				<TOKEN id="token-2-23" start_char="659" end_char="659">4</TOKEN>
				<TOKEN id="token-2-24" start_char="661" end_char="663">lab</TOKEN>
				<TOKEN id="token-2-25" start_char="665" end_char="668">over</TOKEN>
				<TOKEN id="token-2-26" start_char="670" end_char="673">what</TOKEN>
				<TOKEN id="token-2-27" start_char="674" end_char="674">'</TOKEN>
				<TOKEN id="token-2-28" start_char="675" end_char="675">s</TOKEN>
				<TOKEN id="token-2-29" start_char="677" end_char="685">described</TOKEN>
				<TOKEN id="token-2-30" start_char="687" end_char="688">as</TOKEN>
				<TOKEN id="token-2-31" start_char="690" end_char="690">a</TOKEN>
				<TOKEN id="token-2-32" start_char="692" end_char="699">possible</TOKEN>
				<TOKEN id="token-2-33" start_char="701" end_char="701">&quot;</TOKEN>
				<TOKEN id="token-2-34" start_char="702" end_char="707">policy</TOKEN>
				<TOKEN id="token-2-35" start_char="709" end_char="714">breach</TOKEN>
				<TOKEN id="token-2-36" start_char="715" end_char="716">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-3" start_char="718" end_char="810">
				<ORIGINAL_TEXT>The Public Health Agency of Canada had asked the RCMP to get involved several months earlier.</ORIGINAL_TEXT>
				<TOKEN id="token-3-0" start_char="718" end_char="720">The</TOKEN>
				<TOKEN id="token-3-1" start_char="722" end_char="727">Public</TOKEN>
				<TOKEN id="token-3-2" start_char="729" end_char="734">Health</TOKEN>
				<TOKEN id="token-3-3" start_char="736" end_char="741">Agency</TOKEN>
				<TOKEN id="token-3-4" start_char="743" end_char="744">of</TOKEN>
				<TOKEN id="token-3-5" start_char="746" end_char="751">Canada</TOKEN>
				<TOKEN id="token-3-6" start_char="753" end_char="755">had</TOKEN>
				<TOKEN id="token-3-7" start_char="757" end_char="761">asked</TOKEN>
				<TOKEN id="token-3-8" start_char="763" end_char="765">the</TOKEN>
				<TOKEN id="token-3-9" start_char="767" end_char="770">RCMP</TOKEN>
				<TOKEN id="token-3-10" start_char="772" end_char="773">to</TOKEN>
				<TOKEN id="token-3-11" start_char="775" end_char="777">get</TOKEN>
				<TOKEN id="token-3-12" start_char="779" end_char="786">involved</TOKEN>
				<TOKEN id="token-3-13" start_char="788" end_char="794">several</TOKEN>
				<TOKEN id="token-3-14" start_char="796" end_char="801">months</TOKEN>
				<TOKEN id="token-3-15" start_char="803" end_char="809">earlier</TOKEN>
				<TOKEN id="token-3-16" start_char="810" end_char="810">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-4" start_char="812" end_char="930">
				<ORIGINAL_TEXT>The virus shipments are not related to the outbreak of COVID-19 or research into the pandemic, Canadian officials said.</ORIGINAL_TEXT>
				<TOKEN id="token-4-0" start_char="812" end_char="814">The</TOKEN>
				<TOKEN id="token-4-1" start_char="816" end_char="820">virus</TOKEN>
				<TOKEN id="token-4-2" start_char="822" end_char="830">shipments</TOKEN>
				<TOKEN id="token-4-3" start_char="832" end_char="834">are</TOKEN>
				<TOKEN id="token-4-4" start_char="836" end_char="838">not</TOKEN>
				<TOKEN id="token-4-5" start_char="840" end_char="846">related</TOKEN>
				<TOKEN id="token-4-6" start_char="848" end_char="849">to</TOKEN>
				<TOKEN id="token-4-7" start_char="851" end_char="853">the</TOKEN>
				<TOKEN id="token-4-8" start_char="855" end_char="862">outbreak</TOKEN>
				<TOKEN id="token-4-9" start_char="864" end_char="865">of</TOKEN>
				<TOKEN id="token-4-10" start_char="867" end_char="871">COVID</TOKEN>
				<TOKEN id="token-4-11" start_char="872" end_char="872">-</TOKEN>
				<TOKEN id="token-4-12" start_char="873" end_char="874">19</TOKEN>
				<TOKEN id="token-4-13" start_char="876" end_char="877">or</TOKEN>
				<TOKEN id="token-4-14" start_char="879" end_char="886">research</TOKEN>
				<TOKEN id="token-4-15" start_char="888" end_char="891">into</TOKEN>
				<TOKEN id="token-4-16" start_char="893" end_char="895">the</TOKEN>
				<TOKEN id="token-4-17" start_char="897" end_char="904">pandemic</TOKEN>
				<TOKEN id="token-4-18" start_char="905" end_char="905">,</TOKEN>
				<TOKEN id="token-4-19" start_char="907" end_char="914">Canadian</TOKEN>
				<TOKEN id="token-4-20" start_char="916" end_char="924">officials</TOKEN>
				<TOKEN id="token-4-21" start_char="926" end_char="929">said</TOKEN>
				<TOKEN id="token-4-22" start_char="930" end_char="930">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-5" start_char="932" end_char="1004">
				<ORIGINAL_TEXT>PHAC said the shipment and Qiu's eviction from the lab are not connected.</ORIGINAL_TEXT>
				<TOKEN id="token-5-0" start_char="932" end_char="935">PHAC</TOKEN>
				<TOKEN id="token-5-1" start_char="937" end_char="940">said</TOKEN>
				<TOKEN id="token-5-2" start_char="942" end_char="944">the</TOKEN>
				<TOKEN id="token-5-3" start_char="946" end_char="953">shipment</TOKEN>
				<TOKEN id="token-5-4" start_char="955" end_char="957">and</TOKEN>
				<TOKEN id="token-5-5" start_char="959" end_char="961">Qiu</TOKEN>
				<TOKEN id="token-5-6" start_char="962" end_char="962">'</TOKEN>
				<TOKEN id="token-5-7" start_char="963" end_char="963">s</TOKEN>
				<TOKEN id="token-5-8" start_char="965" end_char="972">eviction</TOKEN>
				<TOKEN id="token-5-9" start_char="974" end_char="977">from</TOKEN>
				<TOKEN id="token-5-10" start_char="979" end_char="981">the</TOKEN>
				<TOKEN id="token-5-11" start_char="983" end_char="985">lab</TOKEN>
				<TOKEN id="token-5-12" start_char="987" end_char="989">are</TOKEN>
				<TOKEN id="token-5-13" start_char="991" end_char="993">not</TOKEN>
				<TOKEN id="token-5-14" start_char="995" end_char="1003">connected</TOKEN>
				<TOKEN id="token-5-15" start_char="1004" end_char="1004">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-6" start_char="1006" end_char="1216">
				<ORIGINAL_TEXT>&quot;The administrative investigation is not related to the shipment of virus samples to China,&quot; Eric Morrissette, chief of media relations for Health Canada and the Public Health Agency of Canada wrote in an email.</ORIGINAL_TEXT>
				<TOKEN id="token-6-0" start_char="1006" end_char="1006">&quot;</TOKEN>
				<TOKEN id="token-6-1" start_char="1007" end_char="1009">The</TOKEN>
				<TOKEN id="token-6-2" start_char="1011" end_char="1024">administrative</TOKEN>
				<TOKEN id="token-6-3" start_char="1026" end_char="1038">investigation</TOKEN>
				<TOKEN id="token-6-4" start_char="1040" end_char="1041">is</TOKEN>
				<TOKEN id="token-6-5" start_char="1043" end_char="1045">not</TOKEN>
				<TOKEN id="token-6-6" start_char="1047" end_char="1053">related</TOKEN>
				<TOKEN id="token-6-7" start_char="1055" end_char="1056">to</TOKEN>
				<TOKEN id="token-6-8" start_char="1058" end_char="1060">the</TOKEN>
				<TOKEN id="token-6-9" start_char="1062" end_char="1069">shipment</TOKEN>
				<TOKEN id="token-6-10" start_char="1071" end_char="1072">of</TOKEN>
				<TOKEN id="token-6-11" start_char="1074" end_char="1078">virus</TOKEN>
				<TOKEN id="token-6-12" start_char="1080" end_char="1086">samples</TOKEN>
				<TOKEN id="token-6-13" start_char="1088" end_char="1089">to</TOKEN>
				<TOKEN id="token-6-14" start_char="1091" end_char="1095">China</TOKEN>
				<TOKEN id="token-6-15" start_char="1096" end_char="1097">,&quot;</TOKEN>
				<TOKEN id="token-6-16" start_char="1099" end_char="1102">Eric</TOKEN>
				<TOKEN id="token-6-17" start_char="1104" end_char="1114">Morrissette</TOKEN>
				<TOKEN id="token-6-18" start_char="1115" end_char="1115">,</TOKEN>
				<TOKEN id="token-6-19" start_char="1117" end_char="1121">chief</TOKEN>
				<TOKEN id="token-6-20" start_char="1123" end_char="1124">of</TOKEN>
				<TOKEN id="token-6-21" start_char="1126" end_char="1130">media</TOKEN>
				<TOKEN id="token-6-22" start_char="1132" end_char="1140">relations</TOKEN>
				<TOKEN id="token-6-23" start_char="1142" end_char="1144">for</TOKEN>
				<TOKEN id="token-6-24" start_char="1146" end_char="1151">Health</TOKEN>
				<TOKEN id="token-6-25" start_char="1153" end_char="1158">Canada</TOKEN>
				<TOKEN id="token-6-26" start_char="1160" end_char="1162">and</TOKEN>
				<TOKEN id="token-6-27" start_char="1164" end_char="1166">the</TOKEN>
				<TOKEN id="token-6-28" start_char="1168" end_char="1173">Public</TOKEN>
				<TOKEN id="token-6-29" start_char="1175" end_char="1180">Health</TOKEN>
				<TOKEN id="token-6-30" start_char="1182" end_char="1187">Agency</TOKEN>
				<TOKEN id="token-6-31" start_char="1189" end_char="1190">of</TOKEN>
				<TOKEN id="token-6-32" start_char="1192" end_char="1197">Canada</TOKEN>
				<TOKEN id="token-6-33" start_char="1199" end_char="1203">wrote</TOKEN>
				<TOKEN id="token-6-34" start_char="1205" end_char="1206">in</TOKEN>
				<TOKEN id="token-6-35" start_char="1208" end_char="1209">an</TOKEN>
				<TOKEN id="token-6-36" start_char="1211" end_char="1215">email</TOKEN>
				<TOKEN id="token-6-37" start_char="1216" end_char="1216">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-7" start_char="1218" end_char="1431">
				<ORIGINAL_TEXT>&quot;In response to a request from the Wuhan Institute of Virology for viral samples of Ebola and Henipah viruses, the Public Health Agency of Canada (PHAC) sent samples for the purpose of scientific research in 2019.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-7-0" start_char="1218" end_char="1218">&quot;</TOKEN>
				<TOKEN id="token-7-1" start_char="1219" end_char="1220">In</TOKEN>
				<TOKEN id="token-7-2" start_char="1222" end_char="1229">response</TOKEN>
				<TOKEN id="token-7-3" start_char="1231" end_char="1232">to</TOKEN>
				<TOKEN id="token-7-4" start_char="1234" end_char="1234">a</TOKEN>
				<TOKEN id="token-7-5" start_char="1236" end_char="1242">request</TOKEN>
				<TOKEN id="token-7-6" start_char="1244" end_char="1247">from</TOKEN>
				<TOKEN id="token-7-7" start_char="1249" end_char="1251">the</TOKEN>
				<TOKEN id="token-7-8" start_char="1253" end_char="1257">Wuhan</TOKEN>
				<TOKEN id="token-7-9" start_char="1259" end_char="1267">Institute</TOKEN>
				<TOKEN id="token-7-10" start_char="1269" end_char="1270">of</TOKEN>
				<TOKEN id="token-7-11" start_char="1272" end_char="1279">Virology</TOKEN>
				<TOKEN id="token-7-12" start_char="1281" end_char="1283">for</TOKEN>
				<TOKEN id="token-7-13" start_char="1285" end_char="1289">viral</TOKEN>
				<TOKEN id="token-7-14" start_char="1291" end_char="1297">samples</TOKEN>
				<TOKEN id="token-7-15" start_char="1299" end_char="1300">of</TOKEN>
				<TOKEN id="token-7-16" start_char="1302" end_char="1306">Ebola</TOKEN>
				<TOKEN id="token-7-17" start_char="1308" end_char="1310">and</TOKEN>
				<TOKEN id="token-7-18" start_char="1312" end_char="1318">Henipah</TOKEN>
				<TOKEN id="token-7-19" start_char="1320" end_char="1326">viruses</TOKEN>
				<TOKEN id="token-7-20" start_char="1327" end_char="1327">,</TOKEN>
				<TOKEN id="token-7-21" start_char="1329" end_char="1331">the</TOKEN>
				<TOKEN id="token-7-22" start_char="1333" end_char="1338">Public</TOKEN>
				<TOKEN id="token-7-23" start_char="1340" end_char="1345">Health</TOKEN>
				<TOKEN id="token-7-24" start_char="1347" end_char="1352">Agency</TOKEN>
				<TOKEN id="token-7-25" start_char="1354" end_char="1355">of</TOKEN>
				<TOKEN id="token-7-26" start_char="1357" end_char="1362">Canada</TOKEN>
				<TOKEN id="token-7-27" start_char="1364" end_char="1364">(</TOKEN>
				<TOKEN id="token-7-28" start_char="1365" end_char="1368">PHAC</TOKEN>
				<TOKEN id="token-7-29" start_char="1369" end_char="1369">)</TOKEN>
				<TOKEN id="token-7-30" start_char="1371" end_char="1374">sent</TOKEN>
				<TOKEN id="token-7-31" start_char="1376" end_char="1382">samples</TOKEN>
				<TOKEN id="token-7-32" start_char="1384" end_char="1386">for</TOKEN>
				<TOKEN id="token-7-33" start_char="1388" end_char="1390">the</TOKEN>
				<TOKEN id="token-7-34" start_char="1392" end_char="1398">purpose</TOKEN>
				<TOKEN id="token-7-35" start_char="1400" end_char="1401">of</TOKEN>
				<TOKEN id="token-7-36" start_char="1403" end_char="1412">scientific</TOKEN>
				<TOKEN id="token-7-37" start_char="1414" end_char="1421">research</TOKEN>
				<TOKEN id="token-7-38" start_char="1423" end_char="1424">in</TOKEN>
				<TOKEN id="token-7-39" start_char="1426" end_char="1429">2019</TOKEN>
				<TOKEN id="token-7-40" start_char="1430" end_char="1431">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-8" start_char="1433" end_char="1448">
				<ORIGINAL_TEXT>'It is alarming'</ORIGINAL_TEXT>
				<TOKEN id="token-8-0" start_char="1433" end_char="1433">'</TOKEN>
				<TOKEN id="token-8-1" start_char="1434" end_char="1435">It</TOKEN>
				<TOKEN id="token-8-2" start_char="1437" end_char="1438">is</TOKEN>
				<TOKEN id="token-8-3" start_char="1440" end_char="1447">alarming</TOKEN>
				<TOKEN id="token-8-4" start_char="1448" end_char="1448">'</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-9" start_char="1450" end_char="1480">
				<ORIGINAL_TEXT>However, experts are concerned.</ORIGINAL_TEXT>
				<TOKEN id="token-9-0" start_char="1450" end_char="1456">However</TOKEN>
				<TOKEN id="token-9-1" start_char="1457" end_char="1457">,</TOKEN>
				<TOKEN id="token-9-2" start_char="1459" end_char="1465">experts</TOKEN>
				<TOKEN id="token-9-3" start_char="1467" end_char="1469">are</TOKEN>
				<TOKEN id="token-9-4" start_char="1471" end_char="1479">concerned</TOKEN>
				<TOKEN id="token-9-5" start_char="1480" end_char="1480">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-10" start_char="1482" end_char="1499">
				<ORIGINAL_TEXT>&quot;It is suspicious.</ORIGINAL_TEXT>
				<TOKEN id="token-10-0" start_char="1482" end_char="1482">&quot;</TOKEN>
				<TOKEN id="token-10-1" start_char="1483" end_char="1484">It</TOKEN>
				<TOKEN id="token-10-2" start_char="1486" end_char="1487">is</TOKEN>
				<TOKEN id="token-10-3" start_char="1489" end_char="1498">suspicious</TOKEN>
				<TOKEN id="token-10-4" start_char="1499" end_char="1499">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-11" start_char="1501" end_char="1515">
				<ORIGINAL_TEXT>It is alarming.</ORIGINAL_TEXT>
				<TOKEN id="token-11-0" start_char="1501" end_char="1502">It</TOKEN>
				<TOKEN id="token-11-1" start_char="1504" end_char="1505">is</TOKEN>
				<TOKEN id="token-11-2" start_char="1507" end_char="1514">alarming</TOKEN>
				<TOKEN id="token-11-3" start_char="1515" end_char="1515">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-12" start_char="1517" end_char="1635">
				<ORIGINAL_TEXT>It is potentially life-threatening,&quot; said Amir Attaran, a law professor and epidemiologist at the University of Ottawa.</ORIGINAL_TEXT>
				<TOKEN id="token-12-0" start_char="1517" end_char="1518">It</TOKEN>
				<TOKEN id="token-12-1" start_char="1520" end_char="1521">is</TOKEN>
				<TOKEN id="token-12-2" start_char="1523" end_char="1533">potentially</TOKEN>
				<TOKEN id="token-12-3" start_char="1535" end_char="1538">life</TOKEN>
				<TOKEN id="token-12-4" start_char="1539" end_char="1539">-</TOKEN>
				<TOKEN id="token-12-5" start_char="1540" end_char="1550">threatening</TOKEN>
				<TOKEN id="token-12-6" start_char="1551" end_char="1552">,&quot;</TOKEN>
				<TOKEN id="token-12-7" start_char="1554" end_char="1557">said</TOKEN>
				<TOKEN id="token-12-8" start_char="1559" end_char="1562">Amir</TOKEN>
				<TOKEN id="token-12-9" start_char="1564" end_char="1570">Attaran</TOKEN>
				<TOKEN id="token-12-10" start_char="1571" end_char="1571">,</TOKEN>
				<TOKEN id="token-12-11" start_char="1573" end_char="1573">a</TOKEN>
				<TOKEN id="token-12-12" start_char="1575" end_char="1577">law</TOKEN>
				<TOKEN id="token-12-13" start_char="1579" end_char="1587">professor</TOKEN>
				<TOKEN id="token-12-14" start_char="1589" end_char="1591">and</TOKEN>
				<TOKEN id="token-12-15" start_char="1593" end_char="1606">epidemiologist</TOKEN>
				<TOKEN id="token-12-16" start_char="1608" end_char="1609">at</TOKEN>
				<TOKEN id="token-12-17" start_char="1611" end_char="1613">the</TOKEN>
				<TOKEN id="token-12-18" start_char="1615" end_char="1624">University</TOKEN>
				<TOKEN id="token-12-19" start_char="1626" end_char="1627">of</TOKEN>
				<TOKEN id="token-12-20" start_char="1629" end_char="1634">Ottawa</TOKEN>
				<TOKEN id="token-12-21" start_char="1635" end_char="1635">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-13" start_char="1637" end_char="1706">
				<ORIGINAL_TEXT>WATCH | Deadly viruses were sent from Canada to China, documents show:</ORIGINAL_TEXT>
				<TOKEN id="token-13-0" start_char="1637" end_char="1641">WATCH</TOKEN>
				<TOKEN id="token-13-1" start_char="1643" end_char="1643">|</TOKEN>
				<TOKEN id="token-13-2" start_char="1645" end_char="1650">Deadly</TOKEN>
				<TOKEN id="token-13-3" start_char="1652" end_char="1658">viruses</TOKEN>
				<TOKEN id="token-13-4" start_char="1660" end_char="1663">were</TOKEN>
				<TOKEN id="token-13-5" start_char="1665" end_char="1668">sent</TOKEN>
				<TOKEN id="token-13-6" start_char="1670" end_char="1673">from</TOKEN>
				<TOKEN id="token-13-7" start_char="1675" end_char="1680">Canada</TOKEN>
				<TOKEN id="token-13-8" start_char="1682" end_char="1683">to</TOKEN>
				<TOKEN id="token-13-9" start_char="1685" end_char="1689">China</TOKEN>
				<TOKEN id="token-13-10" start_char="1690" end_char="1690">,</TOKEN>
				<TOKEN id="token-13-11" start_char="1692" end_char="1700">documents</TOKEN>
				<TOKEN id="token-13-12" start_char="1702" end_char="1705">show</TOKEN>
				<TOKEN id="token-13-13" start_char="1706" end_char="1706">:</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-14" start_char="1708" end_char="2113">
				<ORIGINAL_TEXT>Deadly viruses were sent from Canada to China, according to access documents CBC News Manitoba 2:38 One of the scientists escorted from the National Microbiology Lab last year amidst an RCMP investigation was responsible for a shipment of Ebola and Henipah virus to the Wuhan Institute of Virology four months earlier - although the Public Health Agency of Canada still maintains the two are not connected.</ORIGINAL_TEXT>
				<TOKEN id="token-14-0" start_char="1708" end_char="1713">Deadly</TOKEN>
				<TOKEN id="token-14-1" start_char="1715" end_char="1721">viruses</TOKEN>
				<TOKEN id="token-14-2" start_char="1723" end_char="1726">were</TOKEN>
				<TOKEN id="token-14-3" start_char="1728" end_char="1731">sent</TOKEN>
				<TOKEN id="token-14-4" start_char="1733" end_char="1736">from</TOKEN>
				<TOKEN id="token-14-5" start_char="1738" end_char="1743">Canada</TOKEN>
				<TOKEN id="token-14-6" start_char="1745" end_char="1746">to</TOKEN>
				<TOKEN id="token-14-7" start_char="1748" end_char="1752">China</TOKEN>
				<TOKEN id="token-14-8" start_char="1753" end_char="1753">,</TOKEN>
				<TOKEN id="token-14-9" start_char="1755" end_char="1763">according</TOKEN>
				<TOKEN id="token-14-10" start_char="1765" end_char="1766">to</TOKEN>
				<TOKEN id="token-14-11" start_char="1768" end_char="1773">access</TOKEN>
				<TOKEN id="token-14-12" start_char="1775" end_char="1783">documents</TOKEN>
				<TOKEN id="token-14-13" start_char="1785" end_char="1787">CBC</TOKEN>
				<TOKEN id="token-14-14" start_char="1789" end_char="1792">News</TOKEN>
				<TOKEN id="token-14-15" start_char="1794" end_char="1801">Manitoba</TOKEN>
				<TOKEN id="token-14-16" start_char="1803" end_char="1803">2</TOKEN>
				<TOKEN id="token-14-17" start_char="1804" end_char="1804">:</TOKEN>
				<TOKEN id="token-14-18" start_char="1805" end_char="1806">38</TOKEN>
				<TOKEN id="token-14-19" start_char="1808" end_char="1810">One</TOKEN>
				<TOKEN id="token-14-20" start_char="1812" end_char="1813">of</TOKEN>
				<TOKEN id="token-14-21" start_char="1815" end_char="1817">the</TOKEN>
				<TOKEN id="token-14-22" start_char="1819" end_char="1828">scientists</TOKEN>
				<TOKEN id="token-14-23" start_char="1830" end_char="1837">escorted</TOKEN>
				<TOKEN id="token-14-24" start_char="1839" end_char="1842">from</TOKEN>
				<TOKEN id="token-14-25" start_char="1844" end_char="1846">the</TOKEN>
				<TOKEN id="token-14-26" start_char="1848" end_char="1855">National</TOKEN>
				<TOKEN id="token-14-27" start_char="1857" end_char="1868">Microbiology</TOKEN>
				<TOKEN id="token-14-28" start_char="1870" end_char="1872">Lab</TOKEN>
				<TOKEN id="token-14-29" start_char="1874" end_char="1877">last</TOKEN>
				<TOKEN id="token-14-30" start_char="1879" end_char="1882">year</TOKEN>
				<TOKEN id="token-14-31" start_char="1884" end_char="1889">amidst</TOKEN>
				<TOKEN id="token-14-32" start_char="1891" end_char="1892">an</TOKEN>
				<TOKEN id="token-14-33" start_char="1894" end_char="1897">RCMP</TOKEN>
				<TOKEN id="token-14-34" start_char="1899" end_char="1911">investigation</TOKEN>
				<TOKEN id="token-14-35" start_char="1913" end_char="1915">was</TOKEN>
				<TOKEN id="token-14-36" start_char="1917" end_char="1927">responsible</TOKEN>
				<TOKEN id="token-14-37" start_char="1929" end_char="1931">for</TOKEN>
				<TOKEN id="token-14-38" start_char="1933" end_char="1933">a</TOKEN>
				<TOKEN id="token-14-39" start_char="1935" end_char="1942">shipment</TOKEN>
				<TOKEN id="token-14-40" start_char="1944" end_char="1945">of</TOKEN>
				<TOKEN id="token-14-41" start_char="1947" end_char="1951">Ebola</TOKEN>
				<TOKEN id="token-14-42" start_char="1953" end_char="1955">and</TOKEN>
				<TOKEN id="token-14-43" start_char="1957" end_char="1963">Henipah</TOKEN>
				<TOKEN id="token-14-44" start_char="1965" end_char="1969">virus</TOKEN>
				<TOKEN id="token-14-45" start_char="1971" end_char="1972">to</TOKEN>
				<TOKEN id="token-14-46" start_char="1974" end_char="1976">the</TOKEN>
				<TOKEN id="token-14-47" start_char="1978" end_char="1982">Wuhan</TOKEN>
				<TOKEN id="token-14-48" start_char="1984" end_char="1992">Institute</TOKEN>
				<TOKEN id="token-14-49" start_char="1994" end_char="1995">of</TOKEN>
				<TOKEN id="token-14-50" start_char="1997" end_char="2004">Virology</TOKEN>
				<TOKEN id="token-14-51" start_char="2006" end_char="2009">four</TOKEN>
				<TOKEN id="token-14-52" start_char="2011" end_char="2016">months</TOKEN>
				<TOKEN id="token-14-53" start_char="2018" end_char="2024">earlier</TOKEN>
				<TOKEN id="token-14-54" start_char="2026" end_char="2026">-</TOKEN>
				<TOKEN id="token-14-55" start_char="2028" end_char="2035">although</TOKEN>
				<TOKEN id="token-14-56" start_char="2037" end_char="2039">the</TOKEN>
				<TOKEN id="token-14-57" start_char="2041" end_char="2046">Public</TOKEN>
				<TOKEN id="token-14-58" start_char="2048" end_char="2053">Health</TOKEN>
				<TOKEN id="token-14-59" start_char="2055" end_char="2060">Agency</TOKEN>
				<TOKEN id="token-14-60" start_char="2062" end_char="2063">of</TOKEN>
				<TOKEN id="token-14-61" start_char="2065" end_char="2070">Canada</TOKEN>
				<TOKEN id="token-14-62" start_char="2072" end_char="2076">still</TOKEN>
				<TOKEN id="token-14-63" start_char="2078" end_char="2086">maintains</TOKEN>
				<TOKEN id="token-14-64" start_char="2088" end_char="2090">the</TOKEN>
				<TOKEN id="token-14-65" start_char="2092" end_char="2094">two</TOKEN>
				<TOKEN id="token-14-66" start_char="2096" end_char="2098">are</TOKEN>
				<TOKEN id="token-14-67" start_char="2100" end_char="2102">not</TOKEN>
				<TOKEN id="token-14-68" start_char="2104" end_char="2112">connected</TOKEN>
				<TOKEN id="token-14-69" start_char="2113" end_char="2113">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-15" start_char="2115" end_char="2118">
				<ORIGINAL_TEXT>2:38</ORIGINAL_TEXT>
				<TOKEN id="token-15-0" start_char="2115" end_char="2115">2</TOKEN>
				<TOKEN id="token-15-1" start_char="2116" end_char="2116">:</TOKEN>
				<TOKEN id="token-15-2" start_char="2117" end_char="2118">38</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-16" start_char="2120" end_char="2275">
				<ORIGINAL_TEXT>&quot;We have a researcher who was removed by the RCMP from the highest security laboratory that Canada has for reasons that government is unwilling to disclose.</ORIGINAL_TEXT>
				<TOKEN id="token-16-0" start_char="2120" end_char="2120">&quot;</TOKEN>
				<TOKEN id="token-16-1" start_char="2121" end_char="2122">We</TOKEN>
				<TOKEN id="token-16-2" start_char="2124" end_char="2127">have</TOKEN>
				<TOKEN id="token-16-3" start_char="2129" end_char="2129">a</TOKEN>
				<TOKEN id="token-16-4" start_char="2131" end_char="2140">researcher</TOKEN>
				<TOKEN id="token-16-5" start_char="2142" end_char="2144">who</TOKEN>
				<TOKEN id="token-16-6" start_char="2146" end_char="2148">was</TOKEN>
				<TOKEN id="token-16-7" start_char="2150" end_char="2156">removed</TOKEN>
				<TOKEN id="token-16-8" start_char="2158" end_char="2159">by</TOKEN>
				<TOKEN id="token-16-9" start_char="2161" end_char="2163">the</TOKEN>
				<TOKEN id="token-16-10" start_char="2165" end_char="2168">RCMP</TOKEN>
				<TOKEN id="token-16-11" start_char="2170" end_char="2173">from</TOKEN>
				<TOKEN id="token-16-12" start_char="2175" end_char="2177">the</TOKEN>
				<TOKEN id="token-16-13" start_char="2179" end_char="2185">highest</TOKEN>
				<TOKEN id="token-16-14" start_char="2187" end_char="2194">security</TOKEN>
				<TOKEN id="token-16-15" start_char="2196" end_char="2205">laboratory</TOKEN>
				<TOKEN id="token-16-16" start_char="2207" end_char="2210">that</TOKEN>
				<TOKEN id="token-16-17" start_char="2212" end_char="2217">Canada</TOKEN>
				<TOKEN id="token-16-18" start_char="2219" end_char="2221">has</TOKEN>
				<TOKEN id="token-16-19" start_char="2223" end_char="2225">for</TOKEN>
				<TOKEN id="token-16-20" start_char="2227" end_char="2233">reasons</TOKEN>
				<TOKEN id="token-16-21" start_char="2235" end_char="2238">that</TOKEN>
				<TOKEN id="token-16-22" start_char="2240" end_char="2249">government</TOKEN>
				<TOKEN id="token-16-23" start_char="2251" end_char="2252">is</TOKEN>
				<TOKEN id="token-16-24" start_char="2254" end_char="2262">unwilling</TOKEN>
				<TOKEN id="token-16-25" start_char="2264" end_char="2265">to</TOKEN>
				<TOKEN id="token-16-26" start_char="2267" end_char="2274">disclose</TOKEN>
				<TOKEN id="token-16-27" start_char="2275" end_char="2275">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-17" start_char="2277" end_char="2308">
				<ORIGINAL_TEXT>The intelligence remains secret.</ORIGINAL_TEXT>
				<TOKEN id="token-17-0" start_char="2277" end_char="2279">The</TOKEN>
				<TOKEN id="token-17-1" start_char="2281" end_char="2292">intelligence</TOKEN>
				<TOKEN id="token-17-2" start_char="2294" end_char="2300">remains</TOKEN>
				<TOKEN id="token-17-3" start_char="2302" end_char="2307">secret</TOKEN>
				<TOKEN id="token-17-4" start_char="2308" end_char="2308">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-18" start_char="2310" end_char="2602">
				<ORIGINAL_TEXT>But what we know is that before she was removed, she sent one of the deadliest viruses on Earth, and multiple varieties of it to maximize the genetic diversity and maximize what experimenters in China could do with it, to a laboratory in China that does dangerous gain of function experiments.</ORIGINAL_TEXT>
				<TOKEN id="token-18-0" start_char="2310" end_char="2312">But</TOKEN>
				<TOKEN id="token-18-1" start_char="2314" end_char="2317">what</TOKEN>
				<TOKEN id="token-18-2" start_char="2319" end_char="2320">we</TOKEN>
				<TOKEN id="token-18-3" start_char="2322" end_char="2325">know</TOKEN>
				<TOKEN id="token-18-4" start_char="2327" end_char="2328">is</TOKEN>
				<TOKEN id="token-18-5" start_char="2330" end_char="2333">that</TOKEN>
				<TOKEN id="token-18-6" start_char="2335" end_char="2340">before</TOKEN>
				<TOKEN id="token-18-7" start_char="2342" end_char="2344">she</TOKEN>
				<TOKEN id="token-18-8" start_char="2346" end_char="2348">was</TOKEN>
				<TOKEN id="token-18-9" start_char="2350" end_char="2356">removed</TOKEN>
				<TOKEN id="token-18-10" start_char="2357" end_char="2357">,</TOKEN>
				<TOKEN id="token-18-11" start_char="2359" end_char="2361">she</TOKEN>
				<TOKEN id="token-18-12" start_char="2363" end_char="2366">sent</TOKEN>
				<TOKEN id="token-18-13" start_char="2368" end_char="2370">one</TOKEN>
				<TOKEN id="token-18-14" start_char="2372" end_char="2373">of</TOKEN>
				<TOKEN id="token-18-15" start_char="2375" end_char="2377">the</TOKEN>
				<TOKEN id="token-18-16" start_char="2379" end_char="2387">deadliest</TOKEN>
				<TOKEN id="token-18-17" start_char="2389" end_char="2395">viruses</TOKEN>
				<TOKEN id="token-18-18" start_char="2397" end_char="2398">on</TOKEN>
				<TOKEN id="token-18-19" start_char="2400" end_char="2404">Earth</TOKEN>
				<TOKEN id="token-18-20" start_char="2405" end_char="2405">,</TOKEN>
				<TOKEN id="token-18-21" start_char="2407" end_char="2409">and</TOKEN>
				<TOKEN id="token-18-22" start_char="2411" end_char="2418">multiple</TOKEN>
				<TOKEN id="token-18-23" start_char="2420" end_char="2428">varieties</TOKEN>
				<TOKEN id="token-18-24" start_char="2430" end_char="2431">of</TOKEN>
				<TOKEN id="token-18-25" start_char="2433" end_char="2434">it</TOKEN>
				<TOKEN id="token-18-26" start_char="2436" end_char="2437">to</TOKEN>
				<TOKEN id="token-18-27" start_char="2439" end_char="2446">maximize</TOKEN>
				<TOKEN id="token-18-28" start_char="2448" end_char="2450">the</TOKEN>
				<TOKEN id="token-18-29" start_char="2452" end_char="2458">genetic</TOKEN>
				<TOKEN id="token-18-30" start_char="2460" end_char="2468">diversity</TOKEN>
				<TOKEN id="token-18-31" start_char="2470" end_char="2472">and</TOKEN>
				<TOKEN id="token-18-32" start_char="2474" end_char="2481">maximize</TOKEN>
				<TOKEN id="token-18-33" start_char="2483" end_char="2486">what</TOKEN>
				<TOKEN id="token-18-34" start_char="2488" end_char="2500">experimenters</TOKEN>
				<TOKEN id="token-18-35" start_char="2502" end_char="2503">in</TOKEN>
				<TOKEN id="token-18-36" start_char="2505" end_char="2509">China</TOKEN>
				<TOKEN id="token-18-37" start_char="2511" end_char="2515">could</TOKEN>
				<TOKEN id="token-18-38" start_char="2517" end_char="2518">do</TOKEN>
				<TOKEN id="token-18-39" start_char="2520" end_char="2523">with</TOKEN>
				<TOKEN id="token-18-40" start_char="2525" end_char="2526">it</TOKEN>
				<TOKEN id="token-18-41" start_char="2527" end_char="2527">,</TOKEN>
				<TOKEN id="token-18-42" start_char="2529" end_char="2530">to</TOKEN>
				<TOKEN id="token-18-43" start_char="2532" end_char="2532">a</TOKEN>
				<TOKEN id="token-18-44" start_char="2534" end_char="2543">laboratory</TOKEN>
				<TOKEN id="token-18-45" start_char="2545" end_char="2546">in</TOKEN>
				<TOKEN id="token-18-46" start_char="2548" end_char="2552">China</TOKEN>
				<TOKEN id="token-18-47" start_char="2554" end_char="2557">that</TOKEN>
				<TOKEN id="token-18-48" start_char="2559" end_char="2562">does</TOKEN>
				<TOKEN id="token-18-49" start_char="2564" end_char="2572">dangerous</TOKEN>
				<TOKEN id="token-18-50" start_char="2574" end_char="2577">gain</TOKEN>
				<TOKEN id="token-18-51" start_char="2579" end_char="2580">of</TOKEN>
				<TOKEN id="token-18-52" start_char="2582" end_char="2589">function</TOKEN>
				<TOKEN id="token-18-53" start_char="2591" end_char="2601">experiments</TOKEN>
				<TOKEN id="token-18-54" start_char="2602" end_char="2602">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-19" start_char="2604" end_char="2647">
				<ORIGINAL_TEXT>And that has links to the Chinese military.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-19-0" start_char="2604" end_char="2606">And</TOKEN>
				<TOKEN id="token-19-1" start_char="2608" end_char="2611">that</TOKEN>
				<TOKEN id="token-19-2" start_char="2613" end_char="2615">has</TOKEN>
				<TOKEN id="token-19-3" start_char="2617" end_char="2621">links</TOKEN>
				<TOKEN id="token-19-4" start_char="2623" end_char="2624">to</TOKEN>
				<TOKEN id="token-19-5" start_char="2626" end_char="2628">the</TOKEN>
				<TOKEN id="token-19-6" start_char="2630" end_char="2636">Chinese</TOKEN>
				<TOKEN id="token-19-7" start_char="2638" end_char="2645">military</TOKEN>
				<TOKEN id="token-19-8" start_char="2646" end_char="2647">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-20" start_char="2649" end_char="2812">
				<ORIGINAL_TEXT>Gain of function experiments are when a natural pathogen is taken into the lab, made to mutate, and then assessed to see if it has become more deadly or infectious.</ORIGINAL_TEXT>
				<TOKEN id="token-20-0" start_char="2649" end_char="2652">Gain</TOKEN>
				<TOKEN id="token-20-1" start_char="2654" end_char="2655">of</TOKEN>
				<TOKEN id="token-20-2" start_char="2657" end_char="2664">function</TOKEN>
				<TOKEN id="token-20-3" start_char="2666" end_char="2676">experiments</TOKEN>
				<TOKEN id="token-20-4" start_char="2678" end_char="2680">are</TOKEN>
				<TOKEN id="token-20-5" start_char="2682" end_char="2685">when</TOKEN>
				<TOKEN id="token-20-6" start_char="2687" end_char="2687">a</TOKEN>
				<TOKEN id="token-20-7" start_char="2689" end_char="2695">natural</TOKEN>
				<TOKEN id="token-20-8" start_char="2697" end_char="2704">pathogen</TOKEN>
				<TOKEN id="token-20-9" start_char="2706" end_char="2707">is</TOKEN>
				<TOKEN id="token-20-10" start_char="2709" end_char="2713">taken</TOKEN>
				<TOKEN id="token-20-11" start_char="2715" end_char="2718">into</TOKEN>
				<TOKEN id="token-20-12" start_char="2720" end_char="2722">the</TOKEN>
				<TOKEN id="token-20-13" start_char="2724" end_char="2726">lab</TOKEN>
				<TOKEN id="token-20-14" start_char="2727" end_char="2727">,</TOKEN>
				<TOKEN id="token-20-15" start_char="2729" end_char="2732">made</TOKEN>
				<TOKEN id="token-20-16" start_char="2734" end_char="2735">to</TOKEN>
				<TOKEN id="token-20-17" start_char="2737" end_char="2742">mutate</TOKEN>
				<TOKEN id="token-20-18" start_char="2743" end_char="2743">,</TOKEN>
				<TOKEN id="token-20-19" start_char="2745" end_char="2747">and</TOKEN>
				<TOKEN id="token-20-20" start_char="2749" end_char="2752">then</TOKEN>
				<TOKEN id="token-20-21" start_char="2754" end_char="2761">assessed</TOKEN>
				<TOKEN id="token-20-22" start_char="2763" end_char="2764">to</TOKEN>
				<TOKEN id="token-20-23" start_char="2766" end_char="2768">see</TOKEN>
				<TOKEN id="token-20-24" start_char="2770" end_char="2771">if</TOKEN>
				<TOKEN id="token-20-25" start_char="2773" end_char="2774">it</TOKEN>
				<TOKEN id="token-20-26" start_char="2776" end_char="2778">has</TOKEN>
				<TOKEN id="token-20-27" start_char="2780" end_char="2785">become</TOKEN>
				<TOKEN id="token-20-28" start_char="2787" end_char="2790">more</TOKEN>
				<TOKEN id="token-20-29" start_char="2792" end_char="2797">deadly</TOKEN>
				<TOKEN id="token-20-30" start_char="2799" end_char="2800">or</TOKEN>
				<TOKEN id="token-20-31" start_char="2802" end_char="2811">infectious</TOKEN>
				<TOKEN id="token-20-32" start_char="2812" end_char="2812">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-21" start_char="2814" end_char="2990">
				<ORIGINAL_TEXT>In Canada, gain of function experiments to create more dangerous pathogens in humans are not prohibited, but are not done because they're considered too dangerous, Attaran said.</ORIGINAL_TEXT>
				<TOKEN id="token-21-0" start_char="2814" end_char="2815">In</TOKEN>
				<TOKEN id="token-21-1" start_char="2817" end_char="2822">Canada</TOKEN>
				<TOKEN id="token-21-2" start_char="2823" end_char="2823">,</TOKEN>
				<TOKEN id="token-21-3" start_char="2825" end_char="2828">gain</TOKEN>
				<TOKEN id="token-21-4" start_char="2830" end_char="2831">of</TOKEN>
				<TOKEN id="token-21-5" start_char="2833" end_char="2840">function</TOKEN>
				<TOKEN id="token-21-6" start_char="2842" end_char="2852">experiments</TOKEN>
				<TOKEN id="token-21-7" start_char="2854" end_char="2855">to</TOKEN>
				<TOKEN id="token-21-8" start_char="2857" end_char="2862">create</TOKEN>
				<TOKEN id="token-21-9" start_char="2864" end_char="2867">more</TOKEN>
				<TOKEN id="token-21-10" start_char="2869" end_char="2877">dangerous</TOKEN>
				<TOKEN id="token-21-11" start_char="2879" end_char="2887">pathogens</TOKEN>
				<TOKEN id="token-21-12" start_char="2889" end_char="2890">in</TOKEN>
				<TOKEN id="token-21-13" start_char="2892" end_char="2897">humans</TOKEN>
				<TOKEN id="token-21-14" start_char="2899" end_char="2901">are</TOKEN>
				<TOKEN id="token-21-15" start_char="2903" end_char="2905">not</TOKEN>
				<TOKEN id="token-21-16" start_char="2907" end_char="2916">prohibited</TOKEN>
				<TOKEN id="token-21-17" start_char="2917" end_char="2917">,</TOKEN>
				<TOKEN id="token-21-18" start_char="2919" end_char="2921">but</TOKEN>
				<TOKEN id="token-21-19" start_char="2923" end_char="2925">are</TOKEN>
				<TOKEN id="token-21-20" start_char="2927" end_char="2929">not</TOKEN>
				<TOKEN id="token-21-21" start_char="2931" end_char="2934">done</TOKEN>
				<TOKEN id="token-21-22" start_char="2936" end_char="2942">because</TOKEN>
				<TOKEN id="token-21-23" start_char="2944" end_char="2947">they</TOKEN>
				<TOKEN id="token-21-24" start_char="2948" end_char="2948">'</TOKEN>
				<TOKEN id="token-21-25" start_char="2949" end_char="2950">re</TOKEN>
				<TOKEN id="token-21-26" start_char="2952" end_char="2961">considered</TOKEN>
				<TOKEN id="token-21-27" start_char="2963" end_char="2965">too</TOKEN>
				<TOKEN id="token-21-28" start_char="2967" end_char="2975">dangerous</TOKEN>
				<TOKEN id="token-21-29" start_char="2976" end_char="2976">,</TOKEN>
				<TOKEN id="token-21-30" start_char="2978" end_char="2984">Attaran</TOKEN>
				<TOKEN id="token-21-31" start_char="2986" end_char="2989">said</TOKEN>
				<TOKEN id="token-21-32" start_char="2990" end_char="2990">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-22" start_char="2992" end_char="3075">
				<ORIGINAL_TEXT>&quot;The Wuhan lab does them and we have now supplied them with Ebola and Nipah viruses.</ORIGINAL_TEXT>
				<TOKEN id="token-22-0" start_char="2992" end_char="2992">&quot;</TOKEN>
				<TOKEN id="token-22-1" start_char="2993" end_char="2995">The</TOKEN>
				<TOKEN id="token-22-2" start_char="2997" end_char="3001">Wuhan</TOKEN>
				<TOKEN id="token-22-3" start_char="3003" end_char="3005">lab</TOKEN>
				<TOKEN id="token-22-4" start_char="3007" end_char="3010">does</TOKEN>
				<TOKEN id="token-22-5" start_char="3012" end_char="3015">them</TOKEN>
				<TOKEN id="token-22-6" start_char="3017" end_char="3019">and</TOKEN>
				<TOKEN id="token-22-7" start_char="3021" end_char="3022">we</TOKEN>
				<TOKEN id="token-22-8" start_char="3024" end_char="3027">have</TOKEN>
				<TOKEN id="token-22-9" start_char="3029" end_char="3031">now</TOKEN>
				<TOKEN id="token-22-10" start_char="3033" end_char="3040">supplied</TOKEN>
				<TOKEN id="token-22-11" start_char="3042" end_char="3045">them</TOKEN>
				<TOKEN id="token-22-12" start_char="3047" end_char="3050">with</TOKEN>
				<TOKEN id="token-22-13" start_char="3052" end_char="3056">Ebola</TOKEN>
				<TOKEN id="token-22-14" start_char="3058" end_char="3060">and</TOKEN>
				<TOKEN id="token-22-15" start_char="3062" end_char="3066">Nipah</TOKEN>
				<TOKEN id="token-22-16" start_char="3068" end_char="3074">viruses</TOKEN>
				<TOKEN id="token-22-17" start_char="3075" end_char="3075">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-23" start_char="3077" end_char="3158">
				<ORIGINAL_TEXT>It does not take a genius to understand that this is an unwise decision,&quot; he said.</ORIGINAL_TEXT>
				<TOKEN id="token-23-0" start_char="3077" end_char="3078">It</TOKEN>
				<TOKEN id="token-23-1" start_char="3080" end_char="3083">does</TOKEN>
				<TOKEN id="token-23-2" start_char="3085" end_char="3087">not</TOKEN>
				<TOKEN id="token-23-3" start_char="3089" end_char="3092">take</TOKEN>
				<TOKEN id="token-23-4" start_char="3094" end_char="3094">a</TOKEN>
				<TOKEN id="token-23-5" start_char="3096" end_char="3101">genius</TOKEN>
				<TOKEN id="token-23-6" start_char="3103" end_char="3104">to</TOKEN>
				<TOKEN id="token-23-7" start_char="3106" end_char="3115">understand</TOKEN>
				<TOKEN id="token-23-8" start_char="3117" end_char="3120">that</TOKEN>
				<TOKEN id="token-23-9" start_char="3122" end_char="3125">this</TOKEN>
				<TOKEN id="token-23-10" start_char="3127" end_char="3128">is</TOKEN>
				<TOKEN id="token-23-11" start_char="3130" end_char="3131">an</TOKEN>
				<TOKEN id="token-23-12" start_char="3133" end_char="3138">unwise</TOKEN>
				<TOKEN id="token-23-13" start_char="3140" end_char="3147">decision</TOKEN>
				<TOKEN id="token-23-14" start_char="3148" end_char="3149">,&quot;</TOKEN>
				<TOKEN id="token-23-15" start_char="3151" end_char="3152">he</TOKEN>
				<TOKEN id="token-23-16" start_char="3154" end_char="3157">said</TOKEN>
				<TOKEN id="token-23-17" start_char="3158" end_char="3158">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-24" start_char="3160" end_char="3249">
				<ORIGINAL_TEXT>&quot;I am extremely unhappy to see that the Canadian government shared that genetic material.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-24-0" start_char="3160" end_char="3160">&quot;</TOKEN>
				<TOKEN id="token-24-1" start_char="3161" end_char="3161">I</TOKEN>
				<TOKEN id="token-24-2" start_char="3163" end_char="3164">am</TOKEN>
				<TOKEN id="token-24-3" start_char="3166" end_char="3174">extremely</TOKEN>
				<TOKEN id="token-24-4" start_char="3176" end_char="3182">unhappy</TOKEN>
				<TOKEN id="token-24-5" start_char="3184" end_char="3185">to</TOKEN>
				<TOKEN id="token-24-6" start_char="3187" end_char="3189">see</TOKEN>
				<TOKEN id="token-24-7" start_char="3191" end_char="3194">that</TOKEN>
				<TOKEN id="token-24-8" start_char="3196" end_char="3198">the</TOKEN>
				<TOKEN id="token-24-9" start_char="3200" end_char="3207">Canadian</TOKEN>
				<TOKEN id="token-24-10" start_char="3209" end_char="3218">government</TOKEN>
				<TOKEN id="token-24-11" start_char="3220" end_char="3225">shared</TOKEN>
				<TOKEN id="token-24-12" start_char="3227" end_char="3230">that</TOKEN>
				<TOKEN id="token-24-13" start_char="3232" end_char="3238">genetic</TOKEN>
				<TOKEN id="token-24-14" start_char="3240" end_char="3247">material</TOKEN>
				<TOKEN id="token-24-15" start_char="3248" end_char="3249">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-25" start_char="3251" end_char="3345">
				<ORIGINAL_TEXT>Dr. Xiangguo Qiu, right, accepts an award at the Governor General's Innovation Awards from Gov.</ORIGINAL_TEXT>
				<TOKEN id="token-25-0" start_char="3251" end_char="3252">Dr</TOKEN>
				<TOKEN id="token-25-1" start_char="3253" end_char="3253">.</TOKEN>
				<TOKEN id="token-25-2" start_char="3255" end_char="3262">Xiangguo</TOKEN>
				<TOKEN id="token-25-3" start_char="3264" end_char="3266">Qiu</TOKEN>
				<TOKEN id="token-25-4" start_char="3267" end_char="3267">,</TOKEN>
				<TOKEN id="token-25-5" start_char="3269" end_char="3273">right</TOKEN>
				<TOKEN id="token-25-6" start_char="3274" end_char="3274">,</TOKEN>
				<TOKEN id="token-25-7" start_char="3276" end_char="3282">accepts</TOKEN>
				<TOKEN id="token-25-8" start_char="3284" end_char="3285">an</TOKEN>
				<TOKEN id="token-25-9" start_char="3287" end_char="3291">award</TOKEN>
				<TOKEN id="token-25-10" start_char="3293" end_char="3294">at</TOKEN>
				<TOKEN id="token-25-11" start_char="3296" end_char="3298">the</TOKEN>
				<TOKEN id="token-25-12" start_char="3300" end_char="3307">Governor</TOKEN>
				<TOKEN id="token-25-13" start_char="3309" end_char="3315">General</TOKEN>
				<TOKEN id="token-25-14" start_char="3316" end_char="3316">'</TOKEN>
				<TOKEN id="token-25-15" start_char="3317" end_char="3317">s</TOKEN>
				<TOKEN id="token-25-16" start_char="3319" end_char="3328">Innovation</TOKEN>
				<TOKEN id="token-25-17" start_char="3330" end_char="3335">Awards</TOKEN>
				<TOKEN id="token-25-18" start_char="3337" end_char="3340">from</TOKEN>
				<TOKEN id="token-25-19" start_char="3342" end_char="3344">Gov</TOKEN>
				<TOKEN id="token-25-20" start_char="3345" end_char="3345">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-26" start_char="3347" end_char="3402">
				<ORIGINAL_TEXT>Gen. Julie Payette at a ceremony at Rideau Hall in 2018.</ORIGINAL_TEXT>
				<TOKEN id="token-26-0" start_char="3347" end_char="3349">Gen</TOKEN>
				<TOKEN id="token-26-1" start_char="3350" end_char="3350">.</TOKEN>
				<TOKEN id="token-26-2" start_char="3352" end_char="3356">Julie</TOKEN>
				<TOKEN id="token-26-3" start_char="3358" end_char="3364">Payette</TOKEN>
				<TOKEN id="token-26-4" start_char="3366" end_char="3367">at</TOKEN>
				<TOKEN id="token-26-5" start_char="3369" end_char="3369">a</TOKEN>
				<TOKEN id="token-26-6" start_char="3371" end_char="3378">ceremony</TOKEN>
				<TOKEN id="token-26-7" start_char="3380" end_char="3381">at</TOKEN>
				<TOKEN id="token-26-8" start_char="3383" end_char="3388">Rideau</TOKEN>
				<TOKEN id="token-26-9" start_char="3390" end_char="3393">Hall</TOKEN>
				<TOKEN id="token-26-10" start_char="3395" end_char="3396">in</TOKEN>
				<TOKEN id="token-26-11" start_char="3398" end_char="3401">2018</TOKEN>
				<TOKEN id="token-26-12" start_char="3402" end_char="3402">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-27" start_char="3404" end_char="3568">
				<ORIGINAL_TEXT>Qiu is a prominent virologist who helped develop ZMapp, a treatment for the deadly Ebola virus which killed more than 11,000 people in West Africa between 2014-2016.</ORIGINAL_TEXT>
				<TOKEN id="token-27-0" start_char="3404" end_char="3406">Qiu</TOKEN>
				<TOKEN id="token-27-1" start_char="3408" end_char="3409">is</TOKEN>
				<TOKEN id="token-27-2" start_char="3411" end_char="3411">a</TOKEN>
				<TOKEN id="token-27-3" start_char="3413" end_char="3421">prominent</TOKEN>
				<TOKEN id="token-27-4" start_char="3423" end_char="3432">virologist</TOKEN>
				<TOKEN id="token-27-5" start_char="3434" end_char="3436">who</TOKEN>
				<TOKEN id="token-27-6" start_char="3438" end_char="3443">helped</TOKEN>
				<TOKEN id="token-27-7" start_char="3445" end_char="3451">develop</TOKEN>
				<TOKEN id="token-27-8" start_char="3453" end_char="3457">ZMapp</TOKEN>
				<TOKEN id="token-27-9" start_char="3458" end_char="3458">,</TOKEN>
				<TOKEN id="token-27-10" start_char="3460" end_char="3460">a</TOKEN>
				<TOKEN id="token-27-11" start_char="3462" end_char="3470">treatment</TOKEN>
				<TOKEN id="token-27-12" start_char="3472" end_char="3474">for</TOKEN>
				<TOKEN id="token-27-13" start_char="3476" end_char="3478">the</TOKEN>
				<TOKEN id="token-27-14" start_char="3480" end_char="3485">deadly</TOKEN>
				<TOKEN id="token-27-15" start_char="3487" end_char="3491">Ebola</TOKEN>
				<TOKEN id="token-27-16" start_char="3493" end_char="3497">virus</TOKEN>
				<TOKEN id="token-27-17" start_char="3499" end_char="3503">which</TOKEN>
				<TOKEN id="token-27-18" start_char="3505" end_char="3510">killed</TOKEN>
				<TOKEN id="token-27-19" start_char="3512" end_char="3515">more</TOKEN>
				<TOKEN id="token-27-20" start_char="3517" end_char="3520">than</TOKEN>
				<TOKEN id="token-27-21" start_char="3522" end_char="3523">11</TOKEN>
				<TOKEN id="token-27-22" start_char="3524" end_char="3524">,</TOKEN>
				<TOKEN id="token-27-23" start_char="3525" end_char="3527">000</TOKEN>
				<TOKEN id="token-27-24" start_char="3529" end_char="3534">people</TOKEN>
				<TOKEN id="token-27-25" start_char="3536" end_char="3537">in</TOKEN>
				<TOKEN id="token-27-26" start_char="3539" end_char="3542">West</TOKEN>
				<TOKEN id="token-27-27" start_char="3544" end_char="3549">Africa</TOKEN>
				<TOKEN id="token-27-28" start_char="3551" end_char="3557">between</TOKEN>
				<TOKEN id="token-27-29" start_char="3559" end_char="3562">2014</TOKEN>
				<TOKEN id="token-27-30" start_char="3563" end_char="3563">-</TOKEN>
				<TOKEN id="token-27-31" start_char="3564" end_char="3567">2016</TOKEN>
				<TOKEN id="token-27-32" start_char="3568" end_char="3568">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-28" start_char="3570" end_char="3574">
				<ORIGINAL_TEXT>(CBC)</ORIGINAL_TEXT>
				<TOKEN id="token-28-0" start_char="3570" end_char="3570">(</TOKEN>
				<TOKEN id="token-28-1" start_char="3571" end_char="3573">CBC</TOKEN>
				<TOKEN id="token-28-2" start_char="3574" end_char="3574">)</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-29" start_char="3576" end_char="3718">
				<ORIGINAL_TEXT>Attaran pointed to an Ebola study first published in December 2018, three months after Qiu began the process of exporting the viruses to China.</ORIGINAL_TEXT>
				<TOKEN id="token-29-0" start_char="3576" end_char="3582">Attaran</TOKEN>
				<TOKEN id="token-29-1" start_char="3584" end_char="3590">pointed</TOKEN>
				<TOKEN id="token-29-2" start_char="3592" end_char="3593">to</TOKEN>
				<TOKEN id="token-29-3" start_char="3595" end_char="3596">an</TOKEN>
				<TOKEN id="token-29-4" start_char="3598" end_char="3602">Ebola</TOKEN>
				<TOKEN id="token-29-5" start_char="3604" end_char="3608">study</TOKEN>
				<TOKEN id="token-29-6" start_char="3610" end_char="3614">first</TOKEN>
				<TOKEN id="token-29-7" start_char="3616" end_char="3624">published</TOKEN>
				<TOKEN id="token-29-8" start_char="3626" end_char="3627">in</TOKEN>
				<TOKEN id="token-29-9" start_char="3629" end_char="3636">December</TOKEN>
				<TOKEN id="token-29-10" start_char="3638" end_char="3641">2018</TOKEN>
				<TOKEN id="token-29-11" start_char="3642" end_char="3642">,</TOKEN>
				<TOKEN id="token-29-12" start_char="3644" end_char="3648">three</TOKEN>
				<TOKEN id="token-29-13" start_char="3650" end_char="3655">months</TOKEN>
				<TOKEN id="token-29-14" start_char="3657" end_char="3661">after</TOKEN>
				<TOKEN id="token-29-15" start_char="3663" end_char="3665">Qiu</TOKEN>
				<TOKEN id="token-29-16" start_char="3667" end_char="3671">began</TOKEN>
				<TOKEN id="token-29-17" start_char="3673" end_char="3675">the</TOKEN>
				<TOKEN id="token-29-18" start_char="3677" end_char="3683">process</TOKEN>
				<TOKEN id="token-29-19" start_char="3685" end_char="3686">of</TOKEN>
				<TOKEN id="token-29-20" start_char="3688" end_char="3696">exporting</TOKEN>
				<TOKEN id="token-29-21" start_char="3698" end_char="3700">the</TOKEN>
				<TOKEN id="token-29-22" start_char="3702" end_char="3708">viruses</TOKEN>
				<TOKEN id="token-29-23" start_char="3710" end_char="3711">to</TOKEN>
				<TOKEN id="token-29-24" start_char="3713" end_char="3717">China</TOKEN>
				<TOKEN id="token-29-25" start_char="3718" end_char="3718">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-30" start_char="3720" end_char="3790">
				<ORIGINAL_TEXT>The study involved researchers from the NML and University of Manitoba.</ORIGINAL_TEXT>
				<TOKEN id="token-30-0" start_char="3720" end_char="3722">The</TOKEN>
				<TOKEN id="token-30-1" start_char="3724" end_char="3728">study</TOKEN>
				<TOKEN id="token-30-2" start_char="3730" end_char="3737">involved</TOKEN>
				<TOKEN id="token-30-3" start_char="3739" end_char="3749">researchers</TOKEN>
				<TOKEN id="token-30-4" start_char="3751" end_char="3754">from</TOKEN>
				<TOKEN id="token-30-5" start_char="3756" end_char="3758">the</TOKEN>
				<TOKEN id="token-30-6" start_char="3760" end_char="3762">NML</TOKEN>
				<TOKEN id="token-30-7" start_char="3764" end_char="3766">and</TOKEN>
				<TOKEN id="token-30-8" start_char="3768" end_char="3777">University</TOKEN>
				<TOKEN id="token-30-9" start_char="3779" end_char="3780">of</TOKEN>
				<TOKEN id="token-30-10" start_char="3782" end_char="3789">Manitoba</TOKEN>
				<TOKEN id="token-30-11" start_char="3790" end_char="3790">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-31" start_char="3792" end_char="3938">
				<ORIGINAL_TEXT>The lead author, Hualei Wang, is involved with the Academy of Military Medical Sciences , a Chinese military medical research institute in Beijing.</ORIGINAL_TEXT>
				<TOKEN id="token-31-0" start_char="3792" end_char="3794">The</TOKEN>
				<TOKEN id="token-31-1" start_char="3796" end_char="3799">lead</TOKEN>
				<TOKEN id="token-31-2" start_char="3801" end_char="3806">author</TOKEN>
				<TOKEN id="token-31-3" start_char="3807" end_char="3807">,</TOKEN>
				<TOKEN id="token-31-4" start_char="3809" end_char="3814">Hualei</TOKEN>
				<TOKEN id="token-31-5" start_char="3816" end_char="3819">Wang</TOKEN>
				<TOKEN id="token-31-6" start_char="3820" end_char="3820">,</TOKEN>
				<TOKEN id="token-31-7" start_char="3822" end_char="3823">is</TOKEN>
				<TOKEN id="token-31-8" start_char="3825" end_char="3832">involved</TOKEN>
				<TOKEN id="token-31-9" start_char="3834" end_char="3837">with</TOKEN>
				<TOKEN id="token-31-10" start_char="3839" end_char="3841">the</TOKEN>
				<TOKEN id="token-31-11" start_char="3843" end_char="3849">Academy</TOKEN>
				<TOKEN id="token-31-12" start_char="3851" end_char="3852">of</TOKEN>
				<TOKEN id="token-31-13" start_char="3854" end_char="3861">Military</TOKEN>
				<TOKEN id="token-31-14" start_char="3863" end_char="3869">Medical</TOKEN>
				<TOKEN id="token-31-15" start_char="3871" end_char="3878">Sciences</TOKEN>
				<TOKEN id="token-31-16" start_char="3880" end_char="3880">,</TOKEN>
				<TOKEN id="token-31-17" start_char="3882" end_char="3882">a</TOKEN>
				<TOKEN id="token-31-18" start_char="3884" end_char="3890">Chinese</TOKEN>
				<TOKEN id="token-31-19" start_char="3892" end_char="3899">military</TOKEN>
				<TOKEN id="token-31-20" start_char="3901" end_char="3907">medical</TOKEN>
				<TOKEN id="token-31-21" start_char="3909" end_char="3916">research</TOKEN>
				<TOKEN id="token-31-22" start_char="3918" end_char="3926">institute</TOKEN>
				<TOKEN id="token-31-23" start_char="3928" end_char="3929">in</TOKEN>
				<TOKEN id="token-31-24" start_char="3931" end_char="3937">Beijing</TOKEN>
				<TOKEN id="token-31-25" start_char="3938" end_char="3938">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-32" start_char="3940" end_char="4086">
				<ORIGINAL_TEXT>All of this has led to conspiracy theories linking the novel coronavirus responsible for COVID-19, Canada's microbiology lab, and the lab in Wuhan.</ORIGINAL_TEXT>
				<TOKEN id="token-32-0" start_char="3940" end_char="3942">All</TOKEN>
				<TOKEN id="token-32-1" start_char="3944" end_char="3945">of</TOKEN>
				<TOKEN id="token-32-2" start_char="3947" end_char="3950">this</TOKEN>
				<TOKEN id="token-32-3" start_char="3952" end_char="3954">has</TOKEN>
				<TOKEN id="token-32-4" start_char="3956" end_char="3958">led</TOKEN>
				<TOKEN id="token-32-5" start_char="3960" end_char="3961">to</TOKEN>
				<TOKEN id="token-32-6" start_char="3963" end_char="3972">conspiracy</TOKEN>
				<TOKEN id="token-32-7" start_char="3974" end_char="3981">theories</TOKEN>
				<TOKEN id="token-32-8" start_char="3983" end_char="3989">linking</TOKEN>
				<TOKEN id="token-32-9" start_char="3991" end_char="3993">the</TOKEN>
				<TOKEN id="token-32-10" start_char="3995" end_char="3999">novel</TOKEN>
				<TOKEN id="token-32-11" start_char="4001" end_char="4011">coronavirus</TOKEN>
				<TOKEN id="token-32-12" start_char="4013" end_char="4023">responsible</TOKEN>
				<TOKEN id="token-32-13" start_char="4025" end_char="4027">for</TOKEN>
				<TOKEN id="token-32-14" start_char="4029" end_char="4033">COVID</TOKEN>
				<TOKEN id="token-32-15" start_char="4034" end_char="4034">-</TOKEN>
				<TOKEN id="token-32-16" start_char="4035" end_char="4036">19</TOKEN>
				<TOKEN id="token-32-17" start_char="4037" end_char="4037">,</TOKEN>
				<TOKEN id="token-32-18" start_char="4039" end_char="4044">Canada</TOKEN>
				<TOKEN id="token-32-19" start_char="4045" end_char="4045">'</TOKEN>
				<TOKEN id="token-32-20" start_char="4046" end_char="4046">s</TOKEN>
				<TOKEN id="token-32-21" start_char="4048" end_char="4059">microbiology</TOKEN>
				<TOKEN id="token-32-22" start_char="4061" end_char="4063">lab</TOKEN>
				<TOKEN id="token-32-23" start_char="4064" end_char="4064">,</TOKEN>
				<TOKEN id="token-32-24" start_char="4066" end_char="4068">and</TOKEN>
				<TOKEN id="token-32-25" start_char="4070" end_char="4072">the</TOKEN>
				<TOKEN id="token-32-26" start_char="4074" end_char="4076">lab</TOKEN>
				<TOKEN id="token-32-27" start_char="4078" end_char="4079">in</TOKEN>
				<TOKEN id="token-32-28" start_char="4081" end_char="4085">Wuhan</TOKEN>
				<TOKEN id="token-32-29" start_char="4086" end_char="4086">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-33" start_char="4088" end_char="4191">
				<ORIGINAL_TEXT>The RCMP and PHAC have consistently denied any connections between the pandemic and the virus shipments.</ORIGINAL_TEXT>
				<TOKEN id="token-33-0" start_char="4088" end_char="4090">The</TOKEN>
				<TOKEN id="token-33-1" start_char="4092" end_char="4095">RCMP</TOKEN>
				<TOKEN id="token-33-2" start_char="4097" end_char="4099">and</TOKEN>
				<TOKEN id="token-33-3" start_char="4101" end_char="4104">PHAC</TOKEN>
				<TOKEN id="token-33-4" start_char="4106" end_char="4109">have</TOKEN>
				<TOKEN id="token-33-5" start_char="4111" end_char="4122">consistently</TOKEN>
				<TOKEN id="token-33-6" start_char="4124" end_char="4129">denied</TOKEN>
				<TOKEN id="token-33-7" start_char="4131" end_char="4133">any</TOKEN>
				<TOKEN id="token-33-8" start_char="4135" end_char="4145">connections</TOKEN>
				<TOKEN id="token-33-9" start_char="4147" end_char="4153">between</TOKEN>
				<TOKEN id="token-33-10" start_char="4155" end_char="4157">the</TOKEN>
				<TOKEN id="token-33-11" start_char="4159" end_char="4166">pandemic</TOKEN>
				<TOKEN id="token-33-12" start_char="4168" end_char="4170">and</TOKEN>
				<TOKEN id="token-33-13" start_char="4172" end_char="4174">the</TOKEN>
				<TOKEN id="token-33-14" start_char="4176" end_char="4180">virus</TOKEN>
				<TOKEN id="token-33-15" start_char="4182" end_char="4190">shipments</TOKEN>
				<TOKEN id="token-33-16" start_char="4191" end_char="4191">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-34" start_char="4193" end_char="4268">
				<ORIGINAL_TEXT>There is no evidence linking this shipment to the spread of the coronavirus.</ORIGINAL_TEXT>
				<TOKEN id="token-34-0" start_char="4193" end_char="4197">There</TOKEN>
				<TOKEN id="token-34-1" start_char="4199" end_char="4200">is</TOKEN>
				<TOKEN id="token-34-2" start_char="4202" end_char="4203">no</TOKEN>
				<TOKEN id="token-34-3" start_char="4205" end_char="4212">evidence</TOKEN>
				<TOKEN id="token-34-4" start_char="4214" end_char="4220">linking</TOKEN>
				<TOKEN id="token-34-5" start_char="4222" end_char="4225">this</TOKEN>
				<TOKEN id="token-34-6" start_char="4227" end_char="4234">shipment</TOKEN>
				<TOKEN id="token-34-7" start_char="4236" end_char="4237">to</TOKEN>
				<TOKEN id="token-34-8" start_char="4239" end_char="4241">the</TOKEN>
				<TOKEN id="token-34-9" start_char="4243" end_char="4248">spread</TOKEN>
				<TOKEN id="token-34-10" start_char="4250" end_char="4251">of</TOKEN>
				<TOKEN id="token-34-11" start_char="4253" end_char="4255">the</TOKEN>
				<TOKEN id="token-34-12" start_char="4257" end_char="4267">coronavirus</TOKEN>
				<TOKEN id="token-34-13" start_char="4268" end_char="4268">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-35" start_char="4270" end_char="4354">
				<ORIGINAL_TEXT>Ebola is a filovirus and Henipa is a paramyxovirus; no coronavirus samples were sent.</ORIGINAL_TEXT>
				<TOKEN id="token-35-0" start_char="4270" end_char="4274">Ebola</TOKEN>
				<TOKEN id="token-35-1" start_char="4276" end_char="4277">is</TOKEN>
				<TOKEN id="token-35-2" start_char="4279" end_char="4279">a</TOKEN>
				<TOKEN id="token-35-3" start_char="4281" end_char="4289">filovirus</TOKEN>
				<TOKEN id="token-35-4" start_char="4291" end_char="4293">and</TOKEN>
				<TOKEN id="token-35-5" start_char="4295" end_char="4300">Henipa</TOKEN>
				<TOKEN id="token-35-6" start_char="4302" end_char="4303">is</TOKEN>
				<TOKEN id="token-35-7" start_char="4305" end_char="4305">a</TOKEN>
				<TOKEN id="token-35-8" start_char="4307" end_char="4319">paramyxovirus</TOKEN>
				<TOKEN id="token-35-9" start_char="4320" end_char="4320">;</TOKEN>
				<TOKEN id="token-35-10" start_char="4322" end_char="4323">no</TOKEN>
				<TOKEN id="token-35-11" start_char="4325" end_char="4335">coronavirus</TOKEN>
				<TOKEN id="token-35-12" start_char="4337" end_char="4343">samples</TOKEN>
				<TOKEN id="token-35-13" start_char="4345" end_char="4348">were</TOKEN>
				<TOKEN id="token-35-14" start_char="4350" end_char="4353">sent</TOKEN>
				<TOKEN id="token-35-15" start_char="4354" end_char="4354">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-36" start_char="4356" end_char="4577">
				<ORIGINAL_TEXT>Amir Attaran, professor in the Faculty of Law and the School of Epidemiology and Public Health at the University of Ottawa, is concerned about the shipment of dangerous viruses sent from Canada's only level-4 lab to China.</ORIGINAL_TEXT>
				<TOKEN id="token-36-0" start_char="4356" end_char="4359">Amir</TOKEN>
				<TOKEN id="token-36-1" start_char="4361" end_char="4367">Attaran</TOKEN>
				<TOKEN id="token-36-2" start_char="4368" end_char="4368">,</TOKEN>
				<TOKEN id="token-36-3" start_char="4370" end_char="4378">professor</TOKEN>
				<TOKEN id="token-36-4" start_char="4380" end_char="4381">in</TOKEN>
				<TOKEN id="token-36-5" start_char="4383" end_char="4385">the</TOKEN>
				<TOKEN id="token-36-6" start_char="4387" end_char="4393">Faculty</TOKEN>
				<TOKEN id="token-36-7" start_char="4395" end_char="4396">of</TOKEN>
				<TOKEN id="token-36-8" start_char="4398" end_char="4400">Law</TOKEN>
				<TOKEN id="token-36-9" start_char="4402" end_char="4404">and</TOKEN>
				<TOKEN id="token-36-10" start_char="4406" end_char="4408">the</TOKEN>
				<TOKEN id="token-36-11" start_char="4410" end_char="4415">School</TOKEN>
				<TOKEN id="token-36-12" start_char="4417" end_char="4418">of</TOKEN>
				<TOKEN id="token-36-13" start_char="4420" end_char="4431">Epidemiology</TOKEN>
				<TOKEN id="token-36-14" start_char="4433" end_char="4435">and</TOKEN>
				<TOKEN id="token-36-15" start_char="4437" end_char="4442">Public</TOKEN>
				<TOKEN id="token-36-16" start_char="4444" end_char="4449">Health</TOKEN>
				<TOKEN id="token-36-17" start_char="4451" end_char="4452">at</TOKEN>
				<TOKEN id="token-36-18" start_char="4454" end_char="4456">the</TOKEN>
				<TOKEN id="token-36-19" start_char="4458" end_char="4467">University</TOKEN>
				<TOKEN id="token-36-20" start_char="4469" end_char="4470">of</TOKEN>
				<TOKEN id="token-36-21" start_char="4472" end_char="4477">Ottawa</TOKEN>
				<TOKEN id="token-36-22" start_char="4478" end_char="4478">,</TOKEN>
				<TOKEN id="token-36-23" start_char="4480" end_char="4481">is</TOKEN>
				<TOKEN id="token-36-24" start_char="4483" end_char="4491">concerned</TOKEN>
				<TOKEN id="token-36-25" start_char="4493" end_char="4497">about</TOKEN>
				<TOKEN id="token-36-26" start_char="4499" end_char="4501">the</TOKEN>
				<TOKEN id="token-36-27" start_char="4503" end_char="4510">shipment</TOKEN>
				<TOKEN id="token-36-28" start_char="4512" end_char="4513">of</TOKEN>
				<TOKEN id="token-36-29" start_char="4515" end_char="4523">dangerous</TOKEN>
				<TOKEN id="token-36-30" start_char="4525" end_char="4531">viruses</TOKEN>
				<TOKEN id="token-36-31" start_char="4533" end_char="4536">sent</TOKEN>
				<TOKEN id="token-36-32" start_char="4538" end_char="4541">from</TOKEN>
				<TOKEN id="token-36-33" start_char="4543" end_char="4548">Canada</TOKEN>
				<TOKEN id="token-36-34" start_char="4549" end_char="4549">'</TOKEN>
				<TOKEN id="token-36-35" start_char="4550" end_char="4550">s</TOKEN>
				<TOKEN id="token-36-36" start_char="4552" end_char="4555">only</TOKEN>
				<TOKEN id="token-36-37" start_char="4557" end_char="4561">level</TOKEN>
				<TOKEN id="token-36-38" start_char="4562" end_char="4562">-</TOKEN>
				<TOKEN id="token-36-39" start_char="4563" end_char="4563">4</TOKEN>
				<TOKEN id="token-36-40" start_char="4565" end_char="4567">lab</TOKEN>
				<TOKEN id="token-36-41" start_char="4569" end_char="4570">to</TOKEN>
				<TOKEN id="token-36-42" start_char="4572" end_char="4576">China</TOKEN>
				<TOKEN id="token-36-43" start_char="4577" end_char="4577">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-37" start_char="4579" end_char="4583">
				<ORIGINAL_TEXT>(CBC)</ORIGINAL_TEXT>
				<TOKEN id="token-37-0" start_char="4579" end_char="4579">(</TOKEN>
				<TOKEN id="token-37-1" start_char="4580" end_char="4582">CBC</TOKEN>
				<TOKEN id="token-37-2" start_char="4583" end_char="4583">)</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-38" start_char="4585" end_char="4665">
				<ORIGINAL_TEXT>The ATIP documents identify for the first time exactly what was shipped to China.</ORIGINAL_TEXT>
				<TOKEN id="token-38-0" start_char="4585" end_char="4587">The</TOKEN>
				<TOKEN id="token-38-1" start_char="4589" end_char="4592">ATIP</TOKEN>
				<TOKEN id="token-38-2" start_char="4594" end_char="4602">documents</TOKEN>
				<TOKEN id="token-38-3" start_char="4604" end_char="4611">identify</TOKEN>
				<TOKEN id="token-38-4" start_char="4613" end_char="4615">for</TOKEN>
				<TOKEN id="token-38-5" start_char="4617" end_char="4619">the</TOKEN>
				<TOKEN id="token-38-6" start_char="4621" end_char="4625">first</TOKEN>
				<TOKEN id="token-38-7" start_char="4627" end_char="4630">time</TOKEN>
				<TOKEN id="token-38-8" start_char="4632" end_char="4638">exactly</TOKEN>
				<TOKEN id="token-38-9" start_char="4640" end_char="4643">what</TOKEN>
				<TOKEN id="token-38-10" start_char="4645" end_char="4647">was</TOKEN>
				<TOKEN id="token-38-11" start_char="4649" end_char="4655">shipped</TOKEN>
				<TOKEN id="token-38-12" start_char="4657" end_char="4658">to</TOKEN>
				<TOKEN id="token-38-13" start_char="4660" end_char="4664">China</TOKEN>
				<TOKEN id="token-38-14" start_char="4665" end_char="4665">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-39" start_char="4667" end_char="4722">
				<ORIGINAL_TEXT>The list includes two vials each of 15 strains of virus:</ORIGINAL_TEXT>
				<TOKEN id="token-39-0" start_char="4667" end_char="4669">The</TOKEN>
				<TOKEN id="token-39-1" start_char="4671" end_char="4674">list</TOKEN>
				<TOKEN id="token-39-2" start_char="4676" end_char="4683">includes</TOKEN>
				<TOKEN id="token-39-3" start_char="4685" end_char="4687">two</TOKEN>
				<TOKEN id="token-39-4" start_char="4689" end_char="4693">vials</TOKEN>
				<TOKEN id="token-39-5" start_char="4695" end_char="4698">each</TOKEN>
				<TOKEN id="token-39-6" start_char="4700" end_char="4701">of</TOKEN>
				<TOKEN id="token-39-7" start_char="4703" end_char="4704">15</TOKEN>
				<TOKEN id="token-39-8" start_char="4706" end_char="4712">strains</TOKEN>
				<TOKEN id="token-39-9" start_char="4714" end_char="4715">of</TOKEN>
				<TOKEN id="token-39-10" start_char="4717" end_char="4721">virus</TOKEN>
				<TOKEN id="token-39-11" start_char="4722" end_char="4722">:</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-40" start_char="4724" end_char="4763">
				<ORIGINAL_TEXT>Ebola Makona (three different varieties)</ORIGINAL_TEXT>
				<TOKEN id="token-40-0" start_char="4724" end_char="4728">Ebola</TOKEN>
				<TOKEN id="token-40-1" start_char="4730" end_char="4735">Makona</TOKEN>
				<TOKEN id="token-40-2" start_char="4737" end_char="4737">(</TOKEN>
				<TOKEN id="token-40-3" start_char="4738" end_char="4742">three</TOKEN>
				<TOKEN id="token-40-4" start_char="4744" end_char="4752">different</TOKEN>
				<TOKEN id="token-40-5" start_char="4754" end_char="4762">varieties</TOKEN>
				<TOKEN id="token-40-6" start_char="4763" end_char="4763">)</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-41" start_char="4765" end_char="4772">
				<ORIGINAL_TEXT>Mayinga.</ORIGINAL_TEXT>
				<TOKEN id="token-41-0" start_char="4765" end_char="4771">Mayinga</TOKEN>
				<TOKEN id="token-41-1" start_char="4772" end_char="4772">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-42" start_char="4774" end_char="4780">
				<ORIGINAL_TEXT>Kikwit.</ORIGINAL_TEXT>
				<TOKEN id="token-42-0" start_char="4774" end_char="4779">Kikwit</TOKEN>
				<TOKEN id="token-42-1" start_char="4780" end_char="4780">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-43" start_char="4782" end_char="4793">
				<ORIGINAL_TEXT>Ivory Coast.</ORIGINAL_TEXT>
				<TOKEN id="token-43-0" start_char="4782" end_char="4786">Ivory</TOKEN>
				<TOKEN id="token-43-1" start_char="4788" end_char="4792">Coast</TOKEN>
				<TOKEN id="token-43-2" start_char="4793" end_char="4793">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-44" start_char="4795" end_char="4805">
				<ORIGINAL_TEXT>Bundibugyo.</ORIGINAL_TEXT>
				<TOKEN id="token-44-0" start_char="4795" end_char="4804">Bundibugyo</TOKEN>
				<TOKEN id="token-44-1" start_char="4805" end_char="4805">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-45" start_char="4807" end_char="4821">
				<ORIGINAL_TEXT>Sudan Boniface.</ORIGINAL_TEXT>
				<TOKEN id="token-45-0" start_char="4807" end_char="4811">Sudan</TOKEN>
				<TOKEN id="token-45-1" start_char="4813" end_char="4820">Boniface</TOKEN>
				<TOKEN id="token-45-2" start_char="4821" end_char="4821">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-46" start_char="4823" end_char="4833">
				<ORIGINAL_TEXT>Sudan Gulu.</ORIGINAL_TEXT>
				<TOKEN id="token-46-0" start_char="4823" end_char="4827">Sudan</TOKEN>
				<TOKEN id="token-46-1" start_char="4829" end_char="4832">Gulu</TOKEN>
				<TOKEN id="token-46-2" start_char="4833" end_char="4833">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-47" start_char="4835" end_char="4842">
				<ORIGINAL_TEXT>MA-Ebov.</ORIGINAL_TEXT>
				<TOKEN id="token-47-0" start_char="4835" end_char="4836">MA</TOKEN>
				<TOKEN id="token-47-1" start_char="4837" end_char="4837">-</TOKEN>
				<TOKEN id="token-47-2" start_char="4838" end_char="4841">Ebov</TOKEN>
				<TOKEN id="token-47-3" start_char="4842" end_char="4842">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-48" start_char="4844" end_char="4851">
				<ORIGINAL_TEXT>GP-Ebov.</ORIGINAL_TEXT>
				<TOKEN id="token-48-0" start_char="4844" end_char="4845">GP</TOKEN>
				<TOKEN id="token-48-1" start_char="4846" end_char="4846">-</TOKEN>
				<TOKEN id="token-48-2" start_char="4847" end_char="4850">Ebov</TOKEN>
				<TOKEN id="token-48-3" start_char="4851" end_char="4851">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-49" start_char="4853" end_char="4861">
				<ORIGINAL_TEXT>GP-Sudan.</ORIGINAL_TEXT>
				<TOKEN id="token-49-0" start_char="4853" end_char="4854">GP</TOKEN>
				<TOKEN id="token-49-1" start_char="4855" end_char="4855">-</TOKEN>
				<TOKEN id="token-49-2" start_char="4856" end_char="4860">Sudan</TOKEN>
				<TOKEN id="token-49-3" start_char="4861" end_char="4861">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-50" start_char="4863" end_char="4869">
				<ORIGINAL_TEXT>Hendra.</ORIGINAL_TEXT>
				<TOKEN id="token-50-0" start_char="4863" end_char="4868">Hendra</TOKEN>
				<TOKEN id="token-50-1" start_char="4869" end_char="4869">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-51" start_char="4871" end_char="4885">
				<ORIGINAL_TEXT>Nipah Malaysia.</ORIGINAL_TEXT>
				<TOKEN id="token-51-0" start_char="4871" end_char="4875">Nipah</TOKEN>
				<TOKEN id="token-51-1" start_char="4877" end_char="4884">Malaysia</TOKEN>
				<TOKEN id="token-51-2" start_char="4885" end_char="4885">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-52" start_char="4887" end_char="4903">
				<ORIGINAL_TEXT>Nipah Bangladesh.</ORIGINAL_TEXT>
				<TOKEN id="token-52-0" start_char="4887" end_char="4891">Nipah</TOKEN>
				<TOKEN id="token-52-1" start_char="4893" end_char="4902">Bangladesh</TOKEN>
				<TOKEN id="token-52-2" start_char="4903" end_char="4903">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-53" start_char="4905" end_char="4999">
				<ORIGINAL_TEXT>PHAC said the National Microbiology Lab routinely shares samples with other public health labs.</ORIGINAL_TEXT>
				<TOKEN id="token-53-0" start_char="4905" end_char="4908">PHAC</TOKEN>
				<TOKEN id="token-53-1" start_char="4910" end_char="4913">said</TOKEN>
				<TOKEN id="token-53-2" start_char="4915" end_char="4917">the</TOKEN>
				<TOKEN id="token-53-3" start_char="4919" end_char="4926">National</TOKEN>
				<TOKEN id="token-53-4" start_char="4928" end_char="4939">Microbiology</TOKEN>
				<TOKEN id="token-53-5" start_char="4941" end_char="4943">Lab</TOKEN>
				<TOKEN id="token-53-6" start_char="4945" end_char="4953">routinely</TOKEN>
				<TOKEN id="token-53-7" start_char="4955" end_char="4960">shares</TOKEN>
				<TOKEN id="token-53-8" start_char="4962" end_char="4968">samples</TOKEN>
				<TOKEN id="token-53-9" start_char="4970" end_char="4973">with</TOKEN>
				<TOKEN id="token-53-10" start_char="4975" end_char="4979">other</TOKEN>
				<TOKEN id="token-53-11" start_char="4981" end_char="4986">public</TOKEN>
				<TOKEN id="token-53-12" start_char="4988" end_char="4993">health</TOKEN>
				<TOKEN id="token-53-13" start_char="4995" end_char="4998">labs</TOKEN>
				<TOKEN id="token-53-14" start_char="4999" end_char="4999">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-54" start_char="5001" end_char="5232">
				<ORIGINAL_TEXT>The transfers follow strict protocols, including requirements under the Human Pathogens and Toxins Act (HPTA), the Transportation of Dangerous Goods Act, the Canadian Biosafety Standard, and standard operating procedures of the NML.</ORIGINAL_TEXT>
				<TOKEN id="token-54-0" start_char="5001" end_char="5003">The</TOKEN>
				<TOKEN id="token-54-1" start_char="5005" end_char="5013">transfers</TOKEN>
				<TOKEN id="token-54-2" start_char="5015" end_char="5020">follow</TOKEN>
				<TOKEN id="token-54-3" start_char="5022" end_char="5027">strict</TOKEN>
				<TOKEN id="token-54-4" start_char="5029" end_char="5037">protocols</TOKEN>
				<TOKEN id="token-54-5" start_char="5038" end_char="5038">,</TOKEN>
				<TOKEN id="token-54-6" start_char="5040" end_char="5048">including</TOKEN>
				<TOKEN id="token-54-7" start_char="5050" end_char="5061">requirements</TOKEN>
				<TOKEN id="token-54-8" start_char="5063" end_char="5067">under</TOKEN>
				<TOKEN id="token-54-9" start_char="5069" end_char="5071">the</TOKEN>
				<TOKEN id="token-54-10" start_char="5073" end_char="5077">Human</TOKEN>
				<TOKEN id="token-54-11" start_char="5079" end_char="5087">Pathogens</TOKEN>
				<TOKEN id="token-54-12" start_char="5089" end_char="5091">and</TOKEN>
				<TOKEN id="token-54-13" start_char="5093" end_char="5098">Toxins</TOKEN>
				<TOKEN id="token-54-14" start_char="5100" end_char="5102">Act</TOKEN>
				<TOKEN id="token-54-15" start_char="5104" end_char="5104">(</TOKEN>
				<TOKEN id="token-54-16" start_char="5105" end_char="5108">HPTA</TOKEN>
				<TOKEN id="token-54-17" start_char="5109" end_char="5110">),</TOKEN>
				<TOKEN id="token-54-18" start_char="5112" end_char="5114">the</TOKEN>
				<TOKEN id="token-54-19" start_char="5116" end_char="5129">Transportation</TOKEN>
				<TOKEN id="token-54-20" start_char="5131" end_char="5132">of</TOKEN>
				<TOKEN id="token-54-21" start_char="5134" end_char="5142">Dangerous</TOKEN>
				<TOKEN id="token-54-22" start_char="5144" end_char="5148">Goods</TOKEN>
				<TOKEN id="token-54-23" start_char="5150" end_char="5152">Act</TOKEN>
				<TOKEN id="token-54-24" start_char="5153" end_char="5153">,</TOKEN>
				<TOKEN id="token-54-25" start_char="5155" end_char="5157">the</TOKEN>
				<TOKEN id="token-54-26" start_char="5159" end_char="5166">Canadian</TOKEN>
				<TOKEN id="token-54-27" start_char="5168" end_char="5176">Biosafety</TOKEN>
				<TOKEN id="token-54-28" start_char="5178" end_char="5185">Standard</TOKEN>
				<TOKEN id="token-54-29" start_char="5186" end_char="5186">,</TOKEN>
				<TOKEN id="token-54-30" start_char="5188" end_char="5190">and</TOKEN>
				<TOKEN id="token-54-31" start_char="5192" end_char="5199">standard</TOKEN>
				<TOKEN id="token-54-32" start_char="5201" end_char="5209">operating</TOKEN>
				<TOKEN id="token-54-33" start_char="5211" end_char="5220">procedures</TOKEN>
				<TOKEN id="token-54-34" start_char="5222" end_char="5223">of</TOKEN>
				<TOKEN id="token-54-35" start_char="5225" end_char="5227">the</TOKEN>
				<TOKEN id="token-54-36" start_char="5229" end_char="5231">NML</TOKEN>
				<TOKEN id="token-54-37" start_char="5232" end_char="5232">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-55" start_char="5234" end_char="5466">
				<ORIGINAL_TEXT>CBC News has not been provided with some of the paperwork involved with the transfer, as information was redacted under sections of the Access to Information Act dealing with international affairs, national security and other issues.</ORIGINAL_TEXT>
				<TOKEN id="token-55-0" start_char="5234" end_char="5236">CBC</TOKEN>
				<TOKEN id="token-55-1" start_char="5238" end_char="5241">News</TOKEN>
				<TOKEN id="token-55-2" start_char="5243" end_char="5245">has</TOKEN>
				<TOKEN id="token-55-3" start_char="5247" end_char="5249">not</TOKEN>
				<TOKEN id="token-55-4" start_char="5251" end_char="5254">been</TOKEN>
				<TOKEN id="token-55-5" start_char="5256" end_char="5263">provided</TOKEN>
				<TOKEN id="token-55-6" start_char="5265" end_char="5268">with</TOKEN>
				<TOKEN id="token-55-7" start_char="5270" end_char="5273">some</TOKEN>
				<TOKEN id="token-55-8" start_char="5275" end_char="5276">of</TOKEN>
				<TOKEN id="token-55-9" start_char="5278" end_char="5280">the</TOKEN>
				<TOKEN id="token-55-10" start_char="5282" end_char="5290">paperwork</TOKEN>
				<TOKEN id="token-55-11" start_char="5292" end_char="5299">involved</TOKEN>
				<TOKEN id="token-55-12" start_char="5301" end_char="5304">with</TOKEN>
				<TOKEN id="token-55-13" start_char="5306" end_char="5308">the</TOKEN>
				<TOKEN id="token-55-14" start_char="5310" end_char="5317">transfer</TOKEN>
				<TOKEN id="token-55-15" start_char="5318" end_char="5318">,</TOKEN>
				<TOKEN id="token-55-16" start_char="5320" end_char="5321">as</TOKEN>
				<TOKEN id="token-55-17" start_char="5323" end_char="5333">information</TOKEN>
				<TOKEN id="token-55-18" start_char="5335" end_char="5337">was</TOKEN>
				<TOKEN id="token-55-19" start_char="5339" end_char="5346">redacted</TOKEN>
				<TOKEN id="token-55-20" start_char="5348" end_char="5352">under</TOKEN>
				<TOKEN id="token-55-21" start_char="5354" end_char="5361">sections</TOKEN>
				<TOKEN id="token-55-22" start_char="5363" end_char="5364">of</TOKEN>
				<TOKEN id="token-55-23" start_char="5366" end_char="5368">the</TOKEN>
				<TOKEN id="token-55-24" start_char="5370" end_char="5375">Access</TOKEN>
				<TOKEN id="token-55-25" start_char="5377" end_char="5378">to</TOKEN>
				<TOKEN id="token-55-26" start_char="5380" end_char="5390">Information</TOKEN>
				<TOKEN id="token-55-27" start_char="5392" end_char="5394">Act</TOKEN>
				<TOKEN id="token-55-28" start_char="5396" end_char="5402">dealing</TOKEN>
				<TOKEN id="token-55-29" start_char="5404" end_char="5407">with</TOKEN>
				<TOKEN id="token-55-30" start_char="5409" end_char="5421">international</TOKEN>
				<TOKEN id="token-55-31" start_char="5423" end_char="5429">affairs</TOKEN>
				<TOKEN id="token-55-32" start_char="5430" end_char="5430">,</TOKEN>
				<TOKEN id="token-55-33" start_char="5432" end_char="5439">national</TOKEN>
				<TOKEN id="token-55-34" start_char="5441" end_char="5448">security</TOKEN>
				<TOKEN id="token-55-35" start_char="5450" end_char="5452">and</TOKEN>
				<TOKEN id="token-55-36" start_char="5454" end_char="5458">other</TOKEN>
				<TOKEN id="token-55-37" start_char="5460" end_char="5465">issues</TOKEN>
				<TOKEN id="token-55-38" start_char="5466" end_char="5466">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-56" start_char="5468" end_char="5499">
				<ORIGINAL_TEXT>Confusion, concern over shipment</ORIGINAL_TEXT>
				<TOKEN id="token-56-0" start_char="5468" end_char="5476">Confusion</TOKEN>
				<TOKEN id="token-56-1" start_char="5477" end_char="5477">,</TOKEN>
				<TOKEN id="token-56-2" start_char="5479" end_char="5485">concern</TOKEN>
				<TOKEN id="token-56-3" start_char="5487" end_char="5490">over</TOKEN>
				<TOKEN id="token-56-4" start_char="5492" end_char="5499">shipment</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-57" start_char="5501" end_char="5815">
				<ORIGINAL_TEXT>The ATIP documents provide details about the months leading up to the shipment — including confusion over how to package the deadly viruses — the lack of decontamination of the package before it was sent, and concerns expressed by the NML's director-general Matthew Gilmour in Winnipeg, and his superiors in Ottawa.</ORIGINAL_TEXT>
				<TOKEN id="token-57-0" start_char="5501" end_char="5503">The</TOKEN>
				<TOKEN id="token-57-1" start_char="5505" end_char="5508">ATIP</TOKEN>
				<TOKEN id="token-57-2" start_char="5510" end_char="5518">documents</TOKEN>
				<TOKEN id="token-57-3" start_char="5520" end_char="5526">provide</TOKEN>
				<TOKEN id="token-57-4" start_char="5528" end_char="5534">details</TOKEN>
				<TOKEN id="token-57-5" start_char="5536" end_char="5540">about</TOKEN>
				<TOKEN id="token-57-6" start_char="5542" end_char="5544">the</TOKEN>
				<TOKEN id="token-57-7" start_char="5546" end_char="5551">months</TOKEN>
				<TOKEN id="token-57-8" start_char="5553" end_char="5559">leading</TOKEN>
				<TOKEN id="token-57-9" start_char="5561" end_char="5562">up</TOKEN>
				<TOKEN id="token-57-10" start_char="5564" end_char="5565">to</TOKEN>
				<TOKEN id="token-57-11" start_char="5567" end_char="5569">the</TOKEN>
				<TOKEN id="token-57-12" start_char="5571" end_char="5578">shipment</TOKEN>
				<TOKEN id="token-57-13" start_char="5580" end_char="5580">—</TOKEN>
				<TOKEN id="token-57-14" start_char="5582" end_char="5590">including</TOKEN>
				<TOKEN id="token-57-15" start_char="5592" end_char="5600">confusion</TOKEN>
				<TOKEN id="token-57-16" start_char="5602" end_char="5605">over</TOKEN>
				<TOKEN id="token-57-17" start_char="5607" end_char="5609">how</TOKEN>
				<TOKEN id="token-57-18" start_char="5611" end_char="5612">to</TOKEN>
				<TOKEN id="token-57-19" start_char="5614" end_char="5620">package</TOKEN>
				<TOKEN id="token-57-20" start_char="5622" end_char="5624">the</TOKEN>
				<TOKEN id="token-57-21" start_char="5626" end_char="5631">deadly</TOKEN>
				<TOKEN id="token-57-22" start_char="5633" end_char="5639">viruses</TOKEN>
				<TOKEN id="token-57-23" start_char="5641" end_char="5641">—</TOKEN>
				<TOKEN id="token-57-24" start_char="5643" end_char="5645">the</TOKEN>
				<TOKEN id="token-57-25" start_char="5647" end_char="5650">lack</TOKEN>
				<TOKEN id="token-57-26" start_char="5652" end_char="5653">of</TOKEN>
				<TOKEN id="token-57-27" start_char="5655" end_char="5669">decontamination</TOKEN>
				<TOKEN id="token-57-28" start_char="5671" end_char="5672">of</TOKEN>
				<TOKEN id="token-57-29" start_char="5674" end_char="5676">the</TOKEN>
				<TOKEN id="token-57-30" start_char="5678" end_char="5684">package</TOKEN>
				<TOKEN id="token-57-31" start_char="5686" end_char="5691">before</TOKEN>
				<TOKEN id="token-57-32" start_char="5693" end_char="5694">it</TOKEN>
				<TOKEN id="token-57-33" start_char="5696" end_char="5698">was</TOKEN>
				<TOKEN id="token-57-34" start_char="5700" end_char="5703">sent</TOKEN>
				<TOKEN id="token-57-35" start_char="5704" end_char="5704">,</TOKEN>
				<TOKEN id="token-57-36" start_char="5706" end_char="5708">and</TOKEN>
				<TOKEN id="token-57-37" start_char="5710" end_char="5717">concerns</TOKEN>
				<TOKEN id="token-57-38" start_char="5719" end_char="5727">expressed</TOKEN>
				<TOKEN id="token-57-39" start_char="5729" end_char="5730">by</TOKEN>
				<TOKEN id="token-57-40" start_char="5732" end_char="5734">the</TOKEN>
				<TOKEN id="token-57-41" start_char="5736" end_char="5738">NML</TOKEN>
				<TOKEN id="token-57-42" start_char="5739" end_char="5739">'</TOKEN>
				<TOKEN id="token-57-43" start_char="5740" end_char="5740">s</TOKEN>
				<TOKEN id="token-57-44" start_char="5742" end_char="5749">director</TOKEN>
				<TOKEN id="token-57-45" start_char="5750" end_char="5750">-</TOKEN>
				<TOKEN id="token-57-46" start_char="5751" end_char="5757">general</TOKEN>
				<TOKEN id="token-57-47" start_char="5759" end_char="5765">Matthew</TOKEN>
				<TOKEN id="token-57-48" start_char="5767" end_char="5773">Gilmour</TOKEN>
				<TOKEN id="token-57-49" start_char="5775" end_char="5776">in</TOKEN>
				<TOKEN id="token-57-50" start_char="5778" end_char="5785">Winnipeg</TOKEN>
				<TOKEN id="token-57-51" start_char="5786" end_char="5786">,</TOKEN>
				<TOKEN id="token-57-52" start_char="5788" end_char="5790">and</TOKEN>
				<TOKEN id="token-57-53" start_char="5792" end_char="5794">his</TOKEN>
				<TOKEN id="token-57-54" start_char="5796" end_char="5804">superiors</TOKEN>
				<TOKEN id="token-57-55" start_char="5806" end_char="5807">in</TOKEN>
				<TOKEN id="token-57-56" start_char="5809" end_char="5814">Ottawa</TOKEN>
				<TOKEN id="token-57-57" start_char="5815" end_char="5815">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-58" start_char="5817" end_char="5921">
				<ORIGINAL_TEXT>They wanted to know where the package was going, what was in it, and whether it had the proper paperwork.</ORIGINAL_TEXT>
				<TOKEN id="token-58-0" start_char="5817" end_char="5820">They</TOKEN>
				<TOKEN id="token-58-1" start_char="5822" end_char="5827">wanted</TOKEN>
				<TOKEN id="token-58-2" start_char="5829" end_char="5830">to</TOKEN>
				<TOKEN id="token-58-3" start_char="5832" end_char="5835">know</TOKEN>
				<TOKEN id="token-58-4" start_char="5837" end_char="5841">where</TOKEN>
				<TOKEN id="token-58-5" start_char="5843" end_char="5845">the</TOKEN>
				<TOKEN id="token-58-6" start_char="5847" end_char="5853">package</TOKEN>
				<TOKEN id="token-58-7" start_char="5855" end_char="5857">was</TOKEN>
				<TOKEN id="token-58-8" start_char="5859" end_char="5863">going</TOKEN>
				<TOKEN id="token-58-9" start_char="5864" end_char="5864">,</TOKEN>
				<TOKEN id="token-58-10" start_char="5866" end_char="5869">what</TOKEN>
				<TOKEN id="token-58-11" start_char="5871" end_char="5873">was</TOKEN>
				<TOKEN id="token-58-12" start_char="5875" end_char="5876">in</TOKEN>
				<TOKEN id="token-58-13" start_char="5878" end_char="5879">it</TOKEN>
				<TOKEN id="token-58-14" start_char="5880" end_char="5880">,</TOKEN>
				<TOKEN id="token-58-15" start_char="5882" end_char="5884">and</TOKEN>
				<TOKEN id="token-58-16" start_char="5886" end_char="5892">whether</TOKEN>
				<TOKEN id="token-58-17" start_char="5894" end_char="5895">it</TOKEN>
				<TOKEN id="token-58-18" start_char="5897" end_char="5899">had</TOKEN>
				<TOKEN id="token-58-19" start_char="5901" end_char="5903">the</TOKEN>
				<TOKEN id="token-58-20" start_char="5905" end_char="5910">proper</TOKEN>
				<TOKEN id="token-58-21" start_char="5912" end_char="5920">paperwork</TOKEN>
				<TOKEN id="token-58-22" start_char="5921" end_char="5921">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-59" start_char="5923" end_char="6049">
				<ORIGINAL_TEXT>In one email, Gilmour said Material Transfer Agreements would be required, &quot;not generic 'guarantees' on the storage and usage.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-59-0" start_char="5923" end_char="5924">In</TOKEN>
				<TOKEN id="token-59-1" start_char="5926" end_char="5928">one</TOKEN>
				<TOKEN id="token-59-2" start_char="5930" end_char="5934">email</TOKEN>
				<TOKEN id="token-59-3" start_char="5935" end_char="5935">,</TOKEN>
				<TOKEN id="token-59-4" start_char="5937" end_char="5943">Gilmour</TOKEN>
				<TOKEN id="token-59-5" start_char="5945" end_char="5948">said</TOKEN>
				<TOKEN id="token-59-6" start_char="5950" end_char="5957">Material</TOKEN>
				<TOKEN id="token-59-7" start_char="5959" end_char="5966">Transfer</TOKEN>
				<TOKEN id="token-59-8" start_char="5968" end_char="5977">Agreements</TOKEN>
				<TOKEN id="token-59-9" start_char="5979" end_char="5983">would</TOKEN>
				<TOKEN id="token-59-10" start_char="5985" end_char="5986">be</TOKEN>
				<TOKEN id="token-59-11" start_char="5988" end_char="5995">required</TOKEN>
				<TOKEN id="token-59-12" start_char="5996" end_char="5996">,</TOKEN>
				<TOKEN id="token-59-13" start_char="5998" end_char="5998">&quot;</TOKEN>
				<TOKEN id="token-59-14" start_char="5999" end_char="6001">not</TOKEN>
				<TOKEN id="token-59-15" start_char="6003" end_char="6009">generic</TOKEN>
				<TOKEN id="token-59-16" start_char="6011" end_char="6011">'</TOKEN>
				<TOKEN id="token-59-17" start_char="6012" end_char="6021">guarantees</TOKEN>
				<TOKEN id="token-59-18" start_char="6022" end_char="6022">'</TOKEN>
				<TOKEN id="token-59-19" start_char="6024" end_char="6025">on</TOKEN>
				<TOKEN id="token-59-20" start_char="6027" end_char="6029">the</TOKEN>
				<TOKEN id="token-59-21" start_char="6031" end_char="6037">storage</TOKEN>
				<TOKEN id="token-59-22" start_char="6039" end_char="6041">and</TOKEN>
				<TOKEN id="token-59-23" start_char="6043" end_char="6047">usage</TOKEN>
				<TOKEN id="token-59-24" start_char="6048" end_char="6049">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-60" start_char="6051" end_char="6149">
				<ORIGINAL_TEXT>He also asked David Safronetz, chief of special pathogens: &quot;Good to know that you trust this group.</ORIGINAL_TEXT>
				<TOKEN id="token-60-0" start_char="6051" end_char="6052">He</TOKEN>
				<TOKEN id="token-60-1" start_char="6054" end_char="6057">also</TOKEN>
				<TOKEN id="token-60-2" start_char="6059" end_char="6063">asked</TOKEN>
				<TOKEN id="token-60-3" start_char="6065" end_char="6069">David</TOKEN>
				<TOKEN id="token-60-4" start_char="6071" end_char="6079">Safronetz</TOKEN>
				<TOKEN id="token-60-5" start_char="6080" end_char="6080">,</TOKEN>
				<TOKEN id="token-60-6" start_char="6082" end_char="6086">chief</TOKEN>
				<TOKEN id="token-60-7" start_char="6088" end_char="6089">of</TOKEN>
				<TOKEN id="token-60-8" start_char="6091" end_char="6097">special</TOKEN>
				<TOKEN id="token-60-9" start_char="6099" end_char="6107">pathogens</TOKEN>
				<TOKEN id="token-60-10" start_char="6108" end_char="6108">:</TOKEN>
				<TOKEN id="token-60-11" start_char="6110" end_char="6110">&quot;</TOKEN>
				<TOKEN id="token-60-12" start_char="6111" end_char="6114">Good</TOKEN>
				<TOKEN id="token-60-13" start_char="6116" end_char="6117">to</TOKEN>
				<TOKEN id="token-60-14" start_char="6119" end_char="6122">know</TOKEN>
				<TOKEN id="token-60-15" start_char="6124" end_char="6127">that</TOKEN>
				<TOKEN id="token-60-16" start_char="6129" end_char="6131">you</TOKEN>
				<TOKEN id="token-60-17" start_char="6133" end_char="6137">trust</TOKEN>
				<TOKEN id="token-60-18" start_char="6139" end_char="6142">this</TOKEN>
				<TOKEN id="token-60-19" start_char="6144" end_char="6148">group</TOKEN>
				<TOKEN id="token-60-20" start_char="6149" end_char="6149">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-61" start_char="6151" end_char="6186">
				<ORIGINAL_TEXT>How did we get connected with them?&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-61-0" start_char="6151" end_char="6153">How</TOKEN>
				<TOKEN id="token-61-1" start_char="6155" end_char="6157">did</TOKEN>
				<TOKEN id="token-61-2" start_char="6159" end_char="6160">we</TOKEN>
				<TOKEN id="token-61-3" start_char="6162" end_char="6164">get</TOKEN>
				<TOKEN id="token-61-4" start_char="6166" end_char="6174">connected</TOKEN>
				<TOKEN id="token-61-5" start_char="6176" end_char="6179">with</TOKEN>
				<TOKEN id="token-61-6" start_char="6181" end_char="6184">them</TOKEN>
				<TOKEN id="token-61-7" start_char="6185" end_char="6186">?&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-62" start_char="6188" end_char="6273">
				<ORIGINAL_TEXT>Safronetz replied: &quot;They are requesting material from us due to collaboration with Dr.</ORIGINAL_TEXT>
				<TOKEN id="token-62-0" start_char="6188" end_char="6196">Safronetz</TOKEN>
				<TOKEN id="token-62-1" start_char="6198" end_char="6204">replied</TOKEN>
				<TOKEN id="token-62-2" start_char="6205" end_char="6205">:</TOKEN>
				<TOKEN id="token-62-3" start_char="6207" end_char="6207">&quot;</TOKEN>
				<TOKEN id="token-62-4" start_char="6208" end_char="6211">They</TOKEN>
				<TOKEN id="token-62-5" start_char="6213" end_char="6215">are</TOKEN>
				<TOKEN id="token-62-6" start_char="6217" end_char="6226">requesting</TOKEN>
				<TOKEN id="token-62-7" start_char="6228" end_char="6235">material</TOKEN>
				<TOKEN id="token-62-8" start_char="6237" end_char="6240">from</TOKEN>
				<TOKEN id="token-62-9" start_char="6242" end_char="6243">us</TOKEN>
				<TOKEN id="token-62-10" start_char="6245" end_char="6247">due</TOKEN>
				<TOKEN id="token-62-11" start_char="6249" end_char="6250">to</TOKEN>
				<TOKEN id="token-62-12" start_char="6252" end_char="6264">collaboration</TOKEN>
				<TOKEN id="token-62-13" start_char="6266" end_char="6269">with</TOKEN>
				<TOKEN id="token-62-14" start_char="6271" end_char="6272">Dr</TOKEN>
				<TOKEN id="token-62-15" start_char="6273" end_char="6273">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-63" start_char="6275" end_char="6279">
				<ORIGINAL_TEXT>Qiu.&quot;</ORIGINAL_TEXT>
				<TOKEN id="token-63-0" start_char="6275" end_char="6277">Qiu</TOKEN>
				<TOKEN id="token-63-1" start_char="6278" end_char="6279">.&quot;</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-64" start_char="6281" end_char="6509">
				<ORIGINAL_TEXT>CBC News received hundreds of pages of documents through an Access to Information request, detailing a shipment of Ebola and Henipah viruses sent from the National Microbiology Lab in Winnipeg, to the Wuhan virology lab in China.</ORIGINAL_TEXT>
				<TOKEN id="token-64-0" start_char="6281" end_char="6283">CBC</TOKEN>
				<TOKEN id="token-64-1" start_char="6285" end_char="6288">News</TOKEN>
				<TOKEN id="token-64-2" start_char="6290" end_char="6297">received</TOKEN>
				<TOKEN id="token-64-3" start_char="6299" end_char="6306">hundreds</TOKEN>
				<TOKEN id="token-64-4" start_char="6308" end_char="6309">of</TOKEN>
				<TOKEN id="token-64-5" start_char="6311" end_char="6315">pages</TOKEN>
				<TOKEN id="token-64-6" start_char="6317" end_char="6318">of</TOKEN>
				<TOKEN id="token-64-7" start_char="6320" end_char="6328">documents</TOKEN>
				<TOKEN id="token-64-8" start_char="6330" end_char="6336">through</TOKEN>
				<TOKEN id="token-64-9" start_char="6338" end_char="6339">an</TOKEN>
				<TOKEN id="token-64-10" start_char="6341" end_char="6346">Access</TOKEN>
				<TOKEN id="token-64-11" start_char="6348" end_char="6349">to</TOKEN>
				<TOKEN id="token-64-12" start_char="6351" end_char="6361">Information</TOKEN>
				<TOKEN id="token-64-13" start_char="6363" end_char="6369">request</TOKEN>
				<TOKEN id="token-64-14" start_char="6370" end_char="6370">,</TOKEN>
				<TOKEN id="token-64-15" start_char="6372" end_char="6380">detailing</TOKEN>
				<TOKEN id="token-64-16" start_char="6382" end_char="6382">a</TOKEN>
				<TOKEN id="token-64-17" start_char="6384" end_char="6391">shipment</TOKEN>
				<TOKEN id="token-64-18" start_char="6393" end_char="6394">of</TOKEN>
				<TOKEN id="token-64-19" start_char="6396" end_char="6400">Ebola</TOKEN>
				<TOKEN id="token-64-20" start_char="6402" end_char="6404">and</TOKEN>
				<TOKEN id="token-64-21" start_char="6406" end_char="6412">Henipah</TOKEN>
				<TOKEN id="token-64-22" start_char="6414" end_char="6420">viruses</TOKEN>
				<TOKEN id="token-64-23" start_char="6422" end_char="6425">sent</TOKEN>
				<TOKEN id="token-64-24" start_char="6427" end_char="6430">from</TOKEN>
				<TOKEN id="token-64-25" start_char="6432" end_char="6434">the</TOKEN>
				<TOKEN id="token-64-26" start_char="6436" end_char="6443">National</TOKEN>
				<TOKEN id="token-64-27" start_char="6445" end_char="6456">Microbiology</TOKEN>
				<TOKEN id="token-64-28" start_char="6458" end_char="6460">Lab</TOKEN>
				<TOKEN id="token-64-29" start_char="6462" end_char="6463">in</TOKEN>
				<TOKEN id="token-64-30" start_char="6465" end_char="6472">Winnipeg</TOKEN>
				<TOKEN id="token-64-31" start_char="6473" end_char="6473">,</TOKEN>
				<TOKEN id="token-64-32" start_char="6475" end_char="6476">to</TOKEN>
				<TOKEN id="token-64-33" start_char="6478" end_char="6480">the</TOKEN>
				<TOKEN id="token-64-34" start_char="6482" end_char="6486">Wuhan</TOKEN>
				<TOKEN id="token-64-35" start_char="6488" end_char="6495">virology</TOKEN>
				<TOKEN id="token-64-36" start_char="6497" end_char="6499">lab</TOKEN>
				<TOKEN id="token-64-37" start_char="6501" end_char="6502">in</TOKEN>
				<TOKEN id="token-64-38" start_char="6504" end_char="6508">China</TOKEN>
				<TOKEN id="token-64-39" start_char="6509" end_char="6509">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-65" start_char="6511" end_char="6532">
				<ORIGINAL_TEXT>(Karen Pauls/CBC News)</ORIGINAL_TEXT>
				<TOKEN id="token-65-0" start_char="6511" end_char="6511">(</TOKEN>
				<TOKEN id="token-65-1" start_char="6512" end_char="6516">Karen</TOKEN>
				<TOKEN id="token-65-2" start_char="6518" end_char="6522">Pauls</TOKEN>
				<TOKEN id="token-65-3" start_char="6523" end_char="6523">/</TOKEN>
				<TOKEN id="token-65-4" start_char="6524" end_char="6526">CBC</TOKEN>
				<TOKEN id="token-65-5" start_char="6528" end_char="6531">News</TOKEN>
				<TOKEN id="token-65-6" start_char="6532" end_char="6532">)</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-66" start_char="6534" end_char="6704">
				<ORIGINAL_TEXT>Meanwhile, it appears the NML's shipper initially planned to send the viruses in inappropriate packaging and only changed it when the clients in China flagged the problem.</ORIGINAL_TEXT>
				<TOKEN id="token-66-0" start_char="6534" end_char="6542">Meanwhile</TOKEN>
				<TOKEN id="token-66-1" start_char="6543" end_char="6543">,</TOKEN>
				<TOKEN id="token-66-2" start_char="6545" end_char="6546">it</TOKEN>
				<TOKEN id="token-66-3" start_char="6548" end_char="6554">appears</TOKEN>
				<TOKEN id="token-66-4" start_char="6556" end_char="6558">the</TOKEN>
				<TOKEN id="token-66-5" start_char="6560" end_char="6562">NML</TOKEN>
				<TOKEN id="token-66-6" start_char="6563" end_char="6563">'</TOKEN>
				<TOKEN id="token-66-7" start_char="6564" end_char="6564">s</TOKEN>
				<TOKEN id="token-66-8" start_char="6566" end_char="6572">shipper</TOKEN>
				<TOKEN id="token-66-9" start_char="6574" end_char="6582">initially</TOKEN>
				<TOKEN id="token-66-10" start_char="6584" end_char="6590">planned</TOKEN>
				<TOKEN id="token-66-11" start_char="6592" end_char="6593">to</TOKEN>
				<TOKEN id="token-66-12" start_char="6595" end_char="6598">send</TOKEN>
				<TOKEN id="token-66-13" start_char="6600" end_char="6602">the</TOKEN>
				<TOKEN id="token-66-14" start_char="6604" end_char="6610">viruses</TOKEN>
				<TOKEN id="token-66-15" start_char="6612" end_char="6613">in</TOKEN>
				<TOKEN id="token-66-16" start_char="6615" end_char="6627">inappropriate</TOKEN>
				<TOKEN id="token-66-17" start_char="6629" end_char="6637">packaging</TOKEN>
				<TOKEN id="token-66-18" start_char="6639" end_char="6641">and</TOKEN>
				<TOKEN id="token-66-19" start_char="6643" end_char="6646">only</TOKEN>
				<TOKEN id="token-66-20" start_char="6648" end_char="6654">changed</TOKEN>
				<TOKEN id="token-66-21" start_char="6656" end_char="6657">it</TOKEN>
				<TOKEN id="token-66-22" start_char="6659" end_char="6662">when</TOKEN>
				<TOKEN id="token-66-23" start_char="6664" end_char="6666">the</TOKEN>
				<TOKEN id="token-66-24" start_char="6668" end_char="6674">clients</TOKEN>
				<TOKEN id="token-66-25" start_char="6676" end_char="6677">in</TOKEN>
				<TOKEN id="token-66-26" start_char="6679" end_char="6683">China</TOKEN>
				<TOKEN id="token-66-27" start_char="6685" end_char="6691">flagged</TOKEN>
				<TOKEN id="token-66-28" start_char="6693" end_char="6695">the</TOKEN>
				<TOKEN id="token-66-29" start_char="6697" end_char="6703">problem</TOKEN>
				<TOKEN id="token-66-30" start_char="6704" end_char="6704">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-67" start_char="6706" end_char="6835">
				<ORIGINAL_TEXT>&quot;The only reason the correct packaging was used is because the Chinese wrote to them and said, 'Aren't you making a mistake here?'</ORIGINAL_TEXT>
				<TOKEN id="token-67-0" start_char="6706" end_char="6706">&quot;</TOKEN>
				<TOKEN id="token-67-1" start_char="6707" end_char="6709">The</TOKEN>
				<TOKEN id="token-67-2" start_char="6711" end_char="6714">only</TOKEN>
				<TOKEN id="token-67-3" start_char="6716" end_char="6721">reason</TOKEN>
				<TOKEN id="token-67-4" start_char="6723" end_char="6725">the</TOKEN>
				<TOKEN id="token-67-5" start_char="6727" end_char="6733">correct</TOKEN>
				<TOKEN id="token-67-6" start_char="6735" end_char="6743">packaging</TOKEN>
				<TOKEN id="token-67-7" start_char="6745" end_char="6747">was</TOKEN>
				<TOKEN id="token-67-8" start_char="6749" end_char="6752">used</TOKEN>
				<TOKEN id="token-67-9" start_char="6754" end_char="6755">is</TOKEN>
				<TOKEN id="token-67-10" start_char="6757" end_char="6763">because</TOKEN>
				<TOKEN id="token-67-11" start_char="6765" end_char="6767">the</TOKEN>
				<TOKEN id="token-67-12" start_char="6769" end_char="6775">Chinese</TOKEN>
				<TOKEN id="token-67-13" start_char="6777" end_char="6781">wrote</TOKEN>
				<TOKEN id="token-67-14" start_char="6783" end_char="6784">to</TOKEN>
				<TOKEN id="token-67-15" start_char="6786" end_char="6789">them</TOKEN>
				<TOKEN id="token-67-16" start_char="6791" end_char="6793">and</TOKEN>
				<TOKEN id="token-67-17" start_char="6795" end_char="6798">said</TOKEN>
				<TOKEN id="token-67-18" start_char="6799" end_char="6799">,</TOKEN>
				<TOKEN id="token-67-19" start_char="6801" end_char="6801">'</TOKEN>
				<TOKEN id="token-67-20" start_char="6802" end_char="6805">Aren</TOKEN>
				<TOKEN id="token-67-21" start_char="6806" end_char="6806">'</TOKEN>
				<TOKEN id="token-67-22" start_char="6807" end_char="6807">t</TOKEN>
				<TOKEN id="token-67-23" start_char="6809" end_char="6811">you</TOKEN>
				<TOKEN id="token-67-24" start_char="6813" end_char="6818">making</TOKEN>
				<TOKEN id="token-67-25" start_char="6820" end_char="6820">a</TOKEN>
				<TOKEN id="token-67-26" start_char="6822" end_char="6828">mistake</TOKEN>
				<TOKEN id="token-67-27" start_char="6830" end_char="6833">here</TOKEN>
				<TOKEN id="token-67-28" start_char="6834" end_char="6835">?'</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-68" start_char="6837" end_char="6982">
				<ORIGINAL_TEXT>If that had not happened, the scientists would have placed on an Air Canada flight, several of them actually, a deadly virus incorrectly packaged.</ORIGINAL_TEXT>
				<TOKEN id="token-68-0" start_char="6837" end_char="6838">If</TOKEN>
				<TOKEN id="token-68-1" start_char="6840" end_char="6843">that</TOKEN>
				<TOKEN id="token-68-2" start_char="6845" end_char="6847">had</TOKEN>
				<TOKEN id="token-68-3" start_char="6849" end_char="6851">not</TOKEN>
				<TOKEN id="token-68-4" start_char="6853" end_char="6860">happened</TOKEN>
				<TOKEN id="token-68-5" start_char="6861" end_char="6861">,</TOKEN>
				<TOKEN id="token-68-6" start_char="6863" end_char="6865">the</TOKEN>
				<TOKEN id="token-68-7" start_char="6867" end_char="6876">scientists</TOKEN>
				<TOKEN id="token-68-8" start_char="6878" end_char="6882">would</TOKEN>
				<TOKEN id="token-68-9" start_char="6884" end_char="6887">have</TOKEN>
				<TOKEN id="token-68-10" start_char="6889" end_char="6894">placed</TOKEN>
				<TOKEN id="token-68-11" start_char="6896" end_char="6897">on</TOKEN>
				<TOKEN id="token-68-12" start_char="6899" end_char="6900">an</TOKEN>
				<TOKEN id="token-68-13" start_char="6902" end_char="6904">Air</TOKEN>
				<TOKEN id="token-68-14" start_char="6906" end_char="6911">Canada</TOKEN>
				<TOKEN id="token-68-15" start_char="6913" end_char="6918">flight</TOKEN>
				<TOKEN id="token-68-16" start_char="6919" end_char="6919">,</TOKEN>
				<TOKEN id="token-68-17" start_char="6921" end_char="6927">several</TOKEN>
				<TOKEN id="token-68-18" start_char="6929" end_char="6930">of</TOKEN>
				<TOKEN id="token-68-19" start_char="6932" end_char="6935">them</TOKEN>
				<TOKEN id="token-68-20" start_char="6937" end_char="6944">actually</TOKEN>
				<TOKEN id="token-68-21" start_char="6945" end_char="6945">,</TOKEN>
				<TOKEN id="token-68-22" start_char="6947" end_char="6947">a</TOKEN>
				<TOKEN id="token-68-23" start_char="6949" end_char="6954">deadly</TOKEN>
				<TOKEN id="token-68-24" start_char="6956" end_char="6960">virus</TOKEN>
				<TOKEN id="token-68-25" start_char="6962" end_char="6972">incorrectly</TOKEN>
				<TOKEN id="token-68-26" start_char="6974" end_char="6981">packaged</TOKEN>
				<TOKEN id="token-68-27" start_char="6982" end_char="6982">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-69" start_char="6984" end_char="7019">
				<ORIGINAL_TEXT>That nearly happened,&quot; Attaran said.</ORIGINAL_TEXT>
				<TOKEN id="token-69-0" start_char="6984" end_char="6987">That</TOKEN>
				<TOKEN id="token-69-1" start_char="6989" end_char="6994">nearly</TOKEN>
				<TOKEN id="token-69-2" start_char="6996" end_char="7003">happened</TOKEN>
				<TOKEN id="token-69-3" start_char="7004" end_char="7005">,&quot;</TOKEN>
				<TOKEN id="token-69-4" start_char="7007" end_char="7013">Attaran</TOKEN>
				<TOKEN id="token-69-5" start_char="7015" end_char="7018">said</TOKEN>
				<TOKEN id="token-69-6" start_char="7019" end_char="7019">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-70" start_char="7021" end_char="7129">
				<ORIGINAL_TEXT>The package was routed from Winnipeg to Toronto and then to Beijing on a commercial Air Canada flight on Mar.</ORIGINAL_TEXT>
				<TOKEN id="token-70-0" start_char="7021" end_char="7023">The</TOKEN>
				<TOKEN id="token-70-1" start_char="7025" end_char="7031">package</TOKEN>
				<TOKEN id="token-70-2" start_char="7033" end_char="7035">was</TOKEN>
				<TOKEN id="token-70-3" start_char="7037" end_char="7042">routed</TOKEN>
				<TOKEN id="token-70-4" start_char="7044" end_char="7047">from</TOKEN>
				<TOKEN id="token-70-5" start_char="7049" end_char="7056">Winnipeg</TOKEN>
				<TOKEN id="token-70-6" start_char="7058" end_char="7059">to</TOKEN>
				<TOKEN id="token-70-7" start_char="7061" end_char="7067">Toronto</TOKEN>
				<TOKEN id="token-70-8" start_char="7069" end_char="7071">and</TOKEN>
				<TOKEN id="token-70-9" start_char="7073" end_char="7076">then</TOKEN>
				<TOKEN id="token-70-10" start_char="7078" end_char="7079">to</TOKEN>
				<TOKEN id="token-70-11" start_char="7081" end_char="7087">Beijing</TOKEN>
				<TOKEN id="token-70-12" start_char="7089" end_char="7090">on</TOKEN>
				<TOKEN id="token-70-13" start_char="7092" end_char="7092">a</TOKEN>
				<TOKEN id="token-70-14" start_char="7094" end_char="7103">commercial</TOKEN>
				<TOKEN id="token-70-15" start_char="7105" end_char="7107">Air</TOKEN>
				<TOKEN id="token-70-16" start_char="7109" end_char="7114">Canada</TOKEN>
				<TOKEN id="token-70-17" start_char="7116" end_char="7121">flight</TOKEN>
				<TOKEN id="token-70-18" start_char="7123" end_char="7124">on</TOKEN>
				<TOKEN id="token-70-19" start_char="7126" end_char="7128">Mar</TOKEN>
				<TOKEN id="token-70-20" start_char="7129" end_char="7129">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-71" start_char="7131" end_char="7139">
				<ORIGINAL_TEXT>31, 2019.</ORIGINAL_TEXT>
				<TOKEN id="token-71-0" start_char="7131" end_char="7132">31</TOKEN>
				<TOKEN id="token-71-1" start_char="7133" end_char="7133">,</TOKEN>
				<TOKEN id="token-71-2" start_char="7135" end_char="7138">2019</TOKEN>
				<TOKEN id="token-71-3" start_char="7139" end_char="7139">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-72" start_char="7141" end_char="7213">
				<ORIGINAL_TEXT>The next day, the recipients replied that the package had arrived safely.</ORIGINAL_TEXT>
				<TOKEN id="token-72-0" start_char="7141" end_char="7143">The</TOKEN>
				<TOKEN id="token-72-1" start_char="7145" end_char="7148">next</TOKEN>
				<TOKEN id="token-72-2" start_char="7150" end_char="7152">day</TOKEN>
				<TOKEN id="token-72-3" start_char="7153" end_char="7153">,</TOKEN>
				<TOKEN id="token-72-4" start_char="7155" end_char="7157">the</TOKEN>
				<TOKEN id="token-72-5" start_char="7159" end_char="7168">recipients</TOKEN>
				<TOKEN id="token-72-6" start_char="7170" end_char="7176">replied</TOKEN>
				<TOKEN id="token-72-7" start_char="7178" end_char="7181">that</TOKEN>
				<TOKEN id="token-72-8" start_char="7183" end_char="7185">the</TOKEN>
				<TOKEN id="token-72-9" start_char="7187" end_char="7193">package</TOKEN>
				<TOKEN id="token-72-10" start_char="7195" end_char="7197">had</TOKEN>
				<TOKEN id="token-72-11" start_char="7199" end_char="7205">arrived</TOKEN>
				<TOKEN id="token-72-12" start_char="7207" end_char="7212">safely</TOKEN>
				<TOKEN id="token-72-13" start_char="7213" end_char="7213">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-73" start_char="7215" end_char="7332">
				<ORIGINAL_TEXT>&quot;We would like to express our sincere gratitude to you all for your continuous support, especially Dr. Qiu and Anders!</ORIGINAL_TEXT>
				<TOKEN id="token-73-0" start_char="7215" end_char="7215">&quot;</TOKEN>
				<TOKEN id="token-73-1" start_char="7216" end_char="7217">We</TOKEN>
				<TOKEN id="token-73-2" start_char="7219" end_char="7223">would</TOKEN>
				<TOKEN id="token-73-3" start_char="7225" end_char="7228">like</TOKEN>
				<TOKEN id="token-73-4" start_char="7230" end_char="7231">to</TOKEN>
				<TOKEN id="token-73-5" start_char="7233" end_char="7239">express</TOKEN>
				<TOKEN id="token-73-6" start_char="7241" end_char="7243">our</TOKEN>
				<TOKEN id="token-73-7" start_char="7245" end_char="7251">sincere</TOKEN>
				<TOKEN id="token-73-8" start_char="7253" end_char="7261">gratitude</TOKEN>
				<TOKEN id="token-73-9" start_char="7263" end_char="7264">to</TOKEN>
				<TOKEN id="token-73-10" start_char="7266" end_char="7268">you</TOKEN>
				<TOKEN id="token-73-11" start_char="7270" end_char="7272">all</TOKEN>
				<TOKEN id="token-73-12" start_char="7274" end_char="7276">for</TOKEN>
				<TOKEN id="token-73-13" start_char="7278" end_char="7281">your</TOKEN>
				<TOKEN id="token-73-14" start_char="7283" end_char="7292">continuous</TOKEN>
				<TOKEN id="token-73-15" start_char="7294" end_char="7300">support</TOKEN>
				<TOKEN id="token-73-16" start_char="7301" end_char="7301">,</TOKEN>
				<TOKEN id="token-73-17" start_char="7303" end_char="7312">especially</TOKEN>
				<TOKEN id="token-73-18" start_char="7314" end_char="7315">Dr</TOKEN>
				<TOKEN id="token-73-19" start_char="7316" end_char="7316">.</TOKEN>
				<TOKEN id="token-73-20" start_char="7318" end_char="7320">Qiu</TOKEN>
				<TOKEN id="token-73-21" start_char="7322" end_char="7324">and</TOKEN>
				<TOKEN id="token-73-22" start_char="7326" end_char="7331">Anders</TOKEN>
				<TOKEN id="token-73-23" start_char="7332" end_char="7332">!</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-74" start_char="7334" end_char="7346">
				<ORIGINAL_TEXT>Thanks a lot!</ORIGINAL_TEXT>
				<TOKEN id="token-74-0" start_char="7334" end_char="7339">Thanks</TOKEN>
				<TOKEN id="token-74-1" start_char="7341" end_char="7341">a</TOKEN>
				<TOKEN id="token-74-2" start_char="7343" end_char="7345">lot</TOKEN>
				<TOKEN id="token-74-3" start_char="7346" end_char="7346">!</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-75" start_char="7348" end_char="7348">
				<ORIGINAL_TEXT>!</ORIGINAL_TEXT>
				<TOKEN id="token-75-0" start_char="7348" end_char="7348">!</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-76" start_char="7350" end_char="7487">
				<ORIGINAL_TEXT>Looking forward to our further cooperation in the future,&quot; said the heavily redacted email, which does not provide the name of the sender.</ORIGINAL_TEXT>
				<TOKEN id="token-76-0" start_char="7350" end_char="7356">Looking</TOKEN>
				<TOKEN id="token-76-1" start_char="7358" end_char="7364">forward</TOKEN>
				<TOKEN id="token-76-2" start_char="7366" end_char="7367">to</TOKEN>
				<TOKEN id="token-76-3" start_char="7369" end_char="7371">our</TOKEN>
				<TOKEN id="token-76-4" start_char="7373" end_char="7379">further</TOKEN>
				<TOKEN id="token-76-5" start_char="7381" end_char="7391">cooperation</TOKEN>
				<TOKEN id="token-76-6" start_char="7393" end_char="7394">in</TOKEN>
				<TOKEN id="token-76-7" start_char="7396" end_char="7398">the</TOKEN>
				<TOKEN id="token-76-8" start_char="7400" end_char="7405">future</TOKEN>
				<TOKEN id="token-76-9" start_char="7406" end_char="7407">,&quot;</TOKEN>
				<TOKEN id="token-76-10" start_char="7409" end_char="7412">said</TOKEN>
				<TOKEN id="token-76-11" start_char="7414" end_char="7416">the</TOKEN>
				<TOKEN id="token-76-12" start_char="7418" end_char="7424">heavily</TOKEN>
				<TOKEN id="token-76-13" start_char="7426" end_char="7433">redacted</TOKEN>
				<TOKEN id="token-76-14" start_char="7435" end_char="7439">email</TOKEN>
				<TOKEN id="token-76-15" start_char="7440" end_char="7440">,</TOKEN>
				<TOKEN id="token-76-16" start_char="7442" end_char="7446">which</TOKEN>
				<TOKEN id="token-76-17" start_char="7448" end_char="7451">does</TOKEN>
				<TOKEN id="token-76-18" start_char="7453" end_char="7455">not</TOKEN>
				<TOKEN id="token-76-19" start_char="7457" end_char="7463">provide</TOKEN>
				<TOKEN id="token-76-20" start_char="7465" end_char="7467">the</TOKEN>
				<TOKEN id="token-76-21" start_char="7469" end_char="7472">name</TOKEN>
				<TOKEN id="token-76-22" start_char="7474" end_char="7475">of</TOKEN>
				<TOKEN id="token-76-23" start_char="7477" end_char="7479">the</TOKEN>
				<TOKEN id="token-76-24" start_char="7481" end_char="7486">sender</TOKEN>
				<TOKEN id="token-76-25" start_char="7487" end_char="7487">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-77" start_char="7489" end_char="7637">
				<ORIGINAL_TEXT>Access to information documents show a flurry of emails dealing with the shipment of viruses from the National Microbiology Lab in Winnipeg to China.</ORIGINAL_TEXT>
				<TOKEN id="token-77-0" start_char="7489" end_char="7494">Access</TOKEN>
				<TOKEN id="token-77-1" start_char="7496" end_char="7497">to</TOKEN>
				<TOKEN id="token-77-2" start_char="7499" end_char="7509">information</TOKEN>
				<TOKEN id="token-77-3" start_char="7511" end_char="7519">documents</TOKEN>
				<TOKEN id="token-77-4" start_char="7521" end_char="7524">show</TOKEN>
				<TOKEN id="token-77-5" start_char="7526" end_char="7526">a</TOKEN>
				<TOKEN id="token-77-6" start_char="7528" end_char="7533">flurry</TOKEN>
				<TOKEN id="token-77-7" start_char="7535" end_char="7536">of</TOKEN>
				<TOKEN id="token-77-8" start_char="7538" end_char="7543">emails</TOKEN>
				<TOKEN id="token-77-9" start_char="7545" end_char="7551">dealing</TOKEN>
				<TOKEN id="token-77-10" start_char="7553" end_char="7556">with</TOKEN>
				<TOKEN id="token-77-11" start_char="7558" end_char="7560">the</TOKEN>
				<TOKEN id="token-77-12" start_char="7562" end_char="7569">shipment</TOKEN>
				<TOKEN id="token-77-13" start_char="7571" end_char="7572">of</TOKEN>
				<TOKEN id="token-77-14" start_char="7574" end_char="7580">viruses</TOKEN>
				<TOKEN id="token-77-15" start_char="7582" end_char="7585">from</TOKEN>
				<TOKEN id="token-77-16" start_char="7587" end_char="7589">the</TOKEN>
				<TOKEN id="token-77-17" start_char="7591" end_char="7598">National</TOKEN>
				<TOKEN id="token-77-18" start_char="7600" end_char="7611">Microbiology</TOKEN>
				<TOKEN id="token-77-19" start_char="7613" end_char="7615">Lab</TOKEN>
				<TOKEN id="token-77-20" start_char="7617" end_char="7618">in</TOKEN>
				<TOKEN id="token-77-21" start_char="7620" end_char="7627">Winnipeg</TOKEN>
				<TOKEN id="token-77-22" start_char="7629" end_char="7630">to</TOKEN>
				<TOKEN id="token-77-23" start_char="7632" end_char="7636">China</TOKEN>
				<TOKEN id="token-77-24" start_char="7637" end_char="7637">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-78" start_char="7639" end_char="7676">
				<ORIGINAL_TEXT>(John Woods/Canadian Press file photo)</ORIGINAL_TEXT>
				<TOKEN id="token-78-0" start_char="7639" end_char="7639">(</TOKEN>
				<TOKEN id="token-78-1" start_char="7640" end_char="7643">John</TOKEN>
				<TOKEN id="token-78-2" start_char="7645" end_char="7649">Woods</TOKEN>
				<TOKEN id="token-78-3" start_char="7650" end_char="7650">/</TOKEN>
				<TOKEN id="token-78-4" start_char="7651" end_char="7658">Canadian</TOKEN>
				<TOKEN id="token-78-5" start_char="7660" end_char="7664">Press</TOKEN>
				<TOKEN id="token-78-6" start_char="7666" end_char="7669">file</TOKEN>
				<TOKEN id="token-78-7" start_char="7671" end_char="7675">photo</TOKEN>
				<TOKEN id="token-78-8" start_char="7676" end_char="7676">)</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-79" start_char="7678" end_char="7820">
				<ORIGINAL_TEXT>Nearly one year after the expulsion of Qiu, Cheng, and her students from the NML, there are still no updates on the case from the RCMP or PHAC.</ORIGINAL_TEXT>
				<TOKEN id="token-79-0" start_char="7678" end_char="7683">Nearly</TOKEN>
				<TOKEN id="token-79-1" start_char="7685" end_char="7687">one</TOKEN>
				<TOKEN id="token-79-2" start_char="7689" end_char="7692">year</TOKEN>
				<TOKEN id="token-79-3" start_char="7694" end_char="7698">after</TOKEN>
				<TOKEN id="token-79-4" start_char="7700" end_char="7702">the</TOKEN>
				<TOKEN id="token-79-5" start_char="7704" end_char="7712">expulsion</TOKEN>
				<TOKEN id="token-79-6" start_char="7714" end_char="7715">of</TOKEN>
				<TOKEN id="token-79-7" start_char="7717" end_char="7719">Qiu</TOKEN>
				<TOKEN id="token-79-8" start_char="7720" end_char="7720">,</TOKEN>
				<TOKEN id="token-79-9" start_char="7722" end_char="7726">Cheng</TOKEN>
				<TOKEN id="token-79-10" start_char="7727" end_char="7727">,</TOKEN>
				<TOKEN id="token-79-11" start_char="7729" end_char="7731">and</TOKEN>
				<TOKEN id="token-79-12" start_char="7733" end_char="7735">her</TOKEN>
				<TOKEN id="token-79-13" start_char="7737" end_char="7744">students</TOKEN>
				<TOKEN id="token-79-14" start_char="7746" end_char="7749">from</TOKEN>
				<TOKEN id="token-79-15" start_char="7751" end_char="7753">the</TOKEN>
				<TOKEN id="token-79-16" start_char="7755" end_char="7757">NML</TOKEN>
				<TOKEN id="token-79-17" start_char="7758" end_char="7758">,</TOKEN>
				<TOKEN id="token-79-18" start_char="7760" end_char="7764">there</TOKEN>
				<TOKEN id="token-79-19" start_char="7766" end_char="7768">are</TOKEN>
				<TOKEN id="token-79-20" start_char="7770" end_char="7774">still</TOKEN>
				<TOKEN id="token-79-21" start_char="7776" end_char="7777">no</TOKEN>
				<TOKEN id="token-79-22" start_char="7779" end_char="7785">updates</TOKEN>
				<TOKEN id="token-79-23" start_char="7787" end_char="7788">on</TOKEN>
				<TOKEN id="token-79-24" start_char="7790" end_char="7792">the</TOKEN>
				<TOKEN id="token-79-25" start_char="7794" end_char="7797">case</TOKEN>
				<TOKEN id="token-79-26" start_char="7799" end_char="7802">from</TOKEN>
				<TOKEN id="token-79-27" start_char="7804" end_char="7806">the</TOKEN>
				<TOKEN id="token-79-28" start_char="7808" end_char="7811">RCMP</TOKEN>
				<TOKEN id="token-79-29" start_char="7813" end_char="7814">or</TOKEN>
				<TOKEN id="token-79-30" start_char="7816" end_char="7819">PHAC</TOKEN>
				<TOKEN id="token-79-31" start_char="7820" end_char="7820">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-80" start_char="7822" end_char="7961">
				<ORIGINAL_TEXT>At the time, Public Health Agency spokesperson Morrissette said the department was taking steps to resolve this case as quickly as possible.</ORIGINAL_TEXT>
				<TOKEN id="token-80-0" start_char="7822" end_char="7823">At</TOKEN>
				<TOKEN id="token-80-1" start_char="7825" end_char="7827">the</TOKEN>
				<TOKEN id="token-80-2" start_char="7829" end_char="7832">time</TOKEN>
				<TOKEN id="token-80-3" start_char="7833" end_char="7833">,</TOKEN>
				<TOKEN id="token-80-4" start_char="7835" end_char="7840">Public</TOKEN>
				<TOKEN id="token-80-5" start_char="7842" end_char="7847">Health</TOKEN>
				<TOKEN id="token-80-6" start_char="7849" end_char="7854">Agency</TOKEN>
				<TOKEN id="token-80-7" start_char="7856" end_char="7867">spokesperson</TOKEN>
				<TOKEN id="token-80-8" start_char="7869" end_char="7879">Morrissette</TOKEN>
				<TOKEN id="token-80-9" start_char="7881" end_char="7884">said</TOKEN>
				<TOKEN id="token-80-10" start_char="7886" end_char="7888">the</TOKEN>
				<TOKEN id="token-80-11" start_char="7890" end_char="7899">department</TOKEN>
				<TOKEN id="token-80-12" start_char="7901" end_char="7903">was</TOKEN>
				<TOKEN id="token-80-13" start_char="7905" end_char="7910">taking</TOKEN>
				<TOKEN id="token-80-14" start_char="7912" end_char="7916">steps</TOKEN>
				<TOKEN id="token-80-15" start_char="7918" end_char="7919">to</TOKEN>
				<TOKEN id="token-80-16" start_char="7921" end_char="7927">resolve</TOKEN>
				<TOKEN id="token-80-17" start_char="7929" end_char="7932">this</TOKEN>
				<TOKEN id="token-80-18" start_char="7934" end_char="7937">case</TOKEN>
				<TOKEN id="token-80-19" start_char="7939" end_char="7940">as</TOKEN>
				<TOKEN id="token-80-20" start_char="7942" end_char="7948">quickly</TOKEN>
				<TOKEN id="token-80-21" start_char="7950" end_char="7951">as</TOKEN>
				<TOKEN id="token-80-22" start_char="7953" end_char="7960">possible</TOKEN>
				<TOKEN id="token-80-23" start_char="7961" end_char="7961">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-81" start_char="7963" end_char="8023">
				<ORIGINAL_TEXT>On Thursday, he said the investigation has not yet concluded.</ORIGINAL_TEXT>
				<TOKEN id="token-81-0" start_char="7963" end_char="7964">On</TOKEN>
				<TOKEN id="token-81-1" start_char="7966" end_char="7973">Thursday</TOKEN>
				<TOKEN id="token-81-2" start_char="7974" end_char="7974">,</TOKEN>
				<TOKEN id="token-81-3" start_char="7976" end_char="7977">he</TOKEN>
				<TOKEN id="token-81-4" start_char="7979" end_char="7982">said</TOKEN>
				<TOKEN id="token-81-5" start_char="7984" end_char="7986">the</TOKEN>
				<TOKEN id="token-81-6" start_char="7988" end_char="8000">investigation</TOKEN>
				<TOKEN id="token-81-7" start_char="8002" end_char="8004">has</TOKEN>
				<TOKEN id="token-81-8" start_char="8006" end_char="8008">not</TOKEN>
				<TOKEN id="token-81-9" start_char="8010" end_char="8012">yet</TOKEN>
				<TOKEN id="token-81-10" start_char="8014" end_char="8022">concluded</TOKEN>
				<TOKEN id="token-81-11" start_char="8023" end_char="8023">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-82" start_char="8025" end_char="8092">
				<ORIGINAL_TEXT>&quot;Administrative investigations are impartial, thorough and in-depth.</ORIGINAL_TEXT>
				<TOKEN id="token-82-0" start_char="8025" end_char="8025">&quot;</TOKEN>
				<TOKEN id="token-82-1" start_char="8026" end_char="8039">Administrative</TOKEN>
				<TOKEN id="token-82-2" start_char="8041" end_char="8054">investigations</TOKEN>
				<TOKEN id="token-82-3" start_char="8056" end_char="8058">are</TOKEN>
				<TOKEN id="token-82-4" start_char="8060" end_char="8068">impartial</TOKEN>
				<TOKEN id="token-82-5" start_char="8069" end_char="8069">,</TOKEN>
				<TOKEN id="token-82-6" start_char="8071" end_char="8078">thorough</TOKEN>
				<TOKEN id="token-82-7" start_char="8080" end_char="8082">and</TOKEN>
				<TOKEN id="token-82-8" start_char="8084" end_char="8085">in</TOKEN>
				<TOKEN id="token-82-9" start_char="8086" end_char="8086">-</TOKEN>
				<TOKEN id="token-82-10" start_char="8087" end_char="8091">depth</TOKEN>
				<TOKEN id="token-82-11" start_char="8092" end_char="8092">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-83" start_char="8094" end_char="8173">
				<ORIGINAL_TEXT>They are also procedurally fair and respect the rights of individuals,&quot; he said.</ORIGINAL_TEXT>
				<TOKEN id="token-83-0" start_char="8094" end_char="8097">They</TOKEN>
				<TOKEN id="token-83-1" start_char="8099" end_char="8101">are</TOKEN>
				<TOKEN id="token-83-2" start_char="8103" end_char="8106">also</TOKEN>
				<TOKEN id="token-83-3" start_char="8108" end_char="8119">procedurally</TOKEN>
				<TOKEN id="token-83-4" start_char="8121" end_char="8124">fair</TOKEN>
				<TOKEN id="token-83-5" start_char="8126" end_char="8128">and</TOKEN>
				<TOKEN id="token-83-6" start_char="8130" end_char="8136">respect</TOKEN>
				<TOKEN id="token-83-7" start_char="8138" end_char="8140">the</TOKEN>
				<TOKEN id="token-83-8" start_char="8142" end_char="8147">rights</TOKEN>
				<TOKEN id="token-83-9" start_char="8149" end_char="8150">of</TOKEN>
				<TOKEN id="token-83-10" start_char="8152" end_char="8162">individuals</TOKEN>
				<TOKEN id="token-83-11" start_char="8163" end_char="8164">,&quot;</TOKEN>
				<TOKEN id="token-83-12" start_char="8166" end_char="8167">he</TOKEN>
				<TOKEN id="token-83-13" start_char="8169" end_char="8172">said</TOKEN>
				<TOKEN id="token-83-14" start_char="8173" end_char="8173">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-84" start_char="8175" end_char="8425">
				<ORIGINAL_TEXT>Gordon Houlden, director of the China Institute at the University of Alberta, said he welcomes scientific collaboration and exchanges with China, &quot;but there has to be a framework of rules in place&quot; and Canada's intellectual property must be protected.</ORIGINAL_TEXT>
				<TOKEN id="token-84-0" start_char="8175" end_char="8180">Gordon</TOKEN>
				<TOKEN id="token-84-1" start_char="8182" end_char="8188">Houlden</TOKEN>
				<TOKEN id="token-84-2" start_char="8189" end_char="8189">,</TOKEN>
				<TOKEN id="token-84-3" start_char="8191" end_char="8198">director</TOKEN>
				<TOKEN id="token-84-4" start_char="8200" end_char="8201">of</TOKEN>
				<TOKEN id="token-84-5" start_char="8203" end_char="8205">the</TOKEN>
				<TOKEN id="token-84-6" start_char="8207" end_char="8211">China</TOKEN>
				<TOKEN id="token-84-7" start_char="8213" end_char="8221">Institute</TOKEN>
				<TOKEN id="token-84-8" start_char="8223" end_char="8224">at</TOKEN>
				<TOKEN id="token-84-9" start_char="8226" end_char="8228">the</TOKEN>
				<TOKEN id="token-84-10" start_char="8230" end_char="8239">University</TOKEN>
				<TOKEN id="token-84-11" start_char="8241" end_char="8242">of</TOKEN>
				<TOKEN id="token-84-12" start_char="8244" end_char="8250">Alberta</TOKEN>
				<TOKEN id="token-84-13" start_char="8251" end_char="8251">,</TOKEN>
				<TOKEN id="token-84-14" start_char="8253" end_char="8256">said</TOKEN>
				<TOKEN id="token-84-15" start_char="8258" end_char="8259">he</TOKEN>
				<TOKEN id="token-84-16" start_char="8261" end_char="8268">welcomes</TOKEN>
				<TOKEN id="token-84-17" start_char="8270" end_char="8279">scientific</TOKEN>
				<TOKEN id="token-84-18" start_char="8281" end_char="8293">collaboration</TOKEN>
				<TOKEN id="token-84-19" start_char="8295" end_char="8297">and</TOKEN>
				<TOKEN id="token-84-20" start_char="8299" end_char="8307">exchanges</TOKEN>
				<TOKEN id="token-84-21" start_char="8309" end_char="8312">with</TOKEN>
				<TOKEN id="token-84-22" start_char="8314" end_char="8318">China</TOKEN>
				<TOKEN id="token-84-23" start_char="8319" end_char="8319">,</TOKEN>
				<TOKEN id="token-84-24" start_char="8321" end_char="8321">&quot;</TOKEN>
				<TOKEN id="token-84-25" start_char="8322" end_char="8324">but</TOKEN>
				<TOKEN id="token-84-26" start_char="8326" end_char="8330">there</TOKEN>
				<TOKEN id="token-84-27" start_char="8332" end_char="8334">has</TOKEN>
				<TOKEN id="token-84-28" start_char="8336" end_char="8337">to</TOKEN>
				<TOKEN id="token-84-29" start_char="8339" end_char="8340">be</TOKEN>
				<TOKEN id="token-84-30" start_char="8342" end_char="8342">a</TOKEN>
				<TOKEN id="token-84-31" start_char="8344" end_char="8352">framework</TOKEN>
				<TOKEN id="token-84-32" start_char="8354" end_char="8355">of</TOKEN>
				<TOKEN id="token-84-33" start_char="8357" end_char="8361">rules</TOKEN>
				<TOKEN id="token-84-34" start_char="8363" end_char="8364">in</TOKEN>
				<TOKEN id="token-84-35" start_char="8366" end_char="8370">place</TOKEN>
				<TOKEN id="token-84-36" start_char="8371" end_char="8371">&quot;</TOKEN>
				<TOKEN id="token-84-37" start_char="8373" end_char="8375">and</TOKEN>
				<TOKEN id="token-84-38" start_char="8377" end_char="8382">Canada</TOKEN>
				<TOKEN id="token-84-39" start_char="8383" end_char="8383">'</TOKEN>
				<TOKEN id="token-84-40" start_char="8384" end_char="8384">s</TOKEN>
				<TOKEN id="token-84-41" start_char="8386" end_char="8397">intellectual</TOKEN>
				<TOKEN id="token-84-42" start_char="8399" end_char="8406">property</TOKEN>
				<TOKEN id="token-84-43" start_char="8408" end_char="8411">must</TOKEN>
				<TOKEN id="token-84-44" start_char="8413" end_char="8414">be</TOKEN>
				<TOKEN id="token-84-45" start_char="8416" end_char="8424">protected</TOKEN>
				<TOKEN id="token-84-46" start_char="8425" end_char="8425">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-85" start_char="8427" end_char="8515">
				<ORIGINAL_TEXT>Houlden, a former diplomat, has many unanswered questions about this particular shipment.</ORIGINAL_TEXT>
				<TOKEN id="token-85-0" start_char="8427" end_char="8433">Houlden</TOKEN>
				<TOKEN id="token-85-1" start_char="8434" end_char="8434">,</TOKEN>
				<TOKEN id="token-85-2" start_char="8436" end_char="8436">a</TOKEN>
				<TOKEN id="token-85-3" start_char="8438" end_char="8443">former</TOKEN>
				<TOKEN id="token-85-4" start_char="8445" end_char="8452">diplomat</TOKEN>
				<TOKEN id="token-85-5" start_char="8453" end_char="8453">,</TOKEN>
				<TOKEN id="token-85-6" start_char="8455" end_char="8457">has</TOKEN>
				<TOKEN id="token-85-7" start_char="8459" end_char="8462">many</TOKEN>
				<TOKEN id="token-85-8" start_char="8464" end_char="8473">unanswered</TOKEN>
				<TOKEN id="token-85-9" start_char="8475" end_char="8483">questions</TOKEN>
				<TOKEN id="token-85-10" start_char="8485" end_char="8489">about</TOKEN>
				<TOKEN id="token-85-11" start_char="8491" end_char="8494">this</TOKEN>
				<TOKEN id="token-85-12" start_char="8496" end_char="8505">particular</TOKEN>
				<TOKEN id="token-85-13" start_char="8507" end_char="8514">shipment</TOKEN>
				<TOKEN id="token-85-14" start_char="8515" end_char="8515">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-86" start_char="8517" end_char="8720">
				<ORIGINAL_TEXT>Gordon Houlden, the director of the China Institute at the University of Alberta, says there are many good reasons to share biological samples between labs, but any transfers must follow proper protocols.</ORIGINAL_TEXT>
				<TOKEN id="token-86-0" start_char="8517" end_char="8522">Gordon</TOKEN>
				<TOKEN id="token-86-1" start_char="8524" end_char="8530">Houlden</TOKEN>
				<TOKEN id="token-86-2" start_char="8531" end_char="8531">,</TOKEN>
				<TOKEN id="token-86-3" start_char="8533" end_char="8535">the</TOKEN>
				<TOKEN id="token-86-4" start_char="8537" end_char="8544">director</TOKEN>
				<TOKEN id="token-86-5" start_char="8546" end_char="8547">of</TOKEN>
				<TOKEN id="token-86-6" start_char="8549" end_char="8551">the</TOKEN>
				<TOKEN id="token-86-7" start_char="8553" end_char="8557">China</TOKEN>
				<TOKEN id="token-86-8" start_char="8559" end_char="8567">Institute</TOKEN>
				<TOKEN id="token-86-9" start_char="8569" end_char="8570">at</TOKEN>
				<TOKEN id="token-86-10" start_char="8572" end_char="8574">the</TOKEN>
				<TOKEN id="token-86-11" start_char="8576" end_char="8585">University</TOKEN>
				<TOKEN id="token-86-12" start_char="8587" end_char="8588">of</TOKEN>
				<TOKEN id="token-86-13" start_char="8590" end_char="8596">Alberta</TOKEN>
				<TOKEN id="token-86-14" start_char="8597" end_char="8597">,</TOKEN>
				<TOKEN id="token-86-15" start_char="8599" end_char="8602">says</TOKEN>
				<TOKEN id="token-86-16" start_char="8604" end_char="8608">there</TOKEN>
				<TOKEN id="token-86-17" start_char="8610" end_char="8612">are</TOKEN>
				<TOKEN id="token-86-18" start_char="8614" end_char="8617">many</TOKEN>
				<TOKEN id="token-86-19" start_char="8619" end_char="8622">good</TOKEN>
				<TOKEN id="token-86-20" start_char="8624" end_char="8630">reasons</TOKEN>
				<TOKEN id="token-86-21" start_char="8632" end_char="8633">to</TOKEN>
				<TOKEN id="token-86-22" start_char="8635" end_char="8639">share</TOKEN>
				<TOKEN id="token-86-23" start_char="8641" end_char="8650">biological</TOKEN>
				<TOKEN id="token-86-24" start_char="8652" end_char="8658">samples</TOKEN>
				<TOKEN id="token-86-25" start_char="8660" end_char="8666">between</TOKEN>
				<TOKEN id="token-86-26" start_char="8668" end_char="8671">labs</TOKEN>
				<TOKEN id="token-86-27" start_char="8672" end_char="8672">,</TOKEN>
				<TOKEN id="token-86-28" start_char="8674" end_char="8676">but</TOKEN>
				<TOKEN id="token-86-29" start_char="8678" end_char="8680">any</TOKEN>
				<TOKEN id="token-86-30" start_char="8682" end_char="8690">transfers</TOKEN>
				<TOKEN id="token-86-31" start_char="8692" end_char="8695">must</TOKEN>
				<TOKEN id="token-86-32" start_char="8697" end_char="8702">follow</TOKEN>
				<TOKEN id="token-86-33" start_char="8704" end_char="8709">proper</TOKEN>
				<TOKEN id="token-86-34" start_char="8711" end_char="8719">protocols</TOKEN>
				<TOKEN id="token-86-35" start_char="8720" end_char="8720">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-87" start_char="8722" end_char="8738">
				<ORIGINAL_TEXT>(Terry Reith/CBC)</ORIGINAL_TEXT>
				<TOKEN id="token-87-0" start_char="8722" end_char="8722">(</TOKEN>
				<TOKEN id="token-87-1" start_char="8723" end_char="8727">Terry</TOKEN>
				<TOKEN id="token-87-2" start_char="8729" end_char="8733">Reith</TOKEN>
				<TOKEN id="token-87-3" start_char="8734" end_char="8734">/</TOKEN>
				<TOKEN id="token-87-4" start_char="8735" end_char="8737">CBC</TOKEN>
				<TOKEN id="token-87-5" start_char="8738" end_char="8738">)</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-88" start_char="8740" end_char="9013">
				<ORIGINAL_TEXT>A vacuum of information is always a problem, especially in a situation of heightened tension with China over the arrest of a Huawei executive in Canada, the seemingly retaliatory arrest of two Canadian men in China and questions over the origins of the coronavirus, he said.</ORIGINAL_TEXT>
				<TOKEN id="token-88-0" start_char="8740" end_char="8740">A</TOKEN>
				<TOKEN id="token-88-1" start_char="8742" end_char="8747">vacuum</TOKEN>
				<TOKEN id="token-88-2" start_char="8749" end_char="8750">of</TOKEN>
				<TOKEN id="token-88-3" start_char="8752" end_char="8762">information</TOKEN>
				<TOKEN id="token-88-4" start_char="8764" end_char="8765">is</TOKEN>
				<TOKEN id="token-88-5" start_char="8767" end_char="8772">always</TOKEN>
				<TOKEN id="token-88-6" start_char="8774" end_char="8774">a</TOKEN>
				<TOKEN id="token-88-7" start_char="8776" end_char="8782">problem</TOKEN>
				<TOKEN id="token-88-8" start_char="8783" end_char="8783">,</TOKEN>
				<TOKEN id="token-88-9" start_char="8785" end_char="8794">especially</TOKEN>
				<TOKEN id="token-88-10" start_char="8796" end_char="8797">in</TOKEN>
				<TOKEN id="token-88-11" start_char="8799" end_char="8799">a</TOKEN>
				<TOKEN id="token-88-12" start_char="8801" end_char="8809">situation</TOKEN>
				<TOKEN id="token-88-13" start_char="8811" end_char="8812">of</TOKEN>
				<TOKEN id="token-88-14" start_char="8814" end_char="8823">heightened</TOKEN>
				<TOKEN id="token-88-15" start_char="8825" end_char="8831">tension</TOKEN>
				<TOKEN id="token-88-16" start_char="8833" end_char="8836">with</TOKEN>
				<TOKEN id="token-88-17" start_char="8838" end_char="8842">China</TOKEN>
				<TOKEN id="token-88-18" start_char="8844" end_char="8847">over</TOKEN>
				<TOKEN id="token-88-19" start_char="8849" end_char="8851">the</TOKEN>
				<TOKEN id="token-88-20" start_char="8853" end_char="8858">arrest</TOKEN>
				<TOKEN id="token-88-21" start_char="8860" end_char="8861">of</TOKEN>
				<TOKEN id="token-88-22" start_char="8863" end_char="8863">a</TOKEN>
				<TOKEN id="token-88-23" start_char="8865" end_char="8870">Huawei</TOKEN>
				<TOKEN id="token-88-24" start_char="8872" end_char="8880">executive</TOKEN>
				<TOKEN id="token-88-25" start_char="8882" end_char="8883">in</TOKEN>
				<TOKEN id="token-88-26" start_char="8885" end_char="8890">Canada</TOKEN>
				<TOKEN id="token-88-27" start_char="8891" end_char="8891">,</TOKEN>
				<TOKEN id="token-88-28" start_char="8893" end_char="8895">the</TOKEN>
				<TOKEN id="token-88-29" start_char="8897" end_char="8905">seemingly</TOKEN>
				<TOKEN id="token-88-30" start_char="8907" end_char="8917">retaliatory</TOKEN>
				<TOKEN id="token-88-31" start_char="8919" end_char="8924">arrest</TOKEN>
				<TOKEN id="token-88-32" start_char="8926" end_char="8927">of</TOKEN>
				<TOKEN id="token-88-33" start_char="8929" end_char="8931">two</TOKEN>
				<TOKEN id="token-88-34" start_char="8933" end_char="8940">Canadian</TOKEN>
				<TOKEN id="token-88-35" start_char="8942" end_char="8944">men</TOKEN>
				<TOKEN id="token-88-36" start_char="8946" end_char="8947">in</TOKEN>
				<TOKEN id="token-88-37" start_char="8949" end_char="8953">China</TOKEN>
				<TOKEN id="token-88-38" start_char="8955" end_char="8957">and</TOKEN>
				<TOKEN id="token-88-39" start_char="8959" end_char="8967">questions</TOKEN>
				<TOKEN id="token-88-40" start_char="8969" end_char="8972">over</TOKEN>
				<TOKEN id="token-88-41" start_char="8974" end_char="8976">the</TOKEN>
				<TOKEN id="token-88-42" start_char="8978" end_char="8984">origins</TOKEN>
				<TOKEN id="token-88-43" start_char="8986" end_char="8987">of</TOKEN>
				<TOKEN id="token-88-44" start_char="8989" end_char="8991">the</TOKEN>
				<TOKEN id="token-88-45" start_char="8993" end_char="9003">coronavirus</TOKEN>
				<TOKEN id="token-88-46" start_char="9004" end_char="9004">,</TOKEN>
				<TOKEN id="token-88-47" start_char="9006" end_char="9007">he</TOKEN>
				<TOKEN id="token-88-48" start_char="9009" end_char="9012">said</TOKEN>
				<TOKEN id="token-88-49" start_char="9013" end_char="9013">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-89" start_char="9015" end_char="9138">
				<ORIGINAL_TEXT>&quot;There's also a danger if you don't provide information that people will jump always to the worst conclusion,&quot; Houlden said.</ORIGINAL_TEXT>
				<TOKEN id="token-89-0" start_char="9015" end_char="9015">&quot;</TOKEN>
				<TOKEN id="token-89-1" start_char="9016" end_char="9020">There</TOKEN>
				<TOKEN id="token-89-2" start_char="9021" end_char="9021">'</TOKEN>
				<TOKEN id="token-89-3" start_char="9022" end_char="9022">s</TOKEN>
				<TOKEN id="token-89-4" start_char="9024" end_char="9027">also</TOKEN>
				<TOKEN id="token-89-5" start_char="9029" end_char="9029">a</TOKEN>
				<TOKEN id="token-89-6" start_char="9031" end_char="9036">danger</TOKEN>
				<TOKEN id="token-89-7" start_char="9038" end_char="9039">if</TOKEN>
				<TOKEN id="token-89-8" start_char="9041" end_char="9043">you</TOKEN>
				<TOKEN id="token-89-9" start_char="9045" end_char="9047">don</TOKEN>
				<TOKEN id="token-89-10" start_char="9048" end_char="9048">'</TOKEN>
				<TOKEN id="token-89-11" start_char="9049" end_char="9049">t</TOKEN>
				<TOKEN id="token-89-12" start_char="9051" end_char="9057">provide</TOKEN>
				<TOKEN id="token-89-13" start_char="9059" end_char="9069">information</TOKEN>
				<TOKEN id="token-89-14" start_char="9071" end_char="9074">that</TOKEN>
				<TOKEN id="token-89-15" start_char="9076" end_char="9081">people</TOKEN>
				<TOKEN id="token-89-16" start_char="9083" end_char="9086">will</TOKEN>
				<TOKEN id="token-89-17" start_char="9088" end_char="9091">jump</TOKEN>
				<TOKEN id="token-89-18" start_char="9093" end_char="9098">always</TOKEN>
				<TOKEN id="token-89-19" start_char="9100" end_char="9101">to</TOKEN>
				<TOKEN id="token-89-20" start_char="9103" end_char="9105">the</TOKEN>
				<TOKEN id="token-89-21" start_char="9107" end_char="9111">worst</TOKEN>
				<TOKEN id="token-89-22" start_char="9113" end_char="9122">conclusion</TOKEN>
				<TOKEN id="token-89-23" start_char="9123" end_char="9124">,&quot;</TOKEN>
				<TOKEN id="token-89-24" start_char="9126" end_char="9132">Houlden</TOKEN>
				<TOKEN id="token-89-25" start_char="9134" end_char="9137">said</TOKEN>
				<TOKEN id="token-89-26" start_char="9138" end_char="9138">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-90" start_char="9140" end_char="9212">
				<ORIGINAL_TEXT>Current NML head Matthew Gilmour was not made available for an interview.</ORIGINAL_TEXT>
				<TOKEN id="token-90-0" start_char="9140" end_char="9146">Current</TOKEN>
				<TOKEN id="token-90-1" start_char="9148" end_char="9150">NML</TOKEN>
				<TOKEN id="token-90-2" start_char="9152" end_char="9155">head</TOKEN>
				<TOKEN id="token-90-3" start_char="9157" end_char="9163">Matthew</TOKEN>
				<TOKEN id="token-90-4" start_char="9165" end_char="9171">Gilmour</TOKEN>
				<TOKEN id="token-90-5" start_char="9173" end_char="9175">was</TOKEN>
				<TOKEN id="token-90-6" start_char="9177" end_char="9179">not</TOKEN>
				<TOKEN id="token-90-7" start_char="9181" end_char="9184">made</TOKEN>
				<TOKEN id="token-90-8" start_char="9186" end_char="9194">available</TOKEN>
				<TOKEN id="token-90-9" start_char="9196" end_char="9198">for</TOKEN>
				<TOKEN id="token-90-10" start_char="9200" end_char="9201">an</TOKEN>
				<TOKEN id="token-90-11" start_char="9203" end_char="9211">interview</TOKEN>
				<TOKEN id="token-90-12" start_char="9212" end_char="9212">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-91" start_char="9214" end_char="9294">
				<ORIGINAL_TEXT>He is leaving as of July to work for the U.K.-based Quadram Institute Bioscience.</ORIGINAL_TEXT>
				<TOKEN id="token-91-0" start_char="9214" end_char="9215">He</TOKEN>
				<TOKEN id="token-91-1" start_char="9217" end_char="9218">is</TOKEN>
				<TOKEN id="token-91-2" start_char="9220" end_char="9226">leaving</TOKEN>
				<TOKEN id="token-91-3" start_char="9228" end_char="9229">as</TOKEN>
				<TOKEN id="token-91-4" start_char="9231" end_char="9232">of</TOKEN>
				<TOKEN id="token-91-5" start_char="9234" end_char="9237">July</TOKEN>
				<TOKEN id="token-91-6" start_char="9239" end_char="9240">to</TOKEN>
				<TOKEN id="token-91-7" start_char="9242" end_char="9245">work</TOKEN>
				<TOKEN id="token-91-8" start_char="9247" end_char="9249">for</TOKEN>
				<TOKEN id="token-91-9" start_char="9251" end_char="9253">the</TOKEN>
				<TOKEN id="token-91-10" start_char="9255" end_char="9255">U</TOKEN>
				<TOKEN id="token-91-11" start_char="9256" end_char="9256">.</TOKEN>
				<TOKEN id="token-91-12" start_char="9257" end_char="9257">K</TOKEN>
				<TOKEN id="token-91-13" start_char="9258" end_char="9259">.-</TOKEN>
				<TOKEN id="token-91-14" start_char="9260" end_char="9264">based</TOKEN>
				<TOKEN id="token-91-15" start_char="9266" end_char="9272">Quadram</TOKEN>
				<TOKEN id="token-91-16" start_char="9274" end_char="9282">Institute</TOKEN>
				<TOKEN id="token-91-17" start_char="9284" end_char="9293">Bioscience</TOKEN>
				<TOKEN id="token-91-18" start_char="9294" end_char="9294">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-92" start_char="9296" end_char="9398">
				<ORIGINAL_TEXT>His medical adviser, Dr. Guillaume Poliquin, will take over until a permanent replacement can be found.</ORIGINAL_TEXT>
				<TOKEN id="token-92-0" start_char="9296" end_char="9298">His</TOKEN>
				<TOKEN id="token-92-1" start_char="9300" end_char="9306">medical</TOKEN>
				<TOKEN id="token-92-2" start_char="9308" end_char="9314">adviser</TOKEN>
				<TOKEN id="token-92-3" start_char="9315" end_char="9315">,</TOKEN>
				<TOKEN id="token-92-4" start_char="9317" end_char="9318">Dr</TOKEN>
				<TOKEN id="token-92-5" start_char="9319" end_char="9319">.</TOKEN>
				<TOKEN id="token-92-6" start_char="9321" end_char="9329">Guillaume</TOKEN>
				<TOKEN id="token-92-7" start_char="9331" end_char="9338">Poliquin</TOKEN>
				<TOKEN id="token-92-8" start_char="9339" end_char="9339">,</TOKEN>
				<TOKEN id="token-92-9" start_char="9341" end_char="9344">will</TOKEN>
				<TOKEN id="token-92-10" start_char="9346" end_char="9349">take</TOKEN>
				<TOKEN id="token-92-11" start_char="9351" end_char="9354">over</TOKEN>
				<TOKEN id="token-92-12" start_char="9356" end_char="9360">until</TOKEN>
				<TOKEN id="token-92-13" start_char="9362" end_char="9362">a</TOKEN>
				<TOKEN id="token-92-14" start_char="9364" end_char="9372">permanent</TOKEN>
				<TOKEN id="token-92-15" start_char="9374" end_char="9384">replacement</TOKEN>
				<TOKEN id="token-92-16" start_char="9386" end_char="9388">can</TOKEN>
				<TOKEN id="token-92-17" start_char="9390" end_char="9391">be</TOKEN>
				<TOKEN id="token-92-18" start_char="9393" end_char="9397">found</TOKEN>
				<TOKEN id="token-92-19" start_char="9398" end_char="9398">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-0-93" start_char="9400" end_char="9443">
				<ORIGINAL_TEXT>Qiu could also not be reached for a comment.</ORIGINAL_TEXT>
				<TOKEN id="token-93-0" start_char="9400" end_char="9402">Qiu</TOKEN>
				<TOKEN id="token-93-1" start_char="9404" end_char="9408">could</TOKEN>
				<TOKEN id="token-93-2" start_char="9410" end_char="9413">also</TOKEN>
				<TOKEN id="token-93-3" start_char="9415" end_char="9417">not</TOKEN>
				<TOKEN id="token-93-4" start_char="9419" end_char="9420">be</TOKEN>
				<TOKEN id="token-93-5" start_char="9422" end_char="9428">reached</TOKEN>
				<TOKEN id="token-93-6" start_char="9430" end_char="9432">for</TOKEN>
				<TOKEN id="token-93-7" start_char="9434" end_char="9434">a</TOKEN>
				<TOKEN id="token-93-8" start_char="9436" end_char="9442">comment</TOKEN>
				<TOKEN id="token-93-9" start_char="9443" end_char="9443">.</TOKEN>
			</SEG>
		</TEXT>
	</DOC>
</LCTL_TEXT>
