<?xml version="1.0" encoding="utf-8"?>
<LCTL_TEXT>
	<DOC id="covid19scenario-201">
		<TEXT>
			<SEG id="covid19scenario-201-0" start_char="0" end_char="222">
				<ORIGINAL_TEXT>Nos habéis preguntado por publicaciones como esta o esta en las que se afirma que al llevar mascarilla todos los gérmenes que exhalamos quedan “atrapados” en ella y aumenta la probabilidad de dar positivo en una prueba PCR.</ORIGINAL_TEXT>
				<TOKEN id="token-0-0" start_char="0" end_char="2">Nos</TOKEN>
				<TOKEN id="token-0-1" start_char="4" end_char="9">habéis</TOKEN>
				<TOKEN id="token-0-2" start_char="11" end_char="20">preguntado</TOKEN>
				<TOKEN id="token-0-3" start_char="22" end_char="24">por</TOKEN>
				<TOKEN id="token-0-4" start_char="26" end_char="38">publicaciones</TOKEN>
				<TOKEN id="token-0-5" start_char="40" end_char="43">como</TOKEN>
				<TOKEN id="token-0-6" start_char="45" end_char="48">esta</TOKEN>
				<TOKEN id="token-0-7" start_char="50" end_char="50">o</TOKEN>
				<TOKEN id="token-0-8" start_char="52" end_char="55">esta</TOKEN>
				<TOKEN id="token-0-9" start_char="57" end_char="58">en</TOKEN>
				<TOKEN id="token-0-10" start_char="60" end_char="62">las</TOKEN>
				<TOKEN id="token-0-11" start_char="64" end_char="66">que</TOKEN>
				<TOKEN id="token-0-12" start_char="68" end_char="69">se</TOKEN>
				<TOKEN id="token-0-13" start_char="71" end_char="76">afirma</TOKEN>
				<TOKEN id="token-0-14" start_char="78" end_char="80">que</TOKEN>
				<TOKEN id="token-0-15" start_char="82" end_char="83">al</TOKEN>
				<TOKEN id="token-0-16" start_char="85" end_char="90">llevar</TOKEN>
				<TOKEN id="token-0-17" start_char="92" end_char="101">mascarilla</TOKEN>
				<TOKEN id="token-0-18" start_char="103" end_char="107">todos</TOKEN>
				<TOKEN id="token-0-19" start_char="109" end_char="111">los</TOKEN>
				<TOKEN id="token-0-20" start_char="113" end_char="120">gérmenes</TOKEN>
				<TOKEN id="token-0-21" start_char="122" end_char="124">que</TOKEN>
				<TOKEN id="token-0-22" start_char="126" end_char="134">exhalamos</TOKEN>
				<TOKEN id="token-0-23" start_char="136" end_char="141">quedan</TOKEN>
				<TOKEN id="token-0-24" start_char="143" end_char="143">“</TOKEN>
				<TOKEN id="token-0-25" start_char="144" end_char="152">atrapados</TOKEN>
				<TOKEN id="token-0-26" start_char="153" end_char="153">”</TOKEN>
				<TOKEN id="token-0-27" start_char="155" end_char="156">en</TOKEN>
				<TOKEN id="token-0-28" start_char="158" end_char="161">ella</TOKEN>
				<TOKEN id="token-0-29" start_char="163" end_char="163">y</TOKEN>
				<TOKEN id="token-0-30" start_char="165" end_char="171">aumenta</TOKEN>
				<TOKEN id="token-0-31" start_char="173" end_char="174">la</TOKEN>
				<TOKEN id="token-0-32" start_char="176" end_char="187">probabilidad</TOKEN>
				<TOKEN id="token-0-33" start_char="189" end_char="190">de</TOKEN>
				<TOKEN id="token-0-34" start_char="192" end_char="194">dar</TOKEN>
				<TOKEN id="token-0-35" start_char="196" end_char="203">positivo</TOKEN>
				<TOKEN id="token-0-36" start_char="205" end_char="206">en</TOKEN>
				<TOKEN id="token-0-37" start_char="208" end_char="210">una</TOKEN>
				<TOKEN id="token-0-38" start_char="212" end_char="217">prueba</TOKEN>
				<TOKEN id="token-0-39" start_char="219" end_char="221">PCR</TOKEN>
				<TOKEN id="token-0-40" start_char="222" end_char="222">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-1" start_char="224" end_char="236">
				<ORIGINAL_TEXT>No es cierto.</ORIGINAL_TEXT>
				<TOKEN id="token-1-0" start_char="224" end_char="225">No</TOKEN>
				<TOKEN id="token-1-1" start_char="227" end_char="228">es</TOKEN>
				<TOKEN id="token-1-2" start_char="230" end_char="235">cierto</TOKEN>
				<TOKEN id="token-1-3" start_char="236" end_char="236">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-2" start_char="238" end_char="409">
				<ORIGINAL_TEXT>Pepe Alcamí, virólogo del Instituto de Salud Carlos III, indica a Maldita Ciencia que si el virus está en la parte interna de tu mascarilla es que lo tienes en tu garganta.</ORIGINAL_TEXT>
				<TOKEN id="token-2-0" start_char="238" end_char="241">Pepe</TOKEN>
				<TOKEN id="token-2-1" start_char="243" end_char="248">Alcamí</TOKEN>
				<TOKEN id="token-2-2" start_char="249" end_char="249">,</TOKEN>
				<TOKEN id="token-2-3" start_char="251" end_char="258">virólogo</TOKEN>
				<TOKEN id="token-2-4" start_char="260" end_char="262">del</TOKEN>
				<TOKEN id="token-2-5" start_char="264" end_char="272">Instituto</TOKEN>
				<TOKEN id="token-2-6" start_char="274" end_char="275">de</TOKEN>
				<TOKEN id="token-2-7" start_char="277" end_char="281">Salud</TOKEN>
				<TOKEN id="token-2-8" start_char="283" end_char="288">Carlos</TOKEN>
				<TOKEN id="token-2-9" start_char="290" end_char="292">III</TOKEN>
				<TOKEN id="token-2-10" start_char="293" end_char="293">,</TOKEN>
				<TOKEN id="token-2-11" start_char="295" end_char="300">indica</TOKEN>
				<TOKEN id="token-2-12" start_char="302" end_char="302">a</TOKEN>
				<TOKEN id="token-2-13" start_char="304" end_char="310">Maldita</TOKEN>
				<TOKEN id="token-2-14" start_char="312" end_char="318">Ciencia</TOKEN>
				<TOKEN id="token-2-15" start_char="320" end_char="322">que</TOKEN>
				<TOKEN id="token-2-16" start_char="324" end_char="325">si</TOKEN>
				<TOKEN id="token-2-17" start_char="327" end_char="328">el</TOKEN>
				<TOKEN id="token-2-18" start_char="330" end_char="334">virus</TOKEN>
				<TOKEN id="token-2-19" start_char="336" end_char="339">está</TOKEN>
				<TOKEN id="token-2-20" start_char="341" end_char="342">en</TOKEN>
				<TOKEN id="token-2-21" start_char="344" end_char="345">la</TOKEN>
				<TOKEN id="token-2-22" start_char="347" end_char="351">parte</TOKEN>
				<TOKEN id="token-2-23" start_char="353" end_char="359">interna</TOKEN>
				<TOKEN id="token-2-24" start_char="361" end_char="362">de</TOKEN>
				<TOKEN id="token-2-25" start_char="364" end_char="365">tu</TOKEN>
				<TOKEN id="token-2-26" start_char="367" end_char="376">mascarilla</TOKEN>
				<TOKEN id="token-2-27" start_char="378" end_char="379">es</TOKEN>
				<TOKEN id="token-2-28" start_char="381" end_char="383">que</TOKEN>
				<TOKEN id="token-2-29" start_char="385" end_char="386">lo</TOKEN>
				<TOKEN id="token-2-30" start_char="388" end_char="393">tienes</TOKEN>
				<TOKEN id="token-2-31" start_char="395" end_char="396">en</TOKEN>
				<TOKEN id="token-2-32" start_char="398" end_char="399">tu</TOKEN>
				<TOKEN id="token-2-33" start_char="401" end_char="408">garganta</TOKEN>
				<TOKEN id="token-2-34" start_char="409" end_char="409">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-3" start_char="411" end_char="590">
				<ORIGINAL_TEXT>Si no, la mascarilla podrá tener otros microbios, bacterias que estén en la garganta o incluso otros virus pero estos &quot;no serán amplificados por una PCR específica de coronavirus&quot;.</ORIGINAL_TEXT>
				<TOKEN id="token-3-0" start_char="411" end_char="412">Si</TOKEN>
				<TOKEN id="token-3-1" start_char="414" end_char="415">no</TOKEN>
				<TOKEN id="token-3-2" start_char="416" end_char="416">,</TOKEN>
				<TOKEN id="token-3-3" start_char="418" end_char="419">la</TOKEN>
				<TOKEN id="token-3-4" start_char="421" end_char="430">mascarilla</TOKEN>
				<TOKEN id="token-3-5" start_char="432" end_char="436">podrá</TOKEN>
				<TOKEN id="token-3-6" start_char="438" end_char="442">tener</TOKEN>
				<TOKEN id="token-3-7" start_char="444" end_char="448">otros</TOKEN>
				<TOKEN id="token-3-8" start_char="450" end_char="458">microbios</TOKEN>
				<TOKEN id="token-3-9" start_char="459" end_char="459">,</TOKEN>
				<TOKEN id="token-3-10" start_char="461" end_char="469">bacterias</TOKEN>
				<TOKEN id="token-3-11" start_char="471" end_char="473">que</TOKEN>
				<TOKEN id="token-3-12" start_char="475" end_char="479">estén</TOKEN>
				<TOKEN id="token-3-13" start_char="481" end_char="482">en</TOKEN>
				<TOKEN id="token-3-14" start_char="484" end_char="485">la</TOKEN>
				<TOKEN id="token-3-15" start_char="487" end_char="494">garganta</TOKEN>
				<TOKEN id="token-3-16" start_char="496" end_char="496">o</TOKEN>
				<TOKEN id="token-3-17" start_char="498" end_char="504">incluso</TOKEN>
				<TOKEN id="token-3-18" start_char="506" end_char="510">otros</TOKEN>
				<TOKEN id="token-3-19" start_char="512" end_char="516">virus</TOKEN>
				<TOKEN id="token-3-20" start_char="518" end_char="521">pero</TOKEN>
				<TOKEN id="token-3-21" start_char="523" end_char="527">estos</TOKEN>
				<TOKEN id="token-3-22" start_char="529" end_char="529">&quot;</TOKEN>
				<TOKEN id="token-3-23" start_char="530" end_char="531">no</TOKEN>
				<TOKEN id="token-3-24" start_char="533" end_char="537">serán</TOKEN>
				<TOKEN id="token-3-25" start_char="539" end_char="550">amplificados</TOKEN>
				<TOKEN id="token-3-26" start_char="552" end_char="554">por</TOKEN>
				<TOKEN id="token-3-27" start_char="556" end_char="558">una</TOKEN>
				<TOKEN id="token-3-28" start_char="560" end_char="562">PCR</TOKEN>
				<TOKEN id="token-3-29" start_char="564" end_char="573">específica</TOKEN>
				<TOKEN id="token-3-30" start_char="575" end_char="576">de</TOKEN>
				<TOKEN id="token-3-31" start_char="578" end_char="588">coronavirus</TOKEN>
				<TOKEN id="token-3-32" start_char="589" end_char="590">&quot;.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-4" start_char="592" end_char="608">
				<ORIGINAL_TEXT>Os lo explicamos.</ORIGINAL_TEXT>
				<TOKEN id="token-4-0" start_char="592" end_char="593">Os</TOKEN>
				<TOKEN id="token-4-1" start_char="595" end_char="596">lo</TOKEN>
				<TOKEN id="token-4-2" start_char="598" end_char="607">explicamos</TOKEN>
				<TOKEN id="token-4-3" start_char="608" end_char="608">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-5" start_char="610" end_char="668">
				<ORIGINAL_TEXT>Las pruebas PCR para detectar el SARS-CoV-2 son específicas</ORIGINAL_TEXT>
				<TOKEN id="token-5-0" start_char="610" end_char="612">Las</TOKEN>
				<TOKEN id="token-5-1" start_char="614" end_char="620">pruebas</TOKEN>
				<TOKEN id="token-5-2" start_char="622" end_char="624">PCR</TOKEN>
				<TOKEN id="token-5-3" start_char="626" end_char="629">para</TOKEN>
				<TOKEN id="token-5-4" start_char="631" end_char="638">detectar</TOKEN>
				<TOKEN id="token-5-5" start_char="640" end_char="641">el</TOKEN>
				<TOKEN id="token-5-6" start_char="643" end_char="646">SARS</TOKEN>
				<TOKEN id="token-5-7" start_char="647" end_char="647">-</TOKEN>
				<TOKEN id="token-5-8" start_char="648" end_char="650">CoV</TOKEN>
				<TOKEN id="token-5-9" start_char="651" end_char="651">-</TOKEN>
				<TOKEN id="token-5-10" start_char="652" end_char="652">2</TOKEN>
				<TOKEN id="token-5-11" start_char="654" end_char="656">son</TOKEN>
				<TOKEN id="token-5-12" start_char="658" end_char="668">específicas</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-6" start_char="670" end_char="781">
				<ORIGINAL_TEXT>El mensaje afirma que “a mayor uso de mascarillas, mayor probabilidades de dar positivo en una prueba de Covid”.</ORIGINAL_TEXT>
				<TOKEN id="token-6-0" start_char="670" end_char="671">El</TOKEN>
				<TOKEN id="token-6-1" start_char="673" end_char="679">mensaje</TOKEN>
				<TOKEN id="token-6-2" start_char="681" end_char="686">afirma</TOKEN>
				<TOKEN id="token-6-3" start_char="688" end_char="690">que</TOKEN>
				<TOKEN id="token-6-4" start_char="692" end_char="692">“</TOKEN>
				<TOKEN id="token-6-5" start_char="693" end_char="693">a</TOKEN>
				<TOKEN id="token-6-6" start_char="695" end_char="699">mayor</TOKEN>
				<TOKEN id="token-6-7" start_char="701" end_char="703">uso</TOKEN>
				<TOKEN id="token-6-8" start_char="705" end_char="706">de</TOKEN>
				<TOKEN id="token-6-9" start_char="708" end_char="718">mascarillas</TOKEN>
				<TOKEN id="token-6-10" start_char="719" end_char="719">,</TOKEN>
				<TOKEN id="token-6-11" start_char="721" end_char="725">mayor</TOKEN>
				<TOKEN id="token-6-12" start_char="727" end_char="740">probabilidades</TOKEN>
				<TOKEN id="token-6-13" start_char="742" end_char="743">de</TOKEN>
				<TOKEN id="token-6-14" start_char="745" end_char="747">dar</TOKEN>
				<TOKEN id="token-6-15" start_char="749" end_char="756">positivo</TOKEN>
				<TOKEN id="token-6-16" start_char="758" end_char="759">en</TOKEN>
				<TOKEN id="token-6-17" start_char="761" end_char="763">una</TOKEN>
				<TOKEN id="token-6-18" start_char="765" end_char="770">prueba</TOKEN>
				<TOKEN id="token-6-19" start_char="772" end_char="773">de</TOKEN>
				<TOKEN id="token-6-20" start_char="775" end_char="779">Covid</TOKEN>
				<TOKEN id="token-6-21" start_char="780" end_char="781">”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-7" start_char="783" end_char="940">
				<ORIGINAL_TEXT>“Todos los gérmenes que exhalas, se quedan atrapados en la mascarilla y retornan hacia dentro, los cuales se estancan en el conducto nasal que filtra el aire.</ORIGINAL_TEXT>
				<TOKEN id="token-7-0" start_char="783" end_char="783">“</TOKEN>
				<TOKEN id="token-7-1" start_char="784" end_char="788">Todos</TOKEN>
				<TOKEN id="token-7-2" start_char="790" end_char="792">los</TOKEN>
				<TOKEN id="token-7-3" start_char="794" end_char="801">gérmenes</TOKEN>
				<TOKEN id="token-7-4" start_char="803" end_char="805">que</TOKEN>
				<TOKEN id="token-7-5" start_char="807" end_char="813">exhalas</TOKEN>
				<TOKEN id="token-7-6" start_char="814" end_char="814">,</TOKEN>
				<TOKEN id="token-7-7" start_char="816" end_char="817">se</TOKEN>
				<TOKEN id="token-7-8" start_char="819" end_char="824">quedan</TOKEN>
				<TOKEN id="token-7-9" start_char="826" end_char="834">atrapados</TOKEN>
				<TOKEN id="token-7-10" start_char="836" end_char="837">en</TOKEN>
				<TOKEN id="token-7-11" start_char="839" end_char="840">la</TOKEN>
				<TOKEN id="token-7-12" start_char="842" end_char="851">mascarilla</TOKEN>
				<TOKEN id="token-7-13" start_char="853" end_char="853">y</TOKEN>
				<TOKEN id="token-7-14" start_char="855" end_char="862">retornan</TOKEN>
				<TOKEN id="token-7-15" start_char="864" end_char="868">hacia</TOKEN>
				<TOKEN id="token-7-16" start_char="870" end_char="875">dentro</TOKEN>
				<TOKEN id="token-7-17" start_char="876" end_char="876">,</TOKEN>
				<TOKEN id="token-7-18" start_char="878" end_char="880">los</TOKEN>
				<TOKEN id="token-7-19" start_char="882" end_char="887">cuales</TOKEN>
				<TOKEN id="token-7-20" start_char="889" end_char="890">se</TOKEN>
				<TOKEN id="token-7-21" start_char="892" end_char="899">estancan</TOKEN>
				<TOKEN id="token-7-22" start_char="901" end_char="902">en</TOKEN>
				<TOKEN id="token-7-23" start_char="904" end_char="905">el</TOKEN>
				<TOKEN id="token-7-24" start_char="907" end_char="914">conducto</TOKEN>
				<TOKEN id="token-7-25" start_char="916" end_char="920">nasal</TOKEN>
				<TOKEN id="token-7-26" start_char="922" end_char="924">que</TOKEN>
				<TOKEN id="token-7-27" start_char="926" end_char="931">filtra</TOKEN>
				<TOKEN id="token-7-28" start_char="933" end_char="934">el</TOKEN>
				<TOKEN id="token-7-29" start_char="936" end_char="939">aire</TOKEN>
				<TOKEN id="token-7-30" start_char="940" end_char="940">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-8" start_char="942" end_char="1081">
				<ORIGINAL_TEXT>Luego meten el hisopo en esta cavidad, para agarrar, cuántos más gérmenes mejor, el resultado será un positivo asintomático seguro”, indica.</ORIGINAL_TEXT>
				<TOKEN id="token-8-0" start_char="942" end_char="946">Luego</TOKEN>
				<TOKEN id="token-8-1" start_char="948" end_char="952">meten</TOKEN>
				<TOKEN id="token-8-2" start_char="954" end_char="955">el</TOKEN>
				<TOKEN id="token-8-3" start_char="957" end_char="962">hisopo</TOKEN>
				<TOKEN id="token-8-4" start_char="964" end_char="965">en</TOKEN>
				<TOKEN id="token-8-5" start_char="967" end_char="970">esta</TOKEN>
				<TOKEN id="token-8-6" start_char="972" end_char="978">cavidad</TOKEN>
				<TOKEN id="token-8-7" start_char="979" end_char="979">,</TOKEN>
				<TOKEN id="token-8-8" start_char="981" end_char="984">para</TOKEN>
				<TOKEN id="token-8-9" start_char="986" end_char="992">agarrar</TOKEN>
				<TOKEN id="token-8-10" start_char="993" end_char="993">,</TOKEN>
				<TOKEN id="token-8-11" start_char="995" end_char="1001">cuántos</TOKEN>
				<TOKEN id="token-8-12" start_char="1003" end_char="1005">más</TOKEN>
				<TOKEN id="token-8-13" start_char="1007" end_char="1014">gérmenes</TOKEN>
				<TOKEN id="token-8-14" start_char="1016" end_char="1020">mejor</TOKEN>
				<TOKEN id="token-8-15" start_char="1021" end_char="1021">,</TOKEN>
				<TOKEN id="token-8-16" start_char="1023" end_char="1024">el</TOKEN>
				<TOKEN id="token-8-17" start_char="1026" end_char="1034">resultado</TOKEN>
				<TOKEN id="token-8-18" start_char="1036" end_char="1039">será</TOKEN>
				<TOKEN id="token-8-19" start_char="1041" end_char="1042">un</TOKEN>
				<TOKEN id="token-8-20" start_char="1044" end_char="1051">positivo</TOKEN>
				<TOKEN id="token-8-21" start_char="1053" end_char="1064">asintomático</TOKEN>
				<TOKEN id="token-8-22" start_char="1066" end_char="1071">seguro</TOKEN>
				<TOKEN id="token-8-23" start_char="1072" end_char="1073">”,</TOKEN>
				<TOKEN id="token-8-24" start_char="1075" end_char="1080">indica</TOKEN>
				<TOKEN id="token-8-25" start_char="1081" end_char="1081">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-9" start_char="1083" end_char="1115">
				<ORIGINAL_TEXT>No hay evidencias de que sea así.</ORIGINAL_TEXT>
				<TOKEN id="token-9-0" start_char="1083" end_char="1084">No</TOKEN>
				<TOKEN id="token-9-1" start_char="1086" end_char="1088">hay</TOKEN>
				<TOKEN id="token-9-2" start_char="1090" end_char="1099">evidencias</TOKEN>
				<TOKEN id="token-9-3" start_char="1101" end_char="1102">de</TOKEN>
				<TOKEN id="token-9-4" start_char="1104" end_char="1106">que</TOKEN>
				<TOKEN id="token-9-5" start_char="1108" end_char="1110">sea</TOKEN>
				<TOKEN id="token-9-6" start_char="1112" end_char="1114">así</TOKEN>
				<TOKEN id="token-9-7" start_char="1115" end_char="1115">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-10" start_char="1117" end_char="1324">
				<ORIGINAL_TEXT>Si no se está infectado, por muchos gérmenes que acumule la mascarilla eso no provocaría un positivo en la PCR, ya que esta prueba solo detecta el SARS-Cov-2 y no da falsos positivos por cualquier otro virus.</ORIGINAL_TEXT>
				<TOKEN id="token-10-0" start_char="1117" end_char="1118">Si</TOKEN>
				<TOKEN id="token-10-1" start_char="1120" end_char="1121">no</TOKEN>
				<TOKEN id="token-10-2" start_char="1123" end_char="1124">se</TOKEN>
				<TOKEN id="token-10-3" start_char="1126" end_char="1129">está</TOKEN>
				<TOKEN id="token-10-4" start_char="1131" end_char="1139">infectado</TOKEN>
				<TOKEN id="token-10-5" start_char="1140" end_char="1140">,</TOKEN>
				<TOKEN id="token-10-6" start_char="1142" end_char="1144">por</TOKEN>
				<TOKEN id="token-10-7" start_char="1146" end_char="1151">muchos</TOKEN>
				<TOKEN id="token-10-8" start_char="1153" end_char="1160">gérmenes</TOKEN>
				<TOKEN id="token-10-9" start_char="1162" end_char="1164">que</TOKEN>
				<TOKEN id="token-10-10" start_char="1166" end_char="1172">acumule</TOKEN>
				<TOKEN id="token-10-11" start_char="1174" end_char="1175">la</TOKEN>
				<TOKEN id="token-10-12" start_char="1177" end_char="1186">mascarilla</TOKEN>
				<TOKEN id="token-10-13" start_char="1188" end_char="1190">eso</TOKEN>
				<TOKEN id="token-10-14" start_char="1192" end_char="1193">no</TOKEN>
				<TOKEN id="token-10-15" start_char="1195" end_char="1204">provocaría</TOKEN>
				<TOKEN id="token-10-16" start_char="1206" end_char="1207">un</TOKEN>
				<TOKEN id="token-10-17" start_char="1209" end_char="1216">positivo</TOKEN>
				<TOKEN id="token-10-18" start_char="1218" end_char="1219">en</TOKEN>
				<TOKEN id="token-10-19" start_char="1221" end_char="1222">la</TOKEN>
				<TOKEN id="token-10-20" start_char="1224" end_char="1226">PCR</TOKEN>
				<TOKEN id="token-10-21" start_char="1227" end_char="1227">,</TOKEN>
				<TOKEN id="token-10-22" start_char="1229" end_char="1230">ya</TOKEN>
				<TOKEN id="token-10-23" start_char="1232" end_char="1234">que</TOKEN>
				<TOKEN id="token-10-24" start_char="1236" end_char="1239">esta</TOKEN>
				<TOKEN id="token-10-25" start_char="1241" end_char="1246">prueba</TOKEN>
				<TOKEN id="token-10-26" start_char="1248" end_char="1251">solo</TOKEN>
				<TOKEN id="token-10-27" start_char="1253" end_char="1259">detecta</TOKEN>
				<TOKEN id="token-10-28" start_char="1261" end_char="1262">el</TOKEN>
				<TOKEN id="token-10-29" start_char="1264" end_char="1267">SARS</TOKEN>
				<TOKEN id="token-10-30" start_char="1268" end_char="1268">-</TOKEN>
				<TOKEN id="token-10-31" start_char="1269" end_char="1271">Cov</TOKEN>
				<TOKEN id="token-10-32" start_char="1272" end_char="1272">-</TOKEN>
				<TOKEN id="token-10-33" start_char="1273" end_char="1273">2</TOKEN>
				<TOKEN id="token-10-34" start_char="1275" end_char="1275">y</TOKEN>
				<TOKEN id="token-10-35" start_char="1277" end_char="1278">no</TOKEN>
				<TOKEN id="token-10-36" start_char="1280" end_char="1281">da</TOKEN>
				<TOKEN id="token-10-37" start_char="1283" end_char="1288">falsos</TOKEN>
				<TOKEN id="token-10-38" start_char="1290" end_char="1298">positivos</TOKEN>
				<TOKEN id="token-10-39" start_char="1300" end_char="1302">por</TOKEN>
				<TOKEN id="token-10-40" start_char="1304" end_char="1312">cualquier</TOKEN>
				<TOKEN id="token-10-41" start_char="1314" end_char="1317">otro</TOKEN>
				<TOKEN id="token-10-42" start_char="1319" end_char="1323">virus</TOKEN>
				<TOKEN id="token-10-43" start_char="1324" end_char="1324">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-11" start_char="1326" end_char="1559">
				<ORIGINAL_TEXT>En las publicaciones se afirma que el test PCR “solo detecta una secuencia de 200 letras Génicas [sic] de algún germen X” y que “basta con rascar esta zona, donde hay muchos gérmenes acumulados por el uso de la infecciosa mascarilla”.</ORIGINAL_TEXT>
				<TOKEN id="token-11-0" start_char="1326" end_char="1327">En</TOKEN>
				<TOKEN id="token-11-1" start_char="1329" end_char="1331">las</TOKEN>
				<TOKEN id="token-11-2" start_char="1333" end_char="1345">publicaciones</TOKEN>
				<TOKEN id="token-11-3" start_char="1347" end_char="1348">se</TOKEN>
				<TOKEN id="token-11-4" start_char="1350" end_char="1355">afirma</TOKEN>
				<TOKEN id="token-11-5" start_char="1357" end_char="1359">que</TOKEN>
				<TOKEN id="token-11-6" start_char="1361" end_char="1362">el</TOKEN>
				<TOKEN id="token-11-7" start_char="1364" end_char="1367">test</TOKEN>
				<TOKEN id="token-11-8" start_char="1369" end_char="1371">PCR</TOKEN>
				<TOKEN id="token-11-9" start_char="1373" end_char="1373">“</TOKEN>
				<TOKEN id="token-11-10" start_char="1374" end_char="1377">solo</TOKEN>
				<TOKEN id="token-11-11" start_char="1379" end_char="1385">detecta</TOKEN>
				<TOKEN id="token-11-12" start_char="1387" end_char="1389">una</TOKEN>
				<TOKEN id="token-11-13" start_char="1391" end_char="1399">secuencia</TOKEN>
				<TOKEN id="token-11-14" start_char="1401" end_char="1402">de</TOKEN>
				<TOKEN id="token-11-15" start_char="1404" end_char="1406">200</TOKEN>
				<TOKEN id="token-11-16" start_char="1408" end_char="1413">letras</TOKEN>
				<TOKEN id="token-11-17" start_char="1415" end_char="1421">Génicas</TOKEN>
				<TOKEN id="token-11-18" start_char="1423" end_char="1423">[</TOKEN>
				<TOKEN id="token-11-19" start_char="1424" end_char="1426">sic</TOKEN>
				<TOKEN id="token-11-20" start_char="1427" end_char="1427">]</TOKEN>
				<TOKEN id="token-11-21" start_char="1429" end_char="1430">de</TOKEN>
				<TOKEN id="token-11-22" start_char="1432" end_char="1436">algún</TOKEN>
				<TOKEN id="token-11-23" start_char="1438" end_char="1443">germen</TOKEN>
				<TOKEN id="token-11-24" start_char="1445" end_char="1445">X</TOKEN>
				<TOKEN id="token-11-25" start_char="1446" end_char="1446">”</TOKEN>
				<TOKEN id="token-11-26" start_char="1448" end_char="1448">y</TOKEN>
				<TOKEN id="token-11-27" start_char="1450" end_char="1452">que</TOKEN>
				<TOKEN id="token-11-28" start_char="1454" end_char="1454">“</TOKEN>
				<TOKEN id="token-11-29" start_char="1455" end_char="1459">basta</TOKEN>
				<TOKEN id="token-11-30" start_char="1461" end_char="1463">con</TOKEN>
				<TOKEN id="token-11-31" start_char="1465" end_char="1470">rascar</TOKEN>
				<TOKEN id="token-11-32" start_char="1472" end_char="1475">esta</TOKEN>
				<TOKEN id="token-11-33" start_char="1477" end_char="1480">zona</TOKEN>
				<TOKEN id="token-11-34" start_char="1481" end_char="1481">,</TOKEN>
				<TOKEN id="token-11-35" start_char="1483" end_char="1487">donde</TOKEN>
				<TOKEN id="token-11-36" start_char="1489" end_char="1491">hay</TOKEN>
				<TOKEN id="token-11-37" start_char="1493" end_char="1498">muchos</TOKEN>
				<TOKEN id="token-11-38" start_char="1500" end_char="1507">gérmenes</TOKEN>
				<TOKEN id="token-11-39" start_char="1509" end_char="1518">acumulados</TOKEN>
				<TOKEN id="token-11-40" start_char="1520" end_char="1522">por</TOKEN>
				<TOKEN id="token-11-41" start_char="1524" end_char="1525">el</TOKEN>
				<TOKEN id="token-11-42" start_char="1527" end_char="1529">uso</TOKEN>
				<TOKEN id="token-11-43" start_char="1531" end_char="1532">de</TOKEN>
				<TOKEN id="token-11-44" start_char="1534" end_char="1535">la</TOKEN>
				<TOKEN id="token-11-45" start_char="1537" end_char="1546">infecciosa</TOKEN>
				<TOKEN id="token-11-46" start_char="1548" end_char="1557">mascarilla</TOKEN>
				<TOKEN id="token-11-47" start_char="1558" end_char="1559">”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-12" start_char="1561" end_char="1642">
				<ORIGINAL_TEXT>Alcamí sostiene que “el mensaje es erróneo porque la prueba de PCR es específica”.</ORIGINAL_TEXT>
				<TOKEN id="token-12-0" start_char="1561" end_char="1566">Alcamí</TOKEN>
				<TOKEN id="token-12-1" start_char="1568" end_char="1575">sostiene</TOKEN>
				<TOKEN id="token-12-2" start_char="1577" end_char="1579">que</TOKEN>
				<TOKEN id="token-12-3" start_char="1581" end_char="1581">“</TOKEN>
				<TOKEN id="token-12-4" start_char="1582" end_char="1583">el</TOKEN>
				<TOKEN id="token-12-5" start_char="1585" end_char="1591">mensaje</TOKEN>
				<TOKEN id="token-12-6" start_char="1593" end_char="1594">es</TOKEN>
				<TOKEN id="token-12-7" start_char="1596" end_char="1602">erróneo</TOKEN>
				<TOKEN id="token-12-8" start_char="1604" end_char="1609">porque</TOKEN>
				<TOKEN id="token-12-9" start_char="1611" end_char="1612">la</TOKEN>
				<TOKEN id="token-12-10" start_char="1614" end_char="1619">prueba</TOKEN>
				<TOKEN id="token-12-11" start_char="1621" end_char="1622">de</TOKEN>
				<TOKEN id="token-12-12" start_char="1624" end_char="1626">PCR</TOKEN>
				<TOKEN id="token-12-13" start_char="1628" end_char="1629">es</TOKEN>
				<TOKEN id="token-12-14" start_char="1631" end_char="1640">específica</TOKEN>
				<TOKEN id="token-12-15" start_char="1641" end_char="1642">”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-13" start_char="1644" end_char="1721">
				<ORIGINAL_TEXT>Según cuenta, no es cierto que detecte &quot;200 letras génicas de algún germen X&quot;.</ORIGINAL_TEXT>
				<TOKEN id="token-13-0" start_char="1644" end_char="1648">Según</TOKEN>
				<TOKEN id="token-13-1" start_char="1650" end_char="1655">cuenta</TOKEN>
				<TOKEN id="token-13-2" start_char="1656" end_char="1656">,</TOKEN>
				<TOKEN id="token-13-3" start_char="1658" end_char="1659">no</TOKEN>
				<TOKEN id="token-13-4" start_char="1661" end_char="1662">es</TOKEN>
				<TOKEN id="token-13-5" start_char="1664" end_char="1669">cierto</TOKEN>
				<TOKEN id="token-13-6" start_char="1671" end_char="1673">que</TOKEN>
				<TOKEN id="token-13-7" start_char="1675" end_char="1681">detecte</TOKEN>
				<TOKEN id="token-13-8" start_char="1683" end_char="1683">&quot;</TOKEN>
				<TOKEN id="token-13-9" start_char="1684" end_char="1686">200</TOKEN>
				<TOKEN id="token-13-10" start_char="1688" end_char="1693">letras</TOKEN>
				<TOKEN id="token-13-11" start_char="1695" end_char="1701">génicas</TOKEN>
				<TOKEN id="token-13-12" start_char="1703" end_char="1704">de</TOKEN>
				<TOKEN id="token-13-13" start_char="1706" end_char="1710">algún</TOKEN>
				<TOKEN id="token-13-14" start_char="1712" end_char="1717">germen</TOKEN>
				<TOKEN id="token-13-15" start_char="1719" end_char="1719">X</TOKEN>
				<TOKEN id="token-13-16" start_char="1720" end_char="1721">&quot;.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-14" start_char="1723" end_char="1989">
				<ORIGINAL_TEXT>“El método de PCR se caracteriza porque utiliza para amplificar la secuencia genética de un germen cebadores o primers (sustancias necesarias en la reacción en que se basa las PCR) que corresponden a un fragmento del código de ese germen que es único en ese microbio.</ORIGINAL_TEXT>
				<TOKEN id="token-14-0" start_char="1723" end_char="1723">“</TOKEN>
				<TOKEN id="token-14-1" start_char="1724" end_char="1725">El</TOKEN>
				<TOKEN id="token-14-2" start_char="1727" end_char="1732">método</TOKEN>
				<TOKEN id="token-14-3" start_char="1734" end_char="1735">de</TOKEN>
				<TOKEN id="token-14-4" start_char="1737" end_char="1739">PCR</TOKEN>
				<TOKEN id="token-14-5" start_char="1741" end_char="1742">se</TOKEN>
				<TOKEN id="token-14-6" start_char="1744" end_char="1754">caracteriza</TOKEN>
				<TOKEN id="token-14-7" start_char="1756" end_char="1761">porque</TOKEN>
				<TOKEN id="token-14-8" start_char="1763" end_char="1769">utiliza</TOKEN>
				<TOKEN id="token-14-9" start_char="1771" end_char="1774">para</TOKEN>
				<TOKEN id="token-14-10" start_char="1776" end_char="1785">amplificar</TOKEN>
				<TOKEN id="token-14-11" start_char="1787" end_char="1788">la</TOKEN>
				<TOKEN id="token-14-12" start_char="1790" end_char="1798">secuencia</TOKEN>
				<TOKEN id="token-14-13" start_char="1800" end_char="1807">genética</TOKEN>
				<TOKEN id="token-14-14" start_char="1809" end_char="1810">de</TOKEN>
				<TOKEN id="token-14-15" start_char="1812" end_char="1813">un</TOKEN>
				<TOKEN id="token-14-16" start_char="1815" end_char="1820">germen</TOKEN>
				<TOKEN id="token-14-17" start_char="1822" end_char="1830">cebadores</TOKEN>
				<TOKEN id="token-14-18" start_char="1832" end_char="1832">o</TOKEN>
				<TOKEN id="token-14-19" start_char="1834" end_char="1840">primers</TOKEN>
				<TOKEN id="token-14-20" start_char="1842" end_char="1842">(</TOKEN>
				<TOKEN id="token-14-21" start_char="1843" end_char="1852">sustancias</TOKEN>
				<TOKEN id="token-14-22" start_char="1854" end_char="1863">necesarias</TOKEN>
				<TOKEN id="token-14-23" start_char="1865" end_char="1866">en</TOKEN>
				<TOKEN id="token-14-24" start_char="1868" end_char="1869">la</TOKEN>
				<TOKEN id="token-14-25" start_char="1871" end_char="1878">reacción</TOKEN>
				<TOKEN id="token-14-26" start_char="1880" end_char="1881">en</TOKEN>
				<TOKEN id="token-14-27" start_char="1883" end_char="1885">que</TOKEN>
				<TOKEN id="token-14-28" start_char="1887" end_char="1888">se</TOKEN>
				<TOKEN id="token-14-29" start_char="1890" end_char="1893">basa</TOKEN>
				<TOKEN id="token-14-30" start_char="1895" end_char="1897">las</TOKEN>
				<TOKEN id="token-14-31" start_char="1899" end_char="1901">PCR</TOKEN>
				<TOKEN id="token-14-32" start_char="1902" end_char="1902">)</TOKEN>
				<TOKEN id="token-14-33" start_char="1904" end_char="1906">que</TOKEN>
				<TOKEN id="token-14-34" start_char="1908" end_char="1919">corresponden</TOKEN>
				<TOKEN id="token-14-35" start_char="1921" end_char="1921">a</TOKEN>
				<TOKEN id="token-14-36" start_char="1923" end_char="1924">un</TOKEN>
				<TOKEN id="token-14-37" start_char="1926" end_char="1934">fragmento</TOKEN>
				<TOKEN id="token-14-38" start_char="1936" end_char="1938">del</TOKEN>
				<TOKEN id="token-14-39" start_char="1940" end_char="1945">código</TOKEN>
				<TOKEN id="token-14-40" start_char="1947" end_char="1948">de</TOKEN>
				<TOKEN id="token-14-41" start_char="1950" end_char="1952">ese</TOKEN>
				<TOKEN id="token-14-42" start_char="1954" end_char="1959">germen</TOKEN>
				<TOKEN id="token-14-43" start_char="1961" end_char="1963">que</TOKEN>
				<TOKEN id="token-14-44" start_char="1965" end_char="1966">es</TOKEN>
				<TOKEN id="token-14-45" start_char="1968" end_char="1972">único</TOKEN>
				<TOKEN id="token-14-46" start_char="1974" end_char="1975">en</TOKEN>
				<TOKEN id="token-14-47" start_char="1977" end_char="1979">ese</TOKEN>
				<TOKEN id="token-14-48" start_char="1981" end_char="1988">microbio</TOKEN>
				<TOKEN id="token-14-49" start_char="1989" end_char="1989">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-15" start_char="1991" end_char="2142">
				<ORIGINAL_TEXT>En el caso del coronavirus, la PCR amplifica sólo si el virus es el SARS-CoV-2, no amplifica el SARS-CoV-1 ni otros coronavirus respiratorios.”, afirma.</ORIGINAL_TEXT>
				<TOKEN id="token-15-0" start_char="1991" end_char="1992">En</TOKEN>
				<TOKEN id="token-15-1" start_char="1994" end_char="1995">el</TOKEN>
				<TOKEN id="token-15-2" start_char="1997" end_char="2000">caso</TOKEN>
				<TOKEN id="token-15-3" start_char="2002" end_char="2004">del</TOKEN>
				<TOKEN id="token-15-4" start_char="2006" end_char="2016">coronavirus</TOKEN>
				<TOKEN id="token-15-5" start_char="2017" end_char="2017">,</TOKEN>
				<TOKEN id="token-15-6" start_char="2019" end_char="2020">la</TOKEN>
				<TOKEN id="token-15-7" start_char="2022" end_char="2024">PCR</TOKEN>
				<TOKEN id="token-15-8" start_char="2026" end_char="2034">amplifica</TOKEN>
				<TOKEN id="token-15-9" start_char="2036" end_char="2039">sólo</TOKEN>
				<TOKEN id="token-15-10" start_char="2041" end_char="2042">si</TOKEN>
				<TOKEN id="token-15-11" start_char="2044" end_char="2045">el</TOKEN>
				<TOKEN id="token-15-12" start_char="2047" end_char="2051">virus</TOKEN>
				<TOKEN id="token-15-13" start_char="2053" end_char="2054">es</TOKEN>
				<TOKEN id="token-15-14" start_char="2056" end_char="2057">el</TOKEN>
				<TOKEN id="token-15-15" start_char="2059" end_char="2062">SARS</TOKEN>
				<TOKEN id="token-15-16" start_char="2063" end_char="2063">-</TOKEN>
				<TOKEN id="token-15-17" start_char="2064" end_char="2066">CoV</TOKEN>
				<TOKEN id="token-15-18" start_char="2067" end_char="2067">-</TOKEN>
				<TOKEN id="token-15-19" start_char="2068" end_char="2068">2</TOKEN>
				<TOKEN id="token-15-20" start_char="2069" end_char="2069">,</TOKEN>
				<TOKEN id="token-15-21" start_char="2071" end_char="2072">no</TOKEN>
				<TOKEN id="token-15-22" start_char="2074" end_char="2082">amplifica</TOKEN>
				<TOKEN id="token-15-23" start_char="2084" end_char="2085">el</TOKEN>
				<TOKEN id="token-15-24" start_char="2087" end_char="2090">SARS</TOKEN>
				<TOKEN id="token-15-25" start_char="2091" end_char="2091">-</TOKEN>
				<TOKEN id="token-15-26" start_char="2092" end_char="2094">CoV</TOKEN>
				<TOKEN id="token-15-27" start_char="2095" end_char="2095">-</TOKEN>
				<TOKEN id="token-15-28" start_char="2096" end_char="2096">1</TOKEN>
				<TOKEN id="token-15-29" start_char="2098" end_char="2099">ni</TOKEN>
				<TOKEN id="token-15-30" start_char="2101" end_char="2105">otros</TOKEN>
				<TOKEN id="token-15-31" start_char="2107" end_char="2117">coronavirus</TOKEN>
				<TOKEN id="token-15-32" start_char="2119" end_char="2131">respiratorios</TOKEN>
				<TOKEN id="token-15-33" start_char="2132" end_char="2134">.”,</TOKEN>
				<TOKEN id="token-15-34" start_char="2136" end_char="2141">afirma</TOKEN>
				<TOKEN id="token-15-35" start_char="2142" end_char="2142">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-16" start_char="2144" end_char="2227">
				<ORIGINAL_TEXT>Es decir, “se eligen fragmentos ‘únicos’ del virus que no están presentes en otros”.</ORIGINAL_TEXT>
				<TOKEN id="token-16-0" start_char="2144" end_char="2145">Es</TOKEN>
				<TOKEN id="token-16-1" start_char="2147" end_char="2151">decir</TOKEN>
				<TOKEN id="token-16-2" start_char="2152" end_char="2152">,</TOKEN>
				<TOKEN id="token-16-3" start_char="2154" end_char="2154">“</TOKEN>
				<TOKEN id="token-16-4" start_char="2155" end_char="2156">se</TOKEN>
				<TOKEN id="token-16-5" start_char="2158" end_char="2163">eligen</TOKEN>
				<TOKEN id="token-16-6" start_char="2165" end_char="2174">fragmentos</TOKEN>
				<TOKEN id="token-16-7" start_char="2176" end_char="2176">‘</TOKEN>
				<TOKEN id="token-16-8" start_char="2177" end_char="2182">únicos</TOKEN>
				<TOKEN id="token-16-9" start_char="2183" end_char="2183">’</TOKEN>
				<TOKEN id="token-16-10" start_char="2185" end_char="2187">del</TOKEN>
				<TOKEN id="token-16-11" start_char="2189" end_char="2193">virus</TOKEN>
				<TOKEN id="token-16-12" start_char="2195" end_char="2197">que</TOKEN>
				<TOKEN id="token-16-13" start_char="2199" end_char="2200">no</TOKEN>
				<TOKEN id="token-16-14" start_char="2202" end_char="2206">están</TOKEN>
				<TOKEN id="token-16-15" start_char="2208" end_char="2216">presentes</TOKEN>
				<TOKEN id="token-16-16" start_char="2218" end_char="2219">en</TOKEN>
				<TOKEN id="token-16-17" start_char="2221" end_char="2225">otros</TOKEN>
				<TOKEN id="token-16-18" start_char="2226" end_char="2227">”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-17" start_char="2229" end_char="2282">
				<ORIGINAL_TEXT>Para explicarlo, pone como ejemplo los relatos cortos.</ORIGINAL_TEXT>
				<TOKEN id="token-17-0" start_char="2229" end_char="2232">Para</TOKEN>
				<TOKEN id="token-17-1" start_char="2234" end_char="2243">explicarlo</TOKEN>
				<TOKEN id="token-17-2" start_char="2244" end_char="2244">,</TOKEN>
				<TOKEN id="token-17-3" start_char="2246" end_char="2249">pone</TOKEN>
				<TOKEN id="token-17-4" start_char="2251" end_char="2254">como</TOKEN>
				<TOKEN id="token-17-5" start_char="2256" end_char="2262">ejemplo</TOKEN>
				<TOKEN id="token-17-6" start_char="2264" end_char="2266">los</TOKEN>
				<TOKEN id="token-17-7" start_char="2268" end_char="2274">relatos</TOKEN>
				<TOKEN id="token-17-8" start_char="2276" end_char="2281">cortos</TOKEN>
				<TOKEN id="token-17-9" start_char="2282" end_char="2282">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-18" start_char="2284" end_char="2392">
				<ORIGINAL_TEXT>Cuenta que entre diferentes relatos, sobre todo si están escritos en el mismo idioma, hay letras compartidas.</ORIGINAL_TEXT>
				<TOKEN id="token-18-0" start_char="2284" end_char="2289">Cuenta</TOKEN>
				<TOKEN id="token-18-1" start_char="2291" end_char="2293">que</TOKEN>
				<TOKEN id="token-18-2" start_char="2295" end_char="2299">entre</TOKEN>
				<TOKEN id="token-18-3" start_char="2301" end_char="2310">diferentes</TOKEN>
				<TOKEN id="token-18-4" start_char="2312" end_char="2318">relatos</TOKEN>
				<TOKEN id="token-18-5" start_char="2319" end_char="2319">,</TOKEN>
				<TOKEN id="token-18-6" start_char="2321" end_char="2325">sobre</TOKEN>
				<TOKEN id="token-18-7" start_char="2327" end_char="2330">todo</TOKEN>
				<TOKEN id="token-18-8" start_char="2332" end_char="2333">si</TOKEN>
				<TOKEN id="token-18-9" start_char="2335" end_char="2339">están</TOKEN>
				<TOKEN id="token-18-10" start_char="2341" end_char="2348">escritos</TOKEN>
				<TOKEN id="token-18-11" start_char="2350" end_char="2351">en</TOKEN>
				<TOKEN id="token-18-12" start_char="2353" end_char="2354">el</TOKEN>
				<TOKEN id="token-18-13" start_char="2356" end_char="2360">mismo</TOKEN>
				<TOKEN id="token-18-14" start_char="2362" end_char="2367">idioma</TOKEN>
				<TOKEN id="token-18-15" start_char="2368" end_char="2368">,</TOKEN>
				<TOKEN id="token-18-16" start_char="2370" end_char="2372">hay</TOKEN>
				<TOKEN id="token-18-17" start_char="2374" end_char="2379">letras</TOKEN>
				<TOKEN id="token-18-18" start_char="2381" end_char="2391">compartidas</TOKEN>
				<TOKEN id="token-18-19" start_char="2392" end_char="2392">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-19" start_char="2394" end_char="2474">
				<ORIGINAL_TEXT>Pero en todo relato hay una serie de palabras que no están en ningún otro relato.</ORIGINAL_TEXT>
				<TOKEN id="token-19-0" start_char="2394" end_char="2397">Pero</TOKEN>
				<TOKEN id="token-19-1" start_char="2399" end_char="2400">en</TOKEN>
				<TOKEN id="token-19-2" start_char="2402" end_char="2405">todo</TOKEN>
				<TOKEN id="token-19-3" start_char="2407" end_char="2412">relato</TOKEN>
				<TOKEN id="token-19-4" start_char="2414" end_char="2416">hay</TOKEN>
				<TOKEN id="token-19-5" start_char="2418" end_char="2420">una</TOKEN>
				<TOKEN id="token-19-6" start_char="2422" end_char="2426">serie</TOKEN>
				<TOKEN id="token-19-7" start_char="2428" end_char="2429">de</TOKEN>
				<TOKEN id="token-19-8" start_char="2431" end_char="2438">palabras</TOKEN>
				<TOKEN id="token-19-9" start_char="2440" end_char="2442">que</TOKEN>
				<TOKEN id="token-19-10" start_char="2444" end_char="2445">no</TOKEN>
				<TOKEN id="token-19-11" start_char="2447" end_char="2451">están</TOKEN>
				<TOKEN id="token-19-12" start_char="2453" end_char="2454">en</TOKEN>
				<TOKEN id="token-19-13" start_char="2456" end_char="2461">ningún</TOKEN>
				<TOKEN id="token-19-14" start_char="2463" end_char="2466">otro</TOKEN>
				<TOKEN id="token-19-15" start_char="2468" end_char="2473">relato</TOKEN>
				<TOKEN id="token-19-16" start_char="2474" end_char="2474">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-20" start_char="2476" end_char="2553">
				<ORIGINAL_TEXT>Por ejemplo, afirma que puede aparecer la palabra &quot;canguro&quot; en muchos relatos.</ORIGINAL_TEXT>
				<TOKEN id="token-20-0" start_char="2476" end_char="2478">Por</TOKEN>
				<TOKEN id="token-20-1" start_char="2480" end_char="2486">ejemplo</TOKEN>
				<TOKEN id="token-20-2" start_char="2487" end_char="2487">,</TOKEN>
				<TOKEN id="token-20-3" start_char="2489" end_char="2494">afirma</TOKEN>
				<TOKEN id="token-20-4" start_char="2496" end_char="2498">que</TOKEN>
				<TOKEN id="token-20-5" start_char="2500" end_char="2504">puede</TOKEN>
				<TOKEN id="token-20-6" start_char="2506" end_char="2513">aparecer</TOKEN>
				<TOKEN id="token-20-7" start_char="2515" end_char="2516">la</TOKEN>
				<TOKEN id="token-20-8" start_char="2518" end_char="2524">palabra</TOKEN>
				<TOKEN id="token-20-9" start_char="2526" end_char="2526">&quot;</TOKEN>
				<TOKEN id="token-20-10" start_char="2527" end_char="2533">canguro</TOKEN>
				<TOKEN id="token-20-11" start_char="2534" end_char="2534">&quot;</TOKEN>
				<TOKEN id="token-20-12" start_char="2536" end_char="2537">en</TOKEN>
				<TOKEN id="token-20-13" start_char="2539" end_char="2544">muchos</TOKEN>
				<TOKEN id="token-20-14" start_char="2546" end_char="2552">relatos</TOKEN>
				<TOKEN id="token-20-15" start_char="2553" end_char="2553">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-21" start_char="2555" end_char="2665">
				<ORIGINAL_TEXT>Pero &quot;el canguro se llamaba Willy y lo localicé en la sabana de Melbourne&quot; solo existirá en un relato concreto.</ORIGINAL_TEXT>
				<TOKEN id="token-21-0" start_char="2555" end_char="2558">Pero</TOKEN>
				<TOKEN id="token-21-1" start_char="2560" end_char="2560">&quot;</TOKEN>
				<TOKEN id="token-21-2" start_char="2561" end_char="2562">el</TOKEN>
				<TOKEN id="token-21-3" start_char="2564" end_char="2570">canguro</TOKEN>
				<TOKEN id="token-21-4" start_char="2572" end_char="2573">se</TOKEN>
				<TOKEN id="token-21-5" start_char="2575" end_char="2581">llamaba</TOKEN>
				<TOKEN id="token-21-6" start_char="2583" end_char="2587">Willy</TOKEN>
				<TOKEN id="token-21-7" start_char="2589" end_char="2589">y</TOKEN>
				<TOKEN id="token-21-8" start_char="2591" end_char="2592">lo</TOKEN>
				<TOKEN id="token-21-9" start_char="2594" end_char="2601">localicé</TOKEN>
				<TOKEN id="token-21-10" start_char="2603" end_char="2604">en</TOKEN>
				<TOKEN id="token-21-11" start_char="2606" end_char="2607">la</TOKEN>
				<TOKEN id="token-21-12" start_char="2609" end_char="2614">sabana</TOKEN>
				<TOKEN id="token-21-13" start_char="2616" end_char="2617">de</TOKEN>
				<TOKEN id="token-21-14" start_char="2619" end_char="2627">Melbourne</TOKEN>
				<TOKEN id="token-21-15" start_char="2628" end_char="2628">&quot;</TOKEN>
				<TOKEN id="token-21-16" start_char="2630" end_char="2633">solo</TOKEN>
				<TOKEN id="token-21-17" start_char="2635" end_char="2642">existirá</TOKEN>
				<TOKEN id="token-21-18" start_char="2644" end_char="2645">en</TOKEN>
				<TOKEN id="token-21-19" start_char="2647" end_char="2648">un</TOKEN>
				<TOKEN id="token-21-20" start_char="2650" end_char="2655">relato</TOKEN>
				<TOKEN id="token-21-21" start_char="2657" end_char="2664">concreto</TOKEN>
				<TOKEN id="token-21-22" start_char="2665" end_char="2665">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-22" start_char="2667" end_char="2730">
				<ORIGINAL_TEXT>“Si buscamos esa frase entre mil relatos solo aparecerá en ese”.</ORIGINAL_TEXT>
				<TOKEN id="token-22-0" start_char="2667" end_char="2667">“</TOKEN>
				<TOKEN id="token-22-1" start_char="2668" end_char="2669">Si</TOKEN>
				<TOKEN id="token-22-2" start_char="2671" end_char="2678">buscamos</TOKEN>
				<TOKEN id="token-22-3" start_char="2680" end_char="2682">esa</TOKEN>
				<TOKEN id="token-22-4" start_char="2684" end_char="2688">frase</TOKEN>
				<TOKEN id="token-22-5" start_char="2690" end_char="2694">entre</TOKEN>
				<TOKEN id="token-22-6" start_char="2696" end_char="2698">mil</TOKEN>
				<TOKEN id="token-22-7" start_char="2700" end_char="2706">relatos</TOKEN>
				<TOKEN id="token-22-8" start_char="2708" end_char="2711">solo</TOKEN>
				<TOKEN id="token-22-9" start_char="2713" end_char="2721">aparecerá</TOKEN>
				<TOKEN id="token-22-10" start_char="2723" end_char="2724">en</TOKEN>
				<TOKEN id="token-22-11" start_char="2726" end_char="2728">ese</TOKEN>
				<TOKEN id="token-22-12" start_char="2729" end_char="2730">”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-23" start_char="2732" end_char="2883">
				<ORIGINAL_TEXT>Lo mismo ocurre en este caso: “Lo importante para tener una buena PCR es que seleccione un fragmento ‘original’ del virus que nos interesa diagnosticar.</ORIGINAL_TEXT>
				<TOKEN id="token-23-0" start_char="2732" end_char="2733">Lo</TOKEN>
				<TOKEN id="token-23-1" start_char="2735" end_char="2739">mismo</TOKEN>
				<TOKEN id="token-23-2" start_char="2741" end_char="2746">ocurre</TOKEN>
				<TOKEN id="token-23-3" start_char="2748" end_char="2749">en</TOKEN>
				<TOKEN id="token-23-4" start_char="2751" end_char="2754">este</TOKEN>
				<TOKEN id="token-23-5" start_char="2756" end_char="2759">caso</TOKEN>
				<TOKEN id="token-23-6" start_char="2760" end_char="2760">:</TOKEN>
				<TOKEN id="token-23-7" start_char="2762" end_char="2762">“</TOKEN>
				<TOKEN id="token-23-8" start_char="2763" end_char="2764">Lo</TOKEN>
				<TOKEN id="token-23-9" start_char="2766" end_char="2775">importante</TOKEN>
				<TOKEN id="token-23-10" start_char="2777" end_char="2780">para</TOKEN>
				<TOKEN id="token-23-11" start_char="2782" end_char="2786">tener</TOKEN>
				<TOKEN id="token-23-12" start_char="2788" end_char="2790">una</TOKEN>
				<TOKEN id="token-23-13" start_char="2792" end_char="2796">buena</TOKEN>
				<TOKEN id="token-23-14" start_char="2798" end_char="2800">PCR</TOKEN>
				<TOKEN id="token-23-15" start_char="2802" end_char="2803">es</TOKEN>
				<TOKEN id="token-23-16" start_char="2805" end_char="2807">que</TOKEN>
				<TOKEN id="token-23-17" start_char="2809" end_char="2818">seleccione</TOKEN>
				<TOKEN id="token-23-18" start_char="2820" end_char="2821">un</TOKEN>
				<TOKEN id="token-23-19" start_char="2823" end_char="2831">fragmento</TOKEN>
				<TOKEN id="token-23-20" start_char="2833" end_char="2833">‘</TOKEN>
				<TOKEN id="token-23-21" start_char="2834" end_char="2841">original</TOKEN>
				<TOKEN id="token-23-22" start_char="2842" end_char="2842">’</TOKEN>
				<TOKEN id="token-23-23" start_char="2844" end_char="2846">del</TOKEN>
				<TOKEN id="token-23-24" start_char="2848" end_char="2852">virus</TOKEN>
				<TOKEN id="token-23-25" start_char="2854" end_char="2856">que</TOKEN>
				<TOKEN id="token-23-26" start_char="2858" end_char="2860">nos</TOKEN>
				<TOKEN id="token-23-27" start_char="2862" end_char="2869">interesa</TOKEN>
				<TOKEN id="token-23-28" start_char="2871" end_char="2882">diagnosticar</TOKEN>
				<TOKEN id="token-23-29" start_char="2883" end_char="2883">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-24" start_char="2885" end_char="3195">
				<ORIGINAL_TEXT>Si elegimos un fragmento compartido por otros coronavirus no podremos diferenciarlo, pero los tests de PCR que se utilizan diferencian perfectamente entre distintos coronavirus y más todavía entre virus de familias diferentes o microbios tan distintos y distantes genéticamente como las bacterias o los hongos”.</ORIGINAL_TEXT>
				<TOKEN id="token-24-0" start_char="2885" end_char="2886">Si</TOKEN>
				<TOKEN id="token-24-1" start_char="2888" end_char="2895">elegimos</TOKEN>
				<TOKEN id="token-24-2" start_char="2897" end_char="2898">un</TOKEN>
				<TOKEN id="token-24-3" start_char="2900" end_char="2908">fragmento</TOKEN>
				<TOKEN id="token-24-4" start_char="2910" end_char="2919">compartido</TOKEN>
				<TOKEN id="token-24-5" start_char="2921" end_char="2923">por</TOKEN>
				<TOKEN id="token-24-6" start_char="2925" end_char="2929">otros</TOKEN>
				<TOKEN id="token-24-7" start_char="2931" end_char="2941">coronavirus</TOKEN>
				<TOKEN id="token-24-8" start_char="2943" end_char="2944">no</TOKEN>
				<TOKEN id="token-24-9" start_char="2946" end_char="2953">podremos</TOKEN>
				<TOKEN id="token-24-10" start_char="2955" end_char="2967">diferenciarlo</TOKEN>
				<TOKEN id="token-24-11" start_char="2968" end_char="2968">,</TOKEN>
				<TOKEN id="token-24-12" start_char="2970" end_char="2973">pero</TOKEN>
				<TOKEN id="token-24-13" start_char="2975" end_char="2977">los</TOKEN>
				<TOKEN id="token-24-14" start_char="2979" end_char="2983">tests</TOKEN>
				<TOKEN id="token-24-15" start_char="2985" end_char="2986">de</TOKEN>
				<TOKEN id="token-24-16" start_char="2988" end_char="2990">PCR</TOKEN>
				<TOKEN id="token-24-17" start_char="2992" end_char="2994">que</TOKEN>
				<TOKEN id="token-24-18" start_char="2996" end_char="2997">se</TOKEN>
				<TOKEN id="token-24-19" start_char="2999" end_char="3006">utilizan</TOKEN>
				<TOKEN id="token-24-20" start_char="3008" end_char="3018">diferencian</TOKEN>
				<TOKEN id="token-24-21" start_char="3020" end_char="3032">perfectamente</TOKEN>
				<TOKEN id="token-24-22" start_char="3034" end_char="3038">entre</TOKEN>
				<TOKEN id="token-24-23" start_char="3040" end_char="3048">distintos</TOKEN>
				<TOKEN id="token-24-24" start_char="3050" end_char="3060">coronavirus</TOKEN>
				<TOKEN id="token-24-25" start_char="3062" end_char="3062">y</TOKEN>
				<TOKEN id="token-24-26" start_char="3064" end_char="3066">más</TOKEN>
				<TOKEN id="token-24-27" start_char="3068" end_char="3074">todavía</TOKEN>
				<TOKEN id="token-24-28" start_char="3076" end_char="3080">entre</TOKEN>
				<TOKEN id="token-24-29" start_char="3082" end_char="3086">virus</TOKEN>
				<TOKEN id="token-24-30" start_char="3088" end_char="3089">de</TOKEN>
				<TOKEN id="token-24-31" start_char="3091" end_char="3098">familias</TOKEN>
				<TOKEN id="token-24-32" start_char="3100" end_char="3109">diferentes</TOKEN>
				<TOKEN id="token-24-33" start_char="3111" end_char="3111">o</TOKEN>
				<TOKEN id="token-24-34" start_char="3113" end_char="3121">microbios</TOKEN>
				<TOKEN id="token-24-35" start_char="3123" end_char="3125">tan</TOKEN>
				<TOKEN id="token-24-36" start_char="3127" end_char="3135">distintos</TOKEN>
				<TOKEN id="token-24-37" start_char="3137" end_char="3137">y</TOKEN>
				<TOKEN id="token-24-38" start_char="3139" end_char="3147">distantes</TOKEN>
				<TOKEN id="token-24-39" start_char="3149" end_char="3161">genéticamente</TOKEN>
				<TOKEN id="token-24-40" start_char="3163" end_char="3166">como</TOKEN>
				<TOKEN id="token-24-41" start_char="3168" end_char="3170">las</TOKEN>
				<TOKEN id="token-24-42" start_char="3172" end_char="3180">bacterias</TOKEN>
				<TOKEN id="token-24-43" start_char="3182" end_char="3182">o</TOKEN>
				<TOKEN id="token-24-44" start_char="3184" end_char="3186">los</TOKEN>
				<TOKEN id="token-24-45" start_char="3188" end_char="3193">hongos</TOKEN>
				<TOKEN id="token-24-46" start_char="3194" end_char="3195">”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-25" start_char="3197" end_char="3218">
				<ORIGINAL_TEXT>Aquí os lo explicamos.</ORIGINAL_TEXT>
				<TOKEN id="token-25-0" start_char="3197" end_char="3200">Aquí</TOKEN>
				<TOKEN id="token-25-1" start_char="3202" end_char="3203">os</TOKEN>
				<TOKEN id="token-25-2" start_char="3205" end_char="3206">lo</TOKEN>
				<TOKEN id="token-25-3" start_char="3208" end_char="3217">explicamos</TOKEN>
				<TOKEN id="token-25-4" start_char="3218" end_char="3218">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-26" start_char="3220" end_char="3334">
				<ORIGINAL_TEXT>Los gérmenes que exhalamos ya están en nuestro tracto respiratorio y normalmente no suponen un riesgo para la salud</ORIGINAL_TEXT>
				<TOKEN id="token-26-0" start_char="3220" end_char="3222">Los</TOKEN>
				<TOKEN id="token-26-1" start_char="3224" end_char="3231">gérmenes</TOKEN>
				<TOKEN id="token-26-2" start_char="3233" end_char="3235">que</TOKEN>
				<TOKEN id="token-26-3" start_char="3237" end_char="3245">exhalamos</TOKEN>
				<TOKEN id="token-26-4" start_char="3247" end_char="3248">ya</TOKEN>
				<TOKEN id="token-26-5" start_char="3250" end_char="3254">están</TOKEN>
				<TOKEN id="token-26-6" start_char="3256" end_char="3257">en</TOKEN>
				<TOKEN id="token-26-7" start_char="3259" end_char="3265">nuestro</TOKEN>
				<TOKEN id="token-26-8" start_char="3267" end_char="3272">tracto</TOKEN>
				<TOKEN id="token-26-9" start_char="3274" end_char="3285">respiratorio</TOKEN>
				<TOKEN id="token-26-10" start_char="3287" end_char="3287">y</TOKEN>
				<TOKEN id="token-26-11" start_char="3289" end_char="3299">normalmente</TOKEN>
				<TOKEN id="token-26-12" start_char="3301" end_char="3302">no</TOKEN>
				<TOKEN id="token-26-13" start_char="3304" end_char="3310">suponen</TOKEN>
				<TOKEN id="token-26-14" start_char="3312" end_char="3313">un</TOKEN>
				<TOKEN id="token-26-15" start_char="3315" end_char="3320">riesgo</TOKEN>
				<TOKEN id="token-26-16" start_char="3322" end_char="3325">para</TOKEN>
				<TOKEN id="token-26-17" start_char="3327" end_char="3328">la</TOKEN>
				<TOKEN id="token-26-18" start_char="3330" end_char="3334">salud</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-27" start_char="3336" end_char="3387">
				<ORIGINAL_TEXT>¿Qué ocurre exactamente cuando usamos la mascarilla?</ORIGINAL_TEXT>
				<TOKEN id="token-27-0" start_char="3336" end_char="3336">¿</TOKEN>
				<TOKEN id="token-27-1" start_char="3337" end_char="3339">Qué</TOKEN>
				<TOKEN id="token-27-2" start_char="3341" end_char="3346">ocurre</TOKEN>
				<TOKEN id="token-27-3" start_char="3348" end_char="3358">exactamente</TOKEN>
				<TOKEN id="token-27-4" start_char="3360" end_char="3365">cuando</TOKEN>
				<TOKEN id="token-27-5" start_char="3367" end_char="3372">usamos</TOKEN>
				<TOKEN id="token-27-6" start_char="3374" end_char="3375">la</TOKEN>
				<TOKEN id="token-27-7" start_char="3377" end_char="3386">mascarilla</TOKEN>
				<TOKEN id="token-27-8" start_char="3387" end_char="3387">?</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-28" start_char="3389" end_char="3626">
				<ORIGINAL_TEXT>Magdalena Martínez Cañamero, microbióloga de la Universidad de Jaén y miembro de la Sociedad Española de Microbiología, explica a Maldita Ciencia que principalmente se acumulan bacterias nuestras de la piel y de la boca que “son inocuas”.</ORIGINAL_TEXT>
				<TOKEN id="token-28-0" start_char="3389" end_char="3397">Magdalena</TOKEN>
				<TOKEN id="token-28-1" start_char="3399" end_char="3406">Martínez</TOKEN>
				<TOKEN id="token-28-2" start_char="3408" end_char="3415">Cañamero</TOKEN>
				<TOKEN id="token-28-3" start_char="3416" end_char="3416">,</TOKEN>
				<TOKEN id="token-28-4" start_char="3418" end_char="3429">microbióloga</TOKEN>
				<TOKEN id="token-28-5" start_char="3431" end_char="3432">de</TOKEN>
				<TOKEN id="token-28-6" start_char="3434" end_char="3435">la</TOKEN>
				<TOKEN id="token-28-7" start_char="3437" end_char="3447">Universidad</TOKEN>
				<TOKEN id="token-28-8" start_char="3449" end_char="3450">de</TOKEN>
				<TOKEN id="token-28-9" start_char="3452" end_char="3455">Jaén</TOKEN>
				<TOKEN id="token-28-10" start_char="3457" end_char="3457">y</TOKEN>
				<TOKEN id="token-28-11" start_char="3459" end_char="3465">miembro</TOKEN>
				<TOKEN id="token-28-12" start_char="3467" end_char="3468">de</TOKEN>
				<TOKEN id="token-28-13" start_char="3470" end_char="3471">la</TOKEN>
				<TOKEN id="token-28-14" start_char="3473" end_char="3480">Sociedad</TOKEN>
				<TOKEN id="token-28-15" start_char="3482" end_char="3489">Española</TOKEN>
				<TOKEN id="token-28-16" start_char="3491" end_char="3492">de</TOKEN>
				<TOKEN id="token-28-17" start_char="3494" end_char="3506">Microbiología</TOKEN>
				<TOKEN id="token-28-18" start_char="3507" end_char="3507">,</TOKEN>
				<TOKEN id="token-28-19" start_char="3509" end_char="3515">explica</TOKEN>
				<TOKEN id="token-28-20" start_char="3517" end_char="3517">a</TOKEN>
				<TOKEN id="token-28-21" start_char="3519" end_char="3525">Maldita</TOKEN>
				<TOKEN id="token-28-22" start_char="3527" end_char="3533">Ciencia</TOKEN>
				<TOKEN id="token-28-23" start_char="3535" end_char="3537">que</TOKEN>
				<TOKEN id="token-28-24" start_char="3539" end_char="3552">principalmente</TOKEN>
				<TOKEN id="token-28-25" start_char="3554" end_char="3555">se</TOKEN>
				<TOKEN id="token-28-26" start_char="3557" end_char="3564">acumulan</TOKEN>
				<TOKEN id="token-28-27" start_char="3566" end_char="3574">bacterias</TOKEN>
				<TOKEN id="token-28-28" start_char="3576" end_char="3583">nuestras</TOKEN>
				<TOKEN id="token-28-29" start_char="3585" end_char="3586">de</TOKEN>
				<TOKEN id="token-28-30" start_char="3588" end_char="3589">la</TOKEN>
				<TOKEN id="token-28-31" start_char="3591" end_char="3594">piel</TOKEN>
				<TOKEN id="token-28-32" start_char="3596" end_char="3596">y</TOKEN>
				<TOKEN id="token-28-33" start_char="3598" end_char="3599">de</TOKEN>
				<TOKEN id="token-28-34" start_char="3601" end_char="3602">la</TOKEN>
				<TOKEN id="token-28-35" start_char="3604" end_char="3607">boca</TOKEN>
				<TOKEN id="token-28-36" start_char="3609" end_char="3611">que</TOKEN>
				<TOKEN id="token-28-37" start_char="3613" end_char="3613">“</TOKEN>
				<TOKEN id="token-28-38" start_char="3614" end_char="3616">son</TOKEN>
				<TOKEN id="token-28-39" start_char="3618" end_char="3624">inocuas</TOKEN>
				<TOKEN id="token-28-40" start_char="3625" end_char="3626">”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-29" start_char="3628" end_char="3748">
				<ORIGINAL_TEXT>“Una mascarilla reutilizada pierde la capacidad filtrante, ese es su peor peligro para el que la usa (y para los demás)”.</ORIGINAL_TEXT>
				<TOKEN id="token-29-0" start_char="3628" end_char="3628">“</TOKEN>
				<TOKEN id="token-29-1" start_char="3629" end_char="3631">Una</TOKEN>
				<TOKEN id="token-29-2" start_char="3633" end_char="3642">mascarilla</TOKEN>
				<TOKEN id="token-29-3" start_char="3644" end_char="3654">reutilizada</TOKEN>
				<TOKEN id="token-29-4" start_char="3656" end_char="3661">pierde</TOKEN>
				<TOKEN id="token-29-5" start_char="3663" end_char="3664">la</TOKEN>
				<TOKEN id="token-29-6" start_char="3666" end_char="3674">capacidad</TOKEN>
				<TOKEN id="token-29-7" start_char="3676" end_char="3684">filtrante</TOKEN>
				<TOKEN id="token-29-8" start_char="3685" end_char="3685">,</TOKEN>
				<TOKEN id="token-29-9" start_char="3687" end_char="3689">ese</TOKEN>
				<TOKEN id="token-29-10" start_char="3691" end_char="3692">es</TOKEN>
				<TOKEN id="token-29-11" start_char="3694" end_char="3695">su</TOKEN>
				<TOKEN id="token-29-12" start_char="3697" end_char="3700">peor</TOKEN>
				<TOKEN id="token-29-13" start_char="3702" end_char="3708">peligro</TOKEN>
				<TOKEN id="token-29-14" start_char="3710" end_char="3713">para</TOKEN>
				<TOKEN id="token-29-15" start_char="3715" end_char="3716">el</TOKEN>
				<TOKEN id="token-29-16" start_char="3718" end_char="3720">que</TOKEN>
				<TOKEN id="token-29-17" start_char="3722" end_char="3723">la</TOKEN>
				<TOKEN id="token-29-18" start_char="3725" end_char="3727">usa</TOKEN>
				<TOKEN id="token-29-19" start_char="3729" end_char="3729">(</TOKEN>
				<TOKEN id="token-29-20" start_char="3730" end_char="3730">y</TOKEN>
				<TOKEN id="token-29-21" start_char="3732" end_char="3735">para</TOKEN>
				<TOKEN id="token-29-22" start_char="3737" end_char="3739">los</TOKEN>
				<TOKEN id="token-29-23" start_char="3741" end_char="3745">demás</TOKEN>
				<TOKEN id="token-29-24" start_char="3746" end_char="3748">)”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-30" start_char="3750" end_char="3883">
				<ORIGINAL_TEXT>Sí que se puede correr el riesgo de contagiarse y padecer la COVID-19 si no se usa la mascarilla de manera adecuada, según la experta.</ORIGINAL_TEXT>
				<TOKEN id="token-30-0" start_char="3750" end_char="3751">Sí</TOKEN>
				<TOKEN id="token-30-1" start_char="3753" end_char="3755">que</TOKEN>
				<TOKEN id="token-30-2" start_char="3757" end_char="3758">se</TOKEN>
				<TOKEN id="token-30-3" start_char="3760" end_char="3764">puede</TOKEN>
				<TOKEN id="token-30-4" start_char="3766" end_char="3771">correr</TOKEN>
				<TOKEN id="token-30-5" start_char="3773" end_char="3774">el</TOKEN>
				<TOKEN id="token-30-6" start_char="3776" end_char="3781">riesgo</TOKEN>
				<TOKEN id="token-30-7" start_char="3783" end_char="3784">de</TOKEN>
				<TOKEN id="token-30-8" start_char="3786" end_char="3796">contagiarse</TOKEN>
				<TOKEN id="token-30-9" start_char="3798" end_char="3798">y</TOKEN>
				<TOKEN id="token-30-10" start_char="3800" end_char="3806">padecer</TOKEN>
				<TOKEN id="token-30-11" start_char="3808" end_char="3809">la</TOKEN>
				<TOKEN id="token-30-12" start_char="3811" end_char="3815">COVID</TOKEN>
				<TOKEN id="token-30-13" start_char="3816" end_char="3816">-</TOKEN>
				<TOKEN id="token-30-14" start_char="3817" end_char="3818">19</TOKEN>
				<TOKEN id="token-30-15" start_char="3820" end_char="3821">si</TOKEN>
				<TOKEN id="token-30-16" start_char="3823" end_char="3824">no</TOKEN>
				<TOKEN id="token-30-17" start_char="3826" end_char="3827">se</TOKEN>
				<TOKEN id="token-30-18" start_char="3829" end_char="3831">usa</TOKEN>
				<TOKEN id="token-30-19" start_char="3833" end_char="3834">la</TOKEN>
				<TOKEN id="token-30-20" start_char="3836" end_char="3845">mascarilla</TOKEN>
				<TOKEN id="token-30-21" start_char="3847" end_char="3848">de</TOKEN>
				<TOKEN id="token-30-22" start_char="3850" end_char="3855">manera</TOKEN>
				<TOKEN id="token-30-23" start_char="3857" end_char="3864">adecuada</TOKEN>
				<TOKEN id="token-30-24" start_char="3865" end_char="3865">,</TOKEN>
				<TOKEN id="token-30-25" start_char="3867" end_char="3871">según</TOKEN>
				<TOKEN id="token-30-26" start_char="3873" end_char="3874">la</TOKEN>
				<TOKEN id="token-30-27" start_char="3876" end_char="3882">experta</TOKEN>
				<TOKEN id="token-30-28" start_char="3883" end_char="3883">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-31" start_char="3885" end_char="3930">
				<ORIGINAL_TEXT>Por ejemplo, si la tocamos o la guardamos mal.</ORIGINAL_TEXT>
				<TOKEN id="token-31-0" start_char="3885" end_char="3887">Por</TOKEN>
				<TOKEN id="token-31-1" start_char="3889" end_char="3895">ejemplo</TOKEN>
				<TOKEN id="token-31-2" start_char="3896" end_char="3896">,</TOKEN>
				<TOKEN id="token-31-3" start_char="3898" end_char="3899">si</TOKEN>
				<TOKEN id="token-31-4" start_char="3901" end_char="3902">la</TOKEN>
				<TOKEN id="token-31-5" start_char="3904" end_char="3910">tocamos</TOKEN>
				<TOKEN id="token-31-6" start_char="3912" end_char="3912">o</TOKEN>
				<TOKEN id="token-31-7" start_char="3914" end_char="3915">la</TOKEN>
				<TOKEN id="token-31-8" start_char="3917" end_char="3925">guardamos</TOKEN>
				<TOKEN id="token-31-9" start_char="3927" end_char="3929">mal</TOKEN>
				<TOKEN id="token-31-10" start_char="3930" end_char="3930">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-32" start_char="3932" end_char="4064">
				<ORIGINAL_TEXT>Aquí ya os explicamos cuál es la manera idónea de guardar la mascarilla (en un sobre de papel, una tela o un estuche de gafas viejo).</ORIGINAL_TEXT>
				<TOKEN id="token-32-0" start_char="3932" end_char="3935">Aquí</TOKEN>
				<TOKEN id="token-32-1" start_char="3937" end_char="3938">ya</TOKEN>
				<TOKEN id="token-32-2" start_char="3940" end_char="3941">os</TOKEN>
				<TOKEN id="token-32-3" start_char="3943" end_char="3952">explicamos</TOKEN>
				<TOKEN id="token-32-4" start_char="3954" end_char="3957">cuál</TOKEN>
				<TOKEN id="token-32-5" start_char="3959" end_char="3960">es</TOKEN>
				<TOKEN id="token-32-6" start_char="3962" end_char="3963">la</TOKEN>
				<TOKEN id="token-32-7" start_char="3965" end_char="3970">manera</TOKEN>
				<TOKEN id="token-32-8" start_char="3972" end_char="3977">idónea</TOKEN>
				<TOKEN id="token-32-9" start_char="3979" end_char="3980">de</TOKEN>
				<TOKEN id="token-32-10" start_char="3982" end_char="3988">guardar</TOKEN>
				<TOKEN id="token-32-11" start_char="3990" end_char="3991">la</TOKEN>
				<TOKEN id="token-32-12" start_char="3993" end_char="4002">mascarilla</TOKEN>
				<TOKEN id="token-32-13" start_char="4004" end_char="4004">(</TOKEN>
				<TOKEN id="token-32-14" start_char="4005" end_char="4006">en</TOKEN>
				<TOKEN id="token-32-15" start_char="4008" end_char="4009">un</TOKEN>
				<TOKEN id="token-32-16" start_char="4011" end_char="4015">sobre</TOKEN>
				<TOKEN id="token-32-17" start_char="4017" end_char="4018">de</TOKEN>
				<TOKEN id="token-32-18" start_char="4020" end_char="4024">papel</TOKEN>
				<TOKEN id="token-32-19" start_char="4025" end_char="4025">,</TOKEN>
				<TOKEN id="token-32-20" start_char="4027" end_char="4029">una</TOKEN>
				<TOKEN id="token-32-21" start_char="4031" end_char="4034">tela</TOKEN>
				<TOKEN id="token-32-22" start_char="4036" end_char="4036">o</TOKEN>
				<TOKEN id="token-32-23" start_char="4038" end_char="4039">un</TOKEN>
				<TOKEN id="token-32-24" start_char="4041" end_char="4047">estuche</TOKEN>
				<TOKEN id="token-32-25" start_char="4049" end_char="4050">de</TOKEN>
				<TOKEN id="token-32-26" start_char="4052" end_char="4056">gafas</TOKEN>
				<TOKEN id="token-32-27" start_char="4058" end_char="4062">viejo</TOKEN>
				<TOKEN id="token-32-28" start_char="4063" end_char="4064">).</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-33" start_char="4066" end_char="4284">
				<ORIGINAL_TEXT>En la misma línea se posiciona Víctor Jiménez Cid, catedrático de Microbiología de la Universidad Complutense de Madrid y miembro de la Sociedad Española de Microbiología, que compara la mascarilla con la ropa interior.</ORIGINAL_TEXT>
				<TOKEN id="token-33-0" start_char="4066" end_char="4067">En</TOKEN>
				<TOKEN id="token-33-1" start_char="4069" end_char="4070">la</TOKEN>
				<TOKEN id="token-33-2" start_char="4072" end_char="4076">misma</TOKEN>
				<TOKEN id="token-33-3" start_char="4078" end_char="4082">línea</TOKEN>
				<TOKEN id="token-33-4" start_char="4084" end_char="4085">se</TOKEN>
				<TOKEN id="token-33-5" start_char="4087" end_char="4095">posiciona</TOKEN>
				<TOKEN id="token-33-6" start_char="4097" end_char="4102">Víctor</TOKEN>
				<TOKEN id="token-33-7" start_char="4104" end_char="4110">Jiménez</TOKEN>
				<TOKEN id="token-33-8" start_char="4112" end_char="4114">Cid</TOKEN>
				<TOKEN id="token-33-9" start_char="4115" end_char="4115">,</TOKEN>
				<TOKEN id="token-33-10" start_char="4117" end_char="4127">catedrático</TOKEN>
				<TOKEN id="token-33-11" start_char="4129" end_char="4130">de</TOKEN>
				<TOKEN id="token-33-12" start_char="4132" end_char="4144">Microbiología</TOKEN>
				<TOKEN id="token-33-13" start_char="4146" end_char="4147">de</TOKEN>
				<TOKEN id="token-33-14" start_char="4149" end_char="4150">la</TOKEN>
				<TOKEN id="token-33-15" start_char="4152" end_char="4162">Universidad</TOKEN>
				<TOKEN id="token-33-16" start_char="4164" end_char="4174">Complutense</TOKEN>
				<TOKEN id="token-33-17" start_char="4176" end_char="4177">de</TOKEN>
				<TOKEN id="token-33-18" start_char="4179" end_char="4184">Madrid</TOKEN>
				<TOKEN id="token-33-19" start_char="4186" end_char="4186">y</TOKEN>
				<TOKEN id="token-33-20" start_char="4188" end_char="4194">miembro</TOKEN>
				<TOKEN id="token-33-21" start_char="4196" end_char="4197">de</TOKEN>
				<TOKEN id="token-33-22" start_char="4199" end_char="4200">la</TOKEN>
				<TOKEN id="token-33-23" start_char="4202" end_char="4209">Sociedad</TOKEN>
				<TOKEN id="token-33-24" start_char="4211" end_char="4218">Española</TOKEN>
				<TOKEN id="token-33-25" start_char="4220" end_char="4221">de</TOKEN>
				<TOKEN id="token-33-26" start_char="4223" end_char="4235">Microbiología</TOKEN>
				<TOKEN id="token-33-27" start_char="4236" end_char="4236">,</TOKEN>
				<TOKEN id="token-33-28" start_char="4238" end_char="4240">que</TOKEN>
				<TOKEN id="token-33-29" start_char="4242" end_char="4248">compara</TOKEN>
				<TOKEN id="token-33-30" start_char="4250" end_char="4251">la</TOKEN>
				<TOKEN id="token-33-31" start_char="4253" end_char="4262">mascarilla</TOKEN>
				<TOKEN id="token-33-32" start_char="4264" end_char="4266">con</TOKEN>
				<TOKEN id="token-33-33" start_char="4268" end_char="4269">la</TOKEN>
				<TOKEN id="token-33-34" start_char="4271" end_char="4274">ropa</TOKEN>
				<TOKEN id="token-33-35" start_char="4276" end_char="4283">interior</TOKEN>
				<TOKEN id="token-33-36" start_char="4284" end_char="4284">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-34" start_char="4286" end_char="4469">
				<ORIGINAL_TEXT>“En su cara interna va a acumular tras su uso todo tipo de microorganismos procedentes de la microbiota de la piel y mucosas y, por la cara externa, microorganismos del medio ambiente.</ORIGINAL_TEXT>
				<TOKEN id="token-34-0" start_char="4286" end_char="4286">“</TOKEN>
				<TOKEN id="token-34-1" start_char="4287" end_char="4288">En</TOKEN>
				<TOKEN id="token-34-2" start_char="4290" end_char="4291">su</TOKEN>
				<TOKEN id="token-34-3" start_char="4293" end_char="4296">cara</TOKEN>
				<TOKEN id="token-34-4" start_char="4298" end_char="4304">interna</TOKEN>
				<TOKEN id="token-34-5" start_char="4306" end_char="4307">va</TOKEN>
				<TOKEN id="token-34-6" start_char="4309" end_char="4309">a</TOKEN>
				<TOKEN id="token-34-7" start_char="4311" end_char="4318">acumular</TOKEN>
				<TOKEN id="token-34-8" start_char="4320" end_char="4323">tras</TOKEN>
				<TOKEN id="token-34-9" start_char="4325" end_char="4326">su</TOKEN>
				<TOKEN id="token-34-10" start_char="4328" end_char="4330">uso</TOKEN>
				<TOKEN id="token-34-11" start_char="4332" end_char="4335">todo</TOKEN>
				<TOKEN id="token-34-12" start_char="4337" end_char="4340">tipo</TOKEN>
				<TOKEN id="token-34-13" start_char="4342" end_char="4343">de</TOKEN>
				<TOKEN id="token-34-14" start_char="4345" end_char="4359">microorganismos</TOKEN>
				<TOKEN id="token-34-15" start_char="4361" end_char="4371">procedentes</TOKEN>
				<TOKEN id="token-34-16" start_char="4373" end_char="4374">de</TOKEN>
				<TOKEN id="token-34-17" start_char="4376" end_char="4377">la</TOKEN>
				<TOKEN id="token-34-18" start_char="4379" end_char="4388">microbiota</TOKEN>
				<TOKEN id="token-34-19" start_char="4390" end_char="4391">de</TOKEN>
				<TOKEN id="token-34-20" start_char="4393" end_char="4394">la</TOKEN>
				<TOKEN id="token-34-21" start_char="4396" end_char="4399">piel</TOKEN>
				<TOKEN id="token-34-22" start_char="4401" end_char="4401">y</TOKEN>
				<TOKEN id="token-34-23" start_char="4403" end_char="4409">mucosas</TOKEN>
				<TOKEN id="token-34-24" start_char="4411" end_char="4411">y</TOKEN>
				<TOKEN id="token-34-25" start_char="4412" end_char="4412">,</TOKEN>
				<TOKEN id="token-34-26" start_char="4414" end_char="4416">por</TOKEN>
				<TOKEN id="token-34-27" start_char="4418" end_char="4419">la</TOKEN>
				<TOKEN id="token-34-28" start_char="4421" end_char="4424">cara</TOKEN>
				<TOKEN id="token-34-29" start_char="4426" end_char="4432">externa</TOKEN>
				<TOKEN id="token-34-30" start_char="4433" end_char="4433">,</TOKEN>
				<TOKEN id="token-34-31" start_char="4435" end_char="4449">microorganismos</TOKEN>
				<TOKEN id="token-34-32" start_char="4451" end_char="4453">del</TOKEN>
				<TOKEN id="token-34-33" start_char="4455" end_char="4459">medio</TOKEN>
				<TOKEN id="token-34-34" start_char="4461" end_char="4468">ambiente</TOKEN>
				<TOKEN id="token-34-35" start_char="4469" end_char="4469">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-35" start_char="4471" end_char="4673">
				<ORIGINAL_TEXT>Los primeros no suponen ningún peligro para el usuario y los segundos, con las debidas medidas de higiene, tampoco (de hecho las mascarilla está protegiéndonos frente a ellos)”, afirma a Maldita Ciencia.</ORIGINAL_TEXT>
				<TOKEN id="token-35-0" start_char="4471" end_char="4473">Los</TOKEN>
				<TOKEN id="token-35-1" start_char="4475" end_char="4482">primeros</TOKEN>
				<TOKEN id="token-35-2" start_char="4484" end_char="4485">no</TOKEN>
				<TOKEN id="token-35-3" start_char="4487" end_char="4493">suponen</TOKEN>
				<TOKEN id="token-35-4" start_char="4495" end_char="4500">ningún</TOKEN>
				<TOKEN id="token-35-5" start_char="4502" end_char="4508">peligro</TOKEN>
				<TOKEN id="token-35-6" start_char="4510" end_char="4513">para</TOKEN>
				<TOKEN id="token-35-7" start_char="4515" end_char="4516">el</TOKEN>
				<TOKEN id="token-35-8" start_char="4518" end_char="4524">usuario</TOKEN>
				<TOKEN id="token-35-9" start_char="4526" end_char="4526">y</TOKEN>
				<TOKEN id="token-35-10" start_char="4528" end_char="4530">los</TOKEN>
				<TOKEN id="token-35-11" start_char="4532" end_char="4539">segundos</TOKEN>
				<TOKEN id="token-35-12" start_char="4540" end_char="4540">,</TOKEN>
				<TOKEN id="token-35-13" start_char="4542" end_char="4544">con</TOKEN>
				<TOKEN id="token-35-14" start_char="4546" end_char="4548">las</TOKEN>
				<TOKEN id="token-35-15" start_char="4550" end_char="4556">debidas</TOKEN>
				<TOKEN id="token-35-16" start_char="4558" end_char="4564">medidas</TOKEN>
				<TOKEN id="token-35-17" start_char="4566" end_char="4567">de</TOKEN>
				<TOKEN id="token-35-18" start_char="4569" end_char="4575">higiene</TOKEN>
				<TOKEN id="token-35-19" start_char="4576" end_char="4576">,</TOKEN>
				<TOKEN id="token-35-20" start_char="4578" end_char="4584">tampoco</TOKEN>
				<TOKEN id="token-35-21" start_char="4586" end_char="4586">(</TOKEN>
				<TOKEN id="token-35-22" start_char="4587" end_char="4588">de</TOKEN>
				<TOKEN id="token-35-23" start_char="4590" end_char="4594">hecho</TOKEN>
				<TOKEN id="token-35-24" start_char="4596" end_char="4598">las</TOKEN>
				<TOKEN id="token-35-25" start_char="4600" end_char="4609">mascarilla</TOKEN>
				<TOKEN id="token-35-26" start_char="4611" end_char="4614">está</TOKEN>
				<TOKEN id="token-35-27" start_char="4616" end_char="4629">protegiéndonos</TOKEN>
				<TOKEN id="token-35-28" start_char="4631" end_char="4636">frente</TOKEN>
				<TOKEN id="token-35-29" start_char="4638" end_char="4638">a</TOKEN>
				<TOKEN id="token-35-30" start_char="4640" end_char="4644">ellos</TOKEN>
				<TOKEN id="token-35-31" start_char="4645" end_char="4647">)”,</TOKEN>
				<TOKEN id="token-35-32" start_char="4649" end_char="4654">afirma</TOKEN>
				<TOKEN id="token-35-33" start_char="4656" end_char="4656">a</TOKEN>
				<TOKEN id="token-35-34" start_char="4658" end_char="4664">Maldita</TOKEN>
				<TOKEN id="token-35-35" start_char="4666" end_char="4672">Ciencia</TOKEN>
				<TOKEN id="token-35-36" start_char="4673" end_char="4673">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-36" start_char="4675" end_char="4926">
				<ORIGINAL_TEXT>Juan Sabatté, médico y doctor en microbiología e investigador del Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET) de Argentina, explica que retener algunos de los gérmenes que exhalamos es justamente la utilidad de las mascarillas.</ORIGINAL_TEXT>
				<TOKEN id="token-36-0" start_char="4675" end_char="4678">Juan</TOKEN>
				<TOKEN id="token-36-1" start_char="4680" end_char="4686">Sabatté</TOKEN>
				<TOKEN id="token-36-2" start_char="4687" end_char="4687">,</TOKEN>
				<TOKEN id="token-36-3" start_char="4689" end_char="4694">médico</TOKEN>
				<TOKEN id="token-36-4" start_char="4696" end_char="4696">y</TOKEN>
				<TOKEN id="token-36-5" start_char="4698" end_char="4703">doctor</TOKEN>
				<TOKEN id="token-36-6" start_char="4705" end_char="4706">en</TOKEN>
				<TOKEN id="token-36-7" start_char="4708" end_char="4720">microbiología</TOKEN>
				<TOKEN id="token-36-8" start_char="4722" end_char="4722">e</TOKEN>
				<TOKEN id="token-36-9" start_char="4724" end_char="4735">investigador</TOKEN>
				<TOKEN id="token-36-10" start_char="4737" end_char="4739">del</TOKEN>
				<TOKEN id="token-36-11" start_char="4741" end_char="4747">Consejo</TOKEN>
				<TOKEN id="token-36-12" start_char="4749" end_char="4756">Nacional</TOKEN>
				<TOKEN id="token-36-13" start_char="4758" end_char="4759">de</TOKEN>
				<TOKEN id="token-36-14" start_char="4761" end_char="4775">Investigaciones</TOKEN>
				<TOKEN id="token-36-15" start_char="4777" end_char="4787">Científicas</TOKEN>
				<TOKEN id="token-36-16" start_char="4789" end_char="4789">y</TOKEN>
				<TOKEN id="token-36-17" start_char="4791" end_char="4798">Técnicas</TOKEN>
				<TOKEN id="token-36-18" start_char="4800" end_char="4800">(</TOKEN>
				<TOKEN id="token-36-19" start_char="4801" end_char="4807">CONICET</TOKEN>
				<TOKEN id="token-36-20" start_char="4808" end_char="4808">)</TOKEN>
				<TOKEN id="token-36-21" start_char="4810" end_char="4811">de</TOKEN>
				<TOKEN id="token-36-22" start_char="4813" end_char="4821">Argentina</TOKEN>
				<TOKEN id="token-36-23" start_char="4822" end_char="4822">,</TOKEN>
				<TOKEN id="token-36-24" start_char="4824" end_char="4830">explica</TOKEN>
				<TOKEN id="token-36-25" start_char="4832" end_char="4834">que</TOKEN>
				<TOKEN id="token-36-26" start_char="4836" end_char="4842">retener</TOKEN>
				<TOKEN id="token-36-27" start_char="4844" end_char="4850">algunos</TOKEN>
				<TOKEN id="token-36-28" start_char="4852" end_char="4853">de</TOKEN>
				<TOKEN id="token-36-29" start_char="4855" end_char="4857">los</TOKEN>
				<TOKEN id="token-36-30" start_char="4859" end_char="4866">gérmenes</TOKEN>
				<TOKEN id="token-36-31" start_char="4868" end_char="4870">que</TOKEN>
				<TOKEN id="token-36-32" start_char="4872" end_char="4880">exhalamos</TOKEN>
				<TOKEN id="token-36-33" start_char="4882" end_char="4883">es</TOKEN>
				<TOKEN id="token-36-34" start_char="4885" end_char="4894">justamente</TOKEN>
				<TOKEN id="token-36-35" start_char="4896" end_char="4897">la</TOKEN>
				<TOKEN id="token-36-36" start_char="4899" end_char="4906">utilidad</TOKEN>
				<TOKEN id="token-36-37" start_char="4908" end_char="4909">de</TOKEN>
				<TOKEN id="token-36-38" start_char="4911" end_char="4913">las</TOKEN>
				<TOKEN id="token-36-39" start_char="4915" end_char="4925">mascarillas</TOKEN>
				<TOKEN id="token-36-40" start_char="4926" end_char="4926">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-37" start_char="4928" end_char="5049">
				<ORIGINAL_TEXT>“No dejar pasar gérmenes o al menos disminuir notablemente su paso”, cuenta a AFP, medio que ha desmentido la información.</ORIGINAL_TEXT>
				<TOKEN id="token-37-0" start_char="4928" end_char="4928">“</TOKEN>
				<TOKEN id="token-37-1" start_char="4929" end_char="4930">No</TOKEN>
				<TOKEN id="token-37-2" start_char="4932" end_char="4936">dejar</TOKEN>
				<TOKEN id="token-37-3" start_char="4938" end_char="4942">pasar</TOKEN>
				<TOKEN id="token-37-4" start_char="4944" end_char="4951">gérmenes</TOKEN>
				<TOKEN id="token-37-5" start_char="4953" end_char="4953">o</TOKEN>
				<TOKEN id="token-37-6" start_char="4955" end_char="4956">al</TOKEN>
				<TOKEN id="token-37-7" start_char="4958" end_char="4962">menos</TOKEN>
				<TOKEN id="token-37-8" start_char="4964" end_char="4972">disminuir</TOKEN>
				<TOKEN id="token-37-9" start_char="4974" end_char="4985">notablemente</TOKEN>
				<TOKEN id="token-37-10" start_char="4987" end_char="4988">su</TOKEN>
				<TOKEN id="token-37-11" start_char="4990" end_char="4993">paso</TOKEN>
				<TOKEN id="token-37-12" start_char="4994" end_char="4995">”,</TOKEN>
				<TOKEN id="token-37-13" start_char="4997" end_char="5002">cuenta</TOKEN>
				<TOKEN id="token-37-14" start_char="5004" end_char="5004">a</TOKEN>
				<TOKEN id="token-37-15" start_char="5006" end_char="5008">AFP</TOKEN>
				<TOKEN id="token-37-16" start_char="5009" end_char="5009">,</TOKEN>
				<TOKEN id="token-37-17" start_char="5011" end_char="5015">medio</TOKEN>
				<TOKEN id="token-37-18" start_char="5017" end_char="5019">que</TOKEN>
				<TOKEN id="token-37-19" start_char="5021" end_char="5022">ha</TOKEN>
				<TOKEN id="token-37-20" start_char="5024" end_char="5033">desmentido</TOKEN>
				<TOKEN id="token-37-21" start_char="5035" end_char="5036">la</TOKEN>
				<TOKEN id="token-37-22" start_char="5038" end_char="5048">información</TOKEN>
				<TOKEN id="token-37-23" start_char="5049" end_char="5049">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-38" start_char="5051" end_char="5245">
				<ORIGINAL_TEXT>Explica que esto no tiene consecuencias negativas para la salud y que la posibilidad de que los microorganismos atrapados en la mascarilla reingresen al cuerpo “no ha sido debidamente estudiada”.</ORIGINAL_TEXT>
				<TOKEN id="token-38-0" start_char="5051" end_char="5057">Explica</TOKEN>
				<TOKEN id="token-38-1" start_char="5059" end_char="5061">que</TOKEN>
				<TOKEN id="token-38-2" start_char="5063" end_char="5066">esto</TOKEN>
				<TOKEN id="token-38-3" start_char="5068" end_char="5069">no</TOKEN>
				<TOKEN id="token-38-4" start_char="5071" end_char="5075">tiene</TOKEN>
				<TOKEN id="token-38-5" start_char="5077" end_char="5089">consecuencias</TOKEN>
				<TOKEN id="token-38-6" start_char="5091" end_char="5099">negativas</TOKEN>
				<TOKEN id="token-38-7" start_char="5101" end_char="5104">para</TOKEN>
				<TOKEN id="token-38-8" start_char="5106" end_char="5107">la</TOKEN>
				<TOKEN id="token-38-9" start_char="5109" end_char="5113">salud</TOKEN>
				<TOKEN id="token-38-10" start_char="5115" end_char="5115">y</TOKEN>
				<TOKEN id="token-38-11" start_char="5117" end_char="5119">que</TOKEN>
				<TOKEN id="token-38-12" start_char="5121" end_char="5122">la</TOKEN>
				<TOKEN id="token-38-13" start_char="5124" end_char="5134">posibilidad</TOKEN>
				<TOKEN id="token-38-14" start_char="5136" end_char="5137">de</TOKEN>
				<TOKEN id="token-38-15" start_char="5139" end_char="5141">que</TOKEN>
				<TOKEN id="token-38-16" start_char="5143" end_char="5145">los</TOKEN>
				<TOKEN id="token-38-17" start_char="5147" end_char="5161">microorganismos</TOKEN>
				<TOKEN id="token-38-18" start_char="5163" end_char="5171">atrapados</TOKEN>
				<TOKEN id="token-38-19" start_char="5173" end_char="5174">en</TOKEN>
				<TOKEN id="token-38-20" start_char="5176" end_char="5177">la</TOKEN>
				<TOKEN id="token-38-21" start_char="5179" end_char="5188">mascarilla</TOKEN>
				<TOKEN id="token-38-22" start_char="5190" end_char="5199">reingresen</TOKEN>
				<TOKEN id="token-38-23" start_char="5201" end_char="5202">al</TOKEN>
				<TOKEN id="token-38-24" start_char="5204" end_char="5209">cuerpo</TOKEN>
				<TOKEN id="token-38-25" start_char="5211" end_char="5211">“</TOKEN>
				<TOKEN id="token-38-26" start_char="5212" end_char="5213">no</TOKEN>
				<TOKEN id="token-38-27" start_char="5215" end_char="5216">ha</TOKEN>
				<TOKEN id="token-38-28" start_char="5218" end_char="5221">sido</TOKEN>
				<TOKEN id="token-38-29" start_char="5223" end_char="5233">debidamente</TOKEN>
				<TOKEN id="token-38-30" start_char="5235" end_char="5243">estudiada</TOKEN>
				<TOKEN id="token-38-31" start_char="5244" end_char="5245">”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-39" start_char="5247" end_char="5435">
				<ORIGINAL_TEXT>Aunque así fuera, considera que esto no tendría gran relevancia: “Esos gérmenes ya están en nuestro tracto respiratorio y la exhalación de ninguna manera los elimina en forma considerable”.</ORIGINAL_TEXT>
				<TOKEN id="token-39-0" start_char="5247" end_char="5252">Aunque</TOKEN>
				<TOKEN id="token-39-1" start_char="5254" end_char="5256">así</TOKEN>
				<TOKEN id="token-39-2" start_char="5258" end_char="5262">fuera</TOKEN>
				<TOKEN id="token-39-3" start_char="5263" end_char="5263">,</TOKEN>
				<TOKEN id="token-39-4" start_char="5265" end_char="5273">considera</TOKEN>
				<TOKEN id="token-39-5" start_char="5275" end_char="5277">que</TOKEN>
				<TOKEN id="token-39-6" start_char="5279" end_char="5282">esto</TOKEN>
				<TOKEN id="token-39-7" start_char="5284" end_char="5285">no</TOKEN>
				<TOKEN id="token-39-8" start_char="5287" end_char="5293">tendría</TOKEN>
				<TOKEN id="token-39-9" start_char="5295" end_char="5298">gran</TOKEN>
				<TOKEN id="token-39-10" start_char="5300" end_char="5309">relevancia</TOKEN>
				<TOKEN id="token-39-11" start_char="5310" end_char="5310">:</TOKEN>
				<TOKEN id="token-39-12" start_char="5312" end_char="5312">“</TOKEN>
				<TOKEN id="token-39-13" start_char="5313" end_char="5316">Esos</TOKEN>
				<TOKEN id="token-39-14" start_char="5318" end_char="5325">gérmenes</TOKEN>
				<TOKEN id="token-39-15" start_char="5327" end_char="5328">ya</TOKEN>
				<TOKEN id="token-39-16" start_char="5330" end_char="5334">están</TOKEN>
				<TOKEN id="token-39-17" start_char="5336" end_char="5337">en</TOKEN>
				<TOKEN id="token-39-18" start_char="5339" end_char="5345">nuestro</TOKEN>
				<TOKEN id="token-39-19" start_char="5347" end_char="5352">tracto</TOKEN>
				<TOKEN id="token-39-20" start_char="5354" end_char="5365">respiratorio</TOKEN>
				<TOKEN id="token-39-21" start_char="5367" end_char="5367">y</TOKEN>
				<TOKEN id="token-39-22" start_char="5369" end_char="5370">la</TOKEN>
				<TOKEN id="token-39-23" start_char="5372" end_char="5381">exhalación</TOKEN>
				<TOKEN id="token-39-24" start_char="5383" end_char="5384">de</TOKEN>
				<TOKEN id="token-39-25" start_char="5386" end_char="5392">ninguna</TOKEN>
				<TOKEN id="token-39-26" start_char="5394" end_char="5399">manera</TOKEN>
				<TOKEN id="token-39-27" start_char="5401" end_char="5403">los</TOKEN>
				<TOKEN id="token-39-28" start_char="5405" end_char="5411">elimina</TOKEN>
				<TOKEN id="token-39-29" start_char="5413" end_char="5414">en</TOKEN>
				<TOKEN id="token-39-30" start_char="5416" end_char="5420">forma</TOKEN>
				<TOKEN id="token-39-31" start_char="5422" end_char="5433">considerable</TOKEN>
				<TOKEN id="token-39-32" start_char="5434" end_char="5435">”.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-40" start_char="5437" end_char="5490">
				<ORIGINAL_TEXT>Primera fecha de publicación del artículo: 21/08/2020.</ORIGINAL_TEXT>
				<TOKEN id="token-40-0" start_char="5437" end_char="5443">Primera</TOKEN>
				<TOKEN id="token-40-1" start_char="5445" end_char="5449">fecha</TOKEN>
				<TOKEN id="token-40-2" start_char="5451" end_char="5452">de</TOKEN>
				<TOKEN id="token-40-3" start_char="5454" end_char="5464">publicación</TOKEN>
				<TOKEN id="token-40-4" start_char="5466" end_char="5468">del</TOKEN>
				<TOKEN id="token-40-5" start_char="5470" end_char="5477">artículo</TOKEN>
				<TOKEN id="token-40-6" start_char="5478" end_char="5478">:</TOKEN>
				<TOKEN id="token-40-7" start_char="5480" end_char="5481">21</TOKEN>
				<TOKEN id="token-40-8" start_char="5482" end_char="5482">/</TOKEN>
				<TOKEN id="token-40-9" start_char="5483" end_char="5484">08</TOKEN>
				<TOKEN id="token-40-10" start_char="5485" end_char="5485">/</TOKEN>
				<TOKEN id="token-40-11" start_char="5486" end_char="5489">2020</TOKEN>
				<TOKEN id="token-40-12" start_char="5490" end_char="5490">.</TOKEN>
			</SEG>
			<SEG id="covid19scenario-201-41" start_char="5492" end_char="5548">
				<ORIGINAL_TEXT>Primera fecha de publicación de este artículo: 21/08/2020</ORIGINAL_TEXT>
				<TOKEN id="token-41-0" start_char="5492" end_char="5498">Primera</TOKEN>
				<TOKEN id="token-41-1" start_char="5500" end_char="5504">fecha</TOKEN>
				<TOKEN id="token-41-2" start_char="5506" end_char="5507">de</TOKEN>
				<TOKEN id="token-41-3" start_char="5509" end_char="5519">publicación</TOKEN>
				<TOKEN id="token-41-4" start_char="5521" end_char="5522">de</TOKEN>
				<TOKEN id="token-41-5" start_char="5524" end_char="5527">este</TOKEN>
				<TOKEN id="token-41-6" start_char="5529" end_char="5536">artículo</TOKEN>
				<TOKEN id="token-41-7" start_char="5537" end_char="5537">:</TOKEN>
				<TOKEN id="token-41-8" start_char="5539" end_char="5540">21</TOKEN>
				<TOKEN id="token-41-9" start_char="5541" end_char="5541">/</TOKEN>
				<TOKEN id="token-41-10" start_char="5542" end_char="5543">08</TOKEN>
				<TOKEN id="token-41-11" start_char="5544" end_char="5544">/</TOKEN>
				<TOKEN id="token-41-12" start_char="5545" end_char="5548">2020</TOKEN>
			</SEG>
		</TEXT>
	</DOC>
</LCTL_TEXT>
